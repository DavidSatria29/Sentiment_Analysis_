{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis Based Lexicon And Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Data to 50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the pandas library, which is used for data manipulation and analysis\n",
    "import pandas as pd \n",
    "\n",
    "# Importing the numpy library, which is used for numerical computations and working with arrays\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/csv/Dataset-SA.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_price</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Review</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>5</td>\n",
       "      <td>super!</td>\n",
       "      <td>great cooler excellent air flow and for this p...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>5</td>\n",
       "      <td>awesome</td>\n",
       "      <td>best budget 2 fit cooler nice cooling</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>3</td>\n",
       "      <td>fair</td>\n",
       "      <td>the quality is good but the power of air is de...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>1</td>\n",
       "      <td>useless product</td>\n",
       "      <td>very bad product its a only a fan</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>3</td>\n",
       "      <td>fair</td>\n",
       "      <td>ok ok product</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>5</td>\n",
       "      <td>awesome</td>\n",
       "      <td>the cooler is really fantastic and provides go...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>5</td>\n",
       "      <td>highly recommended</td>\n",
       "      <td>very good product</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>3</td>\n",
       "      <td>nice</td>\n",
       "      <td>very nice</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>1</td>\n",
       "      <td>unsatisfactory</td>\n",
       "      <td>very bad cooler</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Candes 12 L Room/Personal Air Cooler??????(Whi...</td>\n",
       "      <td>3999</td>\n",
       "      <td>4</td>\n",
       "      <td>worth the money</td>\n",
       "      <td>very good</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        product_name product_price Rate  \\\n",
       "0  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    5   \n",
       "1  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    5   \n",
       "2  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    3   \n",
       "3  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    1   \n",
       "4  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    3   \n",
       "5  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    5   \n",
       "6  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    5   \n",
       "7  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    3   \n",
       "8  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    1   \n",
       "9  Candes 12 L Room/Personal Air Cooler??????(Whi...          3999    4   \n",
       "\n",
       "               Review                                            Summary  \\\n",
       "0              super!  great cooler excellent air flow and for this p...   \n",
       "1             awesome              best budget 2 fit cooler nice cooling   \n",
       "2                fair  the quality is good but the power of air is de...   \n",
       "3     useless product                  very bad product its a only a fan   \n",
       "4                fair                                      ok ok product   \n",
       "5             awesome  the cooler is really fantastic and provides go...   \n",
       "6  highly recommended                                  very good product   \n",
       "7                nice                                          very nice   \n",
       "8      unsatisfactory                                    very bad cooler   \n",
       "9     worth the money                                          very good   \n",
       "\n",
       "  Sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4   neutral  \n",
       "5  positive  \n",
       "6  positive  \n",
       "7  positive  \n",
       "8  negative  \n",
       "9  positive  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 10 rows\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 205052 entries, 0 to 205051\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   product_name   205052 non-null  object\n",
      " 1   product_price  205052 non-null  object\n",
      " 2   Rate           205052 non-null  object\n",
      " 3   Review         180388 non-null  object\n",
      " 4   Summary        205041 non-null  object\n",
      " 5   Sentiment      205052 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 205041 entries, 0 to 205051\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   product_name   205041 non-null  object\n",
      " 1   product_price  205041 non-null  object\n",
      " 2   Rate           205041 non-null  object\n",
      " 3   Review         180379 non-null  object\n",
      " 4   Summary        205041 non-null  object\n",
      " 5   Sentiment      205041 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 11.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Function to clean NaN (missing) values from a DataFrame\n",
    "def clean_data(data):\n",
    "    # Drops rows where all values in the 'Summary' column are NaN (missing)\n",
    "    data = data.dropna(subset=['Summary'], how='all')\n",
    "    return data\n",
    "\n",
    "# Applying the clean_data function to the DataFrame 'df'\n",
    "clean_data = clean_data(df)\n",
    "\n",
    "# Displaying information about the cleaned DataFrame (e.g., columns, non-null counts, and data types)\n",
    "clean_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great cooler excellent air flow and for this p...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best budget 2 fit cooler nice cooling</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the quality is good but the power of air is de...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>very bad product its a only a fan</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ok ok product</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the cooler is really fantastic and provides go...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>very good product</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>very nice</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>very bad cooler</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>very good</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Summary Sentiment\n",
       "0  great cooler excellent air flow and for this p...  positive\n",
       "1              best budget 2 fit cooler nice cooling  positive\n",
       "2  the quality is good but the power of air is de...  positive\n",
       "3                  very bad product its a only a fan  negative\n",
       "4                                      ok ok product   neutral\n",
       "5  the cooler is really fantastic and provides go...  positive\n",
       "6                                  very good product  positive\n",
       "7                                          very nice  positive\n",
       "8                                    very bad cooler  negative\n",
       "9                                          very good  positive"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to extract specific columns ('Summary' and 'Sentiment') from a DataFrame\n",
    "def get_summary_sentiment(data):\n",
    "    # Selecting only the 'Summary' and 'Sentiment' columns\n",
    "    data = data[['Summary', 'Sentiment']]\n",
    "    return data\n",
    "\n",
    "# Applying the get_summary_sentiment function to the cleaned DataFrame\n",
    "sentiment_dataset = get_summary_sentiment(clean_data)\n",
    "\n",
    "# Displaying the first 10 rows of the resulting DataFrame\n",
    "sentiment_dataset.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "positive    166575\n",
       "negative     28232\n",
       "neutral      10234\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of occurrences of each sentiment value in the 'Sentiment' column\n",
    "\n",
    "# Number of positive sentiment values (assumes positive is at index 0)\n",
    "positive_count = sentiment_dataset['Sentiment'].value_counts()[0]\n",
    "\n",
    "# Number of negative sentiment values (assumes negative is at index 1)\n",
    "negative_count = sentiment_dataset['Sentiment'].value_counts()[1]\n",
    "\n",
    "# Number of neutral sentiment values (assumes neutral is at index 2)\n",
    "neutral_count = sentiment_dataset['Sentiment'].value_counts()[2]\n",
    "\n",
    "# Calculate the total number of sentiment entries\n",
    "total = positive_count + negative_count + neutral_count\n",
    "\n",
    "# Display the count of each sentiment value\n",
    "sentiment_dataset['Sentiment'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "positive    40620\n",
       "negative     6884\n",
       "neutral      2496\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the proportions of each sentiment in the dataset\n",
    "positive_proportion = positive_count / total  # Proportion of positive sentiment\n",
    "negative_proportion = negative_count / total  # Proportion of negative sentiment\n",
    "neutral_proportion = neutral_count / total    # Proportion of neutral sentiment\n",
    "\n",
    "# Determine the sample size for each sentiment to make the total 50,000 samples\n",
    "count_positive = int(positive_proportion * 50000) + 1  # Adjusted sample size for positive sentiment\n",
    "count_negative = int(negative_proportion * 50000)      # Adjusted sample size for negative sentiment\n",
    "count_neutral = int(neutral_proportion * 50000) + 1    # Adjusted sample size for neutral sentiment\n",
    "\n",
    "# Randomly sample the calculated number of rows for each sentiment\n",
    "# Setting 'random_state=42' ensures reproducibility of the random sampling\n",
    "positive_sample = sentiment_dataset[sentiment_dataset['Sentiment'] == 'positive'].sample(n=count_positive, random_state=42)\n",
    "negative_sample = sentiment_dataset[sentiment_dataset['Sentiment'] == 'negative'].sample(n=count_negative, random_state=42)\n",
    "neutral_sample = sentiment_dataset[sentiment_dataset['Sentiment'] == 'neutral'].sample(n=count_neutral, random_state=42)\n",
    "\n",
    "# Combine the sampled subsets into a single dataset\n",
    "sample_dataset = pd.concat([positive_sample, negative_sample, neutral_sample])\n",
    "\n",
    "# Display the count of each sentiment value in the sampled dataset\n",
    "sample_dataset['Sentiment'].value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset to csv\n",
    "sample_dataset.to_csv('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/csv/flipkart.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Data And Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>backlight effect is amazingkey life up to 10 m...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nice product</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>excellent product</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quality was good</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>very good</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>very good i am satisfied</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>best thanks</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>very nice produce</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dont worry you must buy this product</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Summary Sentiment\n",
       "0  backlight effect is amazingkey life up to 10 m...  positive\n",
       "1                                       nice product  positive\n",
       "2                                               nice  positive\n",
       "3                                  excellent product  positive\n",
       "4                                   quality was good  positive\n",
       "5                                          very good  positive\n",
       "6                           very good i am satisfied  positive\n",
       "7                                        best thanks  positive\n",
       "8                                  very nice produce  positive\n",
       "9               dont worry you must buy this product  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load new dataset\n",
    "dataset = pd.read_csv('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/csv/flipkart.csv')\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Summary    50000 non-null  object\n",
      " 1   Sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for case folding (converting text to lowercase)\n",
    "def case_folding(data):\n",
    "    # Converts all characters in the input text (data) to lowercase\n",
    "    data = data.lower()\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Summary'] = dataset['Summary'].apply(case_folding)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for text processing\n",
    "import re  # Library for regular expression operations\n",
    "import string  # Library for handling string operations\n",
    "\n",
    "# Function for text cleansing to remove special characters, numbers, and unnecessary patterns\n",
    "def cleansing(text):\n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove text enclosed in square brackets (e.g., [example])\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    \n",
    "    # Remove all punctuation characters (e.g., ., ?, !, etc.)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    \n",
    "    # Remove words containing numbers (e.g., \"word123\" or \"123word\")\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    \n",
    "    # Remove specific special characters (e.g., fancy quotes, ellipses)\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    \n",
    "    # Remove newline characters\n",
    "    text = re.sub('\\n', '', text)\n",
    "    \n",
    "    # Return the cleaned text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset['Summary'] = dataset['Summary'].apply(cleansing)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries from the NLTK package\n",
    "from nltk.corpus import stopwords  # To access predefined lists of stop words\n",
    "from nltk.tokenize import word_tokenize  # To tokenize text into individual words\n",
    "\n",
    "# Load the English stop words list\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove stop words from the input text\n",
    "def set_stop_words(text):\n",
    "    # Tokenize the text into individual words\n",
    "    word_tokens = word_tokenize(text)\n",
    "    \n",
    "    # Filter out words that are in the stop words list\n",
    "    text = [word for word in word_tokens if word not in stop_words]\n",
    "    \n",
    "    # Join the filtered words back into a single string\n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    # Return the processed text\n",
    "    return text\n",
    "\n",
    "dataset['Summary'] = dataset['Summary'].apply(set_stop_words)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset to csv\n",
    "dataset.to_csv('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/csv/flipkart_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[backlight, effect, amazingkey, life, millions...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[nice, product]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nice]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[excellent, product]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[quality, good]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[good]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[good, satisfied]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[best, thanks]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[nice, produce]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[dont, worry, must, buy, product]</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Summary Sentiment\n",
       "0  [backlight, effect, amazingkey, life, millions...  positive\n",
       "1                                    [nice, product]  positive\n",
       "2                                             [nice]  positive\n",
       "3                               [excellent, product]  positive\n",
       "4                                    [quality, good]  positive\n",
       "5                                             [good]  positive\n",
       "6                                  [good, satisfied]  positive\n",
       "7                                     [best, thanks]  positive\n",
       "8                                    [nice, produce]  positive\n",
       "9                  [dont, worry, must, buy, product]  positive"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the word_tokenize function from the NLTK library\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Function to perform tokenization on text\n",
    "def tokenization(text):\n",
    "    # Tokenize the input text into individual words\n",
    "    tokenization_word = word_tokenize(text)\n",
    "    return tokenization_word\n",
    "\n",
    "# Apply the tokenization function to the 'Summary' column of the dataset\n",
    "dataset['Summary'] = dataset['Summary'].apply(tokenization)\n",
    "\n",
    "# Display the first 10 rows of the modified dataset\n",
    "dataset.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Sentimen Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[backlight, effect, amazingkey, life, millions...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[nice, product]</td>\n",
       "      <td>positive</td>\n",
       "      <td>[9, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nice]</td>\n",
       "      <td>positive</td>\n",
       "      <td>[9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[excellent, product]</td>\n",
       "      <td>positive</td>\n",
       "      <td>[9, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[quality, good]</td>\n",
       "      <td>positive</td>\n",
       "      <td>[5, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[good]</td>\n",
       "      <td>positive</td>\n",
       "      <td>[9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[good, satisfied]</td>\n",
       "      <td>positive</td>\n",
       "      <td>[9, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[best, thanks]</td>\n",
       "      <td>positive</td>\n",
       "      <td>[9, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[nice, produce]</td>\n",
       "      <td>positive</td>\n",
       "      <td>[9, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[dont, worry, must, buy, product]</td>\n",
       "      <td>positive</td>\n",
       "      <td>[1, 5, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Summary Sentiment  \\\n",
       "0  [backlight, effect, amazingkey, life, millions...  positive   \n",
       "1                                    [nice, product]  positive   \n",
       "2                                             [nice]  positive   \n",
       "3                               [excellent, product]  positive   \n",
       "4                                    [quality, good]  positive   \n",
       "5                                             [good]  positive   \n",
       "6                                  [good, satisfied]  positive   \n",
       "7                                     [best, thanks]  positive   \n",
       "8                                    [nice, produce]  positive   \n",
       "9                  [dont, worry, must, buy, product]  positive   \n",
       "\n",
       "                  Sentiment_Score  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "1                          [9, 1]  \n",
       "2                             [9]  \n",
       "3                          [9, 1]  \n",
       "4                          [5, 9]  \n",
       "5                             [9]  \n",
       "6                          [9, 7]  \n",
       "7                          [9, 3]  \n",
       "8                          [9, 1]  \n",
       "9                 [1, 5, 1, 1, 1]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries from NLTK for sentiment analysis\n",
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn  # To access sentiment scores for words\n",
    "\n",
    "# Function to get sentiment score for a single word based on its part-of-speech tag\n",
    "def get_sentiment_score(word, tag):\n",
    "    wn_tag = None  # Initialize variable for WordNet POS tag\n",
    "    # Determine WordNet POS tag based on the input POS tag\n",
    "    if tag.startswith('J'):  # Adjective\n",
    "        wn_tag = 'a'\n",
    "    elif tag.startswith('N'):  # Noun\n",
    "        wn_tag = 'n'\n",
    "    elif tag.startswith('R'):  # Adverb\n",
    "        wn_tag = 'r'\n",
    "    elif tag.startswith('V'):  # Verb\n",
    "        wn_tag = 'v'\n",
    "    \n",
    "    if wn_tag:\n",
    "        try:\n",
    "            # Get sentiment synsets for the word from SentiWordNet\n",
    "            synset = list(swn.senti_synsets(word, wn_tag))\n",
    "            if len(synset) > 0:\n",
    "                synset = synset[0]  # Take the first synset (most probable meaning)\n",
    "                # Compare positive and negative sentiment scores and return a score\n",
    "                if synset.pos_score() > synset.neg_score():\n",
    "                    pos_score = synset.pos_score()\n",
    "                    if pos_score < 0.25:\n",
    "                        return 3  # Low positive sentiment\n",
    "                    elif pos_score >= 0.25 and pos_score < 0.50:\n",
    "                        return 5  # Medium positive sentiment\n",
    "                    elif pos_score >= 0.50 and pos_score < 0.75:\n",
    "                        return 7  # High positive sentiment\n",
    "                    else:\n",
    "                        return 9  # Very high positive sentiment\n",
    "                elif synset.pos_score() < synset.neg_score():\n",
    "                    neg_score = synset.neg_score()\n",
    "                    if neg_score < 0.25:\n",
    "                        return -3  # Low negative sentiment\n",
    "                    elif neg_score >= 0.25 and neg_score < 0.50:\n",
    "                        return -5  # Medium negative sentiment\n",
    "                    elif neg_score >= 0.50 and neg_score < 0.75:\n",
    "                        return -7  # High negative sentiment\n",
    "                    else:\n",
    "                        return -9  # Very high negative sentiment\n",
    "        except:\n",
    "            pass  # If any error occurs, return a neutral score\n",
    "    return 1  # Return a neutral score if no valid sentiment is found\n",
    "\n",
    "# Function to get sentiment scores for all words in a sentence\n",
    "def get_sentiment_score_for_sentence(sentence):\n",
    "    tagged_sentence = nltk.pos_tag(sentence)  # Tag words with POS tags\n",
    "    score = []\n",
    "    # Calculate sentiment score for each word in the tagged sentence\n",
    "    for word, tag in tagged_sentence:\n",
    "        sentiment_score = get_sentiment_score(word, tag)\n",
    "        score.append(sentiment_score)\n",
    "    return score\n",
    "\n",
    "# List to store sentiment scores for all sentences in the dataset\n",
    "sentiment_scores = []\n",
    "\n",
    "# Iterate over all sentences in the 'Summary' column of the dataset\n",
    "for sentences in dataset['Summary']:\n",
    "    score = get_sentiment_score_for_sentence(sentences)  # Get sentiment scores for each sentence\n",
    "    sentiment_scores.append(score)\n",
    "\n",
    "# Add a new column 'Sentiment_Score' to store the sentiment scores\n",
    "dataset['Sentiment_Score'] = sentiment_scores\n",
    "\n",
    "# Display the first 10 rows of the dataset with sentiment scores\n",
    "dataset.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store words and their corresponding sentiment scores\n",
    "Summary = []\n",
    "sentiment_score = []\n",
    "\n",
    "# Iterate through each sentence in the 'Summary' column of the dataset\n",
    "for sentences in dataset['Summary']:\n",
    "    # For each word in the sentence, add the word to the Summary list\n",
    "    for word in sentences:\n",
    "        Summary.append(word)\n",
    "\n",
    "# Iterate through each sentiment score list in the 'Sentiment_Score' column\n",
    "for score in dataset['Sentiment_Score']:\n",
    "    # For each score in the list, add the score to the sentiment_score list\n",
    "    for value in score:\n",
    "        sentiment_score.append(value)\n",
    "\n",
    "# Create a new DataFrame with the words and their sentiment scores\n",
    "new_dataset = pd.DataFrame({'Word': Summary, 'Sentiment_Score': sentiment_score})\n",
    "\n",
    "# Save the new DataFrame as a CSV file to the specified location\n",
    "new_dataset.to_csv('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/csv/flipkart_sentiment_score.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Word Embedding Vectors Using Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pd.read_csv('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/csv/flipkart_sentiment_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>backlight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>effect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazingkey</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>life</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>millions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>keystrokescable</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>length</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>metrekeyboard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>grams</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word  Sentiment_Score\n",
       "0        backlight                1\n",
       "1           effect                1\n",
       "2       amazingkey                1\n",
       "3             life                1\n",
       "4         millions                1\n",
       "5  keystrokescable                1\n",
       "6           length                1\n",
       "7    metrekeyboard                1\n",
       "8           weight                1\n",
       "9            grams                1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 238438 entries, 0 to 238437\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   Word             238438 non-null  object\n",
      " 1   Sentiment_Score  238438 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "score.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238438\n"
     ]
    }
   ],
   "source": [
    "print(len(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to save sentiment scores to a text file\n",
    "def save_sentiment_score_to_txt(data):\n",
    "    words_set = set()  # Set to keep track of unique words and avoid duplicates\n",
    "    \n",
    "    # Open the file in write mode with UTF-8 encoding to handle special characters\n",
    "    with open('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/txt/sentiment_score.txt', 'w', encoding='utf-8') as f:\n",
    "        # Iterate through each row of the DataFrame\n",
    "        for i in range(len(data)):\n",
    "            word = data['Word'][i]  # Get the word from the 'Word' column\n",
    "            if word not in words_set:  # Check if the word has not been written yet\n",
    "                # Write the word and its corresponding sentiment score to the file\n",
    "                f.write(f\"{word},{data['Sentiment_Score'][i]}\\n\")\n",
    "                words_set.add(word)  # Add the word to the set to track it\n",
    "\n",
    "# Call the function to save sentiment scores to the text file\n",
    "save_sentiment_score_to_txt(score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17414\n"
     ]
    }
   ],
   "source": [
    "# Define a function to count the number of lines (index) in the text file\n",
    "def count_index_txt():\n",
    "    # Open the text file in read mode with UTF-8 encoding\n",
    "    with open('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/txt/sentiment_score.txt', 'r', encoding='utf-8') as f:\n",
    "        count = 0  # Initialize a counter to 0\n",
    "        # Iterate over each line in the text file\n",
    "        for line in f:\n",
    "            count += 1  # Increment the counter for each line (index)\n",
    "        return count  # Return the total count of lines in the file\n",
    "\n",
    "# Print the result of the count function\n",
    "print(count_index_txt())  # This will print the number of lines (words) in the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Importing numpy for mathematical operations\n",
    "\n",
    "# Define a function to normalize sentiment scores\n",
    "def normalize_sentiment_score():\n",
    "    words = []  # List to store words\n",
    "    weights = []  # List to store sentiment scores\n",
    "\n",
    "    # Open the file containing sentiment scores and read the lines\n",
    "    with open('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/txt/sentiment_score.txt', 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()  # Read all lines in the file\n",
    "        for line in lines:\n",
    "            line = line.strip().split(',')  # Remove extra spaces and split by comma\n",
    "            words.append(line[0])  # Append the word (first part of the line) to 'words' list\n",
    "            weights.append(float(line[1]))  # Append the sentiment score (second part of the line) to 'weights' list\n",
    "\n",
    "    # Convert the weights list to a numpy array for mathematical operations\n",
    "    weights = np.array(weights)\n",
    "    \n",
    "    # Calculate the mean and standard deviation of the sentiment scores\n",
    "    mean = np.mean(weights)\n",
    "    std = np.std(weights)\n",
    "    \n",
    "    # Normalize the sentiment scores: (score - mean) / std\n",
    "    normalized_weights = (weights - mean) / std\n",
    "    \n",
    "    # Open a new file to save the normalized sentiment scores\n",
    "    with open('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/txt/normalized_sentiment_score.txt', 'w', encoding='utf-8') as f:\n",
    "        for i in range(len(words)):\n",
    "            # Write the word and its normalized sentiment score to the new file\n",
    "            f.write(words[i] + ',' + str(normalized_weights[i]) + '\\n')\n",
    "\n",
    "# Call the function to normalize and save sentiment scores\n",
    "normalize_sentiment_score()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17414\n"
     ]
    }
   ],
   "source": [
    "# Define a function to convert sentiment data into a dictionary\n",
    "def get_sentiment_dict():\n",
    "    sentiment_dict = {}  # Initialize an empty dictionary to store words and their sentiment scores\n",
    "    \n",
    "    # Open the normalized sentiment score file for reading\n",
    "    with open('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/txt/normalized_sentiment_score.txt', 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()  # Read all lines from the file\n",
    "        for line in lines:\n",
    "            line = line.strip().split(',')  # Remove any leading/trailing spaces and split by comma\n",
    "            sentiment_dict[line[0]] = float(line[1])  # Add the word and its sentiment score to the dictionary\n",
    "    \n",
    "    return sentiment_dict  # Return the dictionary containing word-sentiment pairs\n",
    "\n",
    "# Call the function to get the sentiment dictionary\n",
    "sentiment_dict = get_sentiment_dict()\n",
    "\n",
    "# Print the length of the dictionary (the number of unique words and their sentiment scores)\n",
    "print(len(sentiment_dict))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract the list of words from the sentiment score file\n",
    "def get_word_list():\n",
    "    word_list = []  # Initialize an empty list to store the words\n",
    "    \n",
    "    # Open the normalized sentiment score file for reading\n",
    "    with open('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/txt/normalized_sentiment_score.txt', 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()  # Read all lines from the file\n",
    "        for line in lines:\n",
    "            line = line.strip().split(',')  # Remove leading/trailing spaces and split the line by a comma\n",
    "            word_list.append(line[0])  # Append the word (first part of the line) to the word_list\n",
    "    \n",
    "    return word_list  # Return the list of words\n",
    "\n",
    "# Call the function to get the list of words\n",
    "word_list = get_word_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17414\n"
     ]
    }
   ],
   "source": [
    "# Get the list of words from the sentiment score file\n",
    "word_list = get_word_list()\n",
    "\n",
    "# Initialize a counter to count the number of words\n",
    "count = 0\n",
    "\n",
    "# Loop through each word in the word_list\n",
    "for word in word_list:\n",
    "    count += 1  # Increment the counter by 1 for each word\n",
    "\n",
    "# Print the total count of words in the word_list\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 1D or 2D array, got 3D array instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m process_word_vectors(word_list)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# save to txt use numpy \u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavetxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/txt/word_embedding.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\npyio.py:1555\u001b[0m, in \u001b[0;36msavetxt\u001b[1;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[0;32m   1553\u001b[0m \u001b[38;5;66;03m# Handle 1-dimensional arrays\u001b[39;00m\n\u001b[0;32m   1554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1555\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1556\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 1D or 2D array, got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124mD array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m X\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1558\u001b[0m     \u001b[38;5;66;03m# Common case -- 1d array of numbers\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 1D or 2D array, got 3D array instead"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import TFBertModel, BertTokenizer  # Import necessary modules for BERT\n",
    "import tensorflow as tf  # Import tensorflow for model and tensor operations\n",
    "import numpy as np  # Import numpy for handling arrays and saving to text files\n",
    "\n",
    "# Define a function to process word vectors using BERT embeddings\n",
    "def process_word_vectors(word_list):\n",
    "    # Load pre-trained BERT tokenizer and model\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    vectors = []  # List to store the word embeddings\n",
    "\n",
    "    # Iterate over each word in the word_list\n",
    "    for word in word_list:\n",
    "        # Tokenize the word using BERT tokenizer (without special tokens like [CLS] and [SEP])\n",
    "        input_ids = tokenizer.encode(word, add_special_tokens=False, return_tensors=\"tf\")\n",
    "        \n",
    "        # Forward pass through the BERT model to get the output embeddings\n",
    "        outputs = model(input_ids)\n",
    "        \n",
    "        # Extract the embedding for the [CLS] token (first token in the output)\n",
    "        embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Append the embedding to the vectors list\n",
    "        vectors.append(embedding)\n",
    "    \n",
    "    # Convert the list of embeddings into a numpy array for easier handling and saving\n",
    "    return np.array(vectors)\n",
    "\n",
    "# Example list of words (you can replace this with your actual word list)\n",
    "word_list = get_word_list()\n",
    "\n",
    "# Get the embeddings for each word in the list using the function\n",
    "embeddings = process_word_vectors(word_list)\n",
    "\n",
    "# Save the embeddings to a text file using numpy's savetxt function\n",
    "np.savetxt('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/txt/word_embedding.txt', embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing numpy for array manipulations\n",
    "import numpy as np\n",
    "\n",
    "# Convert the list of embeddings to a NumPy array\n",
    "embeddings_array = np.array(embeddings)\n",
    "\n",
    "# Reshape the embeddings array to flatten each word's embedding vector into a 1D array\n",
    "# embeddings_array.shape[0] gives the number of words, and -1 automatically calculates the number of features\n",
    "embeddings_flat = embeddings_array.reshape(embeddings_array.shape[0], -1)\n",
    "\n",
    "# Save the flattened embeddings to a text file using numpy's savetxt function\n",
    "np.savetxt('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/txt/word_embedding.txt', embeddings_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "show = np.loadtxt('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/txt/word_embedding.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.77616346,  0.24664091, -0.26078171, ...,  0.20896782,\n",
       "         0.883726  , -0.47180241],\n",
       "       [ 0.03511808,  0.18267192,  0.27115771, ..., -0.35593194,\n",
       "         0.3574658 ,  0.22869864],\n",
       "       [-0.62352526, -0.22886643, -0.17134449, ...,  0.58301562,\n",
       "         0.20271632, -0.03062649],\n",
       "       ...,\n",
       "       [-0.4443008 , -0.14225343, -1.01399577, ...,  0.12792806,\n",
       "         0.52760661,  0.3065443 ],\n",
       "       [-0.52128363, -0.28688827, -0.57063913, ...,  0.38994253,\n",
       "         0.27535611,  1.00228238],\n",
       "       [ 1.06857228,  0.30602795, -0.73094106, ...,  0.54051507,\n",
       "         1.10048127,  0.26712602]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17414, 768)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Apply Word Embedding Vectors X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get word vectors from the saved embeddings file\n",
    "def get_word_vectors():\n",
    "    # Get the list of words using the previously defined get_word_list() function\n",
    "    word_list = get_word_list()\n",
    "\n",
    "    # Load the word embeddings from the text file 'word_embedding.txt' using np.loadtxt()\n",
    "    # This returns a 2D numpy array, where each row corresponds to a word's embedding\n",
    "    vecs = np.loadtxt('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/txt/word_embedding.txt')\n",
    "\n",
    "    # Create an empty dictionary to store the word and its corresponding vector\n",
    "    word_vec = {}\n",
    "\n",
    "    # Loop through each word in the word_list\n",
    "    for i in range(len(word_list)):\n",
    "        # Assign the corresponding word embedding vector from vecs to the word in word_vec dictionary\n",
    "        word_vec[word_list[i]] = vecs[i]\n",
    "\n",
    "    # Return the dictionary that maps words to their embeddings\n",
    "    return word_vec\n",
    "\n",
    "# Call the function to get the word vectors\n",
    "word_vec = get_word_vectors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backlight [ 2.24759401e-02  7.14216336e-03 -7.55164897e-03 -3.37636099e-04\n",
      " -4.96783691e-03 -1.57731854e-02  2.10904982e-02  2.40129900e-02\n",
      "  1.80216869e-02 -5.53040114e-03 -1.27981762e-02  2.15614382e-02\n",
      "  6.97924559e-03  1.01135165e-02 -6.65933416e-03  2.50162932e-03\n",
      "  1.77967646e-02 -1.13308400e-02  1.54708461e-02 -5.05449283e-03\n",
      "  8.19417476e-03 -1.28532231e-02 -1.57005089e-04  1.82338298e-02\n",
      " -4.88648806e-03 -1.80686432e-02  1.49756694e-02  7.51334523e-03\n",
      " -9.06246429e-03 -1.01891358e-02  1.23337329e-02 -7.50139343e-03\n",
      " -1.89336343e-02  6.83230727e-03  8.15875260e-03  2.69592421e-02\n",
      " -1.02072650e-02 -8.17525849e-03 -3.36370489e-02  3.48926896e-03\n",
      " -1.87413786e-02 -2.39371299e-02  9.61366400e-03  2.12593509e-02\n",
      "  4.77963948e-03 -2.51234689e-02  1.21938229e-02  2.16234348e-04\n",
      " -1.20888475e-02 -2.57468575e-02 -1.38934394e-02 -1.09907235e-02\n",
      " -6.97529301e-03 -2.82756899e-02  1.16371060e-02  3.98601990e-02\n",
      " -2.84190079e-02 -2.51673304e-02 -2.57805320e-02 -1.27685474e-02\n",
      "  2.15097130e-02 -2.28816021e-02  1.11583075e-02 -5.60483299e-03\n",
      "  2.76316012e-02 -2.26487971e-02  8.53767522e-03 -1.27378692e-02\n",
      " -1.24810035e-02 -1.82675510e-02 -2.76241068e-02  3.68060485e-02\n",
      " -1.28645570e-02 -1.89183522e-02 -8.81348133e-03  1.40145056e-02\n",
      " -4.38257860e-03  1.74390375e-02  5.19769390e-03 -1.42738041e-02\n",
      "  1.96257171e-04  2.17085431e-02 -2.79582859e-02  2.37440905e-02\n",
      "  7.86829024e-04  9.24056561e-05 -1.12686897e-02 -3.36504933e-03\n",
      " -2.80028741e-02  1.94870796e-02 -4.59116347e-02 -8.53865473e-03\n",
      "  1.59621772e-02 -2.27949734e-03  2.65559170e-02  2.21840932e-02\n",
      " -9.49880541e-03  1.88776458e-02 -2.24555092e-02  6.78495705e-03\n",
      "  3.46102112e-02 -2.99793784e-03  1.06757048e-02 -1.52322175e-02\n",
      " -3.64765184e-04 -8.38573318e-03  2.90188208e-02 -3.69435429e-02\n",
      "  3.16506636e-02  1.96696765e-03 -1.13858939e-02  4.32073675e-03\n",
      " -1.80019810e-02  1.20200283e-03 -4.28492321e-03 -1.29426489e-02\n",
      " -2.26524325e-03  1.89544622e-02  2.20502623e-03  2.84912537e-02\n",
      "  5.50097128e-03 -1.53094343e-02  1.83949793e-02  3.06603827e-02\n",
      " -4.04486289e-03  1.21360817e-02 -2.95510930e-02  5.55313924e-03\n",
      "  8.28068527e-03 -8.77166083e-03  2.52161162e-02  2.74906858e-02\n",
      " -7.86948271e-03  7.71100597e-03 -6.47564250e-03  2.71358061e-03\n",
      " -1.32548006e-02 -2.44161027e-02  6.33487123e-03 -1.92447897e-03\n",
      " -3.01774918e-02 -4.47384928e-02  7.32404832e-04 -2.60512283e-02\n",
      "  4.57178359e-03  1.02519498e-02  1.35954367e-02 -1.43758556e-02\n",
      " -3.08553604e-02 -7.16788704e-04  1.41800797e-02 -1.35974069e-02\n",
      " -2.77494743e-02 -5.37906235e-03  8.46640457e-03  3.14755882e-03\n",
      " -5.08743255e-03  1.84155793e-02 -4.26193355e-02 -1.13227148e-02\n",
      "  1.21478030e-02 -1.58215311e-02 -1.11980240e-02 -1.99330773e-03\n",
      " -3.04327057e-03  1.06260687e-03  2.38802512e-03  4.38876844e-02\n",
      " -1.00058465e-03  3.90856071e-03  4.64950264e-03 -1.07773974e-02\n",
      "  2.72097094e-02 -6.00282678e-03  2.37151168e-03  1.96855645e-03\n",
      " -1.43355678e-02  8.40051392e-03 -5.21729453e-03  1.61775564e-02\n",
      " -3.98629658e-03  2.11716175e-02 -7.21226507e-06  4.69233070e-03\n",
      " -1.57640511e-03 -1.81127412e-02 -3.87084856e-03 -1.59144218e-02\n",
      "  1.78029282e-02  2.63413474e-02 -2.38765053e-02  8.68369271e-03\n",
      " -1.35811505e-02  2.46196310e-03 -2.65485573e-03 -1.34348396e-02\n",
      "  6.91490576e-03  2.47320188e-02 -4.99222224e-02  1.18298381e-02\n",
      "  8.56071926e-03  1.60098964e-02 -5.68699695e-03 -4.10835438e-03\n",
      " -3.91226863e-02 -3.84682328e-02  2.84641622e-02 -4.08780875e-03\n",
      "  8.95828888e-03 -2.51707514e-02 -2.56550507e-02  2.29336709e-02\n",
      "  2.40560610e-03  3.13623188e-02 -1.06751991e-02  1.07421340e-02\n",
      " -2.64659122e-02  1.82540674e-02 -1.88904201e-02 -1.12054217e-02\n",
      "  7.59777329e-03  1.55173070e-02 -2.27637739e-02  1.89002942e-03\n",
      "  6.52085721e-03  5.66751498e-03 -5.22318370e-03  9.73245186e-03\n",
      "  5.16293453e-03  1.55809556e-02  1.83686368e-02 -2.97619328e-02\n",
      "  1.33470492e-02 -4.96172596e-03 -2.35373035e-02 -8.92615726e-04\n",
      " -1.22506615e-02  3.00199851e-03  1.69563192e-02 -9.17049821e-03\n",
      "  1.64124102e-02  1.10232839e-02 -1.58225736e-02 -2.07867747e-02\n",
      "  2.57840048e-02  2.54102740e-02 -1.92458516e-02  1.90321445e-03\n",
      "  8.15639055e-03  3.66758042e-03 -3.54969104e-02  7.30605072e-03\n",
      " -6.55878037e-03 -1.80818438e-02  1.14673679e-02 -1.63573451e-02\n",
      " -1.61151626e-03 -1.06941025e-02 -2.26797316e-03  1.22356616e-02\n",
      "  2.45997508e-02  1.70215863e-03  4.86063839e-03  5.24259879e-03\n",
      " -1.54749564e-04 -4.42673388e-02  5.87051213e-03  6.95840212e-04\n",
      " -1.58627479e-03  4.76107359e-03  1.40705087e-02  1.10498818e-02\n",
      " -5.78216040e-03  4.78819336e-02 -3.06820856e-02 -8.13089298e-03\n",
      "  4.92125693e-03 -1.28542190e-02 -1.35857028e-02  1.54940420e-02\n",
      " -1.89525385e-03  1.50538838e-02 -1.06139678e-02 -9.29168437e-03\n",
      " -1.76034008e-02  4.71023423e-03 -2.76350860e-02 -1.29601459e-03\n",
      "  7.57215447e-04 -1.48721326e-02 -5.04992364e-03 -3.37611149e-02\n",
      " -3.07975285e-02 -2.70817581e-02  1.60169318e-03 -1.30830283e-02\n",
      "  5.32906743e-03  1.85402063e-02 -5.16671731e-04  7.61569797e-03\n",
      " -1.00374078e-02  3.20964426e-03  1.45760243e-02  2.37272429e-02\n",
      "  1.75472725e-02  3.36159570e-02  5.10684117e-03  2.18038908e-03\n",
      " -4.74500948e-02  5.55587498e-03 -1.03524670e-02  1.15345082e-02\n",
      "  3.06029927e-02  1.04715042e-02 -2.73047145e-02 -1.98791389e-02\n",
      " -2.86373351e-02 -1.23900148e-02 -1.29493907e-03 -2.25067426e-02\n",
      "  3.08996844e-02  2.30408944e-02  1.54835228e-03 -1.68633888e-02\n",
      " -3.82661725e-03 -2.49863317e-02 -6.11840339e-03  1.30644193e-02\n",
      "  2.58504551e-03 -2.04100575e-03 -2.15291889e-03  4.44518983e-03\n",
      "  1.69737727e-02 -3.31646798e-02 -8.56810833e-03 -1.52550216e-02\n",
      " -1.52104749e-02 -6.15021257e-03  1.47473922e-03 -1.58392538e-02\n",
      "  2.01067145e-03  1.65699316e-02  1.39472893e-02  2.66023693e-02\n",
      "  1.66646536e-02 -2.96642713e-02  1.30718429e-02  1.83337765e-02\n",
      " -2.61596721e-02 -2.58927058e-02 -9.31789134e-03  9.37441490e-04\n",
      "  2.70078743e-02 -3.98797362e-04  1.46123621e-02  2.28712564e-02\n",
      " -1.48555077e-02  8.20270991e-03  1.64772359e-02  1.67695022e-02\n",
      "  1.36488888e-02 -2.45562103e-02 -2.81050568e-03  7.33159490e-03\n",
      "  4.04090514e-03 -6.49770422e-04 -6.46441369e-04 -2.14938923e-02\n",
      " -3.18011752e-03  1.54214441e-02 -5.40415819e-03  3.61026625e-02\n",
      " -6.57497687e-03 -1.52048843e-02 -1.23716181e-02  1.21452063e-02\n",
      "  8.07619123e-03  1.77362842e-03 -2.39933238e-02  4.10507012e-02\n",
      " -1.30001580e-02 -7.12797551e-03  5.66429035e-03 -3.58340220e-02\n",
      "  1.83973370e-02  8.13892155e-03 -2.84099549e-02  1.67387517e-03\n",
      "  1.92924678e-02  8.45795767e-04 -1.82534460e-03  3.10084355e-03\n",
      " -9.06052080e-03 -7.71766235e-03 -3.49606515e-03 -9.97660371e-03\n",
      " -1.22504294e-02 -1.44110957e-02  7.82451740e-03 -1.31979680e-02\n",
      "  2.85968824e-02  1.27793609e-03 -1.70514330e-02 -1.28542009e-04\n",
      "  4.25711727e-02  1.04410556e-02 -9.46641414e-03 -5.24904632e-03\n",
      " -2.76899940e-02  1.64770667e-02  2.58623728e-02  1.19674732e-02\n",
      "  1.01570026e-02 -1.16911001e-02  3.47822915e-03  2.12610782e-03\n",
      "  1.27538314e-02  1.33294879e-02 -9.07830739e-03 -2.24016610e-02\n",
      "  1.00298185e-02 -6.95552064e-03 -3.58300112e-03 -2.17836696e-02\n",
      "  1.26499511e-02  3.67338976e-02  8.03375799e-03 -6.13115347e-05\n",
      " -1.09862082e-02 -2.57900182e-02 -3.46798870e-02  6.56887885e-03\n",
      "  3.17493537e-03 -6.24274600e-03 -8.26487065e-03  1.15244373e-03\n",
      "  1.17408120e-02 -9.84896311e-03  2.26114133e-02 -1.37045632e-02\n",
      "  1.70104333e-02  9.64582917e-03 -1.71846210e-02 -2.81714696e-03\n",
      " -1.45257938e-02 -3.53382343e-02 -3.97737532e-02 -5.37527676e-03\n",
      "  3.08940805e-03  2.77692842e-03  3.56475627e-03 -2.42315985e-02\n",
      "  9.05573715e-03  1.95010983e-02 -2.31444795e-02  5.08550934e-03\n",
      " -1.45104547e-02  1.20875444e-02 -7.42369596e-03  2.13979655e-02\n",
      " -4.01240042e-03 -4.49554979e-02  3.85954022e-02  5.34438108e-03\n",
      "  1.30458422e-02  6.58345160e-03 -2.91858491e-03 -2.71874317e-02\n",
      "  1.91692648e-02 -2.39445819e-03  3.17735559e-02  1.34711446e-02\n",
      " -3.33725059e-02  1.86905854e-02 -5.49617597e-03  1.66632193e-02\n",
      " -1.51484730e-02  8.98499725e-03 -4.66398563e-03 -2.75618494e-02\n",
      " -5.60841749e-03 -1.28117893e-02 -6.67937752e-03  4.48376870e-02\n",
      " -1.02349745e-02 -1.34786847e-02 -3.20503467e-02  1.82947129e-03\n",
      " -2.51619763e-02 -1.78533745e-02 -1.29304425e-02  1.96122174e-03\n",
      "  9.42438910e-03  3.52481130e-04  2.40064363e-02 -5.03759514e-03\n",
      "  6.57150455e-03  2.01320037e-02 -2.76091293e-03  2.73878877e-02\n",
      " -3.60409954e-02  9.10656400e-03 -4.42409532e-03 -3.44417796e-02\n",
      "  3.01958497e-02 -1.26548754e-02  1.91877039e-03 -1.20045558e-02\n",
      " -6.28229507e-03 -8.75875314e-04  2.16275239e-02  1.35479989e-03\n",
      "  4.65736964e-02  4.43993756e-03 -8.97488280e-03  6.29721259e-03\n",
      "  8.99390781e-03  5.35401182e-03 -2.29005840e-03 -1.56900363e-02\n",
      "  1.30425947e-02 -4.09208194e-03  1.91022005e-02  2.29878747e-02\n",
      "  1.06467294e-02  2.20926714e-02 -1.09172841e-02 -1.12734500e-02\n",
      " -3.53911816e-02  8.02829688e-03  2.34155520e-02 -4.40735038e-03\n",
      " -2.24297174e-02 -4.83248154e-02 -1.02279133e-02  5.46639987e-02\n",
      " -4.70387956e-02  1.17135539e-02  7.07541617e-03  1.22578430e-03\n",
      "  1.95693380e-02  1.95744652e-03  2.39612013e-03  1.59520956e-02\n",
      " -3.49496460e-02 -2.59539880e-02  1.97875064e-02 -4.23052075e-02\n",
      "  2.84288995e-04  1.85290027e-02  6.08713273e-03  1.38171512e-02\n",
      " -1.08495101e-03  5.85942140e-04 -7.03611954e-03 -2.15276980e-03\n",
      " -1.10704654e-02  3.35536099e-02  3.39289919e-04 -1.93813766e-02\n",
      " -1.27641754e-02 -1.16767837e-02 -1.28872213e-02 -2.30738941e-02\n",
      " -2.70607663e-02  2.11498197e-02 -2.28159428e-02  2.66766933e-02\n",
      " -1.85837001e-02  7.46793030e-03 -2.09601702e-02  4.71347655e-03\n",
      "  2.26120278e-02 -3.11821400e-02  5.09241772e-03 -2.66984894e-02\n",
      "  1.32898430e-02 -2.67932304e-02 -1.25511643e-03 -1.91004745e-02\n",
      "  8.15054367e-03 -5.43622066e-03  2.31591835e-02  3.34337173e-02\n",
      "  1.09511330e-02 -1.39067107e-02 -3.64614633e-02  9.57389487e-03\n",
      " -3.88449841e-02  3.89610665e-03  3.17849140e-03  1.59682839e-02\n",
      "  1.23964279e-02 -1.64437305e-02  7.43314676e-03  2.05373015e-02\n",
      "  1.03256902e-03 -7.34899486e-03 -7.81238438e-03  9.39175446e-03\n",
      " -6.30285024e-05 -4.79422863e-03  1.42457106e-02  1.32791719e-03\n",
      "  2.14308945e-02  1.08921904e-02 -2.96604430e-02  2.97391370e-04\n",
      "  1.68608515e-02 -3.02639721e-02  1.80008039e-02  4.39523375e-03\n",
      "  4.08689310e-03  1.41187956e-03  1.24019779e-02 -1.26550670e-02\n",
      "  1.78769087e-02  2.04680745e-02  2.25327433e-02  7.62628621e-03\n",
      "  4.08392090e-03  1.76383613e-02 -2.16137106e-02  8.61726871e-03\n",
      " -5.47754147e-03 -3.33567642e-03  1.30327150e-02  1.23960548e-03\n",
      "  1.01879863e-02  2.70665312e-02  1.14789270e-02 -2.01685089e-02\n",
      "  6.23879386e-03  2.07277018e-02  9.83751358e-03 -7.25951820e-03\n",
      " -5.80227194e-03  1.03371408e-02  2.31335038e-02 -4.53843265e-03\n",
      "  1.13381532e-02  6.04867580e-03  2.91153586e-03 -2.23176403e-02\n",
      " -1.92394401e-04  2.44935404e-02  2.04901986e-02  3.13654382e-03\n",
      " -3.25958091e-05  2.40589186e-04 -1.29559297e-02  1.28986035e-02\n",
      "  9.34862477e-03  2.38306606e-02 -1.12831804e-02 -4.52835833e-03\n",
      " -1.46573265e-02 -1.14021016e-03  1.33503312e-02  3.14827257e-02\n",
      "  1.77187591e-02  1.57778025e-02  2.45256046e-02 -9.69425945e-03\n",
      " -1.46885519e-02 -2.51196164e-02 -1.38362073e-02  2.26046974e-02\n",
      "  6.21838145e-04  6.39798257e-03  1.64200288e-02 -3.29385199e-02\n",
      " -1.62181040e-02  8.56179629e-03  2.21035366e-02  5.58632319e-03\n",
      " -1.99190893e-02 -1.68297116e-03 -1.06150604e-02  1.16987196e-02\n",
      " -2.73205472e-02 -6.76105863e-03  1.75687856e-02  2.41175624e-02\n",
      "  4.35980986e-03 -2.63556716e-02 -2.33231213e-03 -1.71851199e-02\n",
      "  2.00438060e-02  9.42449266e-03 -2.72830789e-02  3.54922061e-03\n",
      "  1.25494090e-02 -2.91513914e-03 -1.23562643e-02  6.62724580e-03\n",
      " -1.03830934e-02 -1.01798205e-02 -1.74243491e-02 -1.39824776e-02\n",
      "  2.03745710e-02 -1.14521529e-04 -6.07071443e-03 -6.91579164e-03\n",
      "  1.39552998e-03  1.45872416e-02  3.46133275e-03 -8.79168865e-03\n",
      " -7.08220977e-03  2.36173078e-03  4.04999520e-03 -4.23482819e-03\n",
      " -1.21931239e-03  2.60613203e-03 -1.09968008e-02  2.96389887e-02\n",
      " -5.73072383e-03 -1.47743694e-02  1.17056737e-02  3.79800569e-02\n",
      " -2.95293383e-02  2.45257237e-02  1.52223658e-03 -7.33376709e-03\n",
      "  1.13914431e-02  2.09985672e-02  2.09476230e-03  1.29265590e-02\n",
      " -7.41727432e-03  2.25106537e-02 -1.08740664e-02 -3.17534034e-03\n",
      " -2.31980033e-02  4.44085200e-02 -1.01406089e-02 -1.38549087e-02\n",
      " -3.97673920e-03 -4.97692180e-03 -3.07225745e-02 -4.18077585e-03\n",
      " -1.04000230e-02  3.00416854e-02 -2.19231231e-02 -7.01577672e-03\n",
      "  1.53032810e-02  1.83121737e-02 -1.37005938e-03 -3.45482977e-03\n",
      "  2.50412777e-02  5.43203075e-05 -2.85144963e-02 -4.60654901e-03\n",
      "  1.20087690e-02 -9.19875223e-03 -8.77189557e-03  1.55427623e-02\n",
      " -1.64346672e-02 -2.23061105e-02 -2.22960012e-02 -6.15885516e-03\n",
      "  5.09618906e-04 -1.21358871e-05 -5.22132478e-03 -1.25743697e-02\n",
      " -1.35619356e-02  6.05123591e-03  2.55907083e-02 -1.36623319e-02]\n",
      "effect [ 1.01694016e-03  5.28976605e-03  7.85211467e-03  2.25187742e-03\n",
      " -1.78192829e-03  1.02703612e-02 -6.49549254e-03 -1.76357966e-03\n",
      " -1.03363166e-02 -7.54030387e-03 -1.36201653e-02  1.30004355e-03\n",
      "  2.54264118e-03  1.00789711e-02  3.22508002e-03  1.62669174e-02\n",
      " -2.87786280e-03  1.45092430e-03  3.90827031e-03  7.45142355e-03\n",
      "  4.91327410e-03 -5.21368241e-03 -1.58153658e-02  8.36540330e-03\n",
      "  1.13762757e-02 -1.54896580e-02  8.73933773e-03 -1.57814686e-02\n",
      " -8.03510860e-03 -4.73393502e-03  1.94416974e-02 -1.43430007e-03\n",
      "  1.46413764e-02  2.00346150e-02  2.37296110e-03  4.79539089e-04\n",
      "  1.15704961e-03  3.27013464e-03  5.17382396e-03 -9.11600789e-03\n",
      " -8.40948575e-03 -1.54962185e-02  5.00654972e-03 -9.65540769e-03\n",
      "  2.27805353e-03 -5.25957761e-03 -2.69724392e-02  1.09889897e-02\n",
      " -1.26934769e-02  4.43903399e-03 -7.74537634e-04  6.52048223e-03\n",
      "  1.94210439e-02 -3.17580701e-03 -1.13010197e-03 -3.95194283e-03\n",
      "  9.00218319e-03  8.97712834e-03 -4.36930899e-03  5.93432639e-03\n",
      "  9.70112899e-03  1.56173775e-03  1.08764996e-04 -6.44948516e-03\n",
      " -2.24076749e-03 -4.62906833e-03  3.25056399e-03  1.56442235e-03\n",
      "  2.73605960e-03  9.55028125e-03  1.04130285e-02  1.28882897e-02\n",
      " -1.77563836e-03 -2.27454160e-02  8.98850581e-04 -1.86676156e-02\n",
      " -2.87300687e-03 -6.00730104e-04  1.22805941e-02  8.25300429e-03\n",
      " -7.55788938e-03 -8.92079809e-03 -1.19063213e-02 -4.12395454e-03\n",
      "  5.18747502e-03  9.77672676e-03  3.34278718e-03  4.37787737e-03\n",
      " -4.75819848e-03  1.20897580e-02  5.80673067e-03 -7.21456584e-03\n",
      " -2.36783267e-03 -1.20422132e-02  1.15628476e-02 -2.85562632e-03\n",
      "  6.15685039e-03 -4.12259272e-03 -3.38108790e-03 -2.63853819e-03\n",
      "  9.09865022e-03 -6.19656084e-04  6.65736715e-04 -6.85511744e-03\n",
      "  7.82372344e-03 -6.60884302e-03  6.09835528e-03 -1.80975971e-02\n",
      " -2.39601743e-03 -2.22526851e-02  6.95906933e-03  1.06096614e-02\n",
      " -2.57622484e-02  1.26969922e-03 -1.39089023e-03 -1.18974255e-02\n",
      "  1.41621913e-02  1.28618989e-02 -3.29147984e-04  3.01233346e-03\n",
      "  2.36172927e-03  2.56797258e-02  6.16130438e-03  1.62654313e-02\n",
      "  7.27115414e-03 -5.23124117e-04 -1.20293379e-02  5.33453330e-03\n",
      "  4.33014224e-03 -1.97835137e-03  9.41313375e-04  2.59818027e-03\n",
      " -3.92956848e-03 -9.13526678e-03  5.78627220e-03  4.64448166e-03\n",
      "  5.12585108e-03 -2.14936804e-03  2.41702628e-03 -1.89099551e-02\n",
      " -1.35890511e-03  4.33022983e-03 -1.91868823e-02  8.77580413e-03\n",
      " -1.76224858e-03  4.30935195e-03 -1.42524274e-02 -2.06213447e-02\n",
      " -1.38215318e-02  1.13866982e-02 -5.71230509e-03 -5.75934851e-03\n",
      "  9.04654956e-03  1.19488892e-02  1.05825069e-02  7.03969369e-04\n",
      " -2.28152472e-02  1.46199345e-03 -2.59175156e-02  2.66154987e-03\n",
      " -1.69919161e-03 -3.98830264e-03  5.40590491e-03 -6.17622319e-03\n",
      "  2.68549924e-02 -2.06057596e-03  2.16873286e-02  9.01370262e-03\n",
      "  7.12290836e-03  1.15060635e-02 -6.84799201e-03 -1.66449062e-02\n",
      "  1.72593828e-03 -1.23261825e-03 -8.80094355e-03 -1.98259414e-03\n",
      " -9.88818423e-03  2.96518540e-03 -1.13193834e-03 -1.53098330e-02\n",
      " -9.50560937e-03 -1.26679034e-03  6.35348890e-03  1.43210738e-03\n",
      "  1.19163297e-02  2.79880890e-03  9.20423665e-03  4.84194100e-04\n",
      "  1.82393652e-02  6.44597185e-03 -2.69090892e-02 -2.80240851e-03\n",
      "  1.27883698e-02  1.18915052e-02  3.93952673e-03 -1.63146566e-03\n",
      "  3.64984518e-03  4.37071224e-03  2.05307910e-02  8.18133126e-04\n",
      " -3.65544092e-03 -1.23042006e-04  3.05845304e-03 -1.06586259e-02\n",
      " -7.24666025e-03  2.69101628e-02 -6.95300929e-03  1.09398414e-02\n",
      "  4.54517447e-03 -2.25754967e-02 -4.54889274e-03 -2.64930875e-03\n",
      "  7.58125187e-03 -1.62575382e-02 -2.96617462e-03 -6.76405198e-03\n",
      "  1.07024313e-02 -1.49970876e-02  2.73394307e-03  5.28932333e-03\n",
      " -1.56444937e-02 -1.61700948e-02  1.56062089e-02  6.24527332e-03\n",
      "  8.98982751e-03  4.08587907e-03  1.43742651e-02  3.66454134e-03\n",
      "  4.46881165e-03  2.89363276e-03  3.55404008e-03 -2.32043775e-02\n",
      "  5.21153266e-03  4.32780176e-03  1.29112785e-02  4.85994021e-03\n",
      " -4.25014097e-03  2.16958508e-03  1.36247669e-02 -1.57664954e-02\n",
      "  6.45099370e-03 -1.28854556e-02 -1.22514037e-02  1.95242027e-02\n",
      " -1.20908100e-02 -7.64691296e-03 -3.98903232e-03  4.73732362e-03\n",
      "  9.10797847e-03 -1.30599239e-02 -1.12573843e-02 -2.67763655e-03\n",
      " -6.42339492e-04 -1.06467043e-02 -5.10523727e-03 -1.95171640e-02\n",
      "  1.44468630e-02  6.51759709e-04  8.82508447e-03  2.17291811e-02\n",
      " -1.82119647e-02  1.73949154e-02  8.41418396e-03 -7.76488615e-03\n",
      "  1.05476925e-03 -2.27056573e-02 -2.05524956e-02  6.48741436e-03\n",
      "  8.16480229e-03  1.46138603e-02  1.33335682e-02 -6.51075182e-03\n",
      " -7.16204102e-03 -4.32825812e-02 -5.93007478e-03  5.15132966e-03\n",
      "  2.56253080e-02 -1.14247675e-03  5.39983301e-04  6.19031784e-03\n",
      " -5.01147318e-03  1.29420189e-02  5.66181524e-03  4.03448781e-03\n",
      "  1.17759718e-03 -2.22788278e-03  1.39564260e-02 -2.08556047e-02\n",
      " -1.08576097e-02  9.91134218e-03  5.11486628e-03  3.40402039e-03\n",
      " -1.07042549e-02  3.84363145e-03  2.20201718e-02  1.44994133e-02\n",
      " -5.21714437e-03 -3.00163691e-03 -3.54373663e-03  1.09593980e-02\n",
      " -7.41253555e-03  1.88642657e-02 -1.49979795e-03  1.71342714e-02\n",
      "  3.75210558e-03 -9.35666887e-03 -1.07991452e-02  2.23268555e-02\n",
      " -1.69734768e-01 -2.30372801e-03 -9.29555669e-03 -5.32324127e-03\n",
      " -2.51708277e-03  1.74241774e-03  1.15238371e-02 -2.51270797e-03\n",
      " -1.21127250e-03 -1.52384200e-03 -4.64613216e-03  4.10493860e-03\n",
      " -3.03703296e-03  9.80303426e-04  1.39719343e-03  1.44392142e-02\n",
      " -6.51869020e-03 -6.44319502e-04  2.50873641e-03  1.11309579e-02\n",
      " -3.87075795e-03 -4.65810337e-03 -4.94140050e-04  1.47449632e-02\n",
      " -1.01954979e-03 -2.47596990e-02 -1.22512708e-02 -1.71872791e-02\n",
      " -7.50442669e-04  1.00306858e-02  2.60550963e-02  9.33506002e-03\n",
      "  1.27137550e-03 -1.32301738e-02  5.40176884e-04 -2.22721308e-04\n",
      "  9.09526636e-03 -1.68882952e-02 -3.93316453e-04 -2.37246953e-02\n",
      " -9.13076447e-03 -5.90320632e-03 -3.94277768e-03  8.09997400e-03\n",
      " -1.04224880e-02  7.92358985e-03  1.57009741e-02  1.66184706e-02\n",
      " -6.86259713e-03  4.99225141e-03 -9.59933721e-03  1.28760946e-02\n",
      "  5.02105085e-03 -1.98278762e-02  5.08706664e-03  1.77006066e-02\n",
      " -4.10489372e-03  2.14329743e-03  2.87764079e-03  5.04074469e-03\n",
      " -8.00409727e-03  1.03110029e-02 -7.26654481e-03  1.13520114e-02\n",
      " -1.60567273e-03 -6.62633663e-03 -1.30641207e-02  8.20914191e-03\n",
      "  1.12100742e-02 -7.49424772e-03 -2.46769020e-02  4.18724194e-03\n",
      "  1.15087694e-03 -2.36879967e-02  1.46430593e-02  2.69017951e-03\n",
      "  7.63256891e-03  3.53548498e-03  1.99997995e-02 -1.38852127e-03\n",
      " -2.16743628e-02 -1.53052539e-02  3.17169435e-03  2.54112466e-03\n",
      "  1.18541689e-04 -2.69784345e-03 -2.02118509e-02 -2.31072459e-02\n",
      " -1.62968327e-02  5.94243046e-03  6.46371357e-03 -6.36114292e-03\n",
      " -1.10576169e-02  1.54391545e-03  1.68476648e-02  1.49482637e-03\n",
      "  6.97498967e-03 -1.38427834e-02 -9.36139902e-03 -2.85476332e-03\n",
      "  2.13963073e-03  1.94163017e-03  5.26000479e-03  2.03865211e-03\n",
      "  1.82049639e-02  2.21507811e-03 -6.83462661e-03  1.85006546e-02\n",
      "  1.57213428e-02  7.57666153e-03  8.55602104e-03  5.76279925e-03\n",
      "  1.29519719e-02 -2.34880637e-03  5.15907688e-03 -1.38528154e-03\n",
      "  1.76375345e-02 -2.24227279e-03 -3.73909875e-03 -2.42679743e-02\n",
      " -1.40318727e-02  1.95339392e-02  3.87145310e-03  1.22415020e-03\n",
      " -2.70565462e-02  7.75202388e-03 -2.11694872e-03 -3.94143916e-03\n",
      "  1.62235306e-02 -7.62328877e-05  1.36242517e-02 -1.29214102e-02\n",
      "  1.27413950e-03 -7.81547049e-03 -1.58566987e-02 -1.04706481e-02\n",
      "  3.31259312e-03 -4.06649763e-03 -1.62475394e-02 -2.61657874e-02\n",
      " -5.79264595e-03 -1.00137243e-02 -3.81374548e-03  6.47889604e-04\n",
      " -3.16067309e-03 -4.01658600e-03 -6.34018650e-03  3.59293412e-03\n",
      "  9.23858436e-03 -3.63141996e-03  9.56197241e-03 -9.85760786e-03\n",
      "  1.18641962e-02 -3.55448733e-03  1.59711076e-02  1.47873663e-02\n",
      "  7.12883119e-03 -2.73490835e-03  9.40535460e-03 -1.24224104e-02\n",
      "  8.11786588e-03 -1.04827069e-02 -6.02915025e-03 -2.88017415e-03\n",
      " -1.28278179e-02  1.86611724e-02 -2.53346482e-03  1.34433255e-02\n",
      "  9.53911479e-03 -7.10183285e-03 -1.43525363e-02 -1.11762270e-02\n",
      " -1.18156555e-02 -9.84028384e-03  5.63978912e-03  3.10583191e-02\n",
      " -1.93681605e-02  3.52995051e-05 -1.00684200e-03  1.13635886e-02\n",
      "  3.28650719e-03  4.07739440e-03  1.80359421e-03  1.39311640e-02\n",
      " -8.31810702e-03 -9.95561449e-03  1.43717434e-02 -5.96597591e-04\n",
      " -4.06004234e-03 -5.11491763e-03 -1.46487586e-02 -1.17940656e-02\n",
      " -1.36126226e-02  2.20837448e-03 -8.90438886e-03 -5.31975515e-03\n",
      "  6.88879200e-03 -2.28336103e-03  4.75808241e-03  6.86287070e-03\n",
      " -1.58871689e-03 -9.32420769e-03  4.66844782e-03  3.45210288e-04\n",
      " -1.15346208e-03 -1.04298574e-03  1.09535986e-02 -3.67142771e-03\n",
      " -4.86495170e-03  1.31964440e-03 -1.48877895e-03 -3.04590447e-03\n",
      " -1.74623849e-03  5.41581785e-03 -1.35114729e-02 -1.12510774e-02\n",
      "  1.07426932e-02  7.80572195e-03  1.13772587e-02 -9.20669190e-03\n",
      "  1.01140213e-03 -7.01645202e-03  2.03012732e-03 -3.42654598e-04\n",
      "  2.43365420e-02 -1.85586902e-02 -5.60254601e-03 -1.37695783e-03\n",
      "  9.93654374e-05 -3.01097207e-04 -1.57327345e-02 -5.30076207e-03\n",
      "  1.06077989e-03  1.12093389e-02  1.54975295e-04 -6.99856273e-06\n",
      " -2.02745916e-02 -6.16646948e-03  1.01951518e-02 -5.46263862e-03\n",
      "  6.49650528e-03 -8.23301249e-04 -4.90169512e-04  1.39064768e-02\n",
      "  4.64497098e-03 -4.44441312e-03  1.39138590e-02 -1.71553029e-04\n",
      "  2.96267124e-03 -6.10265047e-04  1.90100364e-02 -1.27216757e-02\n",
      "  1.54037231e-02  2.34854725e-03 -3.08611762e-03  7.95244797e-03\n",
      "  5.67747452e-03  7.72005893e-03 -3.62298923e-03  1.80107406e-02\n",
      " -4.99980618e-03  1.28411587e-03 -1.66142315e-02 -8.74948325e-03\n",
      " -1.69547313e-03  7.16741195e-03  1.41336913e-02 -3.84767801e-02\n",
      "  2.52313811e-02 -3.28510826e-03  9.99336591e-03  1.21421141e-02\n",
      "  3.36345341e-03  1.60312196e-02  1.32981184e-02 -6.16561079e-03\n",
      "  5.98371180e-04  4.86941431e-03 -1.28544814e-04 -4.66682320e-03\n",
      "  2.50713018e-02  1.51008280e-02  1.42668036e-03  1.08468499e-04\n",
      "  1.44217918e-02  9.99673423e-03  1.02702309e-02 -7.84448309e-03\n",
      "  4.55079783e-03 -4.43674270e-03  1.60175703e-02  3.55203833e-03\n",
      " -7.55211672e-03 -1.98975607e-02 -7.79229614e-03  2.91150289e-02\n",
      " -5.42543047e-03 -6.31884518e-03  5.97688131e-03 -9.39080342e-04\n",
      " -9.31211954e-03 -6.82947790e-03  1.80613732e-02  3.41567359e-03\n",
      " -1.21169186e-02  1.00764408e-02  7.93285856e-03  1.54920226e-02\n",
      "  2.45222557e-03 -5.35509014e-03  1.74525557e-02 -5.65563265e-03\n",
      " -1.15768258e-02  2.33766563e-02 -2.31168451e-03 -1.93049141e-02\n",
      "  3.76636764e-03 -5.75905121e-03  2.67458927e-02 -4.36595362e-03\n",
      "  3.04538882e-03 -2.34752070e-04  1.66796356e-03 -4.71731305e-03\n",
      "  1.20286139e-02 -2.18979526e-02  3.95438341e-03  4.23470910e-03\n",
      " -5.08660450e-03  1.18758572e-02  1.51220010e-02  1.55895097e-02\n",
      "  2.35842010e-02 -5.50514090e-03 -4.42195679e-03  8.40886179e-03\n",
      "  4.24546563e-03  5.91405865e-03  1.91838462e-03  4.80013031e-03\n",
      " -1.68315749e-02 -1.17761832e-02  1.54867255e-02 -1.00065251e-02\n",
      "  7.23822650e-03  1.28352570e-02  3.89080087e-03 -5.34414677e-03\n",
      " -2.97328391e-02 -7.17905738e-03 -3.18342305e-03  1.24689171e-02\n",
      "  6.11695138e-03 -5.18772788e-03 -1.72001932e-02  2.54990944e-03\n",
      "  2.25325715e-03  2.22903338e-03 -8.05579231e-03 -2.22391324e-02\n",
      "  1.15442541e-03 -5.77316311e-03 -1.03196675e-03 -2.33287071e-03\n",
      " -1.74864218e-03 -6.50436254e-03  1.72779364e-02 -5.44916491e-03\n",
      "  1.37343939e-02  3.09369159e-03 -6.21075516e-04 -6.24835167e-03\n",
      " -1.35269738e-03  2.24753196e-03 -5.01779903e-03 -1.55242525e-02\n",
      "  2.59912915e-03 -1.59794029e-02  1.32635541e-02 -1.14740873e-02\n",
      "  5.02700172e-03  2.03903162e-03 -3.62033894e-03 -1.73332448e-02\n",
      " -3.39031993e-03 -1.12613998e-02 -8.34922406e-04  9.72451909e-03\n",
      " -1.63476294e-02  9.07208769e-03 -4.42447677e-03 -1.93370387e-02\n",
      " -2.93328754e-03  6.18529103e-05 -1.52962061e-02  2.14599433e-03\n",
      "  6.23315842e-03  7.30399418e-03  1.21047597e-02 -1.08140519e-02\n",
      " -6.26126745e-03  8.18771860e-03 -2.56832559e-03 -1.20425031e-02\n",
      "  1.36590292e-02  9.23366522e-03  9.89751852e-03 -3.89272668e-03\n",
      "  6.26983927e-03 -3.21895439e-03  1.22059301e-02 -1.96607638e-03\n",
      " -4.94729819e-03  1.42101452e-02 -2.88585620e-03 -1.36868387e-02\n",
      "  1.67920733e-02  1.04642489e-02 -1.58327485e-02  4.77947379e-04\n",
      "  1.33497988e-02  7.28818042e-03 -3.33099698e-03 -7.14342724e-03\n",
      " -5.40280887e-03  4.99819236e-03 -6.38316990e-03  3.62292796e-03\n",
      "  1.07160229e-02 -5.44118036e-03  5.13230508e-03  3.19659644e-03\n",
      " -8.98748271e-03 -1.05243419e-02 -1.44301483e-02 -6.01228189e-03\n",
      " -2.38928489e-04  1.38370133e-02 -4.67764964e-03  4.15063918e-03\n",
      " -1.20184753e-02 -1.52008455e-02 -6.09744395e-03  5.50217604e-03\n",
      " -5.21757605e-02  1.17319012e-03  5.56960802e-03  7.06644434e-03\n",
      " -2.42977878e-02 -1.69367048e-02  1.39849258e-03 -1.04850707e-02\n",
      " -6.81253878e-03  5.95273694e-03  7.82975759e-03 -1.39539155e-02\n",
      " -1.74654852e-02 -1.03069847e-02  1.03514020e-02  6.62259592e-03]\n",
      "amazingkey [-1.80558828e-02 -6.62745465e-03 -4.96174926e-03 -3.56090531e-03\n",
      "  1.04665264e-02 -2.91212944e-02  6.55991047e-03  6.75324582e-03\n",
      " -2.99143508e-03 -1.63691666e-02 -8.64909213e-03 -4.59624987e-03\n",
      " -1.37964494e-02 -2.62337730e-03  9.53801014e-03  3.40423174e-02\n",
      "  7.02440075e-03  2.46894980e-03  3.87880808e-03 -8.30907736e-03\n",
      "  8.34252496e-05 -6.84596222e-03 -1.92375987e-03 -2.34596707e-03\n",
      " -9.91520242e-03 -1.45343531e-02 -3.40479818e-03  5.85003813e-03\n",
      " -1.18620292e-02 -6.46397377e-03  1.23929284e-02 -5.84032066e-03\n",
      " -2.80583853e-03  1.27315433e-02  7.77316757e-03  1.38032162e-02\n",
      "  1.60653153e-02 -2.87267496e-02 -8.07370576e-03 -4.80346066e-03\n",
      " -3.78034061e-03 -8.94622748e-03  6.62702358e-03  5.46862660e-03\n",
      " -3.81476858e-03  1.26560060e-02 -1.43402937e-02 -8.64328150e-03\n",
      " -8.60630592e-03 -1.75490676e-02  4.01041161e-03  4.51861454e-03\n",
      "  1.64411829e-02 -1.96617282e-03 -4.78678476e-03  2.53690619e-02\n",
      " -1.94889471e-02 -1.99232127e-02  2.50304099e-03 -2.70659910e-02\n",
      "  3.84992105e-03 -1.85219407e-04 -5.55153750e-03 -1.65019317e-02\n",
      "  8.86025291e-03  5.14414425e-03 -7.90084010e-03 -1.42490323e-02\n",
      "  3.98232157e-03 -3.11410471e-02 -3.24147535e-02 -6.73278703e-04\n",
      "  3.39584361e-03 -1.18786965e-02  5.97946170e-03  1.19823213e-02\n",
      " -1.08850576e-02 -1.29044521e-02  1.23031885e-02 -1.75070132e-02\n",
      " -1.59001787e-03  3.43661007e-02 -6.33897138e-03  6.42124387e-04\n",
      "  9.95476961e-03 -1.74301399e-02 -1.24819399e-02  4.58894278e-03\n",
      " -1.45973183e-03 -5.64507979e-03 -2.06968372e-02  1.93912477e-02\n",
      "  2.05772912e-03  2.16579195e-03  2.70119649e-02 -1.38800627e-02\n",
      "  2.77732864e-03  9.36395697e-03 -3.86064694e-03  1.67391036e-02\n",
      "  9.30748346e-03  1.32742625e-03 -1.45694464e-02 -3.80983218e-03\n",
      " -2.50124274e-02  1.65273577e-02 -1.25364684e-03  3.71536690e-03\n",
      " -8.86400181e-03  3.91896341e-03 -4.29549636e-03  2.43235296e-02\n",
      " -1.90784091e-02 -1.06699572e-02 -1.52420506e-02  3.20758331e-02\n",
      "  4.32052671e-04  4.52327478e-03 -1.02227336e-02  3.81454549e-03\n",
      " -9.23760398e-03 -4.23753717e-03  6.95779467e-03  3.47825400e-02\n",
      "  8.02259843e-03  1.10042856e-02 -8.34394893e-05  1.01476847e-02\n",
      " -4.75267135e-03 -9.43576182e-04  8.30369910e-03  1.93362758e-02\n",
      "  7.24341534e-03  1.40764920e-02  3.83481151e-03 -9.64089967e-03\n",
      " -2.14430758e-03  1.43210285e-03  1.15032173e-02 -8.15173721e-03\n",
      " -1.95026482e-02 -2.94145894e-02  5.66893851e-03 -1.57254921e-02\n",
      " -1.28603473e-02 -1.03910486e-02  1.29461812e-02 -1.98057056e-02\n",
      "  3.01984098e-03  1.29981541e-02  2.57964200e-02  6.66914225e-03\n",
      " -2.67544727e-02  2.15351523e-03 -1.51906447e-02 -1.80033618e-02\n",
      " -7.55200021e-03 -2.26185176e-02 -9.88751712e-03  5.95464936e-03\n",
      "  1.03266406e-02 -2.00113953e-03 -2.31735111e-02 -6.41754567e-03\n",
      "  2.19402396e-03 -8.16947289e-03 -1.66306235e-02  2.08526360e-02\n",
      "  1.17012551e-02  7.51405376e-03 -1.22568415e-02 -2.13079831e-02\n",
      "  1.09154070e-02  1.18215567e-02 -2.99418980e-03 -5.93655252e-03\n",
      " -8.56343773e-03 -2.54879378e-03  2.07882867e-02 -1.19858838e-02\n",
      "  5.38809157e-03  1.13363823e-02 -2.71154758e-03 -8.34309282e-03\n",
      " -1.13386235e-02  3.40028875e-03  1.64166890e-03 -1.39483681e-02\n",
      "  1.58833449e-02 -1.59619787e-05  1.10758324e-02 -8.55877749e-03\n",
      " -6.68022543e-03 -4.11473978e-03  1.87228826e-02 -8.21760543e-03\n",
      " -1.98648423e-02  4.91348511e-03  7.97955937e-03  5.33535704e-03\n",
      "  8.83140169e-03  2.13642305e-02 -2.29584426e-02  1.22417613e-02\n",
      " -4.64440381e-02  1.11794270e-02 -4.61666950e-03 -7.87999414e-03\n",
      "  1.59056330e-02 -7.35631231e-03  7.97783421e-03  1.70598111e-02\n",
      "  9.10445912e-03  1.13043142e-03  3.49548284e-03 -8.40794614e-03\n",
      " -2.73700977e-02  2.84976564e-03 -1.17786428e-03 -8.24259728e-03\n",
      " -4.61782420e-03  8.67844993e-03  4.48329335e-03  4.19227403e-04\n",
      " -1.53306470e-02 -7.37301065e-03  1.25352418e-02 -5.03746267e-03\n",
      "  8.71167401e-03  2.40767628e-02 -2.95709319e-03 -2.51825262e-02\n",
      "  6.62949869e-03 -1.74052404e-02  2.07576059e-03  4.68644887e-03\n",
      "  5.83564834e-03 -4.94222715e-03 -8.43315978e-03  6.93515236e-03\n",
      "  1.10028358e-02  4.78547277e-04 -1.94953921e-03 -6.70106664e-03\n",
      "  9.53068838e-04  1.95439311e-02  1.60360680e-03 -4.14599534e-03\n",
      " -5.65910496e-03  5.97662931e-03 -3.71685515e-03  1.33344096e-02\n",
      "  1.83584827e-02  3.16740385e-04 -2.48085521e-03 -2.41391816e-03\n",
      " -2.85276330e-03  6.73507174e-03 -3.09614447e-03  8.51659107e-03\n",
      "  2.00005106e-02  1.95024687e-03 -5.56854221e-03 -1.25061930e-04\n",
      " -1.59794771e-02 -3.18571469e-02  2.80872314e-03  1.09594821e-03\n",
      " -2.62884467e-03  2.24301333e-02  2.62693311e-03  1.25332431e-02\n",
      " -1.83683348e-02  5.61405811e-03  2.12153720e-02  2.67868010e-02\n",
      " -2.38590276e-03 -2.05807523e-02 -7.73907530e-03  1.97171799e-02\n",
      " -1.03766381e-02  2.71475521e-02 -5.43314231e-03  1.01605409e-02\n",
      " -1.41467037e-02  1.44650883e-03  1.42132330e-02  2.78554620e-03\n",
      "  1.63415452e-02 -1.50473975e-02  8.00343016e-03 -1.68656309e-02\n",
      " -4.66676150e-03  1.07903917e-02  4.72028180e-03 -1.03894512e-02\n",
      " -2.70176107e-03  3.07249909e-02  1.54108222e-02  9.12034623e-03\n",
      " -2.27804283e-02 -1.21789041e-02  1.02840598e-03  1.57036736e-02\n",
      "  8.60282595e-04  2.63786569e-02 -7.91769982e-03 -2.57450762e-02\n",
      " -1.24519975e-01 -7.75634150e-03 -1.96303613e-02 -1.98667422e-03\n",
      " -2.08092057e-04  6.59201264e-03 -2.67168680e-02 -1.52833456e-02\n",
      " -5.24858944e-02  1.19668191e-02  2.25293620e-02  6.73773153e-03\n",
      " -4.64842344e-03  1.32348228e-02  2.09252719e-02  1.24254957e-02\n",
      "  1.65911426e-02 -1.53163690e-03 -1.08811206e-02  1.58148963e-02\n",
      "  6.88602434e-03  8.46257023e-03 -1.06419828e-02  1.39592981e-02\n",
      " -7.71786257e-03 -1.66204452e-03  1.12488448e-02 -1.01104070e-02\n",
      " -3.26821859e-02 -1.06177323e-02 -4.70911663e-03 -1.77755277e-02\n",
      " -7.35589979e-03 -3.56096313e-03 -9.51221224e-03  8.64974025e-03\n",
      " -2.88128571e-03  9.39902444e-03  8.83245887e-03 -6.79236468e-03\n",
      " -3.19419909e-02 -3.18591145e-02 -1.98880969e-02  9.47867489e-03\n",
      "  2.08096565e-02  1.51446740e-02  2.85341090e-02  2.82097785e-02\n",
      " -1.16978299e-02  2.14828562e-02  9.80469943e-03  3.69357767e-03\n",
      "  1.95291288e-02 -3.28798099e-03  1.72218598e-02 -7.03039176e-03\n",
      "  7.64909292e-03  2.57659084e-03 -6.15934103e-03 -1.81943955e-02\n",
      "  6.26677818e-03  2.51516789e-02 -3.67754428e-02  2.36308673e-02\n",
      " -4.25040678e-03 -1.55293408e-02 -3.74472738e-02  1.27855193e-02\n",
      "  1.11586665e-02 -1.05628191e-02 -1.91722457e-02  1.05423995e-02\n",
      " -1.18543881e-02 -1.74446436e-02 -1.11963049e-02 -1.91849146e-02\n",
      "  6.26582844e-03 -1.10181093e-02 -4.11702200e-03 -6.02811248e-04\n",
      "  2.15948176e-02  1.09508922e-02  3.22832656e-02  1.98400740e-02\n",
      " -2.43239300e-02 -1.66579170e-02 -1.70438161e-02  2.02882219e-02\n",
      " -1.67843459e-02 -9.46172973e-04 -3.84335486e-03  9.61521569e-03\n",
      "  8.34763656e-03 -4.22592756e-03  1.26301710e-02  2.10360562e-02\n",
      "  3.58680038e-02 -3.20915579e-03  9.56219248e-03 -1.70979509e-02\n",
      "  1.86824904e-02  1.76749666e-02  7.16856666e-03  1.20232054e-02\n",
      "  1.08148174e-02 -1.10497446e-02 -1.01222328e-02 -3.36426539e-04\n",
      "  6.36629551e-03 -4.93988840e-03  1.21645558e-02 -1.77894308e-02\n",
      " -1.74930894e-02 -1.02390453e-02 -5.11621214e-03 -1.52726874e-02\n",
      " -4.59448243e-03  9.97118315e-03  3.34473347e-03  1.02532159e-02\n",
      " -1.21146765e-02 -1.22246901e-02 -1.03006356e-02  3.77967091e-03\n",
      " -2.71504139e-02  1.55919865e-02 -1.33120801e-02  1.44927216e-02\n",
      " -1.39898831e-02 -1.19034544e-02  2.02932826e-02  9.96716866e-04\n",
      "  2.57923811e-03  7.81294274e-03 -1.39750325e-02  1.28208146e-02\n",
      "  2.63544798e-03  3.62288308e-03 -1.61392216e-02 -1.75503017e-02\n",
      "  8.92351570e-03 -3.10994095e-03 -3.63434003e-02  4.65952173e-03\n",
      "  6.56434202e-03 -1.65723756e-03 -9.18536180e-03 -1.09212099e-02\n",
      "  1.62476844e-02  2.28517270e-03  5.77672431e-03 -1.09008360e-02\n",
      "  1.18093244e-02 -6.00459293e-03  1.74559266e-02  9.87953085e-03\n",
      "  1.28346072e-02  1.29516388e-02  1.81023195e-02 -1.85700629e-02\n",
      "  7.93497034e-03 -1.66893270e-02  1.65405617e-02  2.20606417e-02\n",
      " -1.76872645e-02  3.76484305e-02 -1.44814817e-02 -4.20881670e-03\n",
      "  7.20430727e-03  1.79499883e-02  7.61307011e-03  9.38931689e-04\n",
      "  2.26329739e-03 -1.03788206e-02  7.47376855e-03  1.22683048e-04\n",
      " -2.65034099e-02 -2.78232632e-02 -4.04259965e-03  1.70582189e-03\n",
      "  1.50996957e-03 -1.72612199e-02 -1.63801924e-02 -5.69931164e-03\n",
      "  5.44937074e-03 -2.67222601e-02  1.52734382e-02 -1.09221540e-02\n",
      "  1.09406112e-02  1.45957354e-02  2.60465499e-03 -5.00626148e-03\n",
      " -2.15746043e-02  5.00447246e-03 -1.47085081e-02 -2.40864259e-03\n",
      "  1.07955128e-02 -7.03142564e-03  4.07824317e-03 -3.50728386e-02\n",
      "  9.80111191e-04  5.80992164e-03  1.94140449e-03  5.69249345e-03\n",
      "  1.71670226e-02  8.45105954e-04  1.52765036e-02  2.07359418e-02\n",
      " -3.05549162e-02  6.94269807e-03  1.77946209e-02  1.99021312e-02\n",
      "  1.24890286e-02 -3.89606047e-03  1.35219283e-02  6.22377148e-04\n",
      " -1.52803233e-03  2.10630270e-02 -5.86870068e-03  1.40972042e-02\n",
      " -1.61521822e-02  1.83980982e-02  3.40355687e-02 -1.14225467e-02\n",
      " -5.21643929e-03 -2.70701817e-02 -1.46628774e-02  1.77183707e-02\n",
      " -6.94227433e-03  5.32575823e-03 -1.74765093e-02 -2.03049660e-02\n",
      "  1.93640906e-02 -1.84361241e-02  2.36010573e-03  1.12856478e-02\n",
      " -1.49574979e-02 -1.44431590e-02  1.50171801e-02 -1.65305163e-02\n",
      "  1.64604659e-02  3.07596217e-02  9.26737430e-03  1.27557084e-02\n",
      "  3.98981463e-03 -1.02123205e-02  2.10980496e-02 -2.69311581e-02\n",
      " -7.58966274e-03  7.75224826e-03  2.67425939e-03 -1.87818847e-02\n",
      " -5.60131062e-03 -1.40164622e-03  1.55716472e-02 -1.28793378e-02\n",
      " -2.09346563e-02  1.45385853e-02 -1.84138516e-02  1.93313550e-02\n",
      "  2.33589858e-03  5.99253800e-03 -1.77018700e-02  1.90175463e-02\n",
      "  2.78889898e-02 -3.96775727e-02  1.39798204e-02 -3.87905767e-02\n",
      "  1.98675021e-02 -9.67807805e-03  1.29751661e-02  2.59466481e-03\n",
      "  1.26383713e-03 -2.20320520e-02  2.59293370e-02  2.16915988e-02\n",
      "  1.03642013e-02 -1.15404466e-02 -1.33230084e-02  4.09462867e-03\n",
      " -1.89678871e-02 -1.70697616e-02 -4.94238940e-03  2.16281729e-02\n",
      "  1.66838555e-02 -1.63363999e-02 -8.82675180e-03 -1.51970376e-03\n",
      "  2.04248818e-03 -1.65857471e-02 -1.11397073e-03  1.78349389e-02\n",
      "  1.62626490e-02 -3.34510293e-02  1.02442259e-02 -1.25782334e-02\n",
      " -1.17392378e-03  1.35769770e-02 -1.69108111e-02  5.41610524e-03\n",
      "  1.72222022e-03 -1.91177678e-03  7.60627047e-03  2.00447104e-02\n",
      "  7.54986082e-03  2.04934107e-02  4.98299004e-03  6.87126906e-04\n",
      " -1.28356644e-02  2.25184122e-02  8.82728342e-03  3.17038635e-04\n",
      "  1.16649346e-02  1.66354839e-02  1.96173631e-03  5.30949873e-03\n",
      " -1.33914656e-02 -1.61788405e-02  3.99847828e-02  1.14586878e-02\n",
      " -1.14481895e-03  2.36456696e-02  1.71336984e-02 -1.33663504e-02\n",
      " -1.34218392e-02  1.19000904e-02  9.96137507e-03 -8.18142641e-03\n",
      " -6.12918624e-03  1.13076053e-02  4.53542550e-03  6.92745088e-03\n",
      "  1.39510866e-02  5.58833832e-03  1.93777684e-03 -2.54217926e-03\n",
      "  1.73783801e-02  7.80268071e-03 -6.34973180e-05  7.57604966e-03\n",
      " -4.78867043e-03 -1.15958404e-02  1.51534456e-02  1.58849156e-02\n",
      " -5.46567188e-05  1.68176735e-02 -8.92180522e-03 -2.54393022e-02\n",
      " -3.68628785e-03 -3.43007244e-03  2.86890586e-02  1.06751275e-02\n",
      " -2.81115941e-03  1.30716271e-02 -7.22784495e-03  6.12881946e-03\n",
      "  2.08387761e-02 -3.54873103e-02  9.38245727e-03  2.31296910e-02\n",
      "  5.35876569e-03  1.01299033e-02 -1.27557317e-02 -7.16805835e-03\n",
      " -3.83524897e-02 -1.95470137e-02  2.69563303e-02  1.57012571e-02\n",
      " -1.53577179e-02  9.56880485e-03 -8.00605630e-03  5.92908707e-03\n",
      " -2.03582947e-02 -1.30591092e-02  1.15386092e-02 -1.80299528e-02\n",
      " -1.76099743e-03  1.39241607e-02  4.33880037e-03  3.54012304e-02\n",
      "  1.39246880e-02 -6.85301558e-03 -2.23113420e-02 -9.77644369e-03\n",
      "  1.01746530e-03 -2.87026924e-02 -9.90983278e-03  1.55573629e-03\n",
      " -9.57661766e-03 -1.58282816e-02  4.68708922e-03 -4.94229706e-03\n",
      "  1.67021858e-02  1.11279995e-02 -2.17596703e-03  1.08704788e-02\n",
      "  8.60155032e-04  1.57381317e-02  8.52770489e-03 -3.29029640e-02\n",
      "  2.06746009e-02  3.05317600e-02 -7.20619078e-03 -9.72776487e-04\n",
      " -2.83522870e-03  6.64585182e-03 -4.28486194e-03  1.59350270e-02\n",
      "  1.68384582e-03 -1.38070134e-03 -1.99547729e-02  3.85357477e-02\n",
      " -2.09327792e-03 -1.88030923e-02 -8.17331759e-03 -8.74825605e-03\n",
      "  1.49521231e-02  1.76480874e-02 -8.05666653e-03 -1.78979748e-02\n",
      "  3.90422712e-03  7.18774485e-03  7.76869805e-03 -8.90008072e-03\n",
      " -1.42556395e-02  2.30152199e-02 -1.25778278e-02  2.72389766e-03\n",
      "  5.36231352e-03  1.49157424e-03 -4.42606108e-02 -1.02843877e-02\n",
      "  7.04587455e-03  5.78032780e-03 -1.55309339e-02 -2.86726649e-02\n",
      "  9.61513888e-03 -1.45430625e-02 -5.17603240e-03  5.00405434e-04\n",
      " -1.11836877e-02 -2.04650850e-02  7.89001539e-03 -1.03689004e-02\n",
      "  3.45329016e-03  1.93027290e-02  5.16434554e-03 -8.02667960e-03\n",
      " -2.07348717e-02 -2.57773579e-02  6.13817533e-03 -2.58031929e-02\n",
      " -5.74890655e-03 -4.77210844e-03  8.34512046e-04 -9.47046251e-03\n",
      " -2.57675610e-02  1.68828151e-02  5.87020663e-03 -8.86873865e-04]\n",
      "life [-6.63442819e-03  4.81807181e-03  9.19715739e-03 -4.32153589e-04\n",
      "  6.28957842e-03 -2.61152475e-03  4.13916981e-03 -1.11588538e-02\n",
      " -7.74403436e-04 -2.33587350e-02  1.11165267e-02 -1.06496670e-02\n",
      " -5.44153420e-03  4.95320375e-03  4.11429619e-03  1.88838353e-02\n",
      " -1.12615597e-03  2.82225597e-04 -9.45006963e-03 -4.33432999e-03\n",
      "  2.56096392e-03 -1.42271240e-02  4.59844795e-03  4.47214027e-03\n",
      " -3.55291903e-03  3.83827735e-03  2.74575938e-03 -5.12465236e-03\n",
      " -1.25846933e-03  1.45812653e-03  9.02237240e-03 -1.06218255e-02\n",
      " -2.21056566e-03  9.83343803e-04  1.25265298e-02 -1.65356270e-02\n",
      " -6.25939601e-03 -5.49580488e-04 -2.72134229e-03 -5.61918955e-03\n",
      " -2.12155006e-03 -9.49006487e-03  6.30237597e-03 -2.63317481e-03\n",
      "  3.80293243e-03 -9.78440235e-03 -1.61273483e-02 -1.11586130e-02\n",
      " -2.70933207e-02 -1.46197846e-03  7.78918424e-04  1.19565907e-03\n",
      "  2.16501813e-02 -2.10298223e-03 -1.69976003e-02 -1.15644787e-04\n",
      "  4.98404938e-03 -6.86589640e-03 -1.69954704e-02  3.17572524e-03\n",
      "  1.25802391e-02  4.82487102e-03 -2.12984702e-03 -1.12349521e-02\n",
      "  3.74158551e-03 -4.79767764e-03 -4.14184945e-03 -1.13864497e-02\n",
      " -1.82366001e-03  6.29564450e-03 -6.80768264e-04  7.42441658e-03\n",
      "  7.97117352e-03 -1.19807566e-02  5.24864804e-03 -1.18134833e-02\n",
      "  1.41680237e-03  1.45499166e-02  1.06784941e-02  2.23461230e-03\n",
      " -9.47860153e-04 -1.16442509e-03 -1.58444263e-03  4.14729783e-04\n",
      "  7.77373370e-03 -1.13010956e-02  4.61668244e-03  4.86685226e-05\n",
      " -3.42681934e-03  1.25204404e-02  3.40893479e-03 -1.56647674e-02\n",
      "  7.59217064e-03 -1.64364519e-02  1.02529760e-02  3.25619231e-03\n",
      "  2.20593951e-03  3.73631987e-03  9.85998804e-03  6.09578654e-03\n",
      "  3.78919981e-03 -1.12753905e-03 -2.23030783e-03 -1.27880632e-03\n",
      " -1.74524176e-02 -4.12292800e-03 -1.48103572e-03 -1.51477929e-02\n",
      "  2.73733556e-03 -1.08124277e-02 -1.65416077e-02  3.17713259e-03\n",
      " -1.33053055e-02  7.31244216e-03 -1.22570987e-03  1.52888412e-02\n",
      "  3.73704091e-03  1.80017325e-02  5.84238886e-04 -3.53761661e-03\n",
      " -2.03417763e-04  1.28800273e-02  1.64499439e-03  1.16959666e-02\n",
      "  8.30828599e-03  4.40647874e-03  1.42114125e-03  1.76187520e-02\n",
      "  1.90725786e-03 -1.50659176e-04  8.13489820e-03  4.11366965e-03\n",
      " -1.70327230e-02  1.19274150e-02  1.29553653e-02  2.26855677e-03\n",
      " -6.10121184e-03  2.72555765e-03  6.94707352e-05 -1.90351655e-02\n",
      " -1.58145338e-02  1.20312521e-02  4.26688764e-03  1.46668835e-02\n",
      " -2.46414198e-03 -2.16998733e-02  3.22192270e-03 -9.46980101e-04\n",
      " -3.90458742e-03  1.21183995e-02 -3.40008896e-03  6.45850575e-03\n",
      "  8.83846541e-03  8.59910930e-03  4.41971685e-03  3.26901057e-03\n",
      " -1.94703113e-02 -1.52882802e-02 -6.16240212e-03  3.02312969e-03\n",
      "  8.10234641e-03  9.06722292e-03 -1.04463217e-02 -5.33045601e-03\n",
      " -6.35762703e-03 -1.02331095e-02 -7.33983921e-03  2.47655096e-03\n",
      "  2.22934622e-03 -6.58577137e-03  6.68799250e-03 -1.79236199e-02\n",
      "  2.05223672e-03  7.03518318e-03 -1.40279208e-03 -6.34076083e-03\n",
      "  9.49226295e-03  1.96890187e-03 -1.00211651e-02 -1.78337501e-03\n",
      " -5.17317714e-03  3.74562180e-03 -1.06485717e-03  2.75216138e-03\n",
      "  1.60900854e-02  5.65910971e-03  8.92552996e-03  1.87250160e-02\n",
      "  1.45405943e-02  1.12156199e-02 -1.02309727e-02 -4.51382398e-03\n",
      "  1.01656931e-02  1.04255749e-02  1.08183635e-02 -8.91348669e-03\n",
      "  2.86153922e-03  1.97186522e-02  2.52773402e-03 -4.78802404e-03\n",
      " -1.19930938e-03 -4.98869970e-03 -5.27407269e-03  6.24287955e-04\n",
      " -1.77346988e-02  1.45927235e-02  2.50519009e-03  3.78935559e-03\n",
      "  1.10509821e-02 -9.06041465e-03  1.26326875e-02  1.50853892e-03\n",
      "  2.90348011e-03  1.17486446e-04  1.62439579e-02 -1.68011418e-02\n",
      " -5.37421958e-03 -1.44980722e-02  3.42390302e-03  1.25442767e-02\n",
      "  1.48450704e-02 -1.54955868e-02  2.44636475e-02  4.09905633e-03\n",
      " -3.56037542e-03 -7.65979767e-03 -6.57312140e-05 -1.12081531e-02\n",
      " -4.11319284e-03  1.24055033e-02 -2.62282951e-03 -2.04182392e-02\n",
      "  5.02095419e-04  2.91617755e-03  1.15209728e-02  1.77497180e-03\n",
      "  4.96520215e-03 -1.09140279e-02  1.79886165e-02 -1.83816825e-03\n",
      " -1.11966363e-02  2.28866076e-03 -6.77244991e-03 -8.84307732e-03\n",
      " -8.42278211e-03 -1.23866828e-02 -2.28699451e-03 -6.46017783e-03\n",
      "  1.61024958e-03 -6.68260474e-04 -7.28140322e-03  1.04259512e-03\n",
      "  4.54547005e-03  4.70657853e-03  1.12274016e-02 -2.62157361e-03\n",
      " -4.13381355e-03  6.58932437e-03  7.08200696e-03  6.74394950e-04\n",
      "  6.03425753e-03  2.44099525e-03 -2.76373238e-03 -1.47790883e-02\n",
      " -1.36874187e-02 -1.07646611e-02 -2.27266577e-02  1.41303057e-02\n",
      "  1.67293757e-02  5.68538658e-03  2.22965276e-02  3.52432887e-03\n",
      " -5.47701892e-03 -8.88233728e-03 -1.69160841e-02  1.14792696e-02\n",
      "  4.40463708e-03 -4.55690059e-03  5.02337450e-03 -5.12303077e-06\n",
      "  4.87972035e-03  3.14761513e-03  3.19863737e-02 -1.28167188e-02\n",
      "  1.04763293e-02 -1.27786731e-02  4.55747622e-03 -6.50055840e-03\n",
      " -1.57572025e-02 -2.95099276e-02  5.67523501e-03  1.49192425e-02\n",
      " -1.49309000e-02 -1.08570962e-02  1.34349112e-02  4.48054510e-03\n",
      " -6.66144983e-03 -9.04891248e-03  7.68661996e-03  1.21283612e-02\n",
      " -7.19052503e-03  9.93171435e-03  6.55235915e-03  2.47066697e-03\n",
      "  4.98910402e-03 -2.79562678e-03 -5.93677604e-03 -1.27833074e-02\n",
      " -1.82477930e-01 -1.13446240e-02 -1.48476595e-02 -6.96884505e-03\n",
      " -6.01451924e-03 -8.98101102e-03  1.26874980e-02  5.55214204e-03\n",
      " -3.93823136e-03  1.38607391e-02  3.78314236e-03  2.02645720e-02\n",
      " -4.54955985e-04 -1.99192411e-03  5.64520363e-03  2.68251324e-02\n",
      " -1.24163694e-02  2.11465398e-03 -1.11117016e-02  2.47139267e-02\n",
      "  6.75618695e-03  3.91482140e-03 -6.26989623e-03  2.50700716e-03\n",
      " -3.84304158e-03 -9.73925797e-04 -5.09708961e-03  2.44333130e-04\n",
      " -2.19242744e-02 -9.07643121e-03  5.60786128e-03  7.56447413e-03\n",
      " -9.89371266e-03 -1.40612642e-02  5.13994054e-03 -1.09313433e-02\n",
      " -7.79284933e-03  1.00249917e-02 -3.33829932e-03 -1.37899837e-02\n",
      " -7.96480279e-03 -1.79626986e-02 -5.73239073e-03  2.29666904e-03\n",
      "  5.91169703e-03  7.08661974e-03  1.91524344e-02  3.56386866e-03\n",
      " -8.61559793e-03  1.74550273e-02 -1.87382321e-03  1.83566445e-03\n",
      "  1.27959410e-02  2.21366839e-03  1.22729306e-02  5.44048996e-03\n",
      " -8.54819485e-04  1.81728273e-02  3.44831212e-03 -9.12495901e-03\n",
      " -3.29776211e-03  7.50334210e-03 -1.79413357e-02  1.63472751e-03\n",
      " -1.22601460e-02 -8.09217327e-03 -1.61944731e-03  3.54825512e-03\n",
      " -3.93898088e-03  4.84737870e-03 -1.11732962e-02 -5.64531453e-03\n",
      "  4.04874610e-04 -1.49755659e-02 -1.86731742e-03 -9.08618407e-03\n",
      "  1.10875089e-02 -2.83735860e-03 -9.30353283e-04  9.52613860e-03\n",
      " -1.41952289e-02 -1.61428704e-02  9.88190844e-03  1.53523620e-02\n",
      " -1.19190257e-02 -1.43581627e-03  6.02083948e-03 -2.27791048e-03\n",
      " -1.48100789e-02  1.66074418e-03  9.10504769e-03 -1.23396117e-02\n",
      " -6.47890769e-03 -5.00254839e-04  8.13983892e-03 -3.43538253e-03\n",
      "  1.49679887e-02  1.23988175e-03 -6.97172663e-03 -7.06885580e-04\n",
      " -1.00874769e-02  8.92106390e-05  2.08738694e-02 -2.33935794e-03\n",
      "  7.67827553e-03  1.11351383e-02 -6.95057863e-03  4.70969873e-03\n",
      "  1.90245134e-03 -1.25718075e-03  2.03164923e-02 -2.86153879e-03\n",
      "  2.77956771e-03 -7.21128124e-03  1.90652085e-02 -6.93367187e-03\n",
      " -1.46388547e-02  3.49965764e-03 -7.05515361e-03 -9.78737282e-03\n",
      "  1.10901092e-03  4.81278201e-03 -8.67108071e-03 -1.13049938e-03\n",
      " -2.44121898e-02  3.57591215e-03  9.87976214e-04 -2.54759658e-03\n",
      " -5.87843109e-03  1.39494033e-03 -2.98272236e-03 -5.72884183e-04\n",
      "  8.59696214e-03 -7.58164885e-03 -2.40769695e-03  1.66923769e-03\n",
      " -1.48015041e-02  1.05788236e-02 -7.00364412e-03 -1.69901957e-02\n",
      " -2.02118397e-03 -2.15610317e-03  5.80584641e-04  5.12671063e-03\n",
      " -7.15143725e-03 -1.48185709e-02 -1.17323545e-02 -1.66878461e-03\n",
      "  8.82794448e-03 -8.83105649e-03  1.01273626e-02 -4.19965070e-03\n",
      "  2.13461833e-02 -9.72907405e-03 -2.31145711e-03  1.41669482e-02\n",
      " -2.96586674e-03 -2.22323138e-03  4.25311490e-03 -1.80112256e-02\n",
      "  5.13613899e-03 -4.86983719e-03 -1.30088036e-02  9.71187344e-03\n",
      " -4.87757017e-03  1.31956129e-02 -1.74402207e-03  4.93149393e-03\n",
      " -5.08820581e-03 -9.56982492e-03  1.21082255e-02 -1.31550265e-02\n",
      "  2.86499945e-03 -2.18425751e-02  6.82456609e-03  7.53966869e-03\n",
      "  1.11719750e-02 -7.66285186e-03 -1.50915938e-02  6.05160895e-04\n",
      " -2.55434206e-03  1.11827563e-03  9.73607391e-03  1.56563445e-02\n",
      " -9.95143581e-03 -8.06217684e-03  1.13587946e-02 -1.14086816e-02\n",
      " -4.39809635e-03  1.17881712e-02  2.58008559e-03 -8.56679742e-03\n",
      "  2.07618756e-03  1.12497104e-02 -3.32548106e-03  1.64452787e-02\n",
      "  1.56881411e-02  1.32800599e-02  9.14056673e-04 -9.91376896e-03\n",
      " -1.59787970e-02 -6.85969095e-03 -1.35782965e-02 -6.09319493e-03\n",
      "  8.20890890e-03  7.13154793e-03  1.20883142e-02 -5.31993897e-03\n",
      " -4.26226882e-03 -2.97562919e-04 -7.12722340e-03  8.37235397e-03\n",
      " -1.77756999e-03 -1.21676419e-02 -1.78919113e-02 -2.03752010e-02\n",
      " -6.97207400e-03 -8.86144084e-05 -9.67015909e-03 -1.31434682e-03\n",
      " -3.91872134e-03 -1.72460603e-02  6.77452372e-04  2.11987885e-03\n",
      "  8.17881322e-03  5.99895878e-03 -1.23885063e-02 -3.62231436e-03\n",
      " -3.88593523e-03  5.57021817e-03  3.41157430e-03 -1.09275573e-02\n",
      " -1.20966879e-02 -7.31568793e-03  1.44386265e-02  4.60379601e-03\n",
      " -1.09407691e-02 -7.13424224e-03 -1.09481476e-03 -4.16707948e-03\n",
      " -1.13268430e-03 -9.13028722e-03 -2.52215413e-05 -2.07044144e-03\n",
      " -1.79454946e-03 -1.13731326e-02 -8.27101613e-03 -3.93774289e-03\n",
      " -7.28383647e-04  9.49667982e-03  6.39792054e-04 -7.21678032e-03\n",
      "  1.24158654e-02 -1.56372962e-02  9.21986313e-03 -3.58931165e-03\n",
      "  5.03790366e-03  5.76110775e-03  3.61992599e-03  1.46438291e-02\n",
      " -6.75528770e-03  1.07866997e-02 -1.63295649e-02  1.13302316e-02\n",
      "  1.05867184e-02  1.27219812e-02  4.71863302e-03 -1.45624095e-02\n",
      " -2.55980447e-03 -1.15631721e-02  9.31610232e-03  1.93057202e-03\n",
      "  1.83509901e-02  2.39006074e-03  1.14396067e-02 -4.05034946e-03\n",
      " -9.35093246e-03  1.63657629e-02 -1.33659914e-02 -1.37594207e-05\n",
      "  6.40773499e-03  2.82751686e-03 -3.95050333e-03  1.07276027e-02\n",
      "  7.32595082e-03  1.07040676e-02  7.41204191e-03  6.22468756e-03\n",
      " -6.21471982e-03  1.30965387e-02  1.10651147e-02  2.98719361e-03\n",
      " -3.57558852e-03 -4.45459273e-03 -1.24202805e-02  8.86948796e-03\n",
      "  9.39306019e-03 -1.09631029e-02  6.12212252e-03 -2.45853157e-03\n",
      "  1.84083192e-03  7.86624988e-03  1.86616884e-02 -1.83982415e-03\n",
      " -2.92706634e-03  1.32081300e-02  2.54447443e-03  7.47520416e-04\n",
      "  3.41564684e-03  5.23380862e-04  7.55359117e-04  2.88558608e-03\n",
      "  2.91866474e-03  1.73823431e-02 -7.00073492e-03 -1.63781954e-02\n",
      "  6.55354536e-03  4.95234851e-03  2.01089855e-02 -2.43912727e-03\n",
      " -7.29546248e-03 -2.71330467e-03  9.38343161e-03 -1.13242113e-02\n",
      " -8.52802075e-03  1.04052882e-02 -8.68658465e-04 -1.58102550e-02\n",
      "  9.87624279e-03  4.46777776e-03  1.70049721e-02  3.07417575e-03\n",
      "  4.86748376e-03 -4.01460195e-03  9.18394215e-03  2.68028275e-03\n",
      " -8.26772720e-03 -2.50984559e-03  7.41399834e-03  1.75111332e-02\n",
      " -8.20703272e-03 -7.25734687e-03  1.42505628e-03 -1.43948793e-03\n",
      "  1.06483406e-02  6.92155092e-03 -5.59167816e-03  6.59708756e-03\n",
      " -1.42206462e-02  7.09823971e-03  6.98030580e-03  2.98808768e-03\n",
      " -6.35912176e-03 -1.79380231e-03 -1.29371852e-02 -2.41712984e-03\n",
      "  4.82207143e-03 -3.60385549e-03  4.37458370e-03 -3.96364867e-03\n",
      "  7.11960175e-03 -1.86113510e-04  1.05816939e-03 -6.22432208e-03\n",
      " -4.05799614e-03 -1.87981887e-02  2.01565925e-02  4.45060175e-03\n",
      "  4.97008678e-03  1.07083395e-02 -6.23329952e-03 -7.83547383e-04\n",
      " -1.57148167e-02  1.39001743e-02  5.30158279e-03 -6.45504293e-03\n",
      " -3.69340335e-03 -6.15324172e-03  1.98259737e-03  1.12349374e-02\n",
      "  5.90565036e-03 -4.85595053e-03 -9.95449517e-03 -3.77347754e-03\n",
      " -2.23259113e-03  1.28071497e-03 -9.70187722e-03  1.29202788e-02\n",
      "  2.47429829e-03 -3.38157485e-03  6.30340812e-03 -8.11525873e-03\n",
      " -3.66544491e-03 -5.52378144e-03 -9.60334242e-03 -4.13499242e-04\n",
      "  6.27121189e-03 -7.39096984e-03  1.07593174e-02  1.47516930e-02\n",
      " -6.53225539e-03  7.85948648e-03  1.83946703e-02 -8.66935210e-03\n",
      "  1.72293835e-02 -5.92295281e-03  1.23948900e-02  9.56102224e-03\n",
      " -1.56973408e-02 -1.00006264e-02  7.62539472e-03  4.97998763e-03\n",
      "  8.50010762e-03  1.33600263e-02  1.56846145e-03  4.08967803e-03\n",
      "  1.54481300e-02  1.13727072e-02 -6.44980706e-03  1.20530103e-03\n",
      " -2.50082349e-03 -2.00378581e-02 -3.93858260e-03  2.38439095e-02\n",
      " -5.22316396e-05  1.09638451e-02 -1.07526075e-02 -3.81237201e-03\n",
      "  2.23645007e-03  9.43544510e-03 -1.38205385e-02  1.56636766e-02\n",
      " -4.76134976e-03  2.15508547e-03 -7.06829118e-03 -8.00074276e-03\n",
      " -5.50811008e-03 -7.97771598e-03  1.57579136e-02 -4.71012808e-03\n",
      " -9.10189254e-03 -1.14335181e-02 -5.50498772e-03  1.37025049e-02\n",
      " -5.25183740e-04  1.14400477e-02 -1.68413083e-04 -2.23207139e-03\n",
      " -2.08913609e-02  1.43571184e-03  1.58640947e-02 -1.79347027e-02\n",
      "  5.87889194e-04  8.21011711e-03  6.25346370e-03 -1.50857685e-02\n",
      " -1.41010152e-02  5.93860518e-03  1.63732072e-02  1.14179728e-02]\n",
      "millions [-1.92767093e-02  6.53358787e-03  2.99698443e-03  7.81911152e-03\n",
      "  2.11723718e-02 -7.74000735e-03  2.20044702e-02 -8.18019749e-03\n",
      "  1.22858515e-02 -1.57100305e-02 -5.87098506e-03 -1.07538036e-02\n",
      " -1.93931343e-02  2.01156669e-02 -1.52187114e-02  2.53541958e-02\n",
      " -8.71367360e-03  3.32781981e-03  5.80460292e-03  1.17285400e-02\n",
      "  1.72652286e-03  4.69339133e-03  1.16107049e-02  2.94236348e-04\n",
      "  1.02948819e-02 -1.21094984e-02  7.65104504e-03 -2.74953201e-03\n",
      " -1.96189696e-02 -3.36762735e-03  1.06732323e-02 -2.90504552e-02\n",
      "  1.09730180e-02 -2.46095878e-04  4.61670575e-03 -1.93510143e-02\n",
      " -1.53175707e-02  5.91715598e-03  2.22083999e-03  1.00663902e-02\n",
      " -8.54578318e-03 -2.34345624e-02  2.67957953e-02 -1.04643240e-02\n",
      " -1.20546267e-02 -7.95555653e-03 -4.95266541e-02 -5.03774746e-03\n",
      " -1.18860312e-02 -1.37144023e-02 -1.20684969e-02  9.09591793e-03\n",
      "  1.73523697e-03 -6.91394653e-03  3.00666781e-03  3.19546655e-03\n",
      " -1.89678129e-02 -4.79938208e-03 -1.82242453e-02  2.42865359e-03\n",
      "  1.39863551e-02  2.29069918e-04 -8.12854992e-03 -1.46291907e-02\n",
      "  3.15247404e-02 -2.67139139e-03  4.14712070e-03  4.83746058e-03\n",
      " -2.35106810e-03  9.00909157e-03 -8.64996204e-03 -7.25729768e-03\n",
      "  9.01786577e-03 -1.27052306e-03  8.62255118e-03 -4.17128104e-03\n",
      " -6.62947236e-03  1.00033483e-02  1.82202754e-02 -1.06106435e-03\n",
      " -4.58740792e-03 -4.27019641e-03 -2.17516745e-03  2.38178967e-02\n",
      "  5.68869707e-03 -7.53829996e-03  1.49748081e-02  2.05451877e-02\n",
      " -3.97959274e-03 -5.61669719e-04  2.99628669e-03 -3.97388049e-03\n",
      "  1.16073236e-02 -2.41058462e-02  9.89471634e-03 -2.16244304e-03\n",
      " -3.40951128e-03  2.30890192e-02  8.03283975e-03  2.59426740e-03\n",
      "  4.95790542e-03 -8.41207046e-03  5.57173663e-04 -1.61267149e-02\n",
      " -8.68161156e-04  7.34198551e-03  2.79900308e-03  1.15817777e-02\n",
      "  1.86437741e-02 -6.13399578e-03  1.00148445e-02 -4.98549794e-03\n",
      " -7.69408411e-03  6.92491363e-03  2.70907291e-03  1.16750456e-02\n",
      "  1.99057368e-02  9.56259119e-03 -1.53955780e-03 -2.64667528e-02\n",
      "  9.00168265e-03  2.22674965e-03  1.46479284e-02  2.54787899e-03\n",
      "  5.31357126e-03  7.41262616e-03 -2.61081074e-02  1.18028035e-02\n",
      "  8.91601012e-03  1.09852278e-02  5.82570088e-03  6.22045753e-03\n",
      " -1.56676361e-02 -9.21298604e-04  4.82423801e-03 -1.58637719e-02\n",
      " -1.52242174e-02  4.58536863e-03  5.24295909e-03 -2.05539144e-02\n",
      "  8.92941781e-03  3.18535878e-03 -1.40882073e-02  1.16749826e-03\n",
      " -2.43927877e-02  1.49225591e-03 -2.03890730e-02 -2.80123072e-03\n",
      " -1.22820293e-02  1.30445045e-02  1.05818734e-02 -8.00073154e-03\n",
      " -6.21680053e-03  1.97356923e-03  6.60379227e-03  1.49058003e-02\n",
      "  1.49148265e-03 -2.38899233e-02 -2.08243380e-02  2.24900019e-02\n",
      "  7.17582110e-03  1.31376947e-02 -1.20105684e-02 -9.97805356e-03\n",
      "  1.60552078e-02 -1.28002258e-02  4.51191932e-03  8.97569316e-03\n",
      "  1.10301016e-02  4.67250482e-03  2.03108224e-03 -9.69381155e-03\n",
      "  2.21293647e-02  1.52162553e-02  9.98947633e-03  4.78024834e-04\n",
      "  1.75168014e-02  2.19318684e-03  3.90533522e-03 -2.48409166e-02\n",
      " -2.55949292e-03  8.64268343e-03 -2.20489203e-03  1.92610405e-02\n",
      "  1.40242645e-02 -1.27800918e-02  2.39370056e-02 -5.14270044e-03\n",
      "  7.15442412e-03  1.03350290e-02 -1.11253432e-02 -2.60532753e-02\n",
      "  1.24458713e-02  1.28455579e-02  1.06287978e-02 -1.37761920e-02\n",
      "  6.19338885e-03  3.65887638e-02  1.05837306e-02  1.42047099e-02\n",
      "  4.06831211e-03  1.94498822e-02 -1.65957390e-02  2.20548729e-03\n",
      " -2.71995587e-03  8.47223333e-03 -1.22304857e-03  8.41742369e-03\n",
      "  3.28424395e-02 -6.51687400e-03  5.05002504e-03 -2.38183351e-02\n",
      " -2.40369626e-03 -8.77647296e-03  1.23369459e-02 -2.06701254e-02\n",
      "  1.54557486e-02  5.44887106e-03 -1.71529534e-03  7.58846834e-03\n",
      " -1.95137569e-02 -1.99455974e-02  3.71416257e-03  2.98418193e-03\n",
      "  7.24814289e-03 -1.91025811e-03  1.61252012e-02 -1.69627590e-02\n",
      " -1.53117195e-03  9.51201202e-03 -1.03365324e-02 -7.93881331e-03\n",
      "  1.03301513e-02 -1.36126339e-02  9.45678815e-03 -4.03579872e-03\n",
      "  1.78542427e-02 -1.53518257e-03 -3.57181287e-03 -4.86064356e-03\n",
      " -1.81344329e-03  1.26409543e-02 -7.58071594e-03 -1.66401217e-02\n",
      " -1.27498331e-03 -7.67127050e-03 -2.07989120e-02 -7.82738863e-03\n",
      "  1.04221971e-02  2.18562042e-03 -2.43133323e-02  6.99178208e-03\n",
      " -1.49962970e-02 -2.52072855e-03  1.48860909e-02 -2.01432676e-02\n",
      "  1.26513336e-02  2.10235051e-03  5.10798422e-03 -2.00919532e-02\n",
      " -6.58367210e-03 -1.09975153e-02 -2.11654936e-02 -1.14242089e-02\n",
      " -3.02357379e-02 -3.32871924e-02 -1.69298766e-02  3.97393097e-03\n",
      "  9.64669218e-03  2.20829789e-03 -5.98063798e-03  6.33551590e-03\n",
      " -1.03301642e-02  1.10644623e-02 -3.46572524e-03 -1.65936725e-03\n",
      "  1.63695601e-02 -1.49041951e-02  4.56473325e-03 -7.17571841e-03\n",
      "  6.04424253e-03  1.87362005e-02  1.61121577e-02 -8.22723315e-03\n",
      " -8.62399241e-03 -1.04990480e-02  2.65762409e-02 -4.68835870e-03\n",
      " -4.59310679e-03  1.78516243e-02  1.61579754e-03 -2.19721609e-02\n",
      "  5.07841326e-03  4.73105041e-03  1.41607423e-02 -5.18779951e-04\n",
      " -2.42025997e-02  2.02162777e-03  8.87388541e-04  8.56741026e-04\n",
      " -1.11444562e-02  3.12429786e-02 -1.01196550e-02  6.15486245e-03\n",
      "  1.13270117e-02 -4.50505588e-04 -1.42369959e-02 -6.38212394e-03\n",
      " -1.48696403e-01  4.35467000e-04 -3.19855245e-02  1.11254882e-02\n",
      "  2.34148910e-02 -1.56969609e-03  4.17997843e-03 -8.84036316e-03\n",
      " -2.91536123e-02  3.72921291e-02  1.78956550e-02  1.15084264e-02\n",
      "  7.20453338e-03  9.66428977e-03  8.63526588e-04  7.80814614e-03\n",
      " -7.58728893e-04  1.50470920e-02 -8.70645368e-03  2.22903468e-02\n",
      "  3.56971213e-02  4.21509034e-03 -1.42264560e-02  4.01234820e-03\n",
      "  6.88824184e-03 -6.05741332e-03  2.11263821e-02  2.72065771e-03\n",
      " -1.04617143e-02 -1.50751328e-02  8.27932430e-03  1.05609317e-02\n",
      " -1.79177049e-02 -1.16678981e-02 -8.83592558e-03 -1.09077677e-02\n",
      " -3.80517797e-03 -2.37831606e-03 -1.58865972e-03  8.17497198e-03\n",
      " -9.09019274e-03 -1.92534858e-02  1.09341878e-02 -6.84235398e-04\n",
      "  7.07202283e-03  7.21286270e-03  2.26548339e-03  2.60618985e-03\n",
      " -2.15750478e-02  6.17715006e-03 -2.48375556e-03 -8.19363107e-03\n",
      "  3.16826216e-03 -3.15090017e-03  1.25417144e-02  1.34135617e-03\n",
      " -8.04816073e-03  1.27065955e-02  1.82779744e-02 -7.53405742e-03\n",
      " -1.35816717e-02  6.06336722e-03 -4.98455683e-03  1.63978133e-02\n",
      " -2.07870405e-02 -2.43743711e-02  3.75082487e-03  1.37517024e-02\n",
      " -3.03880537e-03 -3.92063031e-03 -3.34605534e-02 -3.26181913e-03\n",
      "  1.16393990e-02 -1.36996665e-02 -9.78923088e-03  8.62617495e-03\n",
      "  1.09576970e-02  2.28309436e-03 -1.00999431e-02 -1.38380869e-02\n",
      " -1.62508206e-02  5.83704080e-03  2.77288346e-02  1.28662839e-02\n",
      " -2.10143136e-02  1.33326352e-03 -1.44901567e-02  1.13371952e-02\n",
      "  3.39557111e-03  2.93296797e-02  1.44066374e-02 -1.51870011e-02\n",
      " -9.33625787e-03  2.97583060e-03  3.43691243e-03 -6.15343072e-03\n",
      " -1.61763689e-02 -5.89779958e-03  1.09516646e-02  3.26475745e-03\n",
      " -2.53597315e-03 -6.08673359e-03  2.40746459e-03  1.88146065e-02\n",
      "  3.29378399e-02 -2.26794736e-02  6.97972629e-03 -3.91346562e-03\n",
      "  1.00756632e-02 -4.11634023e-03 -3.80833443e-03 -9.82736892e-03\n",
      "  8.34199162e-03  9.70204464e-03  6.60200843e-03 -2.94889461e-02\n",
      "  7.74144081e-03  1.16443208e-02  1.97745233e-03 -4.14254330e-03\n",
      " -1.59593759e-02 -1.28382974e-02 -4.02415243e-02 -7.42107846e-03\n",
      " -2.99267604e-02  1.61532058e-02 -3.71794513e-03  9.24614949e-03\n",
      "  5.62959355e-03 -9.84187868e-03  5.77392342e-03 -1.44022283e-02\n",
      "  4.38190287e-03 -3.68040515e-06 -5.15198468e-03 -1.66753894e-02\n",
      "  3.71859929e-03 -3.27830128e-02 -1.47475782e-02 -2.68105665e-02\n",
      "  3.48433018e-03 -1.34504332e-02  8.46324629e-04  8.91543967e-03\n",
      "  7.30098929e-04  3.37152275e-03 -1.79377681e-02 -5.05120175e-03\n",
      " -2.91296069e-03 -5.59208808e-03 -9.95494825e-03 -8.85281076e-04\n",
      "  2.42918330e-02 -1.52147865e-02  1.58636632e-02  1.66960412e-02\n",
      "  1.25080018e-02  1.40441870e-02 -1.71723146e-02 -3.10883656e-02\n",
      "  1.65387770e-02 -3.95653489e-03 -8.27425500e-03  2.83968890e-02\n",
      "  7.82518278e-03  2.60027221e-02 -3.98530542e-03 -2.30914598e-03\n",
      "  1.99262747e-02  2.13670888e-02 -1.41718725e-02 -3.69555051e-03\n",
      " -1.36543258e-02 -7.80796578e-03  3.11893928e-02 -1.32051884e-03\n",
      " -5.63595305e-03 -1.36364675e-02 -6.62807559e-03  9.73289200e-03\n",
      " -2.03895891e-03 -4.78624300e-04  1.29219190e-03  1.74364916e-02\n",
      " -8.42748378e-03 -3.79847154e-03 -6.21759277e-03 -7.67681187e-03\n",
      " -3.79583678e-03  6.03447328e-03 -8.86959928e-03 -8.67846633e-03\n",
      " -4.58137006e-02  4.52709920e-03  9.64555473e-03  1.07879776e-03\n",
      "  4.01775840e-03 -1.01730726e-03 -1.00153726e-02 -3.19518305e-03\n",
      "  4.02582493e-03 -8.58102411e-03 -4.31911774e-03  4.82705141e-03\n",
      "  8.18299363e-03 -8.57849981e-03  1.07396969e-02  2.19707965e-03\n",
      " -2.40572675e-02  1.14636898e-02  3.78981039e-03  7.94090006e-03\n",
      " -9.70953382e-03 -1.76456360e-03 -7.61080212e-03 -2.33127488e-02\n",
      "  1.22823917e-02  1.92000034e-02  1.24663945e-02 -9.15314140e-03\n",
      " -2.29580646e-02 -8.37224178e-03 -1.54615515e-02 -1.35278304e-03\n",
      "  1.07973562e-02 -1.62092460e-02  4.26721990e-03 -1.64761265e-04\n",
      "  1.31103701e-02  7.00508923e-05  2.49496345e-03 -5.18000914e-03\n",
      "  7.38480969e-03  4.34376698e-04 -2.20711363e-03  4.91757285e-04\n",
      " -1.30087061e-02 -6.08523541e-03  7.88863285e-03 -2.21202134e-02\n",
      " -1.77316736e-04 -1.08717949e-02  8.98871595e-03  2.23869691e-03\n",
      "  1.94392879e-03 -1.39475491e-02 -1.91479623e-03 -9.01020140e-03\n",
      "  4.95601500e-03  2.89506622e-02 -6.96225426e-03 -1.21489940e-02\n",
      "  2.44530446e-02 -2.33975014e-02 -3.18236479e-03  2.17889953e-03\n",
      "  9.66179740e-03  4.70663764e-03 -4.28659270e-03  2.07472498e-03\n",
      " -8.90291862e-04  9.45285197e-03 -4.74257631e-03  3.86352853e-03\n",
      "  6.78568888e-03  1.48890700e-02  1.00672359e-02 -1.40756704e-02\n",
      "  2.18634530e-02  5.18303225e-03 -4.04593043e-03 -9.68921862e-04\n",
      "  7.41430385e-03 -2.00732156e-02  1.72065190e-02  6.22910228e-03\n",
      "  1.03158685e-02 -1.32438263e-03 -7.82149688e-04  1.95753894e-02\n",
      " -1.65594478e-03  8.29973876e-03  4.45912309e-03  6.30731841e-03\n",
      "  1.17280023e-02 -1.46762620e-03  2.23680865e-02 -5.69854809e-04\n",
      " -1.50049754e-02  1.03305336e-02 -9.85189561e-03  2.17508218e-02\n",
      "  8.30078213e-03 -2.48033568e-02 -3.17374226e-03 -2.55442491e-03\n",
      "  6.83823398e-03 -2.22087183e-02  3.28276088e-03 -1.49092493e-04\n",
      "  3.98224433e-03 -6.17773864e-03  1.15967595e-02  1.23249527e-02\n",
      " -1.11745571e-02 -1.16258364e-03 -3.86543578e-03  1.90419384e-02\n",
      "  3.27993755e-02  4.27025337e-03  7.47034543e-04 -1.00176743e-02\n",
      "  1.07030743e-02  3.23133812e-02  4.02882648e-03 -2.85050480e-03\n",
      " -5.42236765e-03  6.88456025e-03  9.50970002e-03  1.53347996e-03\n",
      " -8.54064742e-03  7.52436239e-03 -3.51676785e-03 -1.53041561e-02\n",
      "  1.41776607e-02 -3.22675080e-03 -5.00066185e-03  2.46623931e-04\n",
      "  7.23442668e-03 -1.27252710e-02 -2.39548543e-02  8.41653134e-03\n",
      "  8.34797745e-03  1.27452936e-02 -4.67237235e-03 -2.03533773e-02\n",
      " -4.11804855e-03 -2.13204691e-02  7.82510856e-03 -7.94148087e-03\n",
      "  8.92341646e-03 -1.93134199e-02 -1.98552992e-02  4.98325455e-03\n",
      "  5.27564034e-03  1.74447385e-02 -1.32382860e-02 -1.68241288e-02\n",
      "  1.14790496e-03 -1.88590981e-02  9.85047596e-04  3.00963069e-02\n",
      " -5.14355223e-03 -1.08328379e-02  2.37930248e-03  6.88552272e-04\n",
      " -6.71126696e-03 -1.38088111e-02  1.57760286e-03  1.63157429e-03\n",
      "  1.05657594e-02  1.85228460e-02 -1.00295285e-02 -4.47998674e-03\n",
      " -1.19850941e-02 -3.01839976e-03  3.02784154e-02 -1.28174618e-02\n",
      "  1.83763987e-02  1.01545905e-02 -1.93079575e-04 -1.25105069e-03\n",
      " -1.46752221e-03 -9.35787104e-03  1.82999190e-02  1.43336662e-04\n",
      "  1.60018342e-02  8.08493091e-03 -3.57678875e-03  4.20735132e-04\n",
      "  1.24273218e-02  1.16110829e-02 -2.18512535e-02  1.29725564e-02\n",
      "  2.11432246e-02  7.11112485e-03  1.05243117e-02 -4.25036363e-03\n",
      " -9.28157596e-03  5.03390017e-03 -4.81080701e-03  1.15041523e-03\n",
      " -4.79875295e-03 -8.45288642e-03 -1.73002468e-02 -3.00892579e-02\n",
      "  1.95473451e-03 -8.41687568e-03 -1.47356462e-02  8.22046889e-03\n",
      "  1.18467177e-02  1.17256101e-02  3.90751993e-03 -6.80788890e-03\n",
      " -3.66098834e-03 -3.59671000e-03  1.71934410e-02  9.06920180e-03\n",
      " -4.55382569e-03  7.77461224e-03  1.02055485e-02  2.16963005e-02\n",
      " -5.48940783e-03  2.96035385e-03 -8.13126408e-03 -3.65250428e-02\n",
      "  1.34818951e-02  1.24218486e-02 -4.57722227e-03 -6.19751921e-03\n",
      "  1.72289331e-02 -1.00417444e-02  3.59444244e-03 -1.94546184e-02\n",
      " -2.92134291e-02 -4.68432587e-03  3.91171716e-03  1.61543018e-02\n",
      "  1.23617600e-02  2.92701184e-02 -1.26439230e-02  1.38073511e-03\n",
      "  4.57735129e-03 -9.14463473e-03  1.67828287e-04 -3.85048718e-03\n",
      "  9.77670604e-03 -1.26755194e-02  3.92770180e-03 -3.10582225e-03\n",
      "  3.19540225e-04 -2.78701159e-03 -3.70627252e-03 -9.43148389e-03\n",
      "  1.81279733e-02  2.10588561e-03 -2.18262228e-02  2.28961050e-03\n",
      "  1.04323228e-02 -2.71100544e-02 -1.42989616e-02 -1.71942194e-02\n",
      " -2.57228037e-02  6.82785760e-03  1.70370950e-02 -1.30819358e-02\n",
      " -2.06765945e-02 -4.86668181e-04  2.80159901e-02  8.23486731e-03]\n",
      "keystrokescable [ 1.75868276e-02  1.17051413e-02  3.29781993e-03 -1.88131735e-03\n",
      "  2.05179753e-02 -7.99015667e-04  1.23098121e-02 -7.01812582e-03\n",
      " -1.60084215e-03 -3.70765290e-02  8.78773867e-03 -1.42064653e-02\n",
      "  2.39282107e-03  9.01115588e-03 -7.71120360e-03  1.24975232e-02\n",
      " -3.49325023e-03  1.92152631e-02 -2.68344934e-03  6.06276009e-03\n",
      "  7.70876819e-03  1.69046175e-03  6.77443526e-03 -1.40672699e-02\n",
      " -4.76546199e-03 -1.13398395e-02  5.25410484e-03 -1.07433103e-02\n",
      " -2.95550439e-03 -1.52945608e-03  7.12267449e-03 -1.68477701e-02\n",
      "  2.60598618e-03  7.28200819e-03 -5.35850787e-04 -2.61221382e-02\n",
      "  1.71977923e-02  6.83580893e-03  3.73591943e-03 -7.04404886e-03\n",
      "  9.66991744e-03 -1.72300601e-02  1.19385012e-02 -1.14300696e-02\n",
      " -4.04430625e-03 -1.99252063e-02 -1.93230511e-02  2.61114832e-04\n",
      " -1.25895034e-02  7.49371568e-04  1.11027169e-02 -1.07100793e-02\n",
      "  1.64089582e-02 -2.08787377e-03 -9.11851666e-03  1.28083087e-02\n",
      "  4.96582654e-03  2.48498319e-03 -4.29028206e-03 -2.94640526e-03\n",
      "  1.15227963e-02 -7.40091256e-03  1.93424170e-02 -1.34533692e-02\n",
      "  8.34262939e-03  5.68664355e-03  3.24420643e-03 -8.01214913e-03\n",
      "  4.05211992e-03  1.92961253e-02  3.92474254e-03  1.06268085e-02\n",
      " -1.42912440e-03 -1.20485856e-02 -6.16515167e-03 -4.17582024e-04\n",
      " -2.34817085e-02  1.78962108e-02  1.37660102e-02  7.63749064e-03\n",
      " -1.42238385e-02 -1.29603326e-03 -1.42258787e-02  1.12988596e-02\n",
      "  5.32779579e-03  6.66649713e-03  9.15534552e-03  7.36718103e-03\n",
      " -4.49626695e-03  4.06280698e-03  1.33088904e-02 -3.96140873e-03\n",
      " -3.56046647e-03 -9.75010598e-04  2.69448471e-02  2.77557155e-04\n",
      " -1.66302006e-02  6.84584744e-03  1.60957622e-03  1.04762879e-02\n",
      "  7.12267276e-03  1.09153190e-02  3.53005429e-03 -4.99788038e-03\n",
      "  6.82233565e-03 -1.27880505e-02 -6.34074141e-03 -2.43480856e-03\n",
      "  4.68049282e-03  3.70426991e-03  8.96560633e-03 -6.51245842e-03\n",
      " -1.19819899e-02  5.29101439e-03 -1.01323421e-02  2.03143331e-02\n",
      "  5.92081427e-03 -5.88109045e-03  7.20663308e-03 -5.67261708e-03\n",
      " -1.36801504e-02  8.18870243e-03  2.09042956e-02  1.79626348e-02\n",
      " -7.20883245e-03  1.57858026e-02 -2.83582987e-02 -1.44597678e-04\n",
      "  4.59076934e-03  5.21414930e-03  1.64687284e-03 -1.15073800e-04\n",
      "  1.24068504e-02  1.12426415e-02  9.28851627e-03 -1.85013882e-02\n",
      " -7.30811072e-03  3.58894897e-03  2.77896058e-03 -8.72830590e-03\n",
      " -6.81745491e-03  3.06053299e-04 -5.51004063e-03  2.64556890e-03\n",
      "  2.64187782e-03  3.85929030e-03 -1.34157904e-02 -2.69689647e-02\n",
      " -9.80898599e-03  2.76656710e-02 -8.48418502e-04 -6.64349926e-03\n",
      "  1.07660206e-03  2.70319539e-04 -7.35291723e-03  2.66230241e-03\n",
      " -1.18619955e-02 -1.45081987e-02  3.75262252e-03 -1.65552125e-03\n",
      "  7.66623485e-03  7.80915500e-03 -8.90377245e-04  6.87079052e-03\n",
      " -1.08839469e-02 -4.72541281e-03  1.26381616e-02  8.40050183e-03\n",
      " -4.21994605e-03  1.94704270e-02 -4.58211035e-03 -2.73458256e-03\n",
      "  8.81423128e-03  1.06115316e-02 -1.68220973e-02  3.52337482e-03\n",
      "  9.42938160e-03  5.28457981e-03  5.79525266e-03 -5.40482054e-03\n",
      " -6.87797765e-03 -5.11218362e-03 -1.08390645e-02 -1.21248565e-02\n",
      "  1.81576262e-02  1.13139268e-02  2.92393901e-03  1.13972505e-03\n",
      "  5.84520529e-03 -6.88378958e-03 -1.12953739e-02 -6.64732023e-03\n",
      "  3.33816340e-03  1.10492302e-02  3.04110632e-02 -5.86389027e-03\n",
      "  8.33170500e-04 -1.21044783e-02 -5.12614838e-04  4.93890414e-03\n",
      "  7.13024652e-03 -2.61157157e-03 -8.51147516e-03  1.10874651e-03\n",
      " -1.34326794e-02  1.27447473e-02 -2.18649313e-04 -1.46464105e-03\n",
      " -5.72626985e-03 -9.57798984e-03  1.69543912e-02  8.97772296e-03\n",
      "  1.65304956e-02 -8.77069512e-03  1.79858687e-02 -6.18760541e-03\n",
      "  1.16328048e-02 -1.22629464e-02  1.09460680e-02  1.21692574e-02\n",
      " -1.56499064e-02 -2.95735381e-02  3.07557576e-04  1.76614260e-02\n",
      "  6.73410690e-03 -4.87048660e-03  1.12557609e-02 -6.52682361e-03\n",
      " -6.20250858e-04  3.67842930e-03 -9.44417356e-03 -2.61879149e-02\n",
      "  1.48337098e-02  3.06175620e-03 -3.79941610e-03  1.18013582e-03\n",
      "  9.46531768e-04 -5.99057940e-03 -1.98214063e-03 -1.57806124e-02\n",
      "  5.11549326e-03  1.03067577e-02 -3.06424641e-03 -1.06213543e-02\n",
      " -5.33505369e-03 -1.60486265e-02  9.23091718e-04 -1.00184656e-02\n",
      " -1.73782902e-03 -7.61886003e-03 -6.35750534e-03 -3.45825871e-03\n",
      "  6.00657137e-03 -1.82722099e-03  1.08533162e-02 -2.18117260e-02\n",
      "  1.68470866e-02  1.54231112e-04 -1.19029530e-02  1.35722995e-02\n",
      "  7.79344998e-03  1.12815002e-02  4.65367183e-03 -9.19202940e-03\n",
      "  4.07405241e-03 -2.53890389e-02 -2.10797603e-03  2.30074287e-03\n",
      "  7.58181369e-03  6.74745288e-03  2.05259961e-02  3.74922874e-03\n",
      " -1.59839035e-03  6.70210915e-03  9.68358922e-03 -2.18079750e-03\n",
      "  2.21657888e-03 -9.10781191e-03  7.12741844e-03  6.40181605e-03\n",
      " -1.92766023e-03  1.29818622e-02  1.58646418e-02  1.11920511e-02\n",
      " -1.03695329e-02 -8.78495288e-03 -7.55134174e-03 -5.62554949e-03\n",
      " -2.16355309e-03 -1.81838548e-02  5.76182146e-03  1.49487740e-03\n",
      " -1.61902853e-03  3.32874604e-03  1.49321859e-02  1.69463031e-02\n",
      " -9.03318416e-03 -2.28983402e-04  6.90090303e-03 -3.91734052e-03\n",
      " -1.35371811e-02 -6.63404976e-03  2.08566749e-03 -6.48117481e-03\n",
      "  1.05353936e-03 -5.20338026e-03 -9.98024301e-03  5.59165313e-03\n",
      " -1.71981765e-01 -1.13275088e-02 -2.20313667e-02 -5.23341379e-03\n",
      "  1.98959378e-03 -3.86341461e-04  2.29161345e-02 -1.16897978e-02\n",
      "  1.45205415e-02  4.63565524e-03  1.04189997e-03  7.51345569e-03\n",
      "  5.35863883e-03  7.52990808e-03 -2.12254058e-03  3.67300702e-03\n",
      " -2.03092085e-02  1.27288145e-02 -1.22263860e-02  1.06758516e-02\n",
      "  2.52141356e-03 -1.00215664e-02 -4.76256530e-03  9.10207895e-03\n",
      "  6.35167184e-03 -1.65034006e-02 -1.52525569e-02 -6.16164138e-03\n",
      " -1.99830174e-02  3.21970002e-03  3.09195026e-03  1.30962651e-02\n",
      " -3.05831474e-03 -1.28283892e-02  8.36093292e-03  4.14296877e-03\n",
      "  2.24242701e-02 -1.13566328e-02  1.74938644e-02 -1.10821263e-02\n",
      " -8.38212926e-03 -1.57481564e-02 -5.48881279e-03 -1.99216248e-02\n",
      " -1.37259727e-02  5.17950169e-04  6.32569962e-03  1.78548692e-02\n",
      "  1.02597247e-02 -4.32540519e-03 -9.04991184e-03 -1.63181669e-03\n",
      " -1.21168936e-02 -2.24064058e-02 -1.07778065e-02  7.06266005e-03\n",
      "  6.01607266e-03  7.45470902e-03 -6.75661199e-03 -1.29783817e-02\n",
      "  7.61130008e-03  1.76045935e-03 -2.07228563e-04 -6.71549743e-03\n",
      "  1.44371542e-02 -1.62045340e-02 -1.16734956e-02  1.18317204e-02\n",
      " -1.90002033e-02  2.30607919e-02 -1.76346400e-02 -8.47367369e-03\n",
      "  9.71371337e-03 -1.80966892e-02  9.14325305e-03 -5.62998147e-03\n",
      " -6.55802653e-03 -8.29516223e-03  1.56377272e-03 -2.96976516e-03\n",
      " -2.26737846e-02 -1.20680965e-02  5.68210197e-03  3.10967816e-02\n",
      "  7.40714034e-04  6.68085197e-03 -1.29221369e-02 -1.28892382e-02\n",
      " -1.71013770e-02  2.96433576e-03  1.05883149e-02 -2.03011101e-02\n",
      " -3.04480888e-03  9.47487248e-03  1.21954299e-02 -9.90751647e-04\n",
      "  6.66472538e-03 -1.50179689e-02  7.81197531e-03 -9.18800519e-03\n",
      "  7.91949401e-03  8.91474582e-03  2.93413070e-03 -2.62919246e-03\n",
      "  1.11989120e-02 -5.16184455e-04 -6.73636064e-03  7.68456772e-03\n",
      "  2.84093664e-02  1.38348196e-02  2.98500847e-03  3.63290088e-04\n",
      " -6.17909874e-03 -1.25430728e-02  1.38501932e-02  1.14506704e-02\n",
      "  8.32282767e-03  1.21991451e-02  1.24196385e-02 -8.18024841e-03\n",
      " -1.53749280e-02  2.25041354e-03 -3.25737291e-03 -7.02063804e-03\n",
      " -1.03079030e-02  1.40174847e-02  5.27402695e-03 -1.53686176e-02\n",
      "  5.09201469e-03 -1.37584080e-02 -4.77206702e-03 -1.45972249e-02\n",
      "  1.10171915e-03 -1.33179706e-03  5.62394041e-03  2.16994409e-03\n",
      " -3.11835156e-04 -1.27929878e-02 -1.17347191e-02 -1.57656444e-02\n",
      " -6.25245441e-03 -1.36424577e-02 -1.42297406e-02 -6.57524656e-04\n",
      " -5.19117430e-03  1.39169693e-02 -1.80740594e-02 -9.23076551e-03\n",
      " -9.85258774e-03  8.54886476e-05 -6.90607676e-03 -2.95360525e-02\n",
      "  7.26434544e-04 -1.94014071e-02  6.05852013e-03 -1.70102896e-03\n",
      " -2.31081288e-03 -7.64507907e-03 -2.02593905e-02 -7.70867844e-03\n",
      "  2.00914263e-03 -6.38756175e-03 -6.28520988e-03  1.75931500e-02\n",
      " -1.05679083e-02  1.26660755e-02 -4.62733282e-03  2.07256918e-03\n",
      " -6.31360456e-03  2.59609201e-03 -9.16928310e-03  6.65796716e-03\n",
      " -1.45191175e-02 -1.60694974e-02 -4.01654846e-03  2.81918573e-02\n",
      " -1.37952377e-02  9.79331204e-03 -6.06468287e-03  1.82961925e-02\n",
      " -1.40735785e-02  3.01091187e-03 -7.28023233e-05  1.02267837e-02\n",
      " -5.92867023e-03  5.74224326e-03  1.06356975e-02 -9.20088300e-03\n",
      " -8.79367530e-03  9.37299267e-03 -1.66313605e-02 -9.33965294e-04\n",
      " -2.56551145e-02  1.38076728e-02 -1.15072501e-02  3.92212763e-03\n",
      "  5.79423820e-03  1.17400258e-02  5.58488240e-03 -1.19713585e-02\n",
      " -8.12944831e-03 -3.75813843e-03  1.56827163e-02 -9.76103382e-03\n",
      "  8.05355108e-04  1.17665305e-02  1.59963196e-02  6.92320488e-03\n",
      " -1.01267360e-02  2.24934471e-02  1.18136930e-02 -9.82217534e-03\n",
      " -8.26089218e-03 -1.05231725e-02 -1.48776921e-02 -1.31561363e-02\n",
      "  1.42103281e-02  6.01582799e-03 -4.81891670e-03  4.45875199e-05\n",
      " -1.26048167e-02 -2.20099555e-03 -6.36142383e-03 -1.76583610e-03\n",
      "  8.00001869e-03 -1.06121840e-02  1.05223967e-02  2.62589353e-02\n",
      "  7.86378426e-04 -6.18823022e-03  1.54420769e-02  4.67482933e-03\n",
      "  3.16313935e-03 -8.63714076e-04  7.12026842e-04 -3.31295321e-03\n",
      "  6.69921333e-03 -1.83616948e-02  1.24085333e-02 -1.23773200e-02\n",
      "  1.16765800e-02  2.83201702e-03  5.10956266e-03 -1.36875809e-02\n",
      "  4.48159581e-03  1.16736026e-02 -8.66149269e-03 -1.38069746e-02\n",
      "  2.01221447e-02 -2.51875032e-03  7.34874632e-03 -1.59458336e-02\n",
      " -4.80358882e-03 -3.37533789e-03 -9.24987596e-03  1.43506670e-02\n",
      "  2.12704980e-03  1.88936443e-02 -9.40482989e-03  9.84418205e-03\n",
      " -8.29154363e-03  1.97866175e-02 -7.35264366e-03 -1.20631541e-02\n",
      " -3.02702444e-03  9.02344339e-03  1.46391740e-02  1.06887734e-02\n",
      "  4.45817594e-03 -4.54646035e-03 -5.76492311e-03 -4.53228329e-03\n",
      "  1.40699918e-02 -9.19639794e-04  1.47870776e-03 -4.86397477e-03\n",
      "  3.04884560e-03  2.67683180e-03 -9.44225423e-03  1.76238494e-03\n",
      "  1.96359545e-04  7.65717068e-03  2.56596462e-03  1.03151388e-03\n",
      "  6.59063658e-03  4.08259618e-03 -1.11675218e-02  7.75802523e-03\n",
      "  1.55125484e-02  1.01953684e-02 -7.91306461e-03  6.93745918e-03\n",
      " -4.65779183e-03 -1.12559266e-02 -4.33880123e-03  2.42319334e-02\n",
      " -9.22722545e-03 -6.51833766e-03  1.24324110e-02 -1.27669422e-03\n",
      "  2.85429514e-03  6.67071077e-03  1.24997558e-02  1.70756387e-03\n",
      " -2.44402182e-03  1.37690014e-02  3.94977409e-03 -1.70866269e-03\n",
      " -9.71212285e-03  1.65142417e-02  5.42084444e-03  8.28811835e-03\n",
      "  1.18190471e-02  2.43096559e-02 -1.57408450e-02 -1.65420323e-02\n",
      "  9.90368558e-03  6.85693493e-03  1.20114159e-02 -2.19521059e-04\n",
      " -4.75299843e-03  1.17803515e-03  1.16943096e-02 -2.13725724e-02\n",
      "  3.88975577e-04 -1.40052308e-02 -8.63469198e-04 -3.31542551e-03\n",
      "  3.54439381e-03  6.00470425e-03  4.21766167e-03  9.77714791e-03\n",
      "  8.51851385e-05 -5.47825173e-03  5.14299645e-03 -3.37485892e-03\n",
      " -4.73201396e-03 -6.88874756e-03  1.47431975e-02  1.60946886e-02\n",
      "  6.73639559e-03  1.16123515e-02 -1.37832807e-02 -4.96937566e-03\n",
      "  1.30631067e-02  1.01107747e-02 -1.97365855e-02 -1.36636523e-02\n",
      "  1.14865577e-03  3.67206159e-03  1.72362686e-02  1.51249732e-02\n",
      "  7.05479589e-03 -6.21948966e-03 -1.97498607e-04 -7.95462534e-03\n",
      " -3.77960964e-03  5.30767692e-03  7.59621297e-03  2.45325255e-03\n",
      "  2.76661543e-02  1.13749234e-03  5.10399713e-03 -1.19077367e-02\n",
      " -3.95930342e-03  2.69372561e-03  2.53952836e-02 -5.51425426e-03\n",
      " -1.54021610e-02 -1.07852050e-02 -7.76625574e-03  5.03751747e-05\n",
      " -1.04942514e-02 -6.06801667e-03 -8.37944228e-04 -4.08557011e-03\n",
      "  7.44105062e-04  4.28797999e-03  3.10611934e-03  1.09469448e-03\n",
      "  9.75610518e-03  6.18321226e-03 -4.44958577e-04 -2.10342802e-02\n",
      " -7.55391178e-03 -7.57848161e-03 -8.94105806e-03  4.79706318e-03\n",
      "  2.98733320e-03  8.48280172e-03 -2.63134265e-03 -8.05183369e-03\n",
      " -4.44585477e-03 -1.16728440e-02 -7.14274330e-03 -1.17305180e-02\n",
      "  2.53739733e-03  1.42773226e-02 -6.75064954e-05 -6.36373497e-03\n",
      "  5.67704129e-03  8.98104295e-03  8.85912754e-03 -1.19310249e-02\n",
      " -3.76092638e-03  2.78105252e-03  3.10217561e-03  1.03240300e-02\n",
      "  1.68127147e-02 -1.29468578e-03  8.59065182e-03  5.32323609e-03\n",
      " -1.19375812e-02  8.42380046e-03 -2.12843557e-02  5.23254216e-03\n",
      "  7.58886360e-03 -3.67063914e-04 -1.50644557e-02  4.26260799e-03\n",
      "  1.06098988e-02  1.14016473e-02 -7.30059306e-03  3.62076483e-04\n",
      " -1.66226221e-03  3.77269306e-03  2.65887088e-03 -1.16945194e-02\n",
      " -5.10166485e-03  1.62990998e-03 -1.76715664e-02  9.83146174e-04\n",
      "  2.99664527e-03 -1.39286311e-02  2.42950192e-03 -1.11339586e-02\n",
      " -7.53208199e-03  1.60246072e-02  1.84486463e-02 -1.92248046e-03\n",
      "  3.37880028e-03 -1.58732270e-02  1.50664699e-02  1.44074357e-02\n",
      "  1.54589832e-02 -5.71769177e-04 -3.56150251e-03 -6.44437831e-03\n",
      " -9.39486819e-03 -2.65611952e-02  1.13893917e-02 -2.28714769e-03\n",
      " -3.22179929e-03  6.13077720e-03  1.77602232e-02 -1.26585743e-02\n",
      " -1.25350330e-02 -1.20586561e-02  5.45437748e-03 -1.14036550e-03]\n",
      "length [-9.73179856e-03 -4.51515604e-03  1.68131341e-02 -2.53482794e-03\n",
      " -1.64812247e-02 -2.84060472e-02  9.09896521e-03  1.70423050e-03\n",
      "  6.42254205e-03 -1.85093796e-02 -2.02883151e-02  2.77294067e-03\n",
      "  9.63797407e-03  2.49060150e-02  2.30059944e-02  5.68128608e-02\n",
      "  3.14546607e-02 -1.67934782e-02  3.93064681e-03  1.56482538e-04\n",
      "  2.05892598e-02 -5.18510218e-03 -1.60430342e-02  1.48508819e-02\n",
      "  5.82034872e-04 -3.66637480e-03  2.29369158e-02  1.80356332e-02\n",
      "  4.73676439e-03 -2.41996085e-02 -3.37168694e-03  6.87000389e-03\n",
      "  6.62153884e-05 -1.42434549e-03  8.80595245e-03 -4.61742593e-03\n",
      "  8.42678388e-03 -3.73816757e-03  6.18183102e-03 -1.20050538e-02\n",
      " -8.04876052e-03 -9.72739809e-03  9.76568371e-03  1.79379476e-02\n",
      " -8.93648585e-03 -3.86606042e-02 -1.53387144e-02 -2.17385274e-02\n",
      "  1.77252058e-02 -2.30334501e-02  1.48783273e-02 -1.04819181e-02\n",
      "  4.46145787e-02 -7.33820381e-03 -3.02048069e-03  1.56733319e-02\n",
      " -1.62535857e-02 -3.14805992e-02  3.76169359e-03 -2.52927082e-02\n",
      " -7.67635534e-03 -2.47099535e-02 -1.71020588e-02 -1.16883238e-02\n",
      "  4.67261615e-04  1.31931947e-02 -1.83295184e-02  1.06502168e-03\n",
      " -1.89983323e-02 -2.01362134e-02 -6.48796927e-03  1.90182091e-03\n",
      " -1.63447970e-02 -8.45493779e-03 -2.30523034e-02 -4.86882423e-04\n",
      " -1.42309488e-03 -2.65341710e-03  1.85317902e-02  1.47357808e-02\n",
      " -1.34161244e-02 -6.54493858e-03  1.41914457e-03  2.15012447e-03\n",
      " -1.59174626e-03  1.03789052e-02  1.06896407e-02  7.06193340e-03\n",
      "  8.59020446e-04  6.84054468e-03 -7.17831649e-03  5.53023415e-03\n",
      "  2.63730042e-04 -6.79647518e-03  2.36038224e-02  2.45505628e-02\n",
      " -2.58839894e-03 -9.31474136e-03 -6.00689155e-03  2.26286631e-02\n",
      "  7.98639611e-03 -1.80068121e-02 -5.36844390e-03 -1.01318140e-02\n",
      " -2.11134262e-03  2.08665529e-02 -1.62143464e-02 -4.63870865e-02\n",
      "  1.36582481e-02  2.32948492e-03 -1.29186270e-02 -1.62625342e-03\n",
      " -3.12094042e-02 -1.52478897e-02 -7.58692097e-03 -2.33915794e-03\n",
      "  9.69129847e-03  1.67148824e-02 -1.16829292e-02  3.34588602e-03\n",
      " -1.99933994e-03 -5.53624629e-03  1.97427301e-02  1.05607410e-02\n",
      " -1.41362466e-02  8.95601744e-03 -6.91237974e-03  2.68229489e-02\n",
      " -1.68969857e-02 -9.88609575e-03  4.50218252e-02 -1.01285941e-02\n",
      " -9.01375440e-03  1.76950712e-02  5.04079690e-04 -3.40560255e-02\n",
      " -2.23412125e-02 -8.00662394e-04 -2.29802388e-02 -1.95915173e-02\n",
      " -5.37230888e-03  4.26321295e-03  1.36858051e-03 -2.00215991e-02\n",
      " -1.19239189e-02 -1.78888907e-02 -1.22702432e-02  3.01662455e-03\n",
      " -1.12260001e-02 -1.97375210e-02 -4.15043637e-03  3.20727884e-02\n",
      " -9.76760304e-03  1.83554018e-02  7.80087962e-03 -1.07059887e-02\n",
      "  6.32019643e-04 -6.78895450e-03 -1.78287149e-02  1.31263453e-02\n",
      "  7.48095740e-03 -4.49179182e-03 -2.22067213e-03  2.36900852e-03\n",
      "  2.49750419e-02 -3.19331097e-03 -7.50082298e-03  2.17834712e-02\n",
      "  1.34289504e-02  3.10610082e-02  5.26264441e-04 -1.28866932e-02\n",
      "  1.78954082e-02 -2.78288624e-02  8.24866940e-03 -8.20370755e-03\n",
      "  1.39683942e-02 -9.47423126e-03 -1.41090041e-02 -1.80288385e-03\n",
      " -2.08757681e-02  1.04607358e-03 -2.32974770e-03  5.43248987e-03\n",
      "  2.83412612e-02  1.17531064e-02  1.20644473e-03  2.24073491e-03\n",
      "  2.15534778e-02  2.25923184e-02 -4.66390753e-03  8.56331346e-03\n",
      " -1.71912628e-02 -4.67097158e-04  2.16298471e-02 -9.80892299e-03\n",
      "  4.98279327e-03  3.57394708e-02 -1.22710622e-02 -1.36811394e-02\n",
      "  1.04843044e-02  2.51919158e-02 -4.18740159e-03 -2.90778695e-03\n",
      " -1.27354277e-02 -7.38677821e-03 -1.43328075e-03  1.47240923e-02\n",
      "  1.65737090e-03 -7.93685342e-03 -7.43218645e-04  1.33776282e-03\n",
      " -6.85600633e-03 -1.13383655e-02  1.17129049e-02 -2.11117196e-03\n",
      "  4.10462403e-03 -8.74794796e-03  2.53736411e-02  2.09985378e-02\n",
      " -2.56348235e-02 -2.08073212e-02  2.22046436e-03 -2.65903851e-03\n",
      " -9.50040370e-03  4.19650805e-03  1.18647969e-02  1.77677020e-02\n",
      " -2.13676705e-02  1.45517651e-02  3.13385145e-03 -3.28724343e-02\n",
      "  2.05759988e-02 -5.08621269e-04 -1.04999714e-02  1.77871438e-02\n",
      " -3.83405111e-02 -2.59871396e-02  1.11243404e-02 -3.38051663e-02\n",
      "  5.19057624e-03  1.82635570e-02 -7.75604894e-03  5.11028500e-03\n",
      " -7.41503223e-03 -1.72291074e-02 -1.11190545e-02  1.53056267e-02\n",
      "  1.33897845e-02 -4.98016110e-03  2.48124356e-03 -6.23943184e-04\n",
      "  8.41142234e-03 -1.52725372e-02  2.08871045e-03 -1.76698444e-03\n",
      " -6.62782877e-03  4.34421531e-03  1.09971718e-02  3.21512531e-02\n",
      "  2.17765257e-02  1.56019025e-02 -7.37121214e-03  5.69852242e-03\n",
      "  3.07755442e-03 -4.46033950e-03 -1.94486740e-02 -7.73548174e-03\n",
      " -3.52243673e-03  1.75194301e-02 -9.79341819e-04  3.04935499e-03\n",
      " -1.02397495e-02  4.05443192e-02 -2.94358780e-02 -5.13841733e-03\n",
      "  2.41099662e-02  2.00130139e-02 -6.70800997e-03  1.29893635e-02\n",
      " -5.42932652e-03  1.16947735e-03 -2.03883572e-03  2.89568629e-03\n",
      " -2.05281342e-03 -3.38039305e-02 -8.40326605e-03  3.99432083e-03\n",
      "  8.09110918e-03 -7.47850560e-03  7.67934653e-03 -2.91276457e-03\n",
      " -3.73567563e-03 -4.00959970e-02  1.72584427e-02 -1.57004166e-02\n",
      " -8.32172129e-03  9.63548343e-04 -7.57754525e-03  7.50383661e-04\n",
      " -1.03922594e-02  1.27696322e-02  1.94026947e-02 -6.08260453e-03\n",
      " -8.96507676e-04 -1.44660376e-03 -8.78655376e-03 -1.31459278e-03\n",
      " -1.14310736e-01  2.13903137e-03 -5.74997581e-03  1.47552261e-02\n",
      " -9.30742391e-04  8.48998885e-03  1.50056797e-02 -1.58578914e-02\n",
      " -6.90471882e-03 -2.15607236e-02 -9.30424546e-03  7.44889666e-03\n",
      " -1.08600623e-02  1.04594057e-02  1.59836264e-02 -1.86756208e-04\n",
      " -2.75036344e-02 -1.27176722e-02  3.51259456e-03  2.37969221e-02\n",
      "  2.89816291e-04  7.42680020e-03 -3.92535614e-03  2.44604039e-03\n",
      "  3.08062069e-02 -1.85682920e-02 -7.45003065e-03  5.84815548e-03\n",
      " -1.21613868e-02  2.04567691e-02 -5.33202583e-03 -1.27844267e-02\n",
      " -1.15884824e-02 -8.15492948e-03  3.28002557e-03  4.75529834e-03\n",
      " -1.42133029e-02 -1.91019813e-02 -2.24750029e-02  9.61324911e-04\n",
      " -2.15475662e-02 -1.97655412e-02  1.66988632e-02 -6.66089707e-03\n",
      " -1.13788727e-03  1.53799714e-02  4.93996694e-03  1.47777299e-02\n",
      " -2.01470666e-02 -2.87589493e-03 -4.98649817e-03  9.94344435e-03\n",
      "  7.12174287e-03 -2.30463314e-02  3.24962180e-03 -3.34440230e-03\n",
      "  8.26720681e-03 -1.46596722e-02 -2.17773533e-03 -1.66074655e-02\n",
      "  1.23597509e-02  2.02282360e-02 -1.10971608e-02  2.70906954e-02\n",
      " -1.89149588e-03  4.02076685e-03 -1.67204091e-02  6.06755410e-03\n",
      " -7.07907015e-03  8.97981316e-03 -2.46785917e-02 -1.38687539e-02\n",
      "  1.02706443e-02 -1.67531292e-02 -1.73253414e-03 -1.70423352e-02\n",
      " -1.05256735e-02 -3.17010641e-03  3.54534484e-03 -1.61390076e-02\n",
      "  1.01064208e-02 -2.41630343e-02  4.03444164e-03 -5.74514297e-03\n",
      " -4.46290910e-03 -1.74503101e-02  9.53284417e-03 -1.68108886e-02\n",
      " -4.02472676e-03 -8.40669909e-03  7.02850824e-03 -6.54982277e-03\n",
      "  1.32397739e-02 -1.12621325e-02 -7.45882729e-03  5.64251579e-03\n",
      "  6.01071899e-03  2.25889993e-03 -5.85525415e-03 -8.54518425e-03\n",
      "  8.27205864e-03 -6.38864396e-03  1.36157674e-02  4.60715743e-03\n",
      "  2.19650515e-02  2.03220717e-03 -4.80797807e-03  5.07248526e-03\n",
      " -1.73144399e-02  2.76304689e-02 -4.47399811e-04 -1.31866005e-02\n",
      " -7.78456014e-03 -1.10930149e-02  2.87208466e-02 -1.42932192e-02\n",
      " -1.77550227e-02  6.42907114e-03  1.79431256e-02 -1.18136619e-02\n",
      "  4.51446994e-04  2.43110608e-02 -3.14990158e-02  6.66346279e-03\n",
      " -1.49842943e-02  1.34521377e-02 -7.23840083e-03 -1.57257925e-02\n",
      " -2.52636766e-03 -2.15930001e-02  7.92873165e-03  9.94643036e-03\n",
      " -3.52497268e-03 -8.56483753e-03  1.67065647e-03  5.73361621e-03\n",
      "  2.34897875e-03 -1.98990243e-02 -6.90334879e-03  9.66405935e-03\n",
      "  1.33423484e-03  1.76601073e-02 -1.14518053e-02  6.06001411e-04\n",
      "  2.78479279e-02  3.72092355e-02  1.17126581e-02 -6.97293916e-03\n",
      " -2.01929303e-02  1.40169116e-02 -1.54129538e-02 -1.63811917e-02\n",
      "  2.28702691e-02 -4.10767640e-02  1.47001559e-02  9.92275460e-03\n",
      "  1.02592776e-02  1.64157241e-02  9.96876414e-03 -2.90512285e-02\n",
      "  1.81376407e-02 -6.34347499e-03 -4.08990327e-03  7.74046820e-03\n",
      "  1.94338337e-02  8.99533695e-03 -2.62523851e-02  1.43038583e-02\n",
      "  1.19065164e-02  4.33023933e-03 -3.60594604e-02 -2.29532016e-03\n",
      "  1.86533164e-03 -9.69250581e-03  1.85369182e-02  3.86793159e-03\n",
      "  5.59315821e-03  9.88922070e-03 -3.81424888e-02  6.90812122e-03\n",
      "  2.64838593e-02  1.37072480e-02 -1.79168280e-02  9.28169420e-03\n",
      "  1.56303697e-02  1.17814545e-02  1.79548953e-02  2.40742791e-03\n",
      " -2.51334055e-03  1.91945682e-02 -1.20480402e-02  9.72741448e-03\n",
      " -9.01527761e-03 -7.88492710e-03  1.35250265e-02 -2.20636777e-02\n",
      "  4.60788969e-03 -6.97207615e-03  8.15365568e-05 -3.98835917e-03\n",
      " -8.47033902e-03  7.75480708e-03 -1.10737940e-05  2.52162785e-02\n",
      " -9.52436512e-03  3.16278284e-02  7.76890733e-04  7.43796062e-03\n",
      " -5.23940954e-03  2.18762756e-02 -3.84599221e-03 -1.79808149e-02\n",
      " -4.81715875e-03 -1.57844615e-02 -1.26214882e-02 -1.89735709e-02\n",
      "  7.98658857e-03 -1.26072836e-03 -2.18586767e-03  1.54340078e-02\n",
      " -2.23048065e-04 -8.61999150e-03  3.23452572e-02  5.48410292e-03\n",
      " -4.24125458e-03  7.09878729e-03  2.93986971e-03  1.65865583e-02\n",
      " -1.83909853e-02 -1.06928968e-02  4.29094873e-03 -2.89582100e-02\n",
      " -2.65390491e-03  3.40725473e-03  4.76151847e-03  3.26537127e-03\n",
      " -4.30269099e-02 -1.45601363e-02  4.06991040e-03 -5.37512530e-03\n",
      " -5.11790320e-03  5.88066283e-03  1.38297563e-02 -9.56991727e-03\n",
      "  2.31156779e-03 -6.84153412e-03  7.25479064e-03 -1.87331714e-02\n",
      "  6.31895046e-03  1.91727220e-02  2.54018981e-03 -4.02931451e-03\n",
      " -2.11759913e-02 -7.43892633e-03  1.16124827e-02 -2.00590031e-03\n",
      " -2.78264718e-02 -1.42945309e-03 -1.84406669e-03  1.67528099e-02\n",
      "  1.53945413e-03  1.75815926e-02 -2.21029446e-02 -2.29680669e-03\n",
      "  2.52192166e-03  1.50089125e-02  2.93324966e-02  1.13632028e-02\n",
      " -1.73194319e-03  1.76516415e-03 -1.57812217e-02 -5.51302922e-03\n",
      " -1.13315218e-02  1.55987663e-02  2.33472916e-02 -4.40297622e-03\n",
      " -1.70625917e-02 -3.01074121e-03  2.58012939e-05 -1.11691529e-02\n",
      " -1.74543939e-02 -5.50714696e-03 -7.71614260e-03  1.57195976e-04\n",
      "  6.90239215e-03  4.07653916e-03  1.97691917e-02  2.59999984e-02\n",
      " -2.72384933e-03 -2.06290479e-03 -3.32495480e-02  3.07030084e-02\n",
      "  4.31591474e-04 -6.85232431e-03 -1.74449198e-02  2.59991319e-02\n",
      "  1.90627161e-02 -2.50150764e-03 -5.03980962e-03  2.30965774e-03\n",
      " -1.05110309e-03  6.59354534e-03  4.83762611e-02 -2.97404288e-03\n",
      " -1.12170896e-02  2.33661569e-02  1.48682457e-02 -2.74837386e-02\n",
      "  1.58026934e-02  7.30024613e-03 -5.09312452e-03  3.47472327e-02\n",
      "  1.32541481e-02  2.85902873e-02 -5.40426261e-03  8.61504733e-03\n",
      "  2.18971863e-03  8.49325102e-03 -1.06574108e-02  1.12610210e-02\n",
      " -2.66764257e-02  1.43659353e-02  3.22135933e-02 -1.50723781e-02\n",
      " -3.95780869e-03 -6.51871954e-03 -4.04493020e-03 -3.30530049e-03\n",
      " -1.34125228e-03  1.67314150e-04  8.44868961e-03  1.59136865e-02\n",
      " -9.20085862e-04  2.27374263e-02 -9.32131942e-04  6.74086900e-03\n",
      "  2.05828230e-03 -7.16494375e-03 -5.97638702e-04  1.67582848e-02\n",
      "  2.92661106e-02 -1.52361390e-02 -1.47401339e-02  9.94319322e-03\n",
      "  1.14990645e-02  2.19998445e-02 -4.25491211e-03 -1.52937862e-02\n",
      " -6.44874901e-03  4.71691132e-03  1.27054952e-02  1.21151701e-02\n",
      " -1.41145539e-03 -4.12251841e-02  1.01018417e-02  3.18453785e-03\n",
      "  5.04890615e-03  1.18412229e-02  2.65908274e-02 -2.82845711e-03\n",
      "  1.16349278e-02  1.57852304e-03  3.16722837e-02  5.27832990e-03\n",
      " -8.82840101e-03  1.45808975e-03  2.39580992e-02  2.72872092e-02\n",
      " -7.11842806e-03  2.86725458e-02 -4.85500208e-03  4.26821926e-03\n",
      " -9.23742448e-03  1.21421348e-02  1.95357273e-02 -1.88116792e-02\n",
      " -4.09752087e-02  1.76479963e-03  1.05056232e-02  2.05974325e-02\n",
      "  6.27954337e-03  2.36839924e-03 -1.93148698e-02  1.28078047e-02\n",
      "  8.79511490e-04 -1.95610980e-02 -1.64485530e-02 -1.72487667e-02\n",
      " -3.03971170e-02 -1.40818426e-02 -4.47115385e-03 -1.25326295e-02\n",
      "  5.61066390e-03  1.12330664e-02 -3.15782538e-02 -8.35873916e-03\n",
      " -3.87983593e-03  1.70097705e-02  1.12190141e-02 -7.01145175e-03\n",
      " -1.71629268e-02  2.09558189e-02  1.29424504e-02  3.11074968e-02\n",
      "  6.77265056e-03 -6.90424330e-03 -6.32189203e-03  2.14162803e-02\n",
      "  1.11394711e-03 -1.14531067e-02  1.25505378e-02  1.09792265e-02\n",
      " -2.16589823e-02  1.96565053e-02 -1.40095502e-02 -1.39608809e-02\n",
      "  1.61396052e-03 -2.00530613e-03 -2.17667167e-02 -3.91514106e-02\n",
      " -8.65580029e-03 -1.50810703e-02 -1.18355333e-03  4.11017447e-03\n",
      " -2.03189476e-03  3.04754677e-02 -1.49141818e-02 -3.51099076e-04\n",
      "  1.60801280e-02 -1.56753531e-02 -2.77350430e-02 -2.94853819e-03\n",
      " -9.16842613e-03 -2.27988677e-03  1.41763670e-02 -6.21514960e-03\n",
      "  1.40633717e-02 -3.00826783e-03 -8.46305265e-03 -1.59030974e-02\n",
      " -1.37451177e-02  2.55842538e-03 -3.15816989e-02 -1.26751561e-02\n",
      "  6.25057909e-03  3.06850924e-02  5.92306068e-04  9.64123020e-03\n",
      " -1.77297314e-02 -1.84196648e-02  2.13477825e-03 -1.55131887e-02\n",
      " -1.55990356e-02  8.28487690e-03  2.16645038e-02 -6.92492766e-04\n",
      "  4.52731150e-03  2.75450014e-04 -1.31719233e-02  6.26157986e-03]\n",
      "metrekeyboard [-1.28659473e-02 -4.11933788e-03 -2.93630264e-02  2.06839956e-02\n",
      "  1.92226546e-04 -3.18622524e-03 -7.09152206e-03  1.82734833e-02\n",
      "  1.18423561e-02  2.53522061e-06 -9.46945451e-03 -1.42946215e-02\n",
      "  1.36652609e-02 -1.54968984e-03  1.56200792e-02  2.09757026e-02\n",
      "  7.33539213e-03 -8.36833926e-03  1.07602874e-02  9.09493928e-03\n",
      "  6.35123775e-03 -1.81926773e-03 -2.30684520e-02  6.97352083e-03\n",
      "  7.15389294e-03 -1.04661708e-02  2.16547121e-02  3.30056999e-02\n",
      " -4.44445195e-04 -1.27952877e-03  7.31433560e-03 -6.36620878e-04\n",
      " -6.08764665e-03  1.30151364e-02 -1.79113259e-03  2.03811963e-03\n",
      "  1.76945379e-02 -4.02164172e-04 -1.78154539e-02 -1.11719430e-02\n",
      " -1.93396537e-02 -2.12863182e-02 -8.71741452e-04 -5.71377220e-03\n",
      "  2.01997515e-02 -1.81466539e-02  2.26606082e-02 -6.74025497e-03\n",
      "  7.04524887e-03 -6.99449926e-03 -6.78094449e-03  1.03931543e-02\n",
      "  2.35327002e-02 -1.08826300e-02  3.87463976e-03  2.91730852e-02\n",
      " -8.51614576e-03  1.74074480e-03 -7.74889547e-03 -6.41498987e-03\n",
      "  6.07011033e-03  4.79448236e-03  7.58827244e-03 -3.42461426e-02\n",
      "  3.51200728e-02 -4.31599452e-03  1.90932714e-03 -3.70965025e-02\n",
      "  1.98157643e-03 -2.98669160e-02 -2.40612994e-02  8.39179754e-03\n",
      " -5.88268216e-04 -1.67150632e-03  5.81260861e-03  1.61507134e-02\n",
      "  1.81912922e-02  1.01595536e-02 -1.05511875e-02  1.89924008e-03\n",
      " -9.31695476e-04  1.83938660e-02 -1.76924667e-02  1.56154155e-02\n",
      "  8.87099045e-03 -2.45020359e-02 -1.59100429e-02  1.94114576e-02\n",
      " -2.18531176e-02 -2.49858528e-03 -2.17802556e-02  1.36884974e-02\n",
      " -8.33480536e-03 -2.69286282e-03  3.70564520e-02 -3.92231792e-03\n",
      "  1.11618510e-02  5.75769024e-03 -7.77299756e-03  2.73761776e-03\n",
      "  7.75296801e-03  1.03443685e-02 -1.26874220e-02 -1.34587069e-02\n",
      " -1.41083931e-02  6.04689240e-03  6.92948488e-04 -2.06041329e-02\n",
      "  1.45166627e-03  2.36162773e-02  1.83318019e-02  1.90719262e-02\n",
      "  4.14564193e-03 -6.78071925e-03 -1.80510706e-02 -4.65545739e-04\n",
      "  2.17877655e-02  1.86245549e-02 -1.16692401e-02  4.18175191e-03\n",
      "  7.98850962e-03 -2.15471002e-02  6.02292418e-04  1.77873302e-02\n",
      "  9.40450540e-03  1.22704011e-02 -1.81821115e-02  9.99426430e-03\n",
      "  1.52713636e-02  1.03303843e-02  7.51341082e-03 -1.14949699e-03\n",
      "  1.00649688e-02  4.16320975e-03  1.33791531e-02 -2.46809702e-02\n",
      " -8.16749401e-03 -1.54289143e-02  1.32072903e-02 -3.05784893e-03\n",
      " -1.16410163e-02  4.02770802e-03  6.33227487e-03 -6.76919896e-03\n",
      "  3.94276733e-03  7.31687543e-03  1.13735391e-02 -6.74816961e-03\n",
      " -3.20770620e-02 -2.54645913e-04  1.34361858e-02  5.42712628e-03\n",
      "  1.43353486e-02 -2.07771849e-02 -6.33331092e-04 -1.31712804e-02\n",
      " -5.20143374e-03  8.67324902e-04 -4.99946149e-02 -1.09960046e-04\n",
      "  1.07511162e-02  7.59373614e-03 -1.49021222e-02 -1.45547787e-02\n",
      "  1.39234746e-02  7.74364277e-04 -4.22669952e-03  5.69209025e-02\n",
      "  2.75007036e-02 -6.19636537e-03  7.60537467e-03  1.30522569e-02\n",
      "  2.10351000e-02 -6.70525482e-03 -1.85340047e-02  1.51603100e-02\n",
      "  1.57919092e-02  1.43403489e-02 -3.87929482e-03 -8.28070598e-03\n",
      " -1.59586544e-02 -6.14720973e-04  1.95212944e-02  2.19196124e-02\n",
      "  9.48560700e-04  1.65724516e-02  1.19946096e-02 -5.61210814e-05\n",
      " -7.98454151e-03  3.33107422e-03 -4.20748016e-02 -9.37780480e-03\n",
      " -1.90351534e-02 -6.07814321e-03 -8.81971743e-03 -1.67052650e-02\n",
      "  1.79871671e-03  6.33106839e-03 -1.86813978e-02 -1.33627111e-02\n",
      "  4.73969732e-03  3.61643503e-02 -9.41953814e-03 -1.98036361e-02\n",
      " -1.76533983e-02 -1.66787534e-02  9.47905548e-03  2.03264842e-02\n",
      " -1.12445479e-02 -2.22130385e-02 -3.19817479e-02  2.68352140e-03\n",
      "  1.43581752e-02  7.38874932e-03 -2.00144413e-02 -3.62505269e-03\n",
      " -2.57118107e-02  1.25881679e-03  7.05959810e-03 -2.18911884e-03\n",
      "  4.28911700e-04 -5.91085085e-03 -1.20891910e-02 -1.71854323e-02\n",
      " -6.69701180e-03  5.41448364e-03  9.89549391e-03  2.87964168e-06\n",
      "  8.57298001e-03  2.60376773e-02 -5.95388905e-03 -2.71103513e-02\n",
      "  1.55209731e-02 -3.19313586e-02  1.69055981e-03  1.93580754e-02\n",
      " -1.11009373e-02 -9.86171405e-03  2.77461534e-02 -2.49267618e-02\n",
      " -1.15647773e-02 -1.77554904e-02  1.46389652e-02  5.71274393e-03\n",
      " -7.62285748e-03  1.33180893e-02 -1.94705167e-02 -3.41723542e-03\n",
      "  1.55038303e-02 -2.13511042e-02 -2.70501962e-02  2.02261958e-03\n",
      "  9.54260738e-03 -1.73347827e-02  1.38672548e-02 -1.12917398e-02\n",
      "  1.92599359e-02 -1.82531396e-03  2.61718975e-03  1.87367926e-02\n",
      "  3.66869085e-02  1.32315822e-02  2.52187225e-02  1.47860096e-03\n",
      " -1.14315047e-02 -4.68466865e-02 -2.11586931e-03  3.65779736e-03\n",
      " -4.95678437e-03  2.68988419e-02 -9.26617645e-03  1.84891973e-02\n",
      " -1.83328928e-02  3.69667475e-02 -1.01019211e-02 -1.06313557e-02\n",
      "  3.35931766e-03 -1.37691490e-02  1.39590711e-02 -2.61822363e-03\n",
      " -4.41676720e-04 -3.90279884e-03 -2.07260845e-02  2.57562884e-02\n",
      " -3.18135373e-02 -1.51342092e-02  1.30515277e-02  2.92409220e-03\n",
      "  4.40214299e-03 -3.73661286e-03  5.62516588e-03 -8.61285011e-03\n",
      " -1.11378982e-02 -2.16981438e-02  6.63479755e-03 -9.38594555e-03\n",
      "  1.59503983e-04  1.16323888e-02 -2.17476852e-03  2.60430211e-02\n",
      " -1.86696298e-02  2.67020933e-02 -4.54219882e-03  2.55690640e-02\n",
      "  6.16202671e-03  3.25406008e-02  7.65046424e-03 -1.25687369e-02\n",
      " -7.14796252e-02  4.41363739e-03 -2.26099704e-03  1.65307338e-02\n",
      " -7.58616756e-03  1.16290559e-02 -5.32885039e-03 -3.06163382e-02\n",
      " -3.26423425e-02  1.18573362e-03 -1.60705348e-02 -4.35304388e-03\n",
      "  1.16805369e-02  1.18396108e-02  2.53727850e-02 -1.16678809e-02\n",
      " -3.94750740e-03 -1.33857560e-02  9.27974466e-03  4.24839847e-02\n",
      "  5.92050532e-03 -9.68226450e-03 -5.02614605e-03 -7.47225224e-03\n",
      " -6.41704814e-03 -1.08263066e-02  3.73419687e-03 -9.43997675e-03\n",
      " -1.67190714e-02 -3.45683777e-03  1.37131933e-02 -5.07980356e-03\n",
      "  2.27318417e-04 -2.89427553e-02  1.26100180e-02  1.43629467e-02\n",
      "  4.62236794e-03 -6.97024157e-02 -4.35743271e-03  8.39916525e-04\n",
      " -7.69228647e-03 -3.19495612e-02  6.51235227e-03 -1.72626967e-03\n",
      " -8.73497523e-03  1.43948409e-02  2.16359261e-02  2.37726733e-02\n",
      " -2.65565453e-02  2.85268770e-02  1.24833172e-02  2.12002124e-02\n",
      "  7.15899159e-03 -4.37668840e-02 -6.50974684e-03  3.05204270e-02\n",
      " -3.65112869e-04 -1.26429702e-02 -4.73969344e-03 -1.73904415e-02\n",
      " -6.00590427e-03  1.57898156e-02 -2.18730272e-02  2.20453423e-02\n",
      "  4.42035159e-03 -1.83642234e-02 -6.34186160e-03  2.42450459e-02\n",
      " -6.83192496e-03  9.34524524e-03 -1.44396121e-02  1.35241747e-02\n",
      " -3.23830294e-02 -4.73801273e-03 -9.65443077e-03  8.91268301e-04\n",
      "  3.85407428e-03 -1.81020451e-02 -1.27538495e-02 -4.32383106e-03\n",
      " -1.79284752e-02 -2.95492289e-02  1.28032912e-02 -1.26325969e-02\n",
      " -2.32961583e-02 -2.31511937e-02 -3.51078871e-03 -1.04960344e-02\n",
      " -6.86393619e-04 -3.68015125e-02  1.15748055e-02 -1.16252776e-02\n",
      " -1.40730367e-03  1.35034062e-03  1.23301480e-02 -1.47262912e-02\n",
      "  1.26328894e-02  1.25801217e-02 -1.73068092e-02 -3.63266830e-03\n",
      " -3.40073069e-02  1.64328756e-02  1.29064690e-02  3.21150550e-02\n",
      "  1.09218666e-02  1.80565007e-02 -2.75688363e-02  3.80958492e-03\n",
      "  9.54783030e-03 -6.59859739e-03 -1.13430180e-02 -2.59677064e-02\n",
      "  1.59621444e-02 -4.46820495e-03  2.19538220e-02 -2.41796230e-02\n",
      "  1.75584588e-02  3.05577849e-02 -4.85889166e-03 -7.94709301e-03\n",
      " -1.24962727e-02  3.22310869e-03 -2.11471979e-02  1.53076047e-02\n",
      " -2.85918804e-02  4.55194693e-03 -1.38877996e-02  3.46932399e-03\n",
      " -1.18314537e-02 -9.79556536e-03  1.26519101e-02  1.86335061e-03\n",
      " -1.91332222e-02  7.93506656e-04 -4.02281606e-03 -9.86895469e-03\n",
      " -1.12787610e-02 -2.85111064e-02 -6.34757773e-03  4.12287708e-03\n",
      " -3.75666312e-03  1.23740181e-02 -1.77179927e-02 -1.71123614e-02\n",
      "  2.44407537e-02  4.26852520e-02  4.46966214e-03  4.28786564e-03\n",
      " -2.51844197e-02  9.19253771e-03  6.39508330e-03 -2.26538328e-03\n",
      " -1.88305411e-02 -3.86306647e-02  2.92544738e-02  1.09515049e-02\n",
      "  1.65451028e-02  1.17085803e-02  2.11577766e-02 -3.12946003e-02\n",
      "  2.11781747e-02 -1.63228006e-02  1.05781599e-02  2.54220299e-02\n",
      " -2.14170087e-02  2.54666975e-02 -8.75979879e-03  1.66550397e-02\n",
      "  7.51363175e-03 -4.03584834e-03 -1.12592380e-02 -1.08242216e-02\n",
      "  5.39166183e-03 -6.40304325e-03  1.27280809e-02  4.35385839e-02\n",
      " -3.73980443e-02 -2.36842202e-02 -4.54914810e-02 -5.95633180e-03\n",
      " -1.45265135e-02 -1.23814279e-02  1.16158385e-04 -1.32816876e-02\n",
      " -4.05199004e-03  1.07007381e-02 -4.13176175e-03  1.82370212e-02\n",
      "  8.05894488e-03  1.37695399e-02 -5.29578381e-03  4.52365235e-03\n",
      " -3.42130998e-02 -6.78155335e-03 -1.34817915e-02 -3.62325590e-02\n",
      "  1.53458619e-02 -2.80853880e-02  2.82876477e-03 -2.20370798e-02\n",
      " -2.76801281e-02 -1.55894873e-02  1.40744639e-03  5.16497511e-03\n",
      "  2.05160111e-02  2.74172330e-03 -8.70164413e-04  1.13037580e-02\n",
      " -8.61457526e-03  1.61300979e-02 -5.82471057e-03 -2.43431440e-02\n",
      "  1.83173017e-02 -3.65271339e-03 -3.28226810e-03  1.22537148e-02\n",
      " -7.93115066e-03 -5.24651167e-03 -1.26550593e-02 -4.07539266e-03\n",
      " -3.58089809e-02 -2.66901769e-02  2.35580933e-02 -4.14246418e-04\n",
      " -8.08805500e-03 -3.49101651e-02  7.10690259e-03  2.56709818e-02\n",
      " -1.85983212e-02  2.16089986e-02 -8.12368169e-03 -2.03012740e-02\n",
      " -3.97502440e-03 -2.62029468e-02  6.95277584e-03 -9.57886234e-03\n",
      " -3.72141235e-02 -3.61275966e-02  1.11546570e-02  8.49829876e-03\n",
      "  5.22420032e-03 -9.01854841e-03 -6.30593469e-04  2.12572573e-02\n",
      " -1.83961461e-02 -3.78613311e-03 -3.78057534e-03 -2.26284042e-02\n",
      "  9.74731307e-04  1.31077501e-02 -1.85632003e-02 -2.71623044e-02\n",
      " -2.75866307e-03 -2.18479206e-02 -9.24121481e-03  9.43983349e-03\n",
      " -1.25531786e-02  1.93012671e-02  5.96349735e-03  2.34776679e-02\n",
      "  1.40804213e-02 -4.27491405e-03 -3.11439157e-02 -1.74216479e-02\n",
      "  1.16030500e-02 -1.43921846e-02  1.74660928e-02 -2.09188960e-02\n",
      "  4.61230164e-02  9.17315067e-04  1.56348504e-02 -1.64993531e-02\n",
      "  7.67956012e-04 -2.32699005e-02 -1.75072160e-03  2.22316105e-02\n",
      "  1.05320675e-02 -9.59305882e-03 -9.78300859e-03 -1.05857967e-02\n",
      " -2.58622157e-02  1.71068520e-02 -3.63461913e-03  1.57737429e-02\n",
      "  1.50583249e-02  2.93786936e-04 -4.31259858e-03  1.56150202e-02\n",
      " -1.83705389e-02  1.54161625e-02  1.28566337e-02  1.06445511e-02\n",
      "  1.14489893e-02  2.77787880e-03  1.54223248e-03  3.45860392e-03\n",
      "  1.49354964e-02 -7.45680354e-03 -4.10505286e-02 -2.77188392e-03\n",
      "  1.91942558e-02 -2.95099345e-02  2.02187567e-02 -1.41855589e-02\n",
      "  8.26497766e-03  2.68417660e-02  6.77289997e-03 -1.80124424e-02\n",
      "  2.02767629e-02  3.23511395e-02  3.00313984e-03  2.28866300e-02\n",
      "  6.47971072e-03  2.94007156e-02 -2.00962199e-02 -1.55940763e-03\n",
      " -1.53650901e-03  7.05422760e-03  1.50329438e-02  1.42194070e-02\n",
      "  3.19397635e-03  2.68380999e-02  1.32277945e-02 -1.21471791e-02\n",
      " -3.31470606e-02  4.05659807e-03  1.33248268e-02 -1.20464928e-02\n",
      " -7.12762039e-03  1.25731874e-02  8.26621176e-03  2.11385954e-02\n",
      "  1.92387611e-02 -4.40569988e-03 -1.01820471e-02 -2.12579994e-02\n",
      "  3.88669511e-03 -4.37324819e-03  1.44609206e-02  6.03287672e-03\n",
      " -7.59672387e-03 -8.51344196e-03 -6.39333635e-04  1.52198351e-03\n",
      "  2.60161280e-02  3.02475680e-02  7.85918875e-04 -1.86983680e-02\n",
      " -1.26129315e-02  9.65532743e-03 -4.99988601e-03  2.92492267e-02\n",
      "  3.37456050e-02 -1.37069337e-03 -1.59245276e-02 -3.24997564e-03\n",
      "  3.30297813e-02 -3.36056561e-02  2.37508733e-03  3.44081396e-02\n",
      "  1.40920132e-03  1.58183000e-02  2.62838641e-02 -2.86506444e-02\n",
      " -1.91946873e-02  2.48127170e-02  1.87664869e-02  2.40291748e-02\n",
      "  1.89223703e-02  9.43732128e-03  4.50357447e-05  1.75908371e-02\n",
      " -7.24630814e-03  1.36123249e-02  1.16656233e-02 -1.03795317e-02\n",
      " -8.86094763e-03 -1.45125966e-02  1.46903020e-02  2.73548811e-02\n",
      "  2.24751133e-02  3.45579483e-03 -4.44853096e-03 -8.95404029e-03\n",
      "  4.35539223e-04  2.54022722e-02  1.83295167e-02  1.47066733e-02\n",
      "  7.33307064e-03  3.40185446e-03 -6.35959166e-03 -2.32174486e-02\n",
      " -1.89951387e-03  9.03149094e-03 -1.75355770e-02 -3.17684391e-03\n",
      "  1.51872652e-02  1.42299357e-02  2.45316690e-03 -4.55794871e-02\n",
      "  2.71560269e-02  2.25154840e-03 -1.78176788e-02  2.09427841e-02\n",
      "  3.19796431e-04 -4.05989217e-03  5.10872533e-04  3.24541240e-02\n",
      " -5.14502711e-03 -2.28848643e-02  1.86561298e-03  2.11960027e-02\n",
      "  5.22110558e-03 -2.48998476e-03 -2.00112102e-02 -3.06730171e-02\n",
      " -7.29237378e-03  1.33514592e-02 -9.19534421e-03 -1.51125718e-02\n",
      " -9.30283530e-03 -1.71863488e-02 -9.49623192e-03  1.55243526e-02\n",
      " -6.89141598e-03  1.76793507e-02  9.94900817e-03  7.63596571e-03\n",
      " -5.01296101e-03  3.23163068e-03 -3.36699537e-02  2.19725821e-02\n",
      "  2.52745091e-02  3.12527893e-02  7.87814903e-03  1.12722276e-03\n",
      "  2.48621950e-02  4.12984155e-03 -1.16371979e-03 -6.19008051e-03\n",
      "  1.13899104e-02  2.92602559e-02 -2.45361644e-02 -6.01779824e-03\n",
      "  7.16788920e-03  6.07101260e-03 -6.28102817e-03  2.44241900e-03\n",
      " -2.03517617e-02 -4.27369980e-02 -1.21836274e-02 -1.29902205e-02\n",
      " -2.33978120e-02 -8.30225615e-03 -1.06389407e-02 -2.63552901e-02\n",
      " -7.34505523e-03  3.70450767e-03  1.52782952e-02  8.87683043e-03]\n",
      "weight [-1.50951960e-02 -8.30763614e-03 -1.65244200e-02  1.60697063e-02\n",
      "  2.66554883e-04  8.25748244e-03  2.47778657e-03  2.22889418e-02\n",
      "  1.59517694e-02 -2.08473199e-03 -4.03059219e-03 -1.33854090e-02\n",
      " -7.65273136e-03  2.08170248e-02  1.58345330e-03  2.17545224e-02\n",
      " -1.92473161e-03  1.51454654e-04  1.44171272e-02  1.34809639e-02\n",
      "  1.33285377e-02 -8.29063402e-03  3.82131708e-03  3.07077053e-03\n",
      " -1.32356461e-03 -1.73999243e-02  1.91567495e-02  2.54897174e-02\n",
      " -6.91589045e-03  7.67517475e-03  1.12887572e-02 -2.68274504e-02\n",
      " -1.94104505e-04 -7.47167748e-03 -6.21586460e-03 -2.95078632e-02\n",
      "  5.57576202e-04 -5.98431094e-03 -2.49293301e-03  8.34350879e-03\n",
      " -3.14523754e-02  1.12578322e-02  1.13111531e-02 -1.07870277e-02\n",
      "  1.06148766e-02 -1.20311891e-02 -3.54679133e-02  2.29123218e-02\n",
      " -5.18710155e-04 -8.10736825e-03 -2.07950423e-02  2.32150736e-02\n",
      "  6.17989572e-03 -1.05151612e-02  1.19263604e-02  2.19667689e-02\n",
      " -2.69105684e-02 -1.33353900e-02 -2.29222032e-02 -1.13229470e-02\n",
      "  3.63705160e-02 -4.34765957e-03  1.74531339e-02 -2.25791507e-02\n",
      "  4.30528865e-02  4.33741092e-03 -1.51982219e-02  1.28473469e-02\n",
      "  6.01414772e-03 -2.71376793e-02 -1.99388280e-02  2.42196787e-02\n",
      "  2.14681816e-02  4.35038021e-03 -3.71063200e-03  1.22149071e-02\n",
      "  1.85961758e-02  2.06986819e-03  1.60238253e-02  6.34612443e-03\n",
      " -7.53938735e-03 -4.28097323e-03 -5.32564431e-03  1.39852850e-02\n",
      " -4.17330263e-03 -1.93640509e-02 -2.54696662e-02  1.11546311e-02\n",
      "  1.56226904e-03  6.31953839e-04 -1.51488768e-02 -4.26385633e-03\n",
      "  3.98493735e-02 -5.59392586e-03  9.21710064e-03 -1.60309730e-03\n",
      "  9.79444949e-03  1.40998458e-02 -1.58346212e-02 -2.37349810e-03\n",
      "  9.44115476e-03  9.22060445e-03 -4.51193399e-03 -1.07233274e-02\n",
      "  6.28599219e-04  6.25763203e-03  1.83257609e-02 -1.59582126e-02\n",
      " -3.85339886e-04  8.99940614e-04 -4.96454368e-03  5.89525716e-03\n",
      " -1.65567422e-03 -1.82699899e-02 -9.65130754e-03  8.19334110e-03\n",
      "  1.10550693e-02  2.00383431e-02 -2.15521600e-03 -1.81302413e-02\n",
      "  1.77846653e-02  1.50750159e-03  1.22243052e-02  1.88394594e-02\n",
      " -7.83241134e-03  1.06016467e-02 -3.24594850e-02  1.23908865e-02\n",
      " -6.43385954e-03  1.00055438e-02  2.66086140e-02 -4.43111978e-03\n",
      " -5.60175334e-03  2.04087979e-02  1.20289830e-03 -2.24847738e-02\n",
      " -2.81640805e-02 -1.44949844e-02 -5.16253539e-03 -1.69969306e-02\n",
      " -1.26340968e-02 -6.55790312e-03 -3.77861330e-03  3.77662649e-04\n",
      "  4.82575215e-03  1.26662740e-02  1.49240305e-03  8.44682465e-03\n",
      " -1.66814460e-02  5.55076856e-03  1.09526078e-02  1.52649290e-02\n",
      " -1.76789654e-03  4.71598704e-03  2.66480298e-03  5.72358460e-03\n",
      " -5.16323701e-03 -1.72467939e-02 -4.20300012e-02  1.44995980e-02\n",
      "  2.66909778e-02 -1.00138693e-02 -1.39842399e-02  4.72712847e-03\n",
      "  3.10595929e-02 -7.89506830e-03 -5.17960698e-03  2.12326615e-02\n",
      "  2.84690606e-03  9.64475386e-03 -8.20037893e-03 -5.51291725e-04\n",
      "  2.97368676e-02  2.82841439e-03 -1.79144410e-02  3.84337091e-02\n",
      " -1.52320018e-02  1.21022233e-02 -1.46674927e-02 -1.71780467e-02\n",
      " -1.79845914e-02  1.50038743e-02  4.62479515e-03  1.78463186e-02\n",
      "  9.78295595e-03  2.66141502e-03  2.34094109e-02 -2.31601811e-02\n",
      " -6.36604783e-03  3.00875733e-02 -4.02258520e-03 -2.97760447e-02\n",
      " -9.85010055e-03 -1.02699010e-03  9.55479391e-03 -1.71646769e-02\n",
      " -9.11322232e-04  2.36277381e-02 -1.25584343e-02 -2.31529210e-03\n",
      "  2.77006211e-03  2.10999240e-02 -1.22885769e-02 -2.28906378e-03\n",
      " -6.66092555e-03 -1.81052710e-02 -1.39977684e-02  1.46759675e-02\n",
      "  2.39668898e-02 -9.11120267e-03 -1.09811760e-02 -2.05124262e-02\n",
      " -1.66169241e-03  5.03985708e-03  1.03327852e-02 -5.17208629e-03\n",
      "  7.68655696e-03  3.67852423e-03  8.43629509e-03  7.94028905e-03\n",
      " -1.43713913e-02 -5.23316093e-03 -2.54857303e-02 -1.22108553e-02\n",
      "  1.01911337e-02  1.52760583e-02 -3.65699692e-03 -1.49683477e-02\n",
      " -3.84490827e-03  2.42637076e-02 -2.05558666e-02 -6.42293558e-03\n",
      "  2.07702343e-02 -6.43857286e-03 -3.18047416e-03 -2.65949828e-03\n",
      "  6.65650954e-03 -7.46665218e-03  2.00286015e-02 -1.36316977e-02\n",
      " -1.07762556e-02  2.02963704e-02 -3.81484150e-03 -1.09445206e-02\n",
      "  1.63462503e-02  2.86500679e-02 -2.46545691e-02  7.10605037e-04\n",
      "  1.82154115e-02  9.83900486e-03 -1.62759048e-02  9.46592308e-03\n",
      "  6.16807036e-03  4.85372224e-03  1.26192789e-02 -1.70556514e-02\n",
      "  1.01631239e-02 -7.48158222e-03  6.55118503e-03 -5.78669810e-03\n",
      " -7.53129493e-03 -4.42483233e-03 -1.19346297e-02  7.73759525e-03\n",
      " -2.83573598e-02 -3.59243306e-02 -2.50297255e-02  6.33977441e-03\n",
      "  6.50177330e-04 -8.13065479e-03  2.17539304e-02 -1.09147675e-02\n",
      " -2.09252184e-02  1.76222938e-02 -3.71083119e-02  6.15826314e-03\n",
      "  4.17371256e-03  7.45804799e-03  3.65882995e-03  4.14650818e-04\n",
      " -1.55604557e-02  1.86327829e-02  1.20434352e-02  1.08221392e-02\n",
      " -9.21407148e-03  1.28104861e-02  4.45877357e-03 -4.58513950e-05\n",
      " -1.20141378e-02  3.84404925e-04  6.39007915e-03 -9.45016801e-03\n",
      " -6.67220593e-03 -7.42619610e-03  1.30975972e-03 -4.92937006e-03\n",
      " -1.84980259e-02  5.26397334e-03  4.20792547e-02  9.34056773e-04\n",
      " -6.23798738e-03  3.12506698e-02 -1.07118770e-02 -7.85354640e-03\n",
      "  8.24802473e-03  1.11807345e-02 -2.25122589e-02 -1.11132973e-02\n",
      " -1.05885307e-01  1.62246059e-02  6.99422439e-03  1.97106651e-03\n",
      "  3.66149018e-03  3.16532966e-03 -4.70676796e-03 -1.55427278e-02\n",
      " -2.84633147e-02  1.57991947e-02 -1.45528318e-02 -1.27398722e-02\n",
      "  1.16896459e-02  2.42299571e-03  2.52504381e-02 -8.51729097e-03\n",
      "  4.82570728e-04 -2.38605120e-02 -6.78389857e-03  2.36111700e-02\n",
      "  2.80474605e-02 -1.20703058e-02 -1.88759181e-02  1.64166372e-02\n",
      "  1.41285409e-02 -6.40929876e-04  2.60121979e-02 -3.30137811e-03\n",
      "  4.98599050e-05 -2.64929157e-02  3.64506895e-02  1.81732208e-05\n",
      " -2.12381382e-02  6.80859829e-03 -1.10728973e-02 -6.87786072e-03\n",
      " -6.58810322e-03 -1.68086292e-02  1.08632882e-02  1.25643891e-02\n",
      " -2.50189793e-02 -2.20687177e-02  4.18009019e-03  1.73753700e-02\n",
      "  1.74311565e-02 -3.14031710e-03  1.71973124e-02 -5.76451966e-03\n",
      " -2.14839194e-02  4.25951928e-03  2.93539061e-02 -9.77948925e-04\n",
      " -5.03818371e-03 -1.34719489e-02 -7.95215282e-03  1.42735288e-02\n",
      " -1.01228654e-02  1.49822438e-02 -1.31131948e-02 -1.51321397e-02\n",
      " -3.33215772e-03 -8.46377844e-03 -8.70436520e-03  3.81079141e-03\n",
      " -5.28515578e-02 -1.85450184e-02 -4.59686476e-03  3.42433776e-02\n",
      " -2.45319063e-03  1.36312904e-02 -2.64100135e-02  2.46993402e-02\n",
      " -9.01278783e-03  1.39674570e-02 -1.69504594e-02 -9.61490155e-03\n",
      "  7.22085933e-03  3.68618644e-03 -7.13815696e-04  4.47060972e-03\n",
      " -2.80670629e-03 -6.50075128e-03  8.29434323e-03  1.35696725e-02\n",
      " -3.33350479e-02  1.58211721e-02 -1.20695325e-04  3.03537284e-02\n",
      " -1.78013472e-02  1.54774343e-02  5.03194460e-03 -1.53732209e-02\n",
      "  2.31392721e-02  1.08637044e-03 -3.02755261e-03 -4.28415816e-03\n",
      "  2.09031686e-02 -8.69328245e-03 -1.07290116e-04  2.13999211e-04\n",
      " -2.27235474e-02  1.30670342e-02  6.10831655e-03  6.88455636e-03\n",
      "  2.35060678e-02 -2.34769671e-02  1.45740860e-02 -7.76769783e-03\n",
      "  1.07686819e-02 -1.58881786e-03 -3.09836370e-03  1.37334647e-03\n",
      " -7.43281968e-03  4.83924960e-03  1.07264696e-02 -3.60447469e-03\n",
      "  2.00216215e-02 -5.85208648e-03  4.92559181e-03 -1.22676291e-02\n",
      " -2.08154300e-02  8.28974254e-03 -3.75958181e-02 -1.23321277e-02\n",
      " -2.05314072e-02  6.15267084e-03 -2.42577416e-03  3.63715680e-03\n",
      "  1.73012445e-02  1.05491076e-02  8.50431996e-03 -9.78302930e-03\n",
      " -1.97878223e-03  7.10559772e-03  1.96255872e-02 -1.89427649e-02\n",
      "  1.35493728e-02 -3.22785157e-02 -5.23617663e-02 -1.78496429e-02\n",
      " -1.41915102e-02  1.20658630e-02 -1.73630238e-02 -3.63424329e-03\n",
      "  3.67453929e-02  1.15738924e-02 -1.40524684e-02  6.74509946e-03\n",
      "  2.14859975e-03  5.90787347e-03 -2.79986022e-02  4.11231688e-03\n",
      "  7.47344319e-03 -3.49413266e-02  1.26308372e-02  1.38151982e-02\n",
      " -3.51829882e-04  1.58683942e-02  1.11432929e-02 -1.89652152e-02\n",
      "  2.31454961e-02 -1.01879069e-02  5.96074479e-03  1.09348126e-02\n",
      " -2.09698842e-02  2.13280412e-02 -3.14500246e-02 -1.32836665e-02\n",
      "  3.83384779e-02  1.46232161e-03 -2.79044964e-02 -9.88946062e-03\n",
      "  1.08674117e-02 -7.86842638e-03  2.55446047e-02  1.55642460e-02\n",
      "  8.30088742e-03 -3.55167285e-02 -9.78088646e-03  7.10675674e-03\n",
      " -2.47515832e-02 -1.24893100e-02 -1.12736356e-02  2.65491139e-03\n",
      "  9.57561657e-03  5.05393317e-03 -1.69619339e-02  1.49887992e-02\n",
      " -5.12226398e-03  7.16397546e-04 -1.34563233e-02 -2.13802812e-03\n",
      " -4.40015669e-02  1.16826418e-02 -2.02441947e-02  1.46030416e-02\n",
      "  2.05036960e-02 -2.24273596e-02  5.40437566e-03 -1.04834008e-02\n",
      "  4.78267684e-03 -1.67192440e-02  8.85693723e-03  5.73113031e-03\n",
      "  1.86484240e-02  2.07498043e-03  1.86356360e-02 -1.01477770e-02\n",
      " -2.25067736e-02 -5.20688925e-03 -1.13362097e-02  1.66666689e-03\n",
      "  1.19529859e-02 -1.85811664e-02  9.15237332e-03 -6.88231815e-03\n",
      " -8.78600316e-04  2.68512815e-02 -9.00860742e-03 -8.71091715e-03\n",
      " -1.95035975e-02 -1.14069358e-02 -1.06891868e-02  3.39422795e-04\n",
      " -1.45112227e-02 -2.72265726e-02  2.81808729e-02  2.78950244e-03\n",
      " -1.87827590e-03  4.03763261e-03  2.35414105e-03 -1.69796429e-02\n",
      " -5.55980814e-03  2.64136907e-03  1.84049246e-02  1.21064011e-02\n",
      " -1.67885039e-02 -3.62821475e-02  1.92058357e-03 -3.20629397e-02\n",
      " -1.17173019e-02 -3.11435632e-03 -3.16579957e-03  1.58855853e-02\n",
      "  7.57082760e-03  6.42279836e-03  1.93677239e-02 -9.41462762e-03\n",
      " -1.00104129e-03  1.33909789e-02  3.16275962e-03 -1.06372000e-02\n",
      "  4.70895223e-03 -6.07580187e-03 -1.80657711e-02 -9.75425489e-03\n",
      " -3.61457987e-03 -4.39539082e-03  7.19644883e-04  5.95769664e-03\n",
      " -4.45868727e-03  2.07926170e-04 -1.03342299e-02  3.60977227e-03\n",
      "  1.08582000e-02  1.26151943e-02  2.19620948e-02 -2.51779044e-03\n",
      "  2.29097224e-02  2.79357390e-03 -5.80991344e-03 -1.36809916e-03\n",
      " -1.35959476e-02 -3.25247215e-02  5.41820666e-03  5.88967609e-03\n",
      "  6.77419793e-03 -5.89227288e-03 -7.62967287e-04  8.63365637e-03\n",
      " -3.89317199e-03 -8.03971620e-03  1.69927830e-02  1.23897128e-02\n",
      "  5.72408342e-03 -1.33873068e-02  9.95194239e-03  2.04684128e-02\n",
      " -5.52235627e-02  1.73567756e-02  6.25231029e-03  1.72431209e-02\n",
      "  9.39351068e-03 -3.22689121e-02  1.02141777e-02  3.47263427e-03\n",
      "  9.79186305e-03 -3.99296591e-03 -1.79879123e-02 -2.78743446e-03\n",
      " -7.33110557e-03 -1.02887355e-02  1.80697841e-02  1.79848158e-02\n",
      " -5.10514406e-03  2.42276546e-02 -6.18582373e-03  7.21167865e-03\n",
      "  2.28156079e-02  2.76829933e-02  3.96166288e-03 -1.60017472e-03\n",
      "  6.01146592e-03  1.58862826e-02 -2.78083038e-02 -1.38149825e-02\n",
      "  6.37962122e-03  1.79439127e-02  1.54080795e-02  1.03239126e-02\n",
      " -1.27112221e-02  3.09796111e-03  1.58901437e-02 -2.27950701e-02\n",
      "  9.63323443e-03  1.11370499e-02  4.93554747e-03 -2.18909553e-03\n",
      " -7.36301637e-04  6.71442384e-03 -1.28480347e-02  1.55566464e-02\n",
      "  5.40082093e-03  2.03390910e-02  4.91581264e-03 -1.40335703e-02\n",
      " -2.28166629e-03 -6.23462769e-03  1.24368805e-02 -2.63032818e-02\n",
      "  9.06071152e-03 -7.06269069e-03 -2.40440376e-02 -2.82777016e-03\n",
      "  2.68734366e-02  1.96050942e-02  7.64179964e-03 -7.93435674e-03\n",
      "  1.63896958e-02 -1.67462739e-03 -1.58444457e-02  2.07924067e-02\n",
      " -1.16174493e-02 -4.74606114e-03 -9.75786140e-03 -1.03402148e-02\n",
      " -8.14420919e-03 -9.78210847e-03 -1.10457057e-02  1.67811942e-02\n",
      " -4.31932530e-03  2.56067343e-02  8.02700064e-03 -3.57685784e-02\n",
      " -2.96348221e-02  2.40102232e-02  4.62685541e-02  2.14185949e-02\n",
      " -9.80052614e-04  1.03246177e-02  4.50882717e-03  1.94897083e-02\n",
      " -1.22379434e-02 -9.35769930e-03  1.47936852e-02 -1.08572567e-02\n",
      "  1.15488048e-02  1.57020019e-03  1.09445888e-02  1.42087341e-02\n",
      "  1.98157199e-02  2.91345985e-02 -3.16668950e-02 -1.96942464e-02\n",
      "  3.05180209e-02 -7.22179138e-03  4.68792591e-03  3.91694181e-03\n",
      " -2.01549010e-02 -7.93265769e-04 -7.26438815e-03 -8.89400083e-03\n",
      "  7.00708536e-03 -7.21894604e-03  9.61795142e-03 -3.29828751e-02\n",
      " -8.85704079e-03 -1.96522420e-02  1.18254394e-02 -1.24451567e-02\n",
      "  2.11747951e-02 -9.80069982e-04  2.64764116e-02 -9.40057095e-03\n",
      " -1.40016562e-02 -2.63890303e-02  1.39441471e-02  2.26781998e-02\n",
      " -1.98263849e-02 -2.32115603e-03  1.80894710e-02  2.17773749e-02\n",
      " -1.16554027e-02 -1.19756287e-03  4.26318318e-03 -5.31508593e-02\n",
      "  6.97484900e-03  9.49442478e-03 -4.89029824e-02 -4.83502388e-03\n",
      " -8.75228026e-03 -9.50610560e-03  1.15895914e-02  2.86726485e-03\n",
      " -1.87402101e-02 -1.45415087e-03 -1.86665679e-02  8.16637728e-03\n",
      "  2.39449297e-02  9.16741382e-03 -1.35511109e-02 -4.48355873e-03\n",
      "  1.19567262e-02  8.94708013e-03  1.22450433e-02 -8.39324308e-03\n",
      "  1.30591757e-02 -6.52864672e-03  3.66661429e-03  1.20914814e-02\n",
      "  6.53681077e-03 -1.10789548e-02  2.99186529e-03 -1.04663132e-02\n",
      "  2.26477335e-03  1.24265615e-02 -4.95869637e-03 -7.54726921e-03\n",
      " -1.83614342e-03 -1.64646912e-02 -9.94971756e-03  1.17878284e-03\n",
      " -1.21861875e-03 -2.54649628e-02  1.11250334e-02 -4.31266702e-02\n",
      " -2.78324870e-02  1.12918545e-02  7.97369091e-03  2.90238332e-02]\n",
      "grams [ 3.09434389e-02  8.86187795e-03 -2.11664015e-02  2.16859564e-02\n",
      "  6.68712302e-03 -1.02760718e-02  3.40210288e-02  2.02513214e-02\n",
      " -2.15720221e-03 -5.73054433e-03 -1.81319448e-02 -4.49354847e-03\n",
      " -3.26690060e-02  2.39687487e-02 -1.95415198e-04 -4.74664367e-03\n",
      "  1.12214469e-02  1.56768720e-02  5.17799013e-03  4.28397951e-03\n",
      "  2.48896101e-03 -6.49175270e-03  1.06948904e-02 -2.45378530e-04\n",
      " -1.56231653e-02 -1.45371337e-02  3.87698886e-03  1.31678430e-02\n",
      " -1.77079749e-02 -1.38832214e-02  1.49621806e-02 -1.06615929e-02\n",
      " -1.09673817e-02 -2.89891264e-03  1.47335750e-02  1.50967874e-02\n",
      " -2.74240206e-03 -9.96047150e-03 -2.89325476e-02  1.65947586e-02\n",
      " -2.52333902e-02 -8.53376320e-03  1.08021903e-03 -1.75727036e-02\n",
      "  1.29506231e-02 -2.28964873e-02  1.87860772e-02  5.83013242e-03\n",
      "  1.09703237e-03 -3.59175935e-03  1.91682983e-02  4.18465378e-03\n",
      " -1.89758561e-02 -3.30260600e-02  2.27390695e-02  3.98306324e-02\n",
      " -3.42637584e-02 -2.33403012e-02 -1.10035063e-02  4.72027446e-03\n",
      "  1.36312705e-02 -1.92367348e-02  4.81431611e-04 -3.30529997e-02\n",
      "  1.51823754e-02 -1.33030703e-02  8.34330340e-03  2.76058663e-02\n",
      " -2.00870323e-02 -2.73160303e-02 -2.26380389e-02  1.82964462e-02\n",
      " -1.69191529e-02  1.64348001e-02  9.09698288e-03 -7.89901656e-03\n",
      "  5.32956798e-04 -1.19667871e-02  2.39357007e-02  1.58771828e-03\n",
      " -1.19234620e-03  2.82782254e-02  1.20068367e-02  3.25807617e-02\n",
      " -3.86452358e-03  4.48865349e-03 -8.02370049e-03  1.02564832e-02\n",
      "  9.21420093e-03  2.27805387e-02 -2.05843303e-02 -2.66765569e-02\n",
      "  1.74210576e-02 -2.78817716e-02  1.20688931e-02  2.19509793e-02\n",
      "  2.09740750e-02  1.44152692e-02 -3.68860804e-02  5.95824724e-03\n",
      "  7.30971074e-03  1.18665281e-02 -6.70815668e-03 -4.41086153e-04\n",
      " -1.16718594e-02  9.64955823e-03  1.22653370e-02 -3.08285174e-02\n",
      " -4.01333635e-03 -6.26002989e-03 -2.47642315e-02 -9.55988135e-03\n",
      "  7.51583932e-03  1.13049774e-02 -1.98823458e-02  2.72407483e-02\n",
      "  1.90049084e-02 -1.05269728e-03 -1.77227835e-03  1.27113569e-03\n",
      "  3.51128753e-02 -2.24767133e-02  1.48609791e-02  3.36093878e-02\n",
      "  1.47245376e-02 -2.63644466e-02  5.79714869e-03 -2.01330837e-03\n",
      "  6.78950726e-03 -6.93418320e-03 -9.46913865e-06  2.45033425e-02\n",
      " -1.58074019e-02  8.63424753e-03 -1.27959168e-02  1.86089656e-02\n",
      " -1.27547108e-02  3.83422283e-04 -1.01676417e-02 -1.30652504e-02\n",
      " -4.59256569e-03 -2.28006192e-02 -5.62467030e-04 -4.91481802e-03\n",
      " -3.19447594e-02  1.94111314e-02  1.11180577e-02  6.39090677e-03\n",
      " -5.92602684e-03  7.00369633e-03  2.60815250e-02  1.38787833e-03\n",
      "  3.53058201e-03 -9.17952355e-03  1.93002573e-02  4.65443257e-04\n",
      " -2.37001582e-02 -7.45622273e-03 -3.15219995e-02 -1.75513200e-02\n",
      "  7.73181309e-03 -3.62906464e-02 -2.42506693e-02  1.75906214e-02\n",
      "  1.59214726e-02 -3.07364909e-04 -2.10624298e-02  3.07882701e-02\n",
      "  3.91385397e-03  6.73006327e-03 -1.09830824e-02 -2.03201239e-02\n",
      "  5.36535925e-02  1.46391861e-02  1.57912343e-02 -3.72255446e-03\n",
      "  3.75534824e-02 -4.59397498e-03  1.25601068e-02  5.54389988e-03\n",
      " -2.04399318e-02  1.65997364e-02 -1.71546115e-03  4.28797049e-03\n",
      "  2.74098772e-02 -3.08801321e-02  2.05375950e-02 -1.54617189e-02\n",
      "  1.17997925e-02  3.03740816e-02 -3.73920067e-02 -2.28619946e-02\n",
      "  2.77966911e-03 -5.86076122e-04  1.39937753e-02 -1.49446546e-02\n",
      " -4.17739502e-03  3.55493951e-02 -1.23239335e-02  1.91243435e-02\n",
      " -6.60326303e-04 -2.00917500e-03 -1.18543864e-02  8.29365973e-03\n",
      " -4.15459297e-02 -2.48430017e-02 -2.08528190e-02 -4.22308266e-03\n",
      " -6.65944679e-03 -8.10765477e-03 -2.36675020e-02  5.96620892e-03\n",
      " -1.61293332e-02  1.19412740e-02 -2.05252643e-02 -3.39247335e-03\n",
      "  9.93254543e-03 -7.54182794e-03 -1.09667206e-02  6.25935286e-03\n",
      " -8.47652938e-03  5.69729695e-03 -3.03458716e-02 -1.17770290e-02\n",
      "  3.98663402e-03 -1.10363800e-02 -1.98640760e-02  1.79943641e-02\n",
      "  2.07955912e-02 -1.98305705e-02  1.72752058e-02 -1.89981252e-02\n",
      "  3.72002982e-02 -1.87191889e-02 -2.54683631e-02  2.05930734e-03\n",
      " -4.91689787e-03 -1.75614276e-02 -3.88124738e-03 -2.60713623e-02\n",
      " -7.66563592e-03  3.34794464e-02  2.60726991e-03 -2.76419383e-02\n",
      "  1.49225668e-02  4.69635577e-03 -2.31241971e-02  2.31239296e-02\n",
      "  1.09548698e-02 -3.85111071e-03 -3.11922717e-02  8.31290308e-03\n",
      " -1.16677825e-02 -1.43413869e-03 -2.12061862e-02 -9.66761149e-03\n",
      " -1.66249673e-02  1.20785838e-02 -1.05260135e-02 -2.54594310e-02\n",
      "  3.71122610e-02  5.70903429e-03  1.93192901e-02  1.20175648e-02\n",
      " -3.03592654e-02 -3.33747566e-02 -1.17486533e-02 -9.19254289e-03\n",
      "  1.50133311e-02  1.99529891e-03  1.62540154e-02  1.31182399e-02\n",
      " -5.62106832e-03  2.88932791e-02 -5.56499352e-03 -4.81525668e-03\n",
      "  3.04601062e-02 -8.22135261e-03  1.08491177e-02  8.82110255e-03\n",
      " -2.35705431e-02  3.04023468e-02 -4.32612580e-03  2.59419771e-03\n",
      "  7.48984725e-03 -1.12492867e-02  1.54575834e-02 -4.71091169e-03\n",
      "  8.73126602e-03 -7.73497861e-03  1.27991583e-02 -2.71637680e-02\n",
      " -2.08121847e-03 -2.99334918e-02 -9.08355189e-03 -2.82541199e-02\n",
      " -1.00308532e-02  1.73787564e-02  3.39300677e-02  2.86050172e-02\n",
      " -6.91035296e-03  4.19220251e-03  7.85749725e-04  1.98904926e-02\n",
      " -6.28837323e-03  3.45535124e-03 -2.12078846e-03 -1.21791717e-02\n",
      "  3.26372443e-03  1.61455459e-04 -6.92748928e-03  2.26190331e-04\n",
      "  5.94558648e-03  2.31034090e-02 -1.57501707e-02 -4.40706283e-02\n",
      " -5.18471961e-02  1.69180517e-02  2.00279819e-02 -1.51352413e-02\n",
      "  1.86449444e-02  1.18162345e-02  1.71993146e-02 -2.07020100e-02\n",
      " -2.18811214e-03 -9.87316703e-03 -2.43537556e-02  7.25535505e-03\n",
      "  2.93958517e-02 -1.66431233e-02 -1.20746579e-02  4.32493830e-03\n",
      " -1.22338889e-02 -4.01608071e-04 -2.60490807e-03  3.70208391e-03\n",
      " -4.32411534e-02 -2.99621299e-02  1.68943397e-02 -1.68569594e-02\n",
      " -2.90940751e-02  1.76372445e-02 -1.70005276e-02  8.55910921e-04\n",
      " -3.96721893e-03 -1.73279649e-02 -1.35085586e-02 -5.13071067e-03\n",
      "  7.39599028e-04 -5.07017015e-02  1.16205207e-02 -2.19704125e-02\n",
      "  3.00463526e-02  1.39255329e-02  1.53105424e-02  1.21879968e-02\n",
      " -1.86977052e-02  3.00915293e-02  1.32756051e-02  1.70809686e-02\n",
      "  1.76065741e-03  2.55670170e-02  1.00827308e-03  1.22276822e-02\n",
      "  2.26641328e-02  1.21870259e-02  2.60613376e-03 -2.80456430e-02\n",
      "  1.14771285e-02  3.68156590e-03 -7.77297080e-03  2.86216093e-02\n",
      " -4.48466122e-03 -2.52923319e-02 -2.51023321e-02  7.73322152e-03\n",
      "  6.15443656e-03 -3.34658635e-03 -2.22690270e-02  3.02087292e-02\n",
      " -2.90349418e-02  9.14263147e-04 -6.94609400e-03 -1.44524709e-02\n",
      "  1.37840393e-02  1.33204651e-02 -5.87710508e-03 -1.62943887e-02\n",
      "  9.32742585e-03 -1.26215504e-02  2.02263304e-02  7.71678985e-03\n",
      " -3.06458048e-02  4.76176756e-04 -1.02828861e-02 -3.75878008e-03\n",
      " -6.51169250e-03 -1.97309466e-02  1.82955556e-02 -2.16478564e-02\n",
      " -3.07009868e-03  1.65954611e-02 -8.66004629e-03 -3.00302385e-02\n",
      "  1.56254971e-02  3.73011320e-02 -3.06011497e-03 -9.17385531e-03\n",
      "  2.28231592e-03 -3.96449571e-03  3.09457863e-02  3.04871321e-02\n",
      "  1.37348090e-02  1.58954788e-02  1.59601457e-02 -1.64590592e-02\n",
      "  6.58942276e-03 -4.83227218e-03  7.49911077e-03 -2.02962859e-02\n",
      "  5.91742783e-03  1.30407573e-02 -8.03311073e-04 -1.28707612e-02\n",
      "  2.71703373e-02  4.23776691e-02  2.57831021e-02  6.18508456e-03\n",
      "  5.87664639e-03  4.13846257e-03 -2.29326456e-02  2.81856164e-03\n",
      " -4.07949108e-03  1.40256772e-02 -2.24024929e-02  1.21317088e-02\n",
      "  2.48058008e-02 -3.45928440e-03  2.09580593e-02 -2.23298467e-02\n",
      "  1.03798726e-02 -4.56848000e-03 -2.23619376e-03  8.29326188e-03\n",
      "  5.04788737e-03 -2.64681560e-02 -2.73072794e-02 -1.98252337e-02\n",
      " -1.42923918e-03  2.69676840e-02 -2.48099312e-02  2.32921911e-03\n",
      " -6.33200087e-03  6.65415482e-03 -6.35202740e-03 -1.16791578e-02\n",
      " -5.01538606e-03  4.12834251e-03 -2.92034424e-02  1.30522845e-02\n",
      " -1.51221706e-03 -3.73566890e-02  2.36136434e-02  1.01329186e-02\n",
      "  1.31260268e-05  4.33112193e-02  2.37529415e-02 -9.12792776e-03\n",
      "  3.69121519e-03 -2.62857110e-05  3.77005269e-03  4.98364161e-03\n",
      " -1.51759442e-02  1.27364012e-02 -3.24604766e-03 -5.09182311e-03\n",
      "  2.01123116e-02  2.27184229e-02 -1.48390743e-02 -1.08178699e-02\n",
      "  1.13804923e-02 -1.45035281e-02 -1.25621159e-03 -1.61449727e-02\n",
      " -1.34890347e-02 -9.88821185e-03 -1.33349421e-02  1.13090966e-02\n",
      " -1.64310960e-02 -6.93469755e-03 -2.24884815e-04 -7.92070913e-03\n",
      "  9.64720221e-03 -2.57854546e-02 -1.40165716e-02 -2.50264426e-02\n",
      "  4.89622538e-03  1.22438947e-03 -2.56529001e-02  1.42393701e-02\n",
      " -4.13883064e-02 -2.03577993e-02 -4.28985358e-02  3.78354280e-03\n",
      " -7.15295862e-04 -2.74176011e-02  1.57134342e-02 -3.30448710e-03\n",
      "  2.04153827e-02 -5.06172182e-03  2.43998005e-02  9.98747588e-03\n",
      "  1.56097369e-02 -1.15204817e-02  3.56812307e-03  7.82799705e-03\n",
      " -1.76743591e-04 -1.36916153e-03 -2.59386489e-02  1.05026519e-02\n",
      " -2.59575988e-02 -1.91861366e-02  6.90669252e-03 -1.00461993e-02\n",
      "  1.01435642e-03  3.32581850e-02  7.66099035e-03 -1.90100053e-02\n",
      " -3.48814787e-02  4.98552167e-03  6.33280088e-03  7.73705587e-03\n",
      " -9.47670723e-03 -3.02136380e-02 -9.55083271e-03  1.92576075e-02\n",
      " -2.27594227e-02  2.10016268e-04 -1.65042739e-02  6.16782613e-03\n",
      "  1.90425787e-02  1.41041712e-02  1.27628291e-02 -1.02660738e-02\n",
      " -1.20058969e-02 -1.61393441e-02  1.75158124e-02 -2.35568437e-02\n",
      " -2.71519573e-03 -3.12269750e-03 -1.94210507e-04 -1.49467121e-02\n",
      "  2.18704882e-02 -1.15565460e-02  1.95965159e-02  2.53453290e-04\n",
      " -2.93204050e-03  2.57212244e-02 -1.60605878e-02  1.65352318e-04\n",
      "  9.27026797e-03 -9.40770630e-03  1.93766059e-02 -2.40313945e-02\n",
      " -3.61418828e-03  6.09793457e-03  2.49076444e-02  2.26435690e-02\n",
      "  6.94579584e-03 -4.99200329e-03 -2.14031815e-02  3.45476569e-02\n",
      "  1.98525910e-02 -4.34217257e-04  1.30067246e-02 -3.33000650e-02\n",
      "  1.69006794e-02 -1.75748266e-02 -1.29305331e-02 -1.43937233e-02\n",
      "  2.83105847e-02 -1.44757410e-02  4.32388975e-03  9.10202630e-03\n",
      " -1.03235648e-02 -3.58562255e-02 -2.28048052e-03 -2.41714171e-03\n",
      " -3.40965799e-02 -1.24164755e-02 -2.01065173e-02  3.44357075e-02\n",
      "  3.54456028e-02 -2.97319208e-02  2.29270205e-02  1.18537711e-02\n",
      " -1.20684831e-02 -1.20373449e-02 -9.46958310e-03  1.66631295e-02\n",
      "  1.12518118e-02 -9.46974276e-03  9.10270980e-03  1.46556782e-02\n",
      "  5.52956273e-03 -6.16918731e-04 -2.26263330e-02 -2.19957573e-02\n",
      "  1.97602388e-02 -5.38841304e-03  3.97858492e-02  5.71520307e-04\n",
      " -2.01382743e-02 -8.69051619e-04 -2.60544611e-02 -6.97981259e-03\n",
      "  2.77197057e-02  5.67422391e-02  1.02730573e-02 -1.43908133e-02\n",
      "  8.95611842e-03  3.37783220e-03 -1.38566122e-02  3.79124644e-03\n",
      " -3.29617892e-04  1.86397974e-02  1.23584439e-03  2.27766647e-03\n",
      "  1.11504351e-02  1.56187985e-02  7.45641777e-03 -2.14373515e-02\n",
      " -6.45913920e-03  1.29700252e-02 -2.13140673e-02 -8.67049559e-03\n",
      "  1.76063454e-02  1.47005857e-02 -1.96593826e-02 -1.15852298e-03\n",
      " -2.44640998e-02  1.83927683e-02  2.81928700e-03 -2.37603013e-02\n",
      " -6.98863210e-03  1.00915892e-02  1.10234332e-02  1.71583735e-02\n",
      "  1.15635898e-02 -8.37578184e-03 -1.07354366e-03  3.02180256e-02\n",
      "  9.23398884e-03  4.12812244e-02 -7.06625362e-03 -1.82525761e-02\n",
      " -1.23674461e-03 -3.35388071e-04  1.68939738e-02  3.09523107e-02\n",
      " -1.46740861e-02  4.12663427e-02 -3.39480908e-03  1.52987140e-02\n",
      " -8.11545722e-03 -3.72001048e-02 -1.34270328e-02  2.56974986e-02\n",
      "  4.29675721e-03  4.11145690e-03 -1.07242853e-02 -2.24760126e-02\n",
      " -1.84682918e-02  3.26087715e-03  1.43160129e-02 -1.02701990e-02\n",
      "  1.76240129e-02 -6.61550458e-03 -6.22196865e-03  1.82107219e-02\n",
      " -3.86406929e-02  7.73805868e-03  1.83482802e-02  1.47146561e-02\n",
      "  4.37039189e-02  7.77627095e-03 -3.41950871e-02 -1.60296437e-02\n",
      " -1.60412676e-03  2.13909216e-02 -5.45766381e-02 -9.66360713e-03\n",
      "  2.47413341e-02  1.16981000e-02  1.12252079e-02 -9.30521116e-03\n",
      " -2.37091611e-02 -3.54180729e-02 -1.03227424e-02 -3.45087050e-03\n",
      " -3.29910581e-03  3.58271395e-03 -3.74423753e-03 -1.19811321e-02\n",
      "  1.68282834e-03 -5.00520861e-05  5.00209833e-03 -1.09113233e-02\n",
      "  1.86566416e-02 -2.97012046e-02 -6.51701121e-03  1.28237531e-02\n",
      " -8.36587364e-03 -2.75134899e-02  2.92605770e-02  1.71855238e-02\n",
      " -1.56770774e-02 -1.19785568e-02 -1.05237430e-02  5.37797539e-02\n",
      " -2.33582708e-02 -3.35503002e-03 -2.42810903e-02 -3.82144049e-02\n",
      "  1.40242541e-02  5.91309726e-03 -4.23136063e-03 -1.22463758e-02\n",
      "  1.05089467e-03 -1.24640057e-02  7.42803862e-04  7.94922119e-03\n",
      " -1.32201905e-02  1.10681862e-02  2.96685661e-03  2.37432862e-02\n",
      " -1.37699032e-02  9.69868495e-03 -3.18294374e-02 -1.46413074e-02\n",
      " -7.31416473e-03  2.26840208e-03  6.07133796e-03 -1.37377320e-02\n",
      "  1.69303047e-02  1.20568819e-03 -3.35119231e-02 -9.09500055e-03\n",
      "  3.85023734e-02 -1.22975392e-05 -4.43288851e-03 -1.14070022e-02\n",
      "  3.95085613e-02  2.21611873e-02 -1.16376005e-02  7.04943187e-03\n",
      "  7.61000298e-03 -3.43293193e-02 -7.68218582e-03  4.86071412e-04\n",
      " -3.55781898e-03 -3.37739876e-02  1.30071509e-02 -1.12712519e-02\n",
      "  3.98895896e-03  1.56520950e-02  3.18674512e-02  7.73536610e-03]\n"
     ]
    }
   ],
   "source": [
    "# Define a function to get the weighted word vectors\n",
    "def get_weighted_word_vectors():\n",
    "    # Retrieve the word vectors (words and their embeddings)\n",
    "    word_vec = get_word_vectors()\n",
    "    \n",
    "    # Retrieve the sentiment scores for each word\n",
    "    sentiment_dict = get_sentiment_dict()\n",
    "    \n",
    "    # Iterate through each word in the word_vec dictionary\n",
    "    for i in word_vec.keys():\n",
    "        # Check if the word is in the sentiment dictionary\n",
    "        if i in sentiment_dict.keys():\n",
    "            # Update the word's embedding vector by multiplying it with its sentiment score\n",
    "            word_vec[i] = sentiment_dict[i] * word_vec[i]\n",
    "    \n",
    "    # Return the updated word_vec dictionary, which now contains weighted embeddings\n",
    "    return word_vec\n",
    "\n",
    "# Call the function to get the weighted word vectors\n",
    "weighted_word_vec = get_weighted_word_vectors()\n",
    "\n",
    "\n",
    "# is nan\n",
    "def isnan(word_vec):\n",
    "    for i in word_vec.keys():\n",
    "        if np.isnan(word_vec[i]).any():\n",
    "            print(i)\n",
    "            print(word_vec[i])\n",
    "            break\n",
    "\n",
    "isnan(weighted_word_vec)\n",
    "\n",
    "# print weighted word vector only 10\n",
    "count = 0\n",
    "for i in weighted_word_vec.keys():\n",
    "    print(i, weighted_word_vec[i])\n",
    "    count += 1\n",
    "    if count == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create CNN And BiGRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a custom neural network model SLCABG (Sentiment-Analysis with Convolutional and Attention Mechanism)\n",
    "class SLCABG(nn.Module):\n",
    "    def __init__(self, n_dim, sentence_length, word_vectors):\n",
    "        # Initialize the parent class\n",
    "        super(SLCABG, self).__init__()\n",
    "        \n",
    "        # Initialize word embeddings using pre-trained word vectors (from word_vectors)\n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(word_vectors)\n",
    "        \n",
    "        # Make the word embeddings non-trainable by setting requires_grad to False\n",
    "        self.word_embeddings.weight.requires_grad = False\n",
    "        \n",
    "        # Define a list of convolution layers with different filter sizes (3, 4, 5)\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Sequential(\n",
    "                # 1D Convolution layer\n",
    "                nn.Conv1d(n_dim, 128, h),\n",
    "                # Batch normalization\n",
    "                nn.BatchNorm1d(128),\n",
    "                # ReLU activation function\n",
    "                nn.ReLU(),\n",
    "                # Max pooling layer with window size (sentence_length - h + 1)\n",
    "                nn.MaxPool1d(sentence_length - h + 1)\n",
    "                           ) for h in [3, 4, 5]]\n",
    "        )\n",
    "        \n",
    "        # Define a bidirectional GRU (Gated Recurrent Unit) layer\n",
    "        # This layer has an input size of 128*3 (from the output of the conv layers), \n",
    "        # 64 hidden units, batch_first=True, bidirectional=True, and a dropout of 0.4\n",
    "        self.gru = nn.GRU(128*3, 64, batch_first=True, bidirectional=True, dropout=0.4)\n",
    "        \n",
    "        # Define learnable weights for attention mechanism\n",
    "        self.weight_W = nn.Parameter(torch.Tensor(128, 128))  # Attention weight for each word\n",
    "        self.weight_proj = nn.Parameter(torch.Tensor(128, 1))  # Projection weight for attention scoring\n",
    "        \n",
    "        # Fully connected layer to predict sentiment (3 classes)\n",
    "        self.fc = nn.Linear(128, 3)\n",
    "        \n",
    "        # Initialize the attention weights randomly with values between -0.1 and 0.1\n",
    "        nn.init.uniform_(self.weight_W, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.weight_proj, -0.1, 0.1)\n",
    "\n",
    "    # Define the forward pass of the network\n",
    "    def forward(self, x):\n",
    "        # Pass input 'x' through word embeddings\n",
    "        embed_x = self.word_embeddings(x)\n",
    "        \n",
    "        # Permute the dimensions of the embeddings for the conv layer (batch_size, channels, sentence_length)\n",
    "        embed_x = embed_x.permute(0, 2, 1)\n",
    "        \n",
    "        # Apply each convolutional layer (with different filter sizes)\n",
    "        out = [conv(embed_x) for conv in self.convs]\n",
    "        \n",
    "        # Concatenate the outputs from all convolution layers (along the channel dimension)\n",
    "        out = torch.cat(out, 1)\n",
    "        \n",
    "        # Permute the dimensions to match GRU input shape (batch_size, sentence_length, channels)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        \n",
    "        # Pass the result through the GRU layer\n",
    "        out, _ = self.gru(out)\n",
    "        \n",
    "        # Apply attention mechanism: calculate attention scores\n",
    "        u = torch.tanh(torch.matmul(out, self.weight_W))\n",
    "        att = torch.matmul(u, self.weight_proj)\n",
    "        \n",
    "        # Apply softmax to get the attention scores\n",
    "        att_score = F.softmax(att, dim=1)\n",
    "        \n",
    "        # Weight the output based on the attention scores\n",
    "        scored_x = out * att_score\n",
    "        \n",
    "        # Sum over the sequence dimension (across all words) to get the final representation\n",
    "        feat = torch.sum(scored_x, dim=1)\n",
    "        \n",
    "        # Pass the final representation through the fully connected layer to predict sentiment\n",
    "        out = self.fc(feat)\n",
    "        \n",
    "        # Return the output (logits for each class)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Training And Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['backlight effect amazingkey life millions keystrokescable length metrekeyboard weight grams', 'nice product', 'nice', 'excellent product', 'quality good', 'good', 'good satisfied', 'best thanks', 'nice produce', 'dont worry must buy product']\n"
     ]
    }
   ],
   "source": [
    "# Get Sentence List\n",
    "def list_sentences():\n",
    "    sentence_list = []\n",
    "    data = pd.read_csv('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/csv/flipkart_clean.csv')\n",
    "    for sentence in data['Summary']:\n",
    "        sentence_list.append(sentence)\n",
    "    return sentence_list\n",
    "\n",
    "print(list_sentences()[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import torch\n",
    "\n",
    "# Function to process data for sentiment analysis, including word indexing, word embeddings, and sentence preparation\n",
    "def process_data(sentence_length, words_size, embed_size):\n",
    "    # Get the list of sentences (this should be a function that loads the dataset sentences)\n",
    "    sentences = list_sentences()  # Assuming this is defined elsewhere\n",
    "    sentences = [str(sentence) for sentence in sentences]  # Convert sentences to string format\n",
    "    sentences = [sentence.split() for sentence in sentences]  # Split sentences into words (tokenization)\n",
    "\n",
    "    # Initialize a counter to store word frequencies\n",
    "    frequency = collections.Counter()\n",
    "    \n",
    "    # Count the frequency of each word in the dataset\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if word is not None and word != 'nan':  # Avoid None or 'nan' words\n",
    "                frequency[word] += 1\n",
    "\n",
    "    # Create a word2index dictionary, mapping each word to an index\n",
    "    word2index = dict()\n",
    "    for i, x in enumerate(frequency.most_common(words_size)):  # Take top 'words_size' frequent words\n",
    "        word2index[x[0]] = i + 1  # Assign an index to each word (starting from index 1)\n",
    "\n",
    "    # Get the word embeddings (weighted word vectors)\n",
    "    word2vec = get_weighted_word_vectors()  # Assuming this function is defined elsewhere\n",
    "\n",
    "    # Initialize a tensor for the word embeddings (a matrix of size (words_size+1, embed_size))\n",
    "    word_vectors = torch.zeros(words_size + 1, embed_size)\n",
    "    \n",
    "    # Assign the word embeddings to the corresponding words in the word2index\n",
    "    for k, v in word2index.items():\n",
    "        if k in word2vec:  # If word exists in the weighted word vectors\n",
    "            word_vectors[v, :] = torch.from_numpy(word2vec[k])  # Assign the word vector\n",
    "        else:\n",
    "            print(f\"Warning: '{k}' not in word2vec\")  # Print a warning if the word is not in the embeddings\n",
    "\n",
    "    # Prepare the sentences by converting words to indices using word2index\n",
    "    rs_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sen = []\n",
    "        for word in sentence:\n",
    "            if word in word2index.keys():\n",
    "                sen.append(word2index[word])  # Convert word to its index\n",
    "            else:\n",
    "                sen.append(0)  # If word is not found in word2index, assign index 0\n",
    "        # Pad or truncate the sentence to the desired sentence_length\n",
    "        if len(sen) < sentence_length:\n",
    "            sen.extend([0 for _ in range(sentence_length - len(sen))])  # Padding with 0s\n",
    "        else:\n",
    "            sen = sen[:sentence_length]  # Truncate if the sentence is too long\n",
    "        rs_sentences.append(sen)\n",
    "\n",
    "    # Create labels for sentiment classes (0, 1, 2 for different sentiments)\n",
    "    label = [0 for _ in range(40620)]  # Label 0 for positive sentiment\n",
    "    label.extend([1 for _ in range(6884)])  # Label 1 for negative sentiment\n",
    "    label.extend([2 for _ in range(2496)])  # Label 2 for neutral sentiment\n",
    "    label = np.array(label)  # Convert labels to a numpy array\n",
    "\n",
    "    # Return the processed data: sentences, labels, word embeddings, and word2index\n",
    "    return rs_sentences, label, word_vectors, word2index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'good': 1, 'product': 2, 'nice': 3, 'quality': 4, 'best': 5, 'flipkart': 6, 'price': 7, 'money': 8, 'bad': 9, 'awesome': 10, 'super': 11, 'buy': 12, 'one': 13, 'excellent': 14, 'working': 15, 'like': 16, 'also': 17, 'sound': 18, 'ok': 19, 'value': 20, 'happy': 21, 'dont': 22, 'really': 23, 'delivery': 24, 'great': 25, 'go': 26, 'use': 27, 'worth': 28, 'thanks': 29, 'amazing': 30, 'time': 31, 'thank': 32, 'much': 33, 'small': 34, 'products': 35, 'love': 36, 'using': 37, 'size': 38, 'installation': 39, 'superb': 40, 'poor': 41, 'tv': 42, 'got': 43, 'worst': 44, 'well': 45, 'fast': 46, 'low': 47, 'range': 48, 'better': 49, 'easy': 50, 'satisfied': 51, 'waste': 52, 'service': 53, 'battery': 54, 'water': 55, 'perfect': 56, 'performance': 57, 'days': 58, 'u': 59, 'must': 60, 'purchase': 61, 'overall': 62, 'work': 63, 'loved': 64, 'little': 65, 'bass': 66, 'comfortable': 67, 'useful': 68, 'get': 69, 'looking': 70, 'even': 71, 'beautiful': 72, 'experience': 73, 'fine': 74, 'used': 75, 'looks': 76, 'laptop': 77, 'speed': 78, 'design': 79, 'works': 80, 'day': 81, 'im': 82, 'bit': 83, 'look': 84, 'first': 85, 'material': 86, 'expected': 87, 'light': 88, 'watch': 89, 'high': 90, 'bought': 91, 'machine': 92, 'problem': 93, 'month': 94, 'need': 95, 'properly': 96, 'picture': 97, 'average': 98, 'months': 99, 'long': 100, 'backup': 101, 'delivered': 102, 'budget': 103, 'item': 104, 'received': 105, 'book': 106, 'less': 107, 'charging': 108, 'charger': 109, 'issue': 110, 'please': 111, 'recommend': 112, 'review': 113, 'power': 114, 'thing': 115, 'packing': 116, 'colour': 117, 'without': 118, 'full': 119, 'every': 120, 'buying': 121, 'camera': 122, 'air': 123, 'home': 124, 'phone': 125, 'would': 126, 'everything': 127, 'mobile': 128, 'device': 129, 'doesnt': 130, 'weight': 131, 'within': 132, 'set': 133, 'think': 134, 'big': 135, 'packaging': 136, 'display': 137, 'done': 138, 'mi': 139, 'brand': 140, 'gud': 141, 'build': 142, 'wow': 143, 'cant': 144, 'noise': 145, 'made': 146, 'wonderful': 147, 'smart': 148, 'fan': 149, 'nyc': 150, 'cloth': 151, 'speaker': 152, 'wifi': 153, 'box': 154, 'heating': 155, 'ever': 156, 'fit': 157, 'many': 158, 'want': 159, 'osm': 160, 'n': 161, 'smooth': 162, 'soft': 163, 'cheap': 164, 'could': 165, 'shown': 166, 'give': 167, 'original': 168, 'cost': 169, 'plastic': 170, 'available': 171, 'purchased': 172, 'okay': 173, 'support': 174, 'recommended': 175, 'two': 176, 'hard': 177, 'didnt': 178, 'gaming': 179, 'back': 180, 'hours': 181, 'heavy': 182, 'totally': 183, 'quite': 184, 'fantastic': 185, 'feel': 186, 'usage': 187, 'easily': 188, 'person': 189, 'still': 190, 'free': 191, 'lot': 192, 'features': 193, 'make': 194, 'say': 195, 'return': 196, 'fitting': 197, 'bluetooth': 198, 'fabric': 199, 'company': 200, 'liked': 201, 'last': 202, 'flipcart': 203, 'week': 204, 'per': 205, 'remote': 206, 'side': 207, 'new': 208, 'deal': 209, 'cool': 210, 'cycle': 211, 'enough': 212, 'keep': 213, 'google': 214, 'comes': 215, 'table': 216, 'normal': 217, 'always': 218, 'far': 219, 'since': 220, 'getting': 221, 'see': 222, 'came': 223, 'top': 224, 'clean': 225, 'never': 226, 'connectivity': 227, 'take': 228, 'job': 229, 'charge': 230, 'condition': 231, 'strong': 232, 'broken': 233, 'star': 234, 'disappointed': 235, 'pretty': 236, 'family': 237, 'market': 238, 'otherwise': 239, 'smell': 240, 'clear': 241, 'thin': 242, 'giving': 243, 'worthy': 244, 'around': 245, 'issues': 246, 'damaged': 247, 'gives': 248, 'know': 249, 'old': 250, 'ball': 251, 'customer': 252, 'year': 253, 'type': 254, 'decent': 255, 'fully': 256, 'samsung': 257, 'order': 258, 'connect': 259, 'heat': 260, 'boy': 261, 'till': 262, 'nd': 263, 'seeds': 264, 'router': 265, 'proper': 266, 'cooler': 267, 'demo': 268, 'slow': 269, 'perfectly': 270, 'reasonable': 271, 'music': 272, 'color': 273, 'space': 274, 'play': 275, 'room': 276, 'ordered': 277, 'app': 278, 'life': 279, 'perfume': 280, 'highly': 281, 'hot': 282, 'times': 283, 'given': 284, 'genuine': 285, 'seller': 286, 'compared': 287, 'level': 288, 'guys': 289, 'purpose': 290, 'fragrance': 291, 'people': 292, 'boat': 293, 'almost': 294, 'purifier': 295, 'provided': 296, 'helpful': 297, 'oil': 298, 'hair': 299, 'come': 300, 'option': 301, 'cooling': 302, 'quick': 303, 'thats': 304, 'juicer': 305, 'suitable': 306, 'cable': 307, 'though': 308, 'rate': 309, 'years': 310, 'led': 311, 'affordable': 312, 'damage': 313, 'replacement': 314, 'washing': 315, 'body': 316, 'takes': 317, 'found': 318, 'wash': 319, 'class': 320, 'kajal': 321, 'gets': 322, 'makes': 323, 'inside': 324, 'part': 325, 'wise': 326, 'kit': 327, 'motor': 328, 'built': 329, 'care': 330, 'voice': 331, 'according': 332, 'everyone': 333, 'minutes': 334, 'things': 335, 'stopped': 336, 'mark': 337, 'lasting': 338, 'second': 339, 'may': 340, 'friendly': 341, 'kids': 342, 'due': 343, 'try': 344, 'upto': 345, 'daily': 346, 'running': 347, 'connection': 348, 'verry': 349, 'writing': 350, 'warranty': 351, 'bed': 352, 'extra': 353, 'football': 354, 'powerful': 355, 'lovely': 356, 'usb': 357, 'mixer': 358, 'fabulous': 359, 'rs': 360, 'right': 361, 'system': 362, 'cleaning': 363, 'coming': 364, 'call': 365, 'apple': 366, 'single': 367, 'date': 368, 'point': 369, 'card': 370, 'beginners': 371, 'plates': 372, 'premium': 373, 'definitely': 374, 'suggest': 375, 'another': 376, 'installed': 377, 'next': 378, 'way': 379, 'screen': 380, 'handle': 381, 'video': 382, 'provide': 383, 'control': 384, 'however': 385, 'team': 386, 'making': 387, 'mode': 388, 'sturdy': 389, 'wont': 390, 'simply': 391, 'mind': 392, 'taste': 393, 'car': 394, 'doubt': 395, 'bat': 396, 'different': 397, 'short': 398, 'model': 399, 'food': 400, 'user': 401, 'choice': 402, 'android': 403, 'install': 404, 'capacity': 405, 'bag': 406, 'going': 407, 'seems': 408, 'plate': 409, 'cover': 410, 'started': 411, 'jar': 412, 'assemble': 413, 'juice': 414, 'expect': 415, 'update': 416, 'technician': 417, 'bajaj': 418, 'keyboard': 419, 'flip': 420, 'processor': 421, 'tds': 422, 'wear': 423, 'headphone': 424, 'reviews': 425, 'r': 426, 'help': 427, 'dinner': 428, 'mentioned': 429, 'tried': 430, 'useless': 431, 'compact': 432, 'shoes': 433, 'awsome': 434, 'books': 435, 'clarity': 436, 'sounds': 437, 'speakers': 438, 'find': 439, 'volume': 440, 'v': 441, 'check': 442, 'oven': 443, 'absolutely': 444, 'nothing': 445, 'tq': 446, 'hour': 447, 'image': 448, 'packed': 449, 'gift': 450, 'audio': 451, 'expectations': 452, 'seen': 453, 'filter': 454, 'items': 455, 'simple': 456, 'open': 457, 'stand': 458, 'us': 459, 'needs': 460, 'weeks': 461, 'black': 462, 'change': 463, 'late': 464, 'took': 465, 'ipad': 466, 'clothes': 467, 'grinder': 468, 'online': 469, 'etc': 470, 'ur': 471, 'prodect': 472, 'offer': 473, 'thankyou': 474, 'segment': 475, 'brands': 476, 'mivi': 477, 'amount': 478, 'difficult': 479, 'supper': 480, 'sometimes': 481, 'blowing': 482, 'sure': 483, 'guy': 484, 'wire': 485, 'rating': 486, 'thanku': 487, 'package': 488, 'grinding': 489, 'thought': 490, 'actually': 491, 'plus': 492, 'feels': 493, 'wall': 494, 'vary': 495, 'hand': 496, 'study': 497, 'data': 498, 'valuable': 499, 'connected': 500, 'playing': 501, 'showing': 502, 'able': 503, 'others': 504, 'loud': 505, 'completely': 506, 'iam': 507, 'kitchen': 508, 'c': 509, 'producti': 510, 'handy': 511, 'quantity': 512, 'soo': 513, 'bar': 514, 'pipe': 515, 'baby': 516, 'finishing': 517, 'place': 518, 'rest': 519, 'hd': 520, 'ifb': 521, 'bowl': 522, 'button': 523, 'switch': 524, 'put': 525, 'noisy': 526, 'already': 527, 'front': 528, 'penny': 529, 'house': 530, 'carry': 531, 'start': 532, 'sale': 533, 'indian': 534, 'yet': 535, 'soundbar': 536, 'print': 537, 'connecting': 538, 'gd': 539, 'touch': 540, 'trust': 541, 'today': 542, 'durable': 543, 'local': 544, 'youtube': 545, 'anyone': 546, 'stylish': 547, 'anything': 548, 'bank': 549, 'vry': 550, 'effective': 551, 'expensive': 552, 'iron': 553, 'dishwasher': 554, 'port': 555, 'although': 556, 'run': 557, 'filpkart': 558, 'required': 559, 'else': 560, 'improve': 561, 'storage': 562, 'length': 563, 'white': 564, 'microwave': 565, 'providing': 566, 'internet': 567, 'gifted': 568, 'services': 569, 'loving': 570, 'hrs': 571, 'worked': 572, 'feature': 573, 'jars': 574, 'cute': 575, 'outstanding': 576, 'base': 577, 'tablet': 578, 'awsm': 579, 'nic': 580, 'quickly': 581, 'cartridge': 582, 'bowls': 583, 'beast': 584, 'stitching': 585, 'stars': 586, 'utensils': 587, 'safe': 588, 'goodbut': 589, 'wood': 590, 'missing': 591, 'regular': 592, 'medium': 593, 'parts': 594, 'brightness': 595, 'india': 596, 'headphones': 597, 'real': 598, 'pure': 599, 'costly': 600, 'blanket': 601, 'response': 602, 'sufficient': 603, 'bt': 604, 'compare': 605, 'soon': 606, 'pic': 607, 'policy': 608, 'extremely': 609, 'office': 610, 'accessories': 611, 'chimney': 612, 'pro': 613, 'windows': 614, 'sony': 615, 'name': 616, 'inverter': 617, 'transfer': 618, 'smoothly': 619, 'hope': 620, 'automatically': 621, 'nicely': 622, 'except': 623, 'large': 624, 'stop': 625, 'ear': 626, 'min': 627, 'attractive': 628, 'plz': 629, 'timely': 630, 'replaced': 631, 'kart': 632, 'setup': 633, 'finally': 634, 'tank': 635, 'kind': 636, 'output': 637, 'students': 638, 'gb': 639, 'cons': 640, 'hai': 641, 'instead': 642, 'ink': 643, 'main': 644, 'exactly': 645, 'ram': 646, 'shoe': 647, 'feeling': 648, 'something': 649, 'result': 650, 'non': 651, 'memory': 652, 'smaller': 653, 'impressive': 654, 'show': 655, 'dslr': 656, 'bottom': 657, 'otg': 658, 'auto': 659, 'brought': 660, 'half': 661, 'band': 662, 'manual': 663, 'apps': 664, 'options': 665, 'test': 666, 'son': 667, 'finish': 668, 'earlier': 669, 'cap': 670, 'kent': 671, 'defective': 672, 'operate': 673, 'yes': 674, 'supar': 675, 'plug': 676, 'hdmi': 677, 'read': 678, 'god': 679, 'paid': 680, 'believe': 681, 'mom': 682, 'said': 683, 'loose': 684, 'software': 685, 'process': 686, 'area': 687, 'pack': 688, 'ive': 689, 'impressed': 690, 'alexa': 691, 'understand': 692, 'classy': 693, 'pain': 694, 'higher': 695, 'heated': 696, 'taking': 697, 'pathetic': 698, 'goes': 699, 'pocket': 700, 'note': 701, 'ro': 702, 'cast': 703, 'multiple': 704, 'metal': 705, 'charged': 706, 'max': 707, 'man': 708, 'specially': 709, 'piece': 710, 'lid': 711, 'pls': 712, 'mini': 713, 'disk': 714, 'games': 715, 'means': 716, 'replace': 717, 'rice': 718, 'paisa': 719, 'blue': 720, 'unit': 721, 'mins': 722, 'write': 723, 'door': 724, 'dust': 725, 'difference': 726, 'problems': 727, 'might': 728, 'send': 729, 'results': 730, 'panel': 731, 'comfort': 732, 'purchasing': 733, 'hold': 734, 'hp': 735, 'devices': 736, 'bottle': 737, 'refrigerator': 738, 'bigger': 739, 'needed': 740, 'regret': 741, 'shows': 742, 'consumption': 743, 'stick': 744, 'signal': 745, 'third': 746, 'basic': 747, 'usefull': 748, 'l': 749, 'total': 750, 'load': 751, 'stuff': 752, 'cooking': 753, 'livpure': 754, 'reading': 755, 'refund': 756, 'wrost': 757, 'wastage': 758, 'blindly': 759, 'function': 760, 'lower': 761, 'pros': 762, 'fix': 763, 'wd': 764, 'outside': 765, 'pump': 766, 'along': 767, 'tight': 768, 'fridge': 769, 'night': 770, 'billion': 771, 'cushion': 772, 'inch': 773, 'mbps': 774, 'add': 775, 'cut': 776, 'effect': 777, 'flow': 778, 'drive': 779, 'lights': 780, 'tab': 781, 'deliver': 782, 'prefer': 783, 'lag': 784, 'pay': 785, 'warm': 786, 'sent': 787, 'glass': 788, 'break': 789, 'three': 790, 'request': 791, 'number': 792, 'slightly': 793, 'description': 794, 'mic': 795, 'face': 796, 'suction': 797, 'sir': 798, 'pant': 799, 'cheaper': 800, 'daughter': 801, 'setting': 802, 'improved': 803, 'lock': 804, 'waiting': 805, 'operation': 806, 'dress': 807, 'version': 808, 'kettle': 809, 'important': 810, 'foot': 811, 'taken': 812, 'steel': 813, 'returned': 814, 'past': 815, 'turn': 816, 'floor': 817, 'satisfactory': 818, 'true': 819, 'period': 820, 'outer': 821, 'later': 822, 'polite': 823, 'gave': 824, 'scratches': 825, 'network': 826, 'supported': 827, 'faster': 828, 'geyser': 829, 'efficient': 830, 'delicate': 831, 'recieved': 832, 'prize': 833, 'fixed': 834, 'especially': 835, 'behaviour': 836, 'lots': 837, 'become': 838, 'correct': 839, 'wait': 840, 'usual': 841, 'eyes': 842, 'unable': 843, 'feet': 844, 'avarage': 845, 'atleast': 846, 'professional': 847, 'future': 848, 'charges': 849, 'watching': 850, 'macbook': 851, 'materials': 852, 'chromecast': 853, 'goodi': 854, 'twice': 855, 'cotton': 856, 'hdd': 857, 'havent': 858, 'lasts': 859, 'horrible': 860, 'assistant': 861, 'whether': 862, 'indicator': 863, 'says': 864, 'close': 865, 'pictures': 866, 'smells': 867, 'technology': 868, 'members': 869, 'kept': 870, 'store': 871, 'ones': 872, 'standard': 873, 'na': 874, 'felt': 875, 'thinking': 876, 'jeeves': 877, 'shopping': 878, 'tough': 879, 'dry': 880, 'casting': 881, 'plan': 882, 'realme': 883, 'promised': 884, 'weak': 885, 'wheel': 886, 'receive': 887, 'changed': 888, 'fits': 889, 'child': 890, 'movies': 891, 'tested': 892, 'keeping': 893, 'surface': 894, 'left': 895, 'content': 896, 'feedback': 897, 'heater': 898, 'near': 899, 'complete': 900, 'early': 901, 'engineer': 902, 'details': 903, 'butterfly': 904, 'aux': 905, 'initially': 906, 'went': 907, 'pressure': 908, 'durability': 909, 'minimum': 910, 'portable': 911, 'additional': 912, 'beat': 913, 'couldnt': 914, 'rather': 915, 'ask': 916, 'sewing': 917, 'wearing': 918, 'fresh': 919, 'complaints': 920, 'blade': 921, 'winter': 922, 'screws': 923, 'tvs': 924, 'thnx': 925, 'cleaner': 926, 'dark': 927, 'pages': 928, 'height': 929, 'board': 930, 'grip': 931, 'adapter': 932, 'whole': 933, 'liquid': 934, 'silent': 935, 'offers': 936, 'fill': 937, 'huge': 938, 'faced': 939, 'settings': 940, 'kg': 941, 'pubg': 942, 'tell': 943, 'wireless': 944, 'supports': 945, 'electricity': 946, 'broke': 947, 'videos': 948, 'enjoy': 949, 'expectation': 950, 'negative': 951, 'belt': 952, 'reason': 953, 'cart': 954, 'case': 955, 'gifting': 956, 'complaint': 957, 'prompt': 958, 'leakage': 959, 'sole': 960, 'end': 961, 'seed': 962, 'based': 963, 'uv': 964, 'h': 965, 'blades': 966, 'wasted': 967, 'described': 968, 'printer': 969, 'isnt': 970, 'pad': 971, 'sleek': 972, 'philips': 973, 'thick': 974, 'laptops': 975, 'children': 976, 'proof': 977, 'actual': 978, 'chair': 979, 'clearly': 980, 'search': 981, 'hence': 982, 'facing': 983, 'wife': 984, 'helps': 985, 'terms': 986, 'wallet': 987, 'called': 988, 'cleans': 989, 'cello': 990, 'sharp': 991, 'diet': 992, 'spend': 993, 'calls': 994, 'ahead': 995, 'fans': 996, 'customers': 997, 'via': 998, 'lets': 999, 'frame': 1000, 'sister': 1001, 'pixel': 1002, 'temperature': 1003, 'choose': 1004, 'productgood': 1005, 'shop': 1006, 'ultimate': 1007, 'opened': 1008, 'elegant': 1009, 'drawback': 1010, 'fastest': 1011, 'calling': 1012, 'cord': 1013, 'iphone': 1014, 'micro': 1015, 'press': 1016, 'game': 1017, 'types': 1018, 'sometime': 1019, 'satisfy': 1020, 'pieces': 1021, 'dishes': 1022, 'phones': 1023, 'rubber': 1024, 'pin': 1025, 'west': 1026, 'faulty': 1027, 'worry': 1028, 'friends': 1029, 'crompton': 1030, 'reliable': 1031, 'fall': 1032, 'starts': 1033, 'pipes': 1034, 'milk': 1035, 'headset': 1036, 'similar': 1037, 'rupees': 1038, 'word': 1039, 'reviewing': 1040, 'beyond': 1041, 'tube': 1042, 'keeps': 1043, 'coverage': 1044, 'window': 1045, 'blazer': 1046, 'gone': 1047, 'head': 1048, 'careful': 1049, 'wast': 1050, 'repair': 1051, 'osam': 1052, 'heats': 1053, 'placed': 1054, 'dirty': 1055, 'delay': 1056, 'soldering': 1057, 'protect': 1058, 'kid': 1059, 'mid': 1060, 'compatible': 1061, 'competitive': 1062, 'save': 1063, 'external': 1064, 'satisfying': 1065, 'pc': 1066, 'considering': 1067, 'cook': 1068, 'couple': 1069, 'colours': 1070, 'sd': 1071, 'uses': 1072, 'longer': 1073, 'key': 1074, 'delayed': 1075, 'personally': 1076, 'entire': 1077, 'sensor': 1078, 'supply': 1079, 'immediately': 1080, 'sticky': 1081, 'red': 1082, 'vessels': 1083, 'singer': 1084, 'priced': 1085, 'checked': 1086, 'previous': 1087, 'adaptor': 1088, 'ill': 1089, 'wanted': 1090, 'truly': 1091, 'motorola': 1092, 'mac': 1093, 'avoid': 1094, 'crystal': 1095, 'electric': 1096, 'healthy': 1097, 'safely': 1098, 'decision': 1099, 'words': 1100, 'convenient': 1101, 'stay': 1102, 'matter': 1103, 'student': 1104, 'discount': 1105, 'match': 1106, 'mop': 1107, 'saw': 1108, 'dish': 1109, 'brilliant': 1110, 'seconds': 1111, 'thanx': 1112, 'hanging': 1113, 'lg': 1114, 'rooms': 1115, 'theatre': 1116, 'shelf': 1117, 'strength': 1118, 'photo': 1119, 'users': 1120, 'okk': 1121, 'wish': 1122, 'wrong': 1123, 'regarding': 1124, 'nest': 1125, 'friend': 1126, 'health': 1127, 'solid': 1128, 'wheels': 1129, 'ryzen': 1130, 'throw': 1131, 'toy': 1132, 'e': 1133, 'improvement': 1134, 'leather': 1135, 'productthanks': 1136, 'ssd': 1137, 'clock': 1138, 'alot': 1139, 'provides': 1140, 'included': 1141, 'stuck': 1142, 'designed': 1143, 'buttons': 1144, 'safety': 1145, 'functions': 1146, 'fitted': 1147, 'exlent': 1148, 'photography': 1149, 'accurate': 1150, 'apart': 1151, 'hate': 1152, 'away': 1153, 'timer': 1154, 'adjust': 1155, 'expecting': 1156, 'executive': 1157, 'amezing': 1158, 'pm': 1159, 'cold': 1160, 'rough': 1161, 'morning': 1162, 'courier': 1163, 'b': 1164, 'hole': 1165, 'milton': 1166, 'hotspot': 1167, 'branded': 1168, 'fittings': 1169, 'bbd': 1170, 'increase': 1171, 'beginner': 1172, 'questions': 1173, 'plant': 1174, 'streaming': 1175, 'veri': 1176, 'shape': 1177, 'seeing': 1178, 'selling': 1179, 'jack': 1180, 'rich': 1181, 'positive': 1182, 'recently': 1183, 'wants': 1184, 'major': 1185, 'ears': 1186, 'paper': 1187, 'gon': 1188, 'lovers': 1189, 'channels': 1190, 'oud': 1191, 'men': 1192, 'gen': 1193, 'meter': 1194, 'purposes': 1195, 'special': 1196, 'protection': 1197, 'suggestion': 1198, 'serves': 1199, 'surprised': 1200, 'hr': 1201, 'dual': 1202, 'usually': 1203, 'printing': 1204, 'mirroring': 1205, 'graphics': 1206, 'instalation': 1207, 'birthday': 1208, 'interface': 1209, 'tooo': 1210, 'likes': 1211, 'listen': 1212, 'delivering': 1213, 'bicycle': 1214, 'pair': 1215, 'curtains': 1216, 'upgrade': 1217, 'tea': 1218, 'cushions': 1219, 'saving': 1220, 'appreciate': 1221, 'probably': 1222, 'dis': 1223, 'sweet': 1224, 'upsc': 1225, 'spending': 1226, 'carefully': 1227, 'possible': 1228, 'purification': 1229, 'four': 1230, 'produced': 1231, 'ekart': 1232, 'watt': 1233, 'least': 1234, 'tb': 1235, 'song': 1236, 'contact': 1237, 'trying': 1238, 'thomson': 1239, 'exchange': 1240, 'continuously': 1241, 'live': 1242, 'prestige': 1243, 'excited': 1244, 'theres': 1245, 'modes': 1246, 'transparent': 1247, 'lakme': 1248, 'frequently': 1249, 'k': 1250, 'dietician': 1251, 'five': 1252, 'poco': 1253, 'center': 1254, 'fixing': 1255, 'tshirt': 1256, 'grind': 1257, 'growing': 1258, 'suddenly': 1259, 'bcoz': 1260, 'dial': 1261, 'mat': 1262, 'hang': 1263, 'disappointing': 1264, 'party': 1265, 'tap': 1266, 'maximum': 1267, 'seagate': 1268, 'productbut': 1269, 'sofa': 1270, 'width': 1271, 'keys': 1272, 'curtain': 1273, 'lite': 1274, 'approx': 1275, 'filters': 1276, 'loves': 1277, 'remove': 1278, 'productmust': 1279, 'meet': 1280, 'ago': 1281, 'hardly': 1282, 'corner': 1283, 'noice': 1284, 'personal': 1285, 'added': 1286, 'combo': 1287, 'strap': 1288, 'mony': 1289, 'persons': 1290, 'digital': 1291, 'disappoint': 1292, 'instructions': 1293, 'cloths': 1294, 'marq': 1295, 'lowest': 1296, 'deep': 1297, 'colors': 1298, 'automatic': 1299, 'luck': 1300, 'stains': 1301, 'solution': 1302, 'loss': 1303, 'mount': 1304, 'canon': 1305, 'prodact': 1306, 'shock': 1307, 'chip': 1308, 'lover': 1309, 'prices': 1310, 'ups': 1311, 'told': 1312, 'knowledge': 1313, 'pricing': 1314, 'bright': 1315, 'cause': 1316, 'fm': 1317, 'rods': 1318, 'directly': 1319, 'con': 1320, 'reduce': 1321, 'someone': 1322, 'screw': 1323, 'tag': 1324, 'leaking': 1325, 'produce': 1326, 'anyway': 1327, 'wet': 1328, 'learn': 1329, 'covid': 1330, 'defect': 1331, 'luminous': 1332, 'move': 1333, 'runs': 1334, 'assembling': 1335, 'germinated': 1336, 'hesitation': 1337, 'filling': 1338, 'view': 1339, 'ideal': 1340, 'present': 1341, 'double': 1342, 'strongly': 1343, 'vgood': 1344, 'bella': 1345, 'vita': 1346, 'mam': 1347, 'reach': 1348, 'packet': 1349, 'functioning': 1350, 'green': 1351, 'shirt': 1352, 'files': 1353, 'ground': 1354, 'consider': 1355, 'changing': 1356, 'listening': 1357, 'assembly': 1358, 'cheapest': 1359, 'installing': 1360, 'post': 1361, 'planning': 1362, 'realy': 1363, 'goog': 1364, 'vacuum': 1365, 'riding': 1366, 'bike': 1367, 'scratch': 1368, 'absolute': 1369, 'mindblowing': 1370, 'lamp': 1371, 'neither': 1372, 'coz': 1373, 'legs': 1374, 'jbl': 1375, 'ride': 1376, 'asked': 1377, 'paint': 1378, 'plants': 1379, 'fps': 1380, 'stable': 1381, 'shelves': 1382, 'hear': 1383, 'zero': 1384, 'site': 1385, 'china': 1386, 'lightweight': 1387, 'youre': 1388, 'uncomfortable': 1389, 'notice': 1390, 'agent': 1391, 'terrific': 1392, 'w': 1393, 'ya': 1394, 'gym': 1395, 'perfumes': 1396, 'concern': 1397, 'inches': 1398, 'vaccum': 1399, 'depends': 1400, 'extraordinary': 1401, 'literally': 1402, 'latest': 1403, 'specifications': 1404, 'parents': 1405, 'ms': 1406, 'spent': 1407, 'sooo': 1408, 'edges': 1409, 'ghz': 1410, 'let': 1411, 'living': 1412, 'noticed': 1413, 'summer': 1414, 'movie': 1415, 'searching': 1416, 'unique': 1417, 'mother': 1418, 'saves': 1419, 'usable': 1420, 'mistake': 1421, 'minor': 1422, 'internal': 1423, 'hit': 1424, 'limited': 1425, 'slim': 1426, 'world': 1427, 'combination': 1428, 'printed': 1429, 'self': 1430, 'anywhere': 1431, 'operating': 1432, 'hands': 1433, 'cake': 1434, 'wasnt': 1435, 'chain': 1436, 'waist': 1437, 'ice': 1438, 'hall': 1439, 'chinese': 1440, 'handling': 1441, 'switching': 1442, 'productand': 1443, 'worse': 1444, 'burning': 1445, 'middle': 1446, 'irritating': 1447, 'casual': 1448, 'covers': 1449, 'productvalue': 1450, 'energy': 1451, 'surely': 1452, 'experienced': 1453, 'pre': 1454, 'ltr': 1455, 'rod': 1456, 'separately': 1457, 'nivia': 1458, 'detail': 1459, 'removed': 1460, 'bucket': 1461, 'mostly': 1462, 'helped': 1463, 'inner': 1464, 'maybe': 1465, 'overpriced': 1466, 'played': 1467, 'ports': 1468, 'husband': 1469, 'comment': 1470, 'connects': 1471, 'research': 1472, 'moving': 1473, 'ordinary': 1474, 'maintain': 1475, 'dolby': 1476, 'rinse': 1477, 'season': 1478, 'productthank': 1479, 'upper': 1480, 'goodit': 1481, 'completed': 1482, 'manufacturer': 1483, 'continue': 1484, 'sell': 1485, 'vegetables': 1486, 'notch': 1487, 'wrist': 1488, 'goood': 1489, 'redmi': 1490, 'batter': 1491, 'arrived': 1492, 'productworth': 1493, 'infinix': 1494, 'stitches': 1495, 'task': 1496, 'watts': 1497, 'hub': 1498, 'stays': 1499, 'starting': 1500, 'aluminium': 1501, 'grade': 1502, 'worest': 1503, 'category': 1504, 'line': 1505, 'enjoying': 1506, 'productits': 1507, 'bye': 1508, 'application': 1509, 'qulity': 1510, 'download': 1511, 'instant': 1512, 'across': 1513, 'charm': 1514, 'everytime': 1515, 'explained': 1516, 'turned': 1517, 'productit': 1518, 'prime': 1519, 'explain': 1520, 'continuous': 1521, 'cleaned': 1522, 'answer': 1523, 'saying': 1524, 'rack': 1525, 'ie': 1526, 'recording': 1527, 'inalsa': 1528, 'lags': 1529, 'spacious': 1530, 'id': 1531, 'attached': 1532, 'comparing': 1533, 'satisfaction': 1534, 'guide': 1535, 'flask': 1536, 'fruits': 1537, 'effects': 1538, 'asus': 1539, 'stops': 1540, 'became': 1541, 'fair': 1542, 'stitch': 1543, 'link': 1544, 'favourite': 1545, 'finger': 1546, 'page': 1547, 'se': 1548, 'inbuilt': 1549, 'remains': 1550, 'visible': 1551, 'share': 1552, 'moreover': 1553, 'somewhat': 1554, 'computer': 1555, 'step': 1556, 'youll': 1557, 'thread': 1558, 'often': 1559, 'holder': 1560, 'form': 1561, 'socks': 1562, 'hi': 1563, 'diwali': 1564, 'germination': 1565, 'apply': 1566, 'unexpected': 1567, 'crack': 1568, 'lost': 1569, 'zip': 1570, 'kits': 1571, 'smoke': 1572, 'disconnected': 1573, 'pants': 1574, 'oneplus': 1575, 'bcz': 1576, 'covering': 1577, 'grt': 1578, 'mainly': 1579, 'smudge': 1580, 'smartphone': 1581, 'mirror': 1582, 'monitor': 1583, 'supplied': 1584, 'delhi': 1585, 'changes': 1586, 'wonder': 1587, 'comparable': 1588, 'shipping': 1589, 'six': 1590, 'hassle': 1591, 'ios': 1592, 'angle': 1593, 'boys': 1594, 'decided': 1595, 'including': 1596, 'vasool': 1597, 'cpu': 1598, 'hindware': 1599, 'trusted': 1600, 'pics': 1601, 'adjustable': 1602, 'various': 1603, 'msi': 1604, 'worried': 1605, 'detergent': 1606, 'bosch': 1607, 'seat': 1608, 'extended': 1609, 'player': 1610, 'cooker': 1611, 'error': 1612, 'breaks': 1613, 'incredible': 1614, 'bro': 1615, 'talk': 1616, 'rockerz': 1617, 'neat': 1618, 'centre': 1619, 'meterial': 1620, 'drawing': 1621, 'fragile': 1622, 'yesterday': 1623, 'boiling': 1624, 'avg': 1625, 'receiving': 1626, 'session': 1627, 'requested': 1628, 'cancellation': 1629, 'treble': 1630, 'woofer': 1631, 'glad': 1632, 'channel': 1633, 'annoying': 1634, 'comparison': 1635, 'prise': 1636, 'photos': 1637, 'flowers': 1638, 'observed': 1639, 'productdont': 1640, 'efficiently': 1641, 'holes': 1642, 'wave': 1643, 'sides': 1644, 'equipment': 1645, 'weast': 1646, 'brake': 1647, 'prefilter': 1648, 'written': 1649, 'exhaust': 1650, 'dnt': 1651, 'action': 1652, 'initial': 1653, 'happened': 1654, 'becomes': 1655, 'sitting': 1656, 'lesser': 1657, 'performs': 1658, 'slot': 1659, 'carpet': 1660, 'biggest': 1661, 'mine': 1662, 'doubts': 1663, 'technical': 1664, 'speeds': 1665, 'images': 1666, 'th': 1667, 'household': 1668, 'lit': 1669, 'superfast': 1670, 'breaking': 1671, 'vibration': 1672, 'access': 1673, 'guess': 1674, 'advice': 1675, 'wasool': 1676, 'disconnect': 1677, 'pockets': 1678, 'shorts': 1679, 'ready': 1680, 'mechanical': 1681, 'chance': 1682, 'fake': 1683, 'manually': 1684, 'viewing': 1685, 'complain': 1686, 'grill': 1687, 'idea': 1688, 'aspects': 1689, 'switched': 1690, 'opening': 1691, 'either': 1692, 'practice': 1693, 'ultra': 1694, 'stock': 1695, 'ease': 1696, 'removing': 1697, 'balance': 1698, 'delevery': 1699, 'lil': 1700, 'pencil': 1701, 'cargo': 1702, 'drops': 1703, 'previously': 1704, 'urban': 1705, 'fly': 1706, 'current': 1707, 'programming': 1708, 'leg': 1709, 'gap': 1710, 'reached': 1711, 'notes': 1712, 'natural': 1713, 'cards': 1714, 'seriously': 1715, 'ordering': 1716, 'theater': 1717, 'manage': 1718, 'placing': 1719, 'gain': 1720, 'sit': 1721, 'serving': 1722, 'motion': 1723, 'sealed': 1724, 'terrible': 1725, 'pizza': 1726, 'refresh': 1727, 'grey': 1728, 'os': 1729, 'maid': 1730, 'media': 1731, 'editing': 1732, 'songs': 1733, 'pairing': 1734, 'manufacturing': 1735, 'cheated': 1736, 'dead': 1737, 'neckband': 1738, 'track': 1739, 'holds': 1740, 'multi': 1741, 'kudos': 1742, 'closed': 1743, 'city': 1744, 'code': 1745, 'powder': 1746, 'cools': 1747, 'brother': 1748, 'solved': 1749, 'points': 1750, 'corners': 1751, 'reduced': 1752, 'impression': 1753, 'upgraded': 1754, 'jio': 1755, 'tasks': 1756, 'testing': 1757, 'fault': 1758, 'amazed': 1759, 'microphone': 1760, 'suprb': 1761, 'course': 1762, 'buds': 1763, 'rated': 1764, 'camphor': 1765, 'kindly': 1766, 'yeah': 1767, 'flexible': 1768, 'miss': 1769, 'fluffy': 1770, 'minute': 1771, 'remember': 1772, 'responding': 1773, 'joints': 1774, 'dough': 1775, 'requires': 1776, 'arranged': 1777, 'f': 1778, 'fruit': 1779, 'flat': 1780, 'entry': 1781, 'grab': 1782, 'supporting': 1783, 'confused': 1784, 'duper': 1785, 'known': 1786, 'desert': 1787, 'nicee': 1788, 'ac': 1789, 'checking': 1790, 'pulp': 1791, 'buyers': 1792, 'terrain': 1793, 'exams': 1794, 'sleep': 1795, 'behavior': 1796, 'clogs': 1797, 'productthe': 1798, 'website': 1799, 'appreciated': 1800, 'restart': 1801, 'behind': 1802, 'require': 1803, 'disc': 1804, 'august': 1805, 'coolers': 1806, 'whats': 1807, 'separate': 1808, 'chicken': 1809, 'blutooth': 1810, 'updates': 1811, 'sizes': 1812, 'accept': 1813, 'fact': 1814, 'qualityi': 1815, 'pollution': 1816, 'dent': 1817, 'bend': 1818, 'fk': 1819, 'germinate': 1820, 'unsatisfied': 1821, 'honest': 1822, 'medicine': 1823, 'assembled': 1824, 'grow': 1825, 'dissatisfied': 1826, 'threads': 1827, 'visit': 1828, 'hardware': 1829, 'coating': 1830, 'torn': 1831, 'waterproof': 1832, 'question': 1833, 'electronic': 1834, 'furniture': 1835, 'mix': 1836, 'contains': 1837, 'flipkarts': 1838, 'requirement': 1839, 'produces': 1840, 'wired': 1841, 'spot': 1842, 'style': 1843, 'eye': 1844, 'performing': 1845, 'heard': 1846, 'voltas': 1847, 'economical': 1848, 'jst': 1849, 'functionality': 1850, 'common': 1851, 'sense': 1852, 'adjusted': 1853, 'productnice': 1854, 'peace': 1855, 'quiet': 1856, 'moderate': 1857, 'larger': 1858, 'dth': 1859, 'efficiency': 1860, 'awasome': 1861, 'fun': 1862, 'atta': 1863, 'netflix': 1864, 'fell': 1865, 'together': 1866, 'filled': 1867, 'pillow': 1868, 'thermals': 1869, 'gpu': 1870, 'travel': 1871, 'gamer': 1872, 'nearly': 1873, 'position': 1874, 'information': 1875, 'goodthank': 1876, 'cups': 1877, 'sales': 1878, 'supr': 1879, 'vocals': 1880, 'obviously': 1881, 'saver': 1882, 'exam': 1883, 'updated': 1884, 'invest': 1885, 'powerfull': 1886, 'nce': 1887, 'hero': 1888, 'opinion': 1889, 'productvery': 1890, 'specs': 1891, 'sheet': 1892, 'vasul': 1893, 'dull': 1894, 'unbelievable': 1895, 'copy': 1896, 'guard': 1897, 'ontime': 1898, 'follow': 1899, 'dad': 1900, 'trouser': 1901, 'drop': 1902, 'serve': 1903, 'fastly': 1904, 'fr': 1905, 'gta': 1906, 'afford': 1907, 'mouse': 1908, 'xiaomi': 1909, 'fort': 1910, 'omg': 1911, 'hv': 1912, 'suggested': 1913, 'beginning': 1914, 'litres': 1915, 'remaining': 1916, 'ui': 1917, 'rgb': 1918, 'mild': 1919, 'cash': 1920, 'maker': 1921, 'panasonic': 1922, 'tnx': 1923, 'bulb': 1924, 'detailed': 1925, 'currently': 1926, 'fiting': 1927, 'steal': 1928, 'wide': 1929, 'exact': 1930, 'effectively': 1931, 'seal': 1932, 'holding': 1933, 'aspirants': 1934, 'gold': 1935, 'ossam': 1936, 'attachment': 1937, 'valve': 1938, 'direct': 1939, 'layer': 1940, 'cam': 1941, 'cheating': 1942, 'conditions': 1943, 'consultation': 1944, 'contacted': 1945, 'connector': 1946, 'despite': 1947, 'okey': 1948, 'fool': 1949, 'hotstar': 1950, 'tiny': 1951, 'technicians': 1952, 'pickup': 1953, 'carpenter': 1954, 'wan': 1955, 'microtek': 1956, 'inlet': 1957, 'bast': 1958, 'paying': 1959, 'models': 1960, 'falling': 1961, 'stich': 1962, 'superior': 1963, 'prints': 1964, 'increased': 1965, 'comfy': 1966, 'ceramic': 1967, 'cooked': 1968, 'seem': 1969, 'mean': 1970, 'difficulty': 1971, 'offline': 1972, 'designs': 1973, 'voltage': 1974, 'preparation': 1975, 'bill': 1976, 'beauty': 1977, 'aspect': 1978, 'firstly': 1979, 'cricket': 1980, 'skin': 1981, 'proud': 1982, 'requirements': 1983, 'percent': 1984, 'overheating': 1985, 'thickness': 1986, 'dream': 1987, 'stereo': 1988, 'oct': 1989, 'fade': 1990, 'damn': 1991, 'repaired': 1992, 'loaded': 1993, 'gadget': 1994, 'donot': 1995, 'produc': 1996, 'salt': 1997, 'pleasant': 1998, 'p': 1999, 'juices': 2000, 'whenever': 2001, 'facility': 2002, 'stone': 2003, 'agaro': 2004, 'generation': 2005, 'juicing': 2006, 'series': 2007, 'offering': 2008, 'among': 2009, 'anybody': 2010, 'cars': 2011, 'bgmi': 2012, 'lack': 2013, 'solo': 2014, 'boil': 2015, 'itits': 2016, 'lighting': 2017, 'damages': 2018, 'enjoyed': 2019, 'lockdown': 2020, 'uf': 2021, 'rare': 2022, 'kinda': 2023, 'thx': 2024, 'reaches': 2025, 'naic': 2026, 'shiny': 2027, 'effort': 2028, 'inr': 2029, 'cutting': 2030, 'levels': 2031, 'haier': 2032, 'flipkarti': 2033, 'indeed': 2034, 'humble': 2035, 'osum': 2036, 'pureit': 2037, 'desk': 2038, 'browsing': 2039, 'sending': 2040, 'stiching': 2041, 'flower': 2042, 'jan': 2043, 'decoration': 2044, 'standing': 2045, 'respond': 2046, 'file': 2047, 'sim': 2048, 'round': 2049, 'fire': 2050, 'qualities': 2051, 'varry': 2052, 'advantage': 2053, 'mention': 2054, 'drum': 2055, 'pooja': 2056, 'failed': 2057, 'sine': 2058, 'transferring': 2059, 'weather': 2060, 'pick': 2061, 'nise': 2062, 'slight': 2063, 'several': 2064, 'extender': 2065, 'upset': 2066, 'ips': 2067, 'perform': 2068, 'helicopter': 2069, 'washed': 2070, 'aqi': 2071, 'provider': 2072, 'sad': 2073, 'temp': 2074, 'vest': 2075, 'rejected': 2076, 'peoples': 2077, 'scheduled': 2078, 'record': 2079, 'detect': 2080, 'constant': 2081, 'rtx': 2082, 'nearby': 2083, 'brakes': 2084, 'areas': 2085, 'intel': 2086, 'luxury': 2087, 'sport': 2088, 'trouble': 2089, 'pads': 2090, 'valorant': 2091, 'default': 2092, 'frequency': 2093, 'drying': 2094, 'watches': 2095, 'goodand': 2096, 'acceptable': 2097, 'exilent': 2098, 'applications': 2099, 'management': 2100, 'happen': 2101, 'informed': 2102, 'resolved': 2103, 'chopping': 2104, 'doms': 2105, 'create': 2106, 'doors': 2107, 'feb': 2108, 'estimated': 2109, 'typing': 2110, 'washes': 2111, 'jeans': 2112, 'reasoning': 2113, 'configure': 2114, 'itthank': 2115, 'knee': 2116, 'depending': 2117, 'cracked': 2118, 'comments': 2119, 'plazzo': 2120, 'women': 2121, 'luxurious': 2122, 'cm': 2123, 'flipcard': 2124, 'easier': 2125, 'preparing': 2126, 'age': 2127, 'partner': 2128, 'remain': 2129, 'clothe': 2130, 'answers': 2131, 'saurav': 2132, 'example': 2133, 'qwality': 2134, 'plugs': 2135, 'password': 2136, 'mounted': 2137, 'unfortunately': 2138, 'faber': 2139, 'extension': 2140, 'exllent': 2141, 'eyeconic': 2142, 'everyday': 2143, 'girls': 2144, 'tip': 2145, 'drink': 2146, 'secure': 2147, 'essential': 2148, 'classes': 2149, 'places': 2150, 'web': 2151, 'abt': 2152, 'mobiles': 2153, 'ppm': 2154, 'logo': 2155, 'force': 2156, 'z': 2157, 'iti': 2158, 'liter': 2159, 'manner': 2160, 'wonderfull': 2161, 'visited': 2162, 'formal': 2163, 'learning': 2164, 'meant': 2165, 'balanced': 2166, 'beautifully': 2167, 'sensitive': 2168, 'net': 2169, 'surprise': 2170, 'shocked': 2171, 'alarm': 2172, 'components': 2173, 'news': 2174, 'boss': 2175, 'coconut': 2176, 'dint': 2177, 'draining': 2178, 'exellent': 2179, 'sized': 2180, 'booked': 2181, 'advance': 2182, 'happening': 2183, 'straight': 2184, 'shining': 2185, 'detected': 2186, 'diy': 2187, 'electrical': 2188, 'empty': 2189, 'upon': 2190, 'patchwall': 2191, 'marvelous': 2192, 'louder': 2193, 'raised': 2194, 'group': 2195, 'asking': 2196, 'distance': 2197, 'location': 2198, 'member': 2199, 'duration': 2200, 'vguard': 2201, 'returning': 2202, 'amd': 2203, 'core': 2204, 'lose': 2205, 'closing': 2206, 'chose': 2207, 'rude': 2208, 'burnt': 2209, 'dried': 2210, 'backlight': 2211, 'moneyi': 2212, 'faded': 2213, 'thankful': 2214, 'prepared': 2215, 'adorable': 2216, 'supposed': 2217, 'controls': 2218, 'colourful': 2219, 'bedroom': 2220, 'recognition': 2221, 'evening': 2222, 'goodvalue': 2223, 'cocoa': 2224, 'suits': 2225, 'covered': 2226, 'sediment': 2227, 'chrome': 2228, 'aroma': 2229, 'skateboard': 2230, 'happythank': 2231, 'act': 2232, 'recomended': 2233, 'thumbs': 2234, 'leaves': 2235, 'vera': 2236, 'coding': 2237, 'saved': 2238, 'trousers': 2239, 'thnku': 2240, 'pattern': 2241, 'fiber': 2242, 'backlit': 2243, 'shopsy': 2244, 'crisp': 2245, 'interested': 2246, 'program': 2247, 'broadband': 2248, 'companies': 2249, 'towards': 2250, 'x': 2251, 'variety': 2252, 'helpfull': 2253, 'compromise': 2254, 'investment': 2255, 'ply': 2256, 'owsome': 2257, 'drain': 2258, 'performancei': 2259, 'paste': 2260, 'include': 2261, 'kneading': 2262, 'goods': 2263, 'recived': 2264, 'resolve': 2265, 'tastes': 2266, 'portion': 2267, 'varient': 2268, 'cup': 2269, 'aid': 2270, 'collect': 2271, 'secondly': 2272, 'plugged': 2273, 'lighter': 2274, 'cookware': 2275, 'brings': 2276, 'fir': 2277, 'qualityand': 2278, 'convection': 2279, 'eating': 2280, 'vey': 2281, 'par': 2282, 'sq': 2283, 'stabilizer': 2284, 'advise': 2285, 'throughout': 2286, 'cakes': 2287, 'garbage': 2288, 'washer': 2289, 'livepure': 2290, 'studying': 2291, 'duty': 2292, 'instruction': 2293, 'king': 2294, 'appliances': 2295, 'affect': 2296, 'weighted': 2297, 'showed': 2298, 'related': 2299, 'resolution': 2300, 'speak': 2301, 'bottles': 2302, 'command': 2303, 'neck': 2304, 'lens': 2305, 'instantly': 2306, 'meters': 2307, 'soundless': 2308, 'assured': 2309, 'addition': 2310, 'configuration': 2311, 'creates': 2312, 'staff': 2313, 'carbon': 2314, 'duct': 2315, 'sweat': 2316, 'impress': 2317, 'elastic': 2318, 'nature': 2319, 'edit': 2320, 'gloves': 2321, 'responsible': 2322, 'graphic': 2323, 'shakes': 2324, 'machines': 2325, 'promptly': 2326, 'section': 2327, 'school': 2328, 'switches': 2329, 'outlet': 2330, 'regularly': 2331, 'suggesting': 2332, 'cancel': 2333, 'slowly': 2334, 'maintenance': 2335, 'chutney': 2336, 'bahut': 2337, 'helping': 2338, 'handles': 2339, 'adopter': 2340, 'unlike': 2341, 'enabled': 2342, 'ia': 2343, 'specific': 2344, 'marks': 2345, 'disadvantage': 2346, 'mast': 2347, 'workout': 2348, 'sandal': 2349, 'srushti': 2350, 'absorbs': 2351, 'flash': 2352, 'general': 2353, 'homes': 2354, 'harddisk': 2355, 'refill': 2356, 'prepare': 2357, 'relief': 2358, 'cell': 2359, 'defected': 2360, 'producteasy': 2361, 'ver': 2362, 'finished': 2363, 'balloons': 2364, 'orange': 2365, 'driver': 2366, 'lagging': 2367, 'onoff': 2368, 'itthe': 2369, 'usha': 2370, 'hitting': 2371, 'turning': 2372, 'purifiers': 2373, 'flying': 2374, 'factor': 2375, 'disappointment': 2376, 'arrange': 2377, 'unless': 2378, 'lan': 2379, 'quility': 2380, 'cherry': 2381, 'punctured': 2382, 'deserve': 2383, 'ceiling': 2384, 'basketball': 2385, 'television': 2386, 'june': 2387, 'duplicate': 2388, 'bear': 2389, 'worsted': 2390, 'worthless': 2391, 'worrest': 2392, 'decrease': 2393, 'qualitygood': 2394, 'desired': 2395, 'mr': 2396, 'rotation': 2397, 'awesomethe': 2398, 'toys': 2399, 'reasonably': 2400, 'drilling': 2401, 'engine': 2402, 'genuinely': 2403, 'fitness': 2404, 'exercise': 2405, 'productlove': 2406, 'pillows': 2407, 'purified': 2408, 'intensity': 2409, 'badly': 2410, 'fulfilled': 2411, 'foldable': 2412, 'production': 2413, 'wind': 2414, 'subscription': 2415, 'expert': 2416, 'socket': 2417, 'polluted': 2418, 'ring': 2419, 'tnq': 2420, 'swing': 2421, 'stability': 2422, 'lacks': 2423, 'mbs': 2424, 'needle': 2425, 'situation': 2426, 'timex': 2427, 'starter': 2428, 'schedule': 2429, 'sparkling': 2430, 'dishwashers': 2431, 'radio': 2432, 'unboxing': 2433, 'luv': 2434, 'mah': 2435, 'useits': 2436, 'kick': 2437, 'moulded': 2438, 'direction': 2439, 'raise': 2440, 'moneygo': 2441, 'existing': 2442, 'controlled': 2443, 'communication': 2444, 'chennai': 2445, 'optimal': 2446, 'thermal': 2447, 'stage': 2448, 'dealer': 2449, 'galaxy': 2450, 'bhk': 2451, 'willing': 2452, 'productgo': 2453, 'hey': 2454, 'earphones': 2455, 'wat': 2456, 'solve': 2457, 'sample': 2458, 'winters': 2459, 'wach': 2460, 'eco': 2461, 'sec': 2462, 'tyres': 2463, 'respect': 2464, 'considered': 2465, 'efforts': 2466, 'entertainment': 2467, 'tracking': 2468, 'turns': 2469, 'dim': 2470, 'midea': 2471, 'cc': 2472, 'neet': 2473, 'robust': 2474, 'rain': 2475, 'baking': 2476, 'yaar': 2477, 'booster': 2478, 'turbo': 2479, 'buyer': 2480, 'thnk': 2481, 'demonstration': 2482, 'gigabit': 2483, 'consuming': 2484, 'timings': 2485, 'qualitynice': 2486, 'offered': 2487, 'dynamic': 2488, 'owsm': 2489, 'costlier': 2490, 'final': 2491, 'reviewers': 2492, 'art': 2493, 'suited': 2494, 'hurts': 2495, 'filpcart': 2496, 'orginal': 2497, 'asome': 2498, 'hated': 2499, 'figure': 2500, 'source': 2501, 'breeze': 2502, 'goodproduct': 2503, 'freezer': 2504, 'firmware': 2505, 'disconnecting': 2506, 'iq': 2507, 'mask': 2508, 'select': 2509, 'reality': 2510, 'adequate': 2511, 'highest': 2512, 'sign': 2513, 'stunning': 2514, 'allow': 2515, 'wrap': 2516, 'term': 2517, 'protected': 2518, 'importantly': 2519, 'aaa': 2520, 'dropped': 2521, 'sharing': 2522, 'extend': 2523, 'successfully': 2524, 'swimming': 2525, 'followed': 2526, 'hight': 2527, 'clearity': 2528, 'khub': 2529, 'goodworth': 2530, 'confusing': 2531, 'geography': 2532, 'frequent': 2533, 'mixie': 2534, 'productbest': 2535, 'skating': 2536, 'pot': 2537, 'indoor': 2538, 'moter': 2539, 'aslo': 2540, 'passport': 2541, 'sensors': 2542, 'ladies': 2543, 'okbut': 2544, 'slots': 2545, 'talking': 2546, 'nicebut': 2547, 'accordingly': 2548, 'glow': 2549, 'needles': 2550, 'limit': 2551, 'consumes': 2552, 'collection': 2553, 'shots': 2554, 'bring': 2555, 'trainer': 2556, 'male': 2557, 'apt': 2558, 'distortion': 2559, 'rotating': 2560, 'failure': 2561, 'input': 2562, 'locking': 2563, 'spare': 2564, 'eat': 2565, 'ratings': 2566, 'degree': 2567, 'wipe': 2568, 'hesitate': 2569, 'suit': 2570, 'batteries': 2571, 'rear': 2572, 'paired': 2573, 'afterall': 2574, 'chosen': 2575, 'superr': 2576, 'documents': 2577, 'chamber': 2578, 'putting': 2579, 'serious': 2580, 'ft': 2581, 'attachments': 2582, 'applied': 2583, 'titles': 2584, 'catch': 2585, 'whatever': 2586, 'shaking': 2587, 'febric': 2588, 'hz': 2589, 'nephew': 2590, 'barely': 2591, 'pink': 2592, 'qualityvery': 2593, 'training': 2594, 'alright': 2595, 'g': 2596, 'strip': 2597, 'awesomei': 2598, 'productjust': 2599, 'measurements': 2600, 'october': 2601, 'clamp': 2602, 'bulky': 2603, 'pots': 2604, 'tennis': 2605, 'bearing': 2606, 'rubbish': 2607, 'productquality': 2608, 'tubes': 2609, 'basically': 2610, 'juicers': 2611, 'maintained': 2612, 'fab': 2613, 'cycling': 2614, 'advised': 2615, 'favorite': 2616, 'goodgood': 2617, 'smallest': 2618, 'modern': 2619, 'variant': 2620, 'opt': 2621, 'wid': 2622, 'partially': 2623, 'litre': 2624, 'following': 2625, 'electrician': 2626, 'tha': 2627, 'bother': 2628, 'niece': 2629, 'qualitybest': 2630, 'sleeping': 2631, 'gorgeous': 2632, 'solder': 2633, 'tester': 2634, 'indication': 2635, 'somehow': 2636, 'goodvery': 2637, 'method': 2638, 'packages': 2639, 'blinking': 2640, 'palazzo': 2641, 'linux': 2642, 'cse': 2643, 'knows': 2644, 'prevent': 2645, 'boom': 2646, 'rang': 2647, 'older': 2648, 'installations': 2649, 'ot': 2650, 'bachelors': 2651, 'frost': 2652, 'amazingly': 2653, 'occurred': 2654, 'bay': 2655, 'certain': 2656, 'steps': 2657, 'melodious': 2658, 'thousand': 2659, 'fe': 2660, 'fragrances': 2661, 'splendid': 2662, 'bathroom': 2663, 'sorry': 2664, 'sticking': 2665, 'meets': 2666, 'container': 2667, 'lids': 2668, 'mm': 2669, 'lookwise': 2670, 'wake': 2671, 'gentle': 2672, 'authentic': 2673, 'soothing': 2674, 'sarvice': 2675, 'pricevery': 2676, 'pleased': 2677, 'growth': 2678, 'rapid': 2679, 'count': 2680, 'theyre': 2681, 'systems': 2682, 'appearance': 2683, 'block': 2684, 'exceptional': 2685, 'generated': 2686, 'xl': 2687, 'investing': 2688, 'mob': 2689, 'costs': 2690, 'attitude': 2691, 'trap': 2692, 'shops': 2693, 'activity': 2694, 'insane': 2695, 'kumar': 2696, 'sun': 2697, 'selected': 2698, 'classic': 2699, 'female': 2700, 'microfiber': 2701, 'happythanks': 2702, 'designing': 2703, 'accepted': 2704, 'report': 2705, 'certainly': 2706, 'click': 2707, 'specifically': 2708, 'carried': 2709, 'lenovo': 2710, 'deducted': 2711, 'handled': 2712, 'moneygood': 2713, 'bullets': 2714, 'mechine': 2715, 'valueable': 2716, 'copper': 2717, 'consume': 2718, 'vision': 2719, 'parfum': 2720, 'sticked': 2721, 'credit': 2722, 'discounts': 2723, 'drivers': 2724, 'goodjust': 2725, 'immediate': 2726, 'surround': 2727, 'packaged': 2728, 'deliverythanks': 2729, 'babys': 2730, 'logistics': 2731, 'seamlessly': 2732, 'yr': 2733, 'processing': 2734, 'humidity': 2735, 'competition': 2736, 'marvellous': 2737, 'causes': 2738, 'cross': 2739, 'suspension': 2740, 'project': 2741, 'boot': 2742, 'nicegood': 2743, 'joint': 2744, 'smile': 2745, 'vibrating': 2746, 'intact': 2747, 'gear': 2748, 'tools': 2749, 'pomegranate': 2750, 'plzz': 2751, 'tips': 2752, 'drinking': 2753, 'wardrobe': 2754, 'law': 2755, 'tplink': 2756, 'dirt': 2757, 'hairs': 2758, 'dd': 2759, 'loudness': 2760, 'quit': 2761, 'reliability': 2762, 'shot': 2763, 'players': 2764, 'yonex': 2765, 'circuit': 2766, 'nova': 2767, 'couldve': 2768, 'brush': 2769, 'leaving': 2770, 'ballons': 2771, 'concept': 2772, 'processors': 2773, 'burn': 2774, 'particles': 2775, 'shorter': 2776, 'unnecessary': 2777, 'camra': 2778, 'bang': 2779, 'typical': 2780, 'honestly': 2781, 'insert': 2782, 'valo': 2783, 'stuffs': 2784, 'q': 2785, 'goodgo': 2786, 'storing': 2787, 'parfect': 2788, 'sober': 2789, 'finest': 2790, 'warrenty': 2791, 'freeze': 2792, 'met': 2793, 'experiencei': 2794, 'yellow': 2795, 'convert': 2796, 'forget': 2797, 'downside': 2798, 'rock': 2799, 'alone': 2800, 'hurt': 2801, 'nive': 2802, 'fingers': 2803, 'cabinet': 2804, 'undoubtedly': 2805, 'surprisingly': 2806, 'fails': 2807, 'extreme': 2808, 'opalware': 2809, 'butter': 2810, 'edition': 2811, 'availability': 2812, 'nvidia': 2813, 'cult': 2814, 'matching': 2815, 'steam': 2816, 'packets': 2817, 'leds': 2818, 'grilling': 2819, 'semi': 2820, 'connections': 2821, 'chala': 2822, 'beutiful': 2823, 'ventilation': 2824, 'fragnance': 2825, 'airflow': 2826, 'nov': 2827, 'arm': 2828, 'decreasing': 2829, 'atomberg': 2830, 'wouldnt': 2831, 'father': 2832, 'consumer': 2833, 'cutter': 2834, 'productfor': 2835, 'wasting': 2836, 'vu': 2837, 'interesting': 2838, 'playstore': 2839, 'equivalent': 2840, 'specification': 2841, 'sandals': 2842, 'necessary': 2843, 'wooden': 2844, 'polyester': 2845, 'pricego': 2846, 'killer': 2847, 'appears': 2848, 'dedicated': 2849, 'imported': 2850, 'list': 2851, 'message': 2852, 'shine': 2853, 'sites': 2854, 'looked': 2855, 'thnks': 2856, 'goodthe': 2857, 'filtration': 2858, 'decide': 2859, 'btw': 2860, 'anti': 2861, 'register': 2862, 'extract': 2863, 'ml': 2864, 'decreased': 2865, 'replacing': 2866, 'crockery': 2867, 'downloading': 2868, 'bucks': 2869, 'operated': 2870, 'fancy': 2871, 'overload': 2872, 'gyser': 2873, 'tat': 2874, 'format': 2875, 'totaly': 2876, 'teared': 2877, 'productdelivery': 2878, 'tyre': 2879, 'havells': 2880, 'physically': 2881, 'march': 2882, 'nylon': 2883, 'ace': 2884, 'nose': 2885, 'detects': 2886, 'crazy': 2887, 'flimsy': 2888, 'operations': 2889, 'pouch': 2890, 'productthis': 2891, 'sticker': 2892, 'badminton': 2893, 'weird': 2894, 'diameter': 2895, 'pen': 2896, 'amazon': 2897, 'unhappy': 2898, 'burned': 2899, 'superbly': 2900, 'reheating': 2901, 'pandemic': 2902, 'mixing': 2903, 'productreally': 2904, 'activities': 2905, 'roads': 2906, 'rides': 2907, 'perfection': 2908, 'deliveryi': 2909, 'moneymust': 2910, 'co': 2911, 'superrrr': 2912, 'ozone': 2913, 'bounce': 2914, 'elderly': 2915, 'recieve': 2916, 'honey': 2917, 'gate': 2918, 'controller': 2919, 'builtin': 2920, 'smelling': 2921, 'goodthis': 2922, 'modem': 2923, 'ofcourse': 2924, 'risk': 2925, 'yrs': 2926, 'anytime': 2927, 'economic': 2928, 'cry': 2929, 'mechanic': 2930, 'stands': 2931, 'hardness': 2932, 'boots': 2933, 'compete': 2934, 'racket': 2935, 'dimensions': 2936, 'sqft': 2937, 'lucky': 2938, 'dear': 2939, 'lift': 2940, 'worthable': 2941, 'velue': 2942, 'gun': 2943, 'fourth': 2944, 'hubby': 2945, 'woodbuzz': 2946, 'itthanks': 2947, 'utility': 2948, 'express': 2949, 'superband': 2950, 'coil': 2951, 'productmy': 2952, 'ek': 2953, 'microsoft': 2954, 'typec': 2955, 'hurry': 2956, 'environment': 2957, 'account': 2958, 'nobody': 2959, 'reviewed': 2960, 'official': 2961, 'altogether': 2962, 'al': 2963, 'praduct': 2964, 'queries': 2965, 'cousin': 2966, 'harmful': 2967, 'mud': 2968, 'equal': 2969, 'gameplay': 2970, 'arent': 2971, 'everywhere': 2972, 'basis': 2973, 'dilevery': 2974, 'membrane': 2975, 'july': 2976, 'reply': 2977, 'unisex': 2978, 'pico': 2979, 'sceptical': 2980, 'advanced': 2981, 'loading': 2982, 'onebut': 2983, 'goodmust': 2984, 'afternoon': 2985, 'nycc': 2986, 'productyou': 2987, 'sennheiser': 2988, 'timing': 2989, 'longevity': 2990, 'prefect': 2991, 'funtastic': 2992, 'standby': 2993, 'knowledgeable': 2994, 'meal': 2995, 'egg': 2996, 'span': 2997, 'partition': 2998, 'thus': 2999, 'soaked': 3000, 'describe': 3001, 'baked': 3002, 'guality': 3003, 'tp': 3004, 'soooo': 3005, 'nt': 3006, 'building': 3007, 'chapter': 3008, 'physical': 3009, 'mb': 3010, 'vs': 3011, 'fist': 3012, 'touchpad': 3013, 'cheat': 3014, 'hundred': 3015, 'itam': 3016, 'nis': 3017, 'christmas': 3018, 'prduct': 3019, 'purse': 3020, 'zone': 3021, 'cloud': 3022, 'notification': 3023, 'thi': 3024, 'extracts': 3025, 'pricei': 3026, 'goof': 3027, 'workingvery': 3028, 'plenty': 3029, 'ethernet': 3030, 'volumes': 3031, 'appreciable': 3032, 'latency': 3033, 'scale': 3034, 'september': 3035, 'itbest': 3036, 'draw': 3037, 'okayish': 3038, 'explore': 3039, 'facilities': 3040, 'acc': 3041, 'walls': 3042, 'improvements': 3043, 'leaked': 3044, 'updating': 3045, 'itvalue': 3046, 'bullet': 3047, 'dilvery': 3048, 'explanation': 3049, 'ty': 3050, 'tables': 3051, 'bubble': 3052, 'yo': 3053, 'fi': 3054, 'delightful': 3055, 'tasty': 3056, 'repairs': 3057, 'battry': 3058, 'isp': 3059, 'vessel': 3060, 'appliance': 3061, 'improves': 3062, 'values': 3063, 'registered': 3064, 'chart': 3065, 'childrens': 3066, 'tablets': 3067, 'arc': 3068, 'waited': 3069, 'goodits': 3070, 'studies': 3071, 'reputed': 3072, 'road': 3073, 'dangerous': 3074, 'afraid': 3075, 'deserves': 3076, 'shift': 3077, 'silky': 3078, 'minus': 3079, 'forever': 3080, 'cinema': 3081, 'language': 3082, 'gs': 3083, 'challenge': 3084, 'spoiled': 3085, 'recommending': 3086, 'flaws': 3087, 'qualitythe': 3088, 'nc': 3089, 'latter': 3090, 'degrees': 3091, 'stoped': 3092, 'itvery': 3093, 'reminders': 3094, 'eurodomo': 3095, 'produt': 3096, 'catvision': 3097, 'conversation': 3098, 'spin': 3099, 'dents': 3100, 'ex': 3101, 'copying': 3102, 'ah': 3103, 'soul': 3104, 'mixi': 3105, 'tooi': 3106, 'perfomance': 3107, 'bracket': 3108, 'neptune': 3109, 'vx': 3110, 'advertisement': 3111, 'atmos': 3112, 'earphone': 3113, 'flawlessly': 3114, 'cod': 3115, 'texture': 3116, 'rapidly': 3117, 'pass': 3118, 'sumsung': 3119, 'maam': 3120, 'thumb': 3121, 'responsive': 3122, 'matt': 3123, 'smudges': 3124, 'pendrive': 3125, 'pvc': 3126, 'fo': 3127, 'behaved': 3128, 'tall': 3129, 'qualitythanks': 3130, 'vishal': 3131, 'rounder': 3132, 'correctly': 3133, 'accuracy': 3134, 'soil': 3135, 'retail': 3136, 'absorb': 3137, 'leader': 3138, 'bose': 3139, 'wil': 3140, 'glossy': 3141, 'rotor': 3142, 'minimal': 3143, 'vibrations': 3144, 'quilty': 3145, 'moneypacking': 3146, 'realise': 3147, 'justify': 3148, 'throws': 3149, 'containers': 3150, 'speaking': 3151, 'platform': 3152, 'edge': 3153, 'tabs': 3154, 'carrot': 3155, 'capable': 3156, 'magnet': 3157, 'errors': 3158, 'blower': 3159, 'primary': 3160, 'thq': 3161, 'tuf': 3162, 'inform': 3163, 'displays': 3164, 'sports': 3165, 'qualitybut': 3166, 'productivity': 3167, 'prouduct': 3168, 'mylab': 3169, 'inferior': 3170, 'reconnect': 3171, 'trustable': 3172, 'itbut': 3173, 'sketch': 3174, 'dlink': 3175, 'racks': 3176, 'backward': 3177, 'meaning': 3178, 'sellers': 3179, 'writting': 3180, 'structure': 3181, 'competitors': 3182, 'monster': 3183, 'enhance': 3184, 'expense': 3185, 'amp': 3186, 'dec': 3187, 'moneyit': 3188, 'tilt': 3189, 'aspected': 3190, 'attach': 3191, 'itit': 3192, 'bending': 3193, 'upgrading': 3194, 'phillips': 3195, 'multipurpose': 3196, 'driving': 3197, 'refer': 3198, 'displayed': 3199, 'carrying': 3200, 'ends': 3201, 'installtion': 3202, 'wondering': 3203, 'harder': 3204, 'bookshelf': 3205, 'bouncy': 3206, 'producing': 3207, 'multimedia': 3208, 'refil': 3209, 'cycles': 3210, 'distorted': 3211, 'tray': 3212, 'engineering': 3213, 'artificial': 3214, 'purches': 3215, 'confusion': 3216, 'dismantle': 3217, 'sleeve': 3218, 'purely': 3219, 'chief': 3220, 'background': 3221, 'ha': 3222, 'intense': 3223, 'inverters': 3224, 'purifying': 3225, 'ecommerce': 3226, 'shared': 3227, 'bugs': 3228, 'ssc': 3229, 'un': 3230, 'attended': 3231, 'sort': 3232, 'ji': 3233, 'commands': 3234, 'op': 3235, 'measures': 3236, 'none': 3237, 'mediocre': 3238, 'representative': 3239, 'matches': 3240, 'manufactured': 3241, 'firestick': 3242, 'mistakes': 3243, 'alignment': 3244, 'worn': 3245, 'demage': 3246, 'boring': 3247, 'okok': 3248, 'disgusting': 3249, 'wrote': 3250, 'hook': 3251, 'irresponsible': 3252, 'prefilled': 3253, 'reject': 3254, 'ridiculous': 3255, 'fooling': 3256, 'restarting': 3257, 'leaks': 3258, 'nit': 3259, 'tubicast': 3260, 'bladder': 3261, 'hopefully': 3262, 'shade': 3263, 'firm': 3264, 'maharaja': 3265, 'navigation': 3266, 'grinds': 3267, 'narrow': 3268, 'clothing': 3269, 'responded': 3270, 'address': 3271, 'furnifry': 3272, 'sexy': 3273, 'goodone': 3274, 'quarter': 3275, 'germinating': 3276, 'superbbut': 3277, 'cat': 3278, 'adds': 3279, 'dumb': 3280, 'personality': 3281, 'awsum': 3282, 'shut': 3283, 'onto': 3284, 'headache': 3285, 'commitment': 3286, 'lap': 3287, 'plumber': 3288, 'csgo': 3289, 'versions': 3290, 'shirts': 3291, 'decorative': 3292, 'solves': 3293, 'awesomegood': 3294, 'detection': 3295, 'plans': 3296, 'glasses': 3297, 'wery': 3298, 'melt': 3299, 'softwares': 3300, 'mixture': 3301, 'trays': 3302, 'specified': 3303, 'platforms': 3304, 'practical': 3305, 'vfm': 3306, 'niec': 3307, 'imagine': 3308, 'supb': 3309, 'handel': 3310, 'occasions': 3311, 'guilty': 3312, 'onei': 3313, 'surfing': 3314, 'restricted': 3315, 'sucks': 3316, 'impossible': 3317, 'leave': 3318, 'menus': 3319, 'spray': 3320, 'itand': 3321, 'ticket': 3322, 'swift': 3323, 'vegetable': 3324, 'movable': 3325, 'niceee': 3326, 'ltrs': 3327, 'hostellers': 3328, 'wowww': 3329, 'polish': 3330, 'flifcart': 3331, 'awesomely': 3332, 'itom': 3333, 'coffee': 3334, 'finely': 3335, 'bell': 3336, 'gel': 3337, 'routine': 3338, 'marked': 3339, 'papers': 3340, 'energetic': 3341, 'blending': 3342, 'saund': 3343, 'delighted': 3344, 'moneyno': 3345, 'hdr': 3346, 'stronger': 3347, 'drawbacks': 3348, 'citrus': 3349, 'purify': 3350, 'asthma': 3351, 'idk': 3352, 'applying': 3353, 'decreases': 3354, 'delicious': 3355, 'college': 3356, 'trial': 3357, 'wider': 3358, 'adjustment': 3359, 'searched': 3360, 'municipality': 3361, 'welloverall': 3362, 'filtering': 3363, 'committed': 3364, 'dining': 3365, 'besides': 3366, 'ptoduct': 3367, 'nowadays': 3368, 'hinges': 3369, 'false': 3370, 'indicate': 3371, 'thru': 3372, 'qubo': 3373, 'binding': 3374, 'mentioning': 3375, 'productim': 3376, 'emi': 3377, 'mops': 3378, 'girl': 3379, 'newer': 3380, 'fairy': 3381, 'qc': 3382, 'gooddelivery': 3383, 'goggles': 3384, 'thanking': 3385, 'tysm': 3386, 'impresive': 3387, 'sleeves': 3388, 'traveling': 3389, 'jacket': 3390, 'stiches': 3391, 'performer': 3392, 'promise': 3393, 'uper': 3394, 'shall': 3395, 'microwaves': 3396, 'magic': 3397, 'priduct': 3398, 'impressions': 3399, 'politely': 3400, 'itt': 3401, 'hygienic': 3402, 'pairs': 3403, 'refreshing': 3404, 'gadgets': 3405, 'profuct': 3406, 'prblm': 3407, 'kurti': 3408, 'enable': 3409, 'colling': 3410, 'broadcast': 3411, 'workingi': 3412, 'laggy': 3413, 'powered': 3414, 'private': 3415, 'pour': 3416, 'suparb': 3417, 'enter': 3418, 'sudden': 3419, 'productgot': 3420, 'enhancer': 3421, 'superrr': 3422, 'wattage': 3423, 'stream': 3424, 'reset': 3425, 'elbow': 3426, 'pricey': 3427, 'helmet': 3428, 'mrp': 3429, 'blender': 3430, 'grinders': 3431, 'banking': 3432, 'concepts': 3433, 'amzing': 3434, 'aware': 3435, 'wires': 3436, 'goodnot': 3437, 'nokia': 3438, 'goo': 3439, 'stainless': 3440, 'english': 3441, 'packs': 3442, 'ways': 3443, 'treat': 3444, 'moneybut': 3445, 'purple': 3446, 'social': 3447, 'lab': 3448, 'companion': 3449, 'trendy': 3450, 'powerbank': 3451, 'selection': 3452, 'insulation': 3453, 'mattress': 3454, 'seemed': 3455, 'awesomeits': 3456, 'productin': 3457, 'completion': 3458, 'authorised': 3459, 'seperate': 3460, 'balloon': 3461, 'osem': 3462, 'exclusive': 3463, 'untill': 3464, 'metirial': 3465, 'railway': 3466, 'programme': 3467, 'rises': 3468, 'popular': 3469, 'vibrant': 3470, 'sells': 3471, 'upload': 3472, 'lcd': 3473, 'bringing': 3474, 'plumbing': 3475, 'aluminum': 3476, 'easly': 3477, 'brown': 3478, 'bread': 3479, 'monitoring': 3480, 'thanq': 3481, 'knead': 3482, 'extensive': 3483, 'complained': 3484, 'functionalities': 3485, 'dettol': 3486, 'productno': 3487, 'flipkartthanks': 3488, 'knob': 3489, 'cuz': 3490, 'nearest': 3491, 'picked': 3492, 'flpkart': 3493, 'pause': 3494, 'temperatures': 3495, 'softness': 3496, 'liters': 3497, 'tqsm': 3498, 'posting': 3499, 'honor': 3500, 'filtered': 3501, 'valued': 3502, 'dr': 3503, 'tension': 3504, 'productas': 3505, 'cinematic': 3506, 'journey': 3507, 'gesture': 3508, 'skeptical': 3509, 'guidance': 3510, 'woww': 3511, 'beko': 3512, 'depend': 3513, 'silver': 3514, 'push': 3515, 'tires': 3516, 'yield': 3517, 'deliverygood': 3518, 'hindi': 3519, 'ad': 3520, 'focus': 3521, 'land': 3522, 'lifting': 3523, 'fashion': 3524, 'frustrated': 3525, 'ut': 3526, 'converter': 3527, 'fairly': 3528, 'productbass': 3529, 'amc': 3530, 'blocked': 3531, 'plastics': 3532, 'rangei': 3533, 'ironing': 3534, 'victory': 3535, 'activated': 3536, 'hepa': 3537, 'habit': 3538, 'bravia': 3539, 'chances': 3540, 'fulfills': 3541, 'moms': 3542, 'parcel': 3543, 'subwoofer': 3544, 'fentastic': 3545, 'oily': 3546, 'itnice': 3547, 'maintains': 3548, 'defrost': 3549, 'balls': 3550, 'demanding': 3551, 'plugin': 3552, 'drawer': 3553, 'hats': 3554, 'cartridges': 3555, 'touching': 3556, 'ai': 3557, 'torfin': 3558, 'roam': 3559, 'tikka': 3560, 'outdoor': 3561, 'lives': 3562, 'hesitant': 3563, 'semma': 3564, 'sling': 3565, 'dateproduct': 3566, 'rapped': 3567, 'outstandin': 3568, 'boiled': 3569, 'thinner': 3570, 'spread': 3571, 'buyed': 3572, 'unbeatable': 3573, 'reduction': 3574, 'slip': 3575, 'hinge': 3576, 'claims': 3577, 'boll': 3578, 'gaining': 3579, 'relatives': 3580, 'cheep': 3581, 'criteria': 3582, 'sophisticated': 3583, 'manufacturers': 3584, 'noiseless': 3585, 'flipkard': 3586, 'patient': 3587, 'collector': 3588, 'lol': 3589, 'release': 3590, 'qualityno': 3591, 'tool': 3592, 'cardboard': 3593, 'planted': 3594, 'field': 3595, 'neatly': 3596, 'wool': 3597, 'crushed': 3598, 'deliverd': 3599, 'human': 3600, 'anatomy': 3601, 'security': 3602, 'performed': 3603, 'juiceri': 3604, 'hamper': 3605, 'includes': 3606, 'firmly': 3607, 'hello': 3608, 'assistance': 3609, 'odour': 3610, 'rid': 3611, 'cuts': 3612, 'complex': 3613, 'yt': 3614, 'fot': 3615, 'acha': 3616, 'thn': 3617, 'ability': 3618, 'skilled': 3619, 'absent': 3620, 'okaybut': 3621, 'mood': 3622, 'productfast': 3623, 'decently': 3624, 'ended': 3625, 'owned': 3626, 'busy': 3627, 'booklet': 3628, 'tata': 3629, 'managed': 3630, 'utilise': 3631, 'wroth': 3632, 'rates': 3633, 'waight': 3634, 'pcs': 3635, 'routers': 3636, 'audible': 3637, 'aavante': 3638, 'preferred': 3639, 'sub': 3640, 'trustworthy': 3641, 'vnice': 3642, 'rigid': 3643, 'oh': 3644, 'qualitynot': 3645, 'motar': 3646, 'itoverall': 3647, 'gtx': 3648, 'reception': 3649, 'article': 3650, 'tricks': 3651, 'pointed': 3652, 'sturdiness': 3653, 'fork': 3654, 'reducing': 3655, 'kapoor': 3656, 'goodmy': 3657, 'traditional': 3658, 'examination': 3659, 'grass': 3660, 'ratio': 3661, 'synthetic': 3662, 'proved': 3663, 'claim': 3664, 'sieve': 3665, 'fregrence': 3666, 'scent': 3667, 'centrifugal': 3668, 'exillent': 3669, 'zipper': 3670, 'recommendation': 3671, 'sooper': 3672, 'flipkartthank': 3673, 'beats': 3674, 'foam': 3675, 'calm': 3676, 'answered': 3677, 'worthful': 3678, 'pavilion': 3679, 'consistent': 3680, 'increasing': 3681, 'ample': 3682, 'hanged': 3683, 'vego': 3684, 'moneyif': 3685, 'dependent': 3686, 'qualityworth': 3687, 'reference': 3688, 'verygood': 3689, 'staying': 3690, 'corrected': 3691, 'qualityloved': 3692, 'flipcort': 3693, 'freaking': 3694, 'lappy': 3695, 'complaining': 3696, 'productnot': 3697, 'comming': 3698, 'hammer': 3699, 'lo': 3700, 'liner': 3701, 'sata': 3702, 'compartment': 3703, 'dose': 3704, 'recomend': 3705, 'qualify': 3706, 'advertised': 3707, 'blank': 3708, 'tym': 3709, 'goodif': 3710, 'nvme': 3711, 'allergy': 3712, 'soap': 3713, 'cases': 3714, 'lengthy': 3715, 'veru': 3716, 'consistently': 3717, 'temporary': 3718, 'defects': 3719, 'repeated': 3720, 'adults': 3721, 'moves': 3722, 'neo': 3723, 'coin': 3724, 'qualityit': 3725, 'rotator': 3726, 'ergonomic': 3727, 'todays': 3728, 'controlling': 3729, 'lense': 3730, 'vendor': 3731, 'discharge': 3732, 'ensure': 3733, 'uploaded': 3734, 'qualitysound': 3735, 'electronics': 3736, 'tape': 3737, 'mains': 3738, 'permanent': 3739, 'swab': 3740, 'booting': 3741, 'superbb': 3742, 'alternative': 3743, 'thumping': 3744, 'wrt': 3745, 'reboot': 3746, 'flipkar': 3747, 'forza': 3748, 'badnot': 3749, 'numbers': 3750, 'split': 3751, 'cum': 3752, 'tear': 3753, 'fused': 3754, 'pl': 3755, 'babies': 3756, 'mouth': 3757, 'launch': 3758, 'goodlooks': 3759, 'cultfit': 3760, 'whirpool': 3761, 'ranges': 3762, 'enquired': 3763, 'bands': 3764, 'faces': 3765, 'tricky': 3766, 'personnel': 3767, 'particular': 3768, 'exchanged': 3769, 'glue': 3770, 'falls': 3771, 'filipkart': 3772, 'onwards': 3773, 'badi': 3774, 'dialogue': 3775, 'movement': 3776, 'branding': 3777, 'aap': 3778, 'stupid': 3779, 'trash': 3780, 'sold': 3781, 'forced': 3782, 'baad': 3783, 'tracker': 3784, 'thise': 3785, 'agree': 3786, 'avail': 3787, 'harm': 3788, 'cancelling': 3789, 'rtpcr': 3790, 'inserting': 3791, 'loosing': 3792, 'claimed': 3793, 'patience': 3794, 'angry': 3795, 'flies': 3796, 'utter': 3797, 'cancelled': 3798, 'solar': 3799, 'flew': 3800, 'hearing': 3801, 'qualitydont': 3802, 'sponge': 3803, 'fail': 3804, 'va': 3805, 'segate': 3806, 'avrage': 3807, 'superbthank': 3808, 'pd': 3809, 'qualitygo': 3810, 'absorbing': 3811, 'iot': 3812, 'furnitureplease': 3813, 'wellbecause': 3814, 'ossum': 3815, 'trained': 3816, 'qualityamazing': 3817, 'productonly': 3818, 'productsuper': 3819, 'hmm': 3820, 'authenticity': 3821, 'wrking': 3822, 'fight': 3823, 'invalid': 3824, 'aesthetic': 3825, 'cellbell': 3826, 'comb': 3827, 'okgood': 3828, 'measured': 3829, 'exp': 3830, 'incoming': 3831, 'futuristic': 3832, 'gifts': 3833, 'utmost': 3834, 'authorized': 3835, 'slower': 3836, 'stores': 3837, 'costing': 3838, 'travels': 3839, 'showpiece': 3840, 'boost': 3841, 'wound': 3842, 'experiance': 3843, 'fulfil': 3844, 'usefully': 3845, 'visual': 3846, 'claiming': 3847, 'threading': 3848, 'buffering': 3849, 'niceeeeee': 3850, 'soak': 3851, 'generates': 3852, 'matters': 3853, 'smalloverall': 3854, 'kam': 3855, 'grateful': 3856, 'dressing': 3857, 'filp': 3858, 'sweatshirt': 3859, 'earbuds': 3860, 'spoil': 3861, 'connectors': 3862, 'cuality': 3863, 'loads': 3864, 'thoroughly': 3865, 'descent': 3866, 'shrushti': 3867, 'ipados': 3868, 'hul': 3869, 'beep': 3870, 'darun': 3871, 'creating': 3872, 'horizontal': 3873, 'privacy': 3874, 'integration': 3875, 'unserviceable': 3876, 'fear': 3877, 'njoying': 3878, 'suberb': 3879, 'ovens': 3880, 'survive': 3881, 'exide': 3882, 'overhead': 3883, 'win': 3884, 'mens': 3885, 'royal': 3886, 'fallen': 3887, 'garden': 3888, 'boosted': 3889, 'adult': 3890, 'stipulated': 3891, 'happiness': 3892, 'confusions': 3893, 'smartbuy': 3894, 'rcvd': 3895, 'nicevalue': 3896, 'mach': 3897, 'perfum': 3898, 'master': 3899, 'truth': 3900, 'disturbing': 3901, 'mu': 3902, 'worthwhile': 3903, 'presentation': 3904, 'crispy': 3905, 'preloaded': 3906, 'irritation': 3907, 'bb': 3908, 'veg': 3909, 'troubleshooting': 3910, 'spinning': 3911, 'iphones': 3912, 'optimised': 3913, 'chopper': 3914, 'shredding': 3915, 'town': 3916, 'shifting': 3917, 'savings': 3918, 'attempts': 3919, 'giant': 3920, 'rainy': 3921, 'assures': 3922, 'timeless': 3923, 'productdelivered': 3924, 'tech': 3925, 'vivo': 3926, 'separated': 3927, 'serials': 3928, 'posted': 3929, 'owen': 3930, 'forgot': 3931, 'proudect': 3932, 'osome': 3933, 'cooperative': 3934, 'shrusti': 3935, 'inspiration': 3936, 'enjoys': 3937, 'lifestyle': 3938, 'wit': 3939, 'font': 3940, 'cleaneri': 3941, 'excellence': 3942, 'lace': 3943, 'productperfect': 3944, 'awesomevery': 3945, 'smoothbattery': 3946, 'nuce': 3947, 'tshirts': 3948, 'entirely': 3949, 'reasons': 3950, 'moisture': 3951, 'hyundai': 3952, 'requests': 3953, 'foreign': 3954, 'topping': 3955, 'reminder': 3956, 'whoever': 3957, 'mbbs': 3958, 'seperately': 3959, 'aside': 3960, 'ecosystem': 3961, 'watery': 3962, 'rocks': 3963, 'nyz': 3964, 'expiry': 3965, 'refused': 3966, 'onenice': 3967, 'beware': 3968, 'orignal': 3969, 'normally': 3970, 'luckily': 3971, 'occasion': 3972, 'instrument': 3973, 'thnq': 3974, 'tis': 3975, 'kneeding': 3976, 'productsame': 3977, 'van': 3978, 'foe': 3979, 'excepted': 3980, 'dat': 3981, 'tho': 3982, 'st': 3983, 'grand': 3984, 'caused': 3985, 'qty': 3986, 'studio': 3987, 'lazy': 3988, 'aa': 3989, 'painting': 3990, 'era': 3991, 'proudly': 3992, 'maids': 3993, 'intimation': 3994, 'litter': 3995, 'meditation': 3996, 'repeater': 3997, 'trip': 3998, 'footwear': 3999, 'education': 4000, 'tks': 4001, 'shipment': 4002, 'bhubaneswar': 4003, 'solely': 4004, 'productsuperb': 4005, 'recipes': 4006, 'zelio': 4007, 'smarter': 4008, 'famous': 4009, 'overthink': 4010, 'eg': 4011, 'sizegood': 4012, 'ir': 4013, 'inox': 4014, 'beautifull': 4015, 'til': 4016, 'darkening': 4017, 'buzzing': 4018, 'qualityvalue': 4019, 'dell': 4020, 'bhavna': 4021, 'madam': 4022, 'gamers': 4023, 'bldc': 4024, 'awesomego': 4025, 'fogg': 4026, 'surat': 4027, 'precious': 4028, 'rusting': 4029, 'serviceand': 4030, 'story': 4031, 'stories': 4032, 'damm': 4033, 'wi': 4034, 'satisfiedthank': 4035, 'transferred': 4036, 'lov': 4037, 'achcha': 4038, 'bulbs': 4039, 'useit': 4040, 'hppy': 4041, 'served': 4042, 'refilling': 4043, 'peak': 4044, 'sinewave': 4045, 'opposite': 4046, 'seamless': 4047, 'contain': 4048, 'longlasting': 4049, 'technically': 4050, 'punchy': 4051, 'shines': 4052, 'preety': 4053, 'supeb': 4054, 'palm': 4055, 'combined': 4056, 'decenti': 4057, 'comfortably': 4058, 'pet': 4059, 'chargers': 4060, 'unbearable': 4061, 'com': 4062, 'hiting': 4063, 'exelant': 4064, 'cancelation': 4065, 'beginers': 4066, 'filpcard': 4067, 'rat': 4068, 'racquet': 4069, 'monsoon': 4070, 'loking': 4071, 'flifkart': 4072, 'antivirus': 4073, 'pigeon': 4074, 'stain': 4075, 'settop': 4076, 'mixed': 4077, 'waoooo': 4078, 'grove': 4079, 'shocks': 4080, 'wirelessly': 4081, 'diagrams': 4082, 'medical': 4083, 'productsatisfied': 4084, 'telling': 4085, 'kadai': 4086, 'anazing': 4087, 'competing': 4088, 'insurance': 4089, 'yeast': 4090, 'active': 4091, 'sunday': 4092, 'weights': 4093, 'googles': 4094, 'meat': 4095, 'roti': 4096, 'oranges': 4097, 'parameters': 4098, 'accommodate': 4099, 'ayurveda': 4100, 'excelent': 4101, 'depth': 4102, 'cms': 4103, 'raising': 4104, 'basics': 4105, 'optional': 4106, 'satisfies': 4107, 'punch': 4108, 'equally': 4109, 'stretchable': 4110, 'makers': 4111, 'vero': 4112, 'dinning': 4113, 'micromax': 4114, 'bacteria': 4115, 'bestest': 4116, 'cities': 4117, 'costumer': 4118, 'walking': 4119, 'fold': 4120, 'spec': 4121, 'wisely': 4122, 'itll': 4123, 'problm': 4124, 'tuff': 4125, 'exercises': 4126, 'dail': 4127, 'tweeter': 4128, 'performancebest': 4129, 'companys': 4130, 'listens': 4131, 'awesomethanks': 4132, 'filipcart': 4133, 'wiring': 4134, 'happens': 4135, 'drives': 4136, 'aqua': 4137, 'owsom': 4138, 'garlic': 4139, 'amaron': 4140, 'groom': 4141, 'productloved': 4142, 'owsum': 4143, 'softener': 4144, 'blend': 4145, 'cracks': 4146, 'horn': 4147, 'batry': 4148, 'absence': 4149, 'jus': 4150, 'archer': 4151, 'photoshop': 4152, 'kwality': 4153, 'recognise': 4154, 'throwed': 4155, 'workingand': 4156, 'antenna': 4157, 'triple': 4158, 'aloe': 4159, 'hygiene': 4160, 'productwe': 4161, 'curry': 4162, 'doesnot': 4163, 'impact': 4164, 'drawn': 4165, 'grating': 4166, 'hu': 4167, 'smartwatch': 4168, 'problematic': 4169, 'removable': 4170, 'installer': 4171, 'itif': 4172, 'itz': 4173, 'postive': 4174, 'idle': 4175, 'hybrid': 4176, 'guards': 4177, 'moneyand': 4178, 'nicemy': 4179, 'itgreat': 4180, 'deals': 4181, 'thorough': 4182, 'bigbillion': 4183, 'sadly': 4184, 'tempered': 4185, 'airits': 4186, 'log': 4187, 'skate': 4188, 'factory': 4189, 'supportive': 4190, 'whos': 4191, 'stated': 4192, 'mst': 4193, 'selves': 4194, 'variants': 4195, 'village': 4196, 'stroke': 4197, 'fav': 4198, 'moneybest': 4199, 'nowhere': 4200, 'smoother': 4201, 'whose': 4202, 'reheat': 4203, 'tubular': 4204, 'pricebest': 4205, 'luk': 4206, 'deadly': 4207, 'attaching': 4208, 'vocal': 4209, 'blurred': 4210, 'goodnice': 4211, 'warmer': 4212, 'transmitter': 4213, 'provision': 4214, 'street': 4215, 'concerned': 4216, 'benefits': 4217, 'intensive': 4218, 'unavailable': 4219, 'mate': 4220, 'wraps': 4221, 'cavity': 4222, 'ti': 4223, 'typically': 4224, 'aspirant': 4225, 'tuned': 4226, 'sufficiently': 4227, 'string': 4228, 'fone': 4229, 'initiated': 4230, 'prone': 4231, 'lead': 4232, 'optical': 4233, 'everybody': 4234, 'increases': 4235, 'itmust': 4236, 'camara': 4237, 'prodcut': 4238, 'compair': 4239, 'festival': 4240, 'expectationonly': 4241, 'november': 4242, 'sharpness': 4243, 'neighbours': 4244, 'pigmented': 4245, 'productawesome': 4246, 'bild': 4247, 'watched': 4248, 'niceeee': 4249, 'pruduct': 4250, 'flipkartnice': 4251, 'nly': 4252, 'entrance': 4253, 'fibres': 4254, 'tightly': 4255, 'itnot': 4256, 'steady': 4257, 'accessory': 4258, 'productwith': 4259, 'goodquality': 4260, 'goodeverything': 4261, 'gooddecent': 4262, 'pricethank': 4263, 'suggests': 4264, 'skinny': 4265, 'fabulas': 4266, 'tanks': 4267, 'mice': 4268, 'godd': 4269, 'agency': 4270, 'billions': 4271, 'buget': 4272, 'niceeasy': 4273, 'moto': 4274, 'dilivery': 4275, 'kitchens': 4276, 'sanyasi': 4277, 'teams': 4278, 'spices': 4279, 'webcam': 4280, 'niceproduct': 4281, 'adjusting': 4282, 'indicates': 4283, 'choosing': 4284, 'gooddesign': 4285, 'qualitythank': 4286, 'blessing': 4287, 'jeevs': 4288, 'adidas': 4289, 'chargeing': 4290, 'cosco': 4291, 'buyvery': 4292, 'signals': 4293, 'decor': 4294, 'sunlight': 4295, 'bettersound': 4296, 'evry': 4297, 'bite': 4298, 'leading': 4299, 'lint': 4300, 'performence': 4301, 'dc': 4302, 'frozen': 4303, 'bake': 4304, 'ruf': 4305, 'pavan': 4306, 'expections': 4307, 'booking': 4308, 'passing': 4309, 'shoot': 4310, 'creation': 4311, 'golden': 4312, 'funny': 4313, 'relevant': 4314, 'exelent': 4315, 'heres': 4316, 'incomplete': 4317, 'goodoverall': 4318, 'angles': 4319, 'regrets': 4320, 'kall': 4321, 'variation': 4322, 'availed': 4323, 'nicesame': 4324, 'multitasking': 4325, 'injuries': 4326, 'wobble': 4327, 'degraded': 4328, 'complicated': 4329, 'whereas': 4330, 'silently': 4331, 'qualitywise': 4332, 'qality': 4333, 'possess': 4334, 'crayons': 4335, 'pastel': 4336, 'achi': 4337, 'prdct': 4338, 'slips': 4339, 'fuse': 4340, 'titan': 4341, 'goodthanks': 4342, 'locks': 4343, 'named': 4344, 'appreciating': 4345, 'boards': 4346, 'awesomebut': 4347, 'cracking': 4348, 'bold': 4349, 'learner': 4350, 'heart': 4351, 'upar': 4352, 'households': 4353, 'cameras': 4354, 'complains': 4355, 'owner': 4356, 'purchases': 4357, 'xxl': 4358, 'prod': 4359, 'clicky': 4360, 'shoaib': 4361, 'commendable': 4362, 'accidentally': 4363, 'considerable': 4364, 'jet': 4365, 'readings': 4366, 'vim': 4367, 'thinks': 4368, 'goodsound': 4369, 'fullfill': 4370, 'gaana': 4371, 'lime': 4372, 'continues': 4373, 'carton': 4374, 'floral': 4375, 'vibes': 4376, 'deel': 4377, 'vehicle': 4378, 'gardening': 4379, 'maxie': 4380, 'frnd': 4381, 'donated': 4382, 'bough': 4383, 'notifications': 4384, 'dani': 4385, 'relative': 4386, 'lean': 4387, 'deteriorated': 4388, 'skai': 4389, 'moneywell': 4390, 'removes': 4391, 'oknot': 4392, 'plays': 4393, 'benchmarks': 4394, 'allmost': 4395, 'simpler': 4396, 'wander': 4397, 'av': 4398, 'decorate': 4399, 'anymore': 4400, 'tightened': 4401, 'housing': 4402, 'dp': 4403, 'bleeding': 4404, 'organic': 4405, 'capture': 4406, 'server': 4407, 'behaving': 4408, 'spr': 4409, 'flipkartmy': 4410, 'hostel': 4411, 'familiar': 4412, 'letters': 4413, 'pills': 4414, 'negligible': 4415, 'property': 4416, 'portal': 4417, 'doctor': 4418, 'disturbance': 4419, 'closely': 4420, 'pressing': 4421, 'dam': 4422, 'die': 4423, 'copied': 4424, 'pasted': 4425, 'colorful': 4426, 'antiseptic': 4427, 'buybut': 4428, 'merchant': 4429, 'stopper': 4430, 'speakar': 4431, 'zebronics': 4432, 'ths': 4433, 'liberty': 4434, 'scared': 4435, 'thks': 4436, 'porduct': 4437, 'alluminium': 4438, 'demand': 4439, 'confident': 4440, 'rarely': 4441, 'modest': 4442, 'cannon': 4443, 'grounds': 4444, 'mail': 4445, 'dosent': 4446, 'nuts': 4447, 'itgood': 4448, 'collecting': 4449, 'instruments': 4450, 'softer': 4451, 'burns': 4452, 'alternate': 4453, 'adding': 4454, 'fading': 4455, 'wfh': 4456, 'dj': 4457, 'april': 4458, 'allergic': 4459, 'behave': 4460, 'delivary': 4461, 'goodbest': 4462, 'coders': 4463, 'specialy': 4464, 'confidence': 4465, 'lightning': 4466, 'sowing': 4467, 'itthis': 4468, 'highlights': 4469, 'proce': 4470, 'aero': 4471, 'metre': 4472, 'beneficial': 4473, 'gx': 4474, 'rechargeable': 4475, 'woking': 4476, 'successful': 4477, 'bolt': 4478, 'cardio': 4479, 'state': 4480, 'sandisk': 4481, 'hardcore': 4482, 'daysi': 4483, 'extracting': 4484, 'ke': 4485, 'producton': 4486, 'ache': 4487, 'uneven': 4488, 'kb': 4489, 'pins': 4490, 'vgaurd': 4491, 'mute': 4492, 'continously': 4493, 'nozzle': 4494, 'shower': 4495, 'refunded': 4496, 'owsam': 4497, 'alsoi': 4498, 'mad': 4499, 'greasy': 4500, 'awsme': 4501, 'drill': 4502, 'properlyoverall': 4503, 'wps': 4504, 'stones': 4505, 'begin': 4506, 'shes': 4507, 'sided': 4508, 'headrest': 4509, 'solutions': 4510, 'awosome': 4511, 'justified': 4512, 'flux': 4513, 'mega': 4514, 'resistant': 4515, 'charts': 4516, 'stretch': 4517, 'goodeasy': 4518, 'blocks': 4519, 'withstand': 4520, 'crash': 4521, 'menu': 4522, 'colity': 4523, 'packup': 4524, 'moment': 4525, 'feeting': 4526, 'smale': 4527, 'inspite': 4528, 'balt': 4529, 'bluethooth': 4530, 'optimization': 4531, 'goodall': 4532, 'snapdragon': 4533, 'engineers': 4534, 'itreally': 4535, 'membership': 4536, 'atomberge': 4537, 'recive': 4538, 'capability': 4539, 'analog': 4540, 'spaces': 4541, 'passed': 4542, 'approximately': 4543, 'transit': 4544, 'professionally': 4545, 'constantly': 4546, 'designgood': 4547, 'ballon': 4548, 'liking': 4549, 'recorded': 4550, 'ware': 4551, 'bath': 4552, 'visiting': 4553, 'wishmaster': 4554, 'invoice': 4555, 'smashing': 4556, 'tree': 4557, 'perhaps': 4558, 'superrrrr': 4559, 'pushed': 4560, 'ott': 4561, 'ultimately': 4562, 'academic': 4563, 'bends': 4564, 'broked': 4565, 'drains': 4566, 'excellant': 4567, 'central': 4568, 'created': 4569, 'partitions': 4570, 'nicethank': 4571, 'geniune': 4572, 'extracted': 4573, 'qualitysize': 4574, 'supp': 4575, 'professionals': 4576, 'usages': 4577, 'refuse': 4578, 'somewhere': 4579, 'ook': 4580, 'backside': 4581, 'pans': 4582, 'waooo': 4583, 'domestic': 4584, 'defferent': 4585, 'varieties': 4586, 'usei': 4587, 'phonepe': 4588, 'stiff': 4589, 'yrr': 4590, 'strategy': 4591, 'topic': 4592, 'buck': 4593, 'sources': 4594, 'western': 4595, 'bettery': 4596, 'qualiti': 4597, 'functional': 4598, 'fifty': 4599, 'thish': 4600, 'brocken': 4601, 'runner': 4602, 'occurs': 4603, 'stomach': 4604, 'informative': 4605, 'tub': 4606, 'copies': 4607, 'fhd': 4608, 'extent': 4609, 'bursts': 4610, 'masala': 4611, 'speedy': 4612, 'stink': 4613, 'feets': 4614, 'blast': 4615, 'strangely': 4616, 'solving': 4617, 'reschedule': 4618, 'missed': 4619, 'messy': 4620, 'tomorrow': 4621, 'manageable': 4622, 'shipped': 4623, 'sunny': 4624, 'nightmare': 4625, 'attending': 4626, 'warking': 4627, 'crusty': 4628, 'repeatedly': 4629, 'snowcrest': 4630, 'scanning': 4631, 'smal': 4632, 'ing': 4633, 'softly': 4634, 'lastic': 4635, 'dissapointed': 4636, 'gst': 4637, 'status': 4638, 'reused': 4639, 'irrespective': 4640, 'tournament': 4641, 'finnish': 4642, 'aur': 4643, 'corrupted': 4644, 'erase': 4645, 'ful': 4646, 'symphony': 4647, 'incredibly': 4648, 'lessons': 4649, 'email': 4650, 'moneyits': 4651, 'irritated': 4652, 'amphisound': 4653, 'badd': 4654, 'autocut': 4655, 'unreliable': 4656, 'faltu': 4657, 'shaky': 4658, 'mismatch': 4659, 'painful': 4660, 'warehouse': 4661, 'caller': 4662, 'antigen': 4663, 'itching': 4664, 'lie': 4665, 'struggling': 4666, 'stiched': 4667, 'ban': 4668, 'experiencing': 4669, 'clip': 4670, 'likely': 4671, 'displaying': 4672, 'returnable': 4673, 'dustbin': 4674, 'demanded': 4675, 'damege': 4676, 'malfunctioning': 4677, 'attract': 4678, 'wate': 4679, 'detecting': 4680, 'tiles': 4681, 'goodwaste': 4682, 'fibers': 4683, 'continued': 4684, 'melted': 4685, 'rusted': 4686, 'conditionthe': 4687, 'national': 4688, 'dameged': 4689, 'divice': 4690, 'remot': 4691, 'tik': 4692, 'productwaste': 4693, 'cabin': 4694, 'orders': 4695, 'struck': 4696, 'polythene': 4697, 'tedious': 4698, 'loosely': 4699, 'unstable': 4700, 'loudly': 4701, 'okkk': 4702, 'oky': 4703, 'toooo': 4704, 'avarege': 4705, 'infected': 4706, 'priceit': 4707, 'awesomein': 4708, 'pricemust': 4709, 'infinx': 4710, 'crushes': 4711, 'productmoon': 4712, 'rural': 4713, 'pace': 4714, 'blind': 4715, 'knitting': 4716, 'recovery': 4717, 'valid': 4718, 'yearsvery': 4719, 'disappointedwaste': 4720, 'soung': 4721, 'roadnot': 4722, 'commutes': 4723, 'shopscommercials': 4724, 'consthe': 4725, 'spoken': 4726, 'employee': 4727, 'la': 4728, 'verne': 4729, 'artist': 4730, 'sbig': 4731, 'soundboard': 4732, 'worths': 4733, 'oils': 4734, 'satisfiedthanks': 4735, 'calimed': 4736, 'lay': 4737, 'raw': 4738, 'goodbattery': 4739, 'goodno': 4740, 'intelligent': 4741, 'masterpiece': 4742, 'clog': 4743, 'podcast': 4744, 'cooleri': 4745, 'overnight': 4746, 'shockproof': 4747, 'massive': 4748, 'breadth': 4749, 'bluthooth': 4750, 'alter': 4751, 'object': 4752, 'shooting': 4753, 'justifies': 4754, 'delicately': 4755, 'sizejust': 4756, 'neighbor': 4757, 'born': 4758, 'notifies': 4759, 'nowthe': 4760, 'sincere': 4761, 'dialogues': 4762, 'bestquality': 4763, 'antibacterial': 4764, 'quelity': 4765, 'minded': 4766, 'assigned': 4767, 'anatomyalso': 4768, 'sevice': 4769, 'owesome': 4770, 'carefull': 4771, 'transperant': 4772, 'profit': 4773, 'overal': 4774, 'bi': 4775, 'awasom': 4776, 'possibly': 4777, 'becoz': 4778, 'dealing': 4779, 'onego': 4780, 'containing': 4781, 'identified': 4782, 'achieve': 4783, 'moneyinstallation': 4784, 'clearing': 4785, 'cleared': 4786, 'youi': 4787, 'ncerts': 4788, 'happyness': 4789, 'packagevery': 4790, 'stuffbut': 4791, 'moneypicture': 4792, 'mounting': 4793, 'transition': 4794, 'priceand': 4795, 'ramesh': 4796, 'og': 4797, 'usageeverything': 4798, 'keypad': 4799, 'dos': 4800, 'donts': 4801, 'buythanks': 4802, 'waterthe': 4803, 'mess': 4804, 'smallgood': 4805, 'laminated': 4806, 'qualitylook': 4807, 'thisand': 4808, 'desire': 4809, 'bas': 4810, 'tx': 4811, 'fiesta': 4812, 'slices': 4813, 'wallmount': 4814, 'deliveryvery': 4815, 'deleverd': 4816, 'doubtful': 4817, 'deliverybut': 4818, 'customization': 4819, 'futures': 4820, 'invested': 4821, 'sizer': 4822, 'buythe': 4823, 'timegood': 4824, 'justice': 4825, 'supppper': 4826, 'mba': 4827, 'raj': 4828, 'skills': 4829, 'oneneed': 4830, 'settingsit': 4831, 'utilises': 4832, 'upwards': 4833, 'issuebought': 4834, 'repasted': 4835, 'sinknow': 4836, 'zippers': 4837, 'tracks': 4838, 'creative': 4839, 'productexcellent': 4840, 'costosum': 4841, 'comfortthanks': 4842, 'womens': 4843, 'chairs': 4844, 'hq': 4845, 'den': 4846, 'moneythanks': 4847, 'clicked': 4848, 'awesomelight': 4849, 'superbthick': 4850, 'wintermy': 4851, 'paddle': 4852, 'stretching': 4853, 'defeated': 4854, 'ghatia': 4855, 'itdont': 4856, 'qualityu': 4857, 'frm': 4858, 'hav': 4859, 'heared': 4860, 'amazingits': 4861, 'pdct': 4862, 'whirlpool': 4863, 'responsibility': 4864, 'monday': 4865, 'bisleri': 4866, 'families': 4867, 'gas': 4868, 'label': 4869, 'flipi': 4870, 'conectivity': 4871, 'sogood': 4872, 'timenot': 4873, 'blaster': 4874, 'towels': 4875, 'yields': 4876, 'wellthe': 4877, 'decade': 4878, 'rackets': 4879, 'therefore': 4880, 'educart': 4881, 'chager': 4882, 'fitmy': 4883, 'overclock': 4884, 'minium': 4885, 'bestproduct': 4886, 'sealing': 4887, 'itone': 4888, 'itlove': 4889, 'flipkark': 4890, 'chunks': 4891, 'formatting': 4892, 'firmness': 4893, 'thighs': 4894, 'midnight': 4895, 'flour': 4896, 'sticks': 4897, 'transportation': 4898, 'uh': 4899, 'hotel': 4900, 'intention': 4901, 'observe': 4902, 'goodreally': 4903, 'productthanx': 4904, 'podect': 4905, 'uneasy': 4906, 'cutain': 4907, 'marroon': 4908, 'vanishing': 4909, 'river': 4910, 'sab': 4911, 'bhi': 4912, 'gf': 4913, 'preinstalled': 4914, 'moneyjust': 4915, 'magnetically': 4916, 'reconnects': 4917, 'minimises': 4918, 'radiation': 4919, 'exposure': 4920, 'equaliser': 4921, 'storm': 4922, 'altimate': 4923, 'rented': 4924, 'occasional': 4925, 'idli': 4926, 'issueand': 4927, 'rangeand': 4928, 'remembers': 4929, 'lookand': 4930, 'leads': 4931, 'thenk': 4932, 'expectedmatetial': 4933, 'gor': 4934, 'dashing': 4935, 'imagination': 4936, 'tge': 4937, 'flipkartits': 4938, 'deformed': 4939, 'urad': 4940, 'dhal': 4941, 'uniform': 4942, 'cleaners': 4943, 'thisi': 4944, 'magnificent': 4945, 'vvv': 4946, 'verify': 4947, 'misleading': 4948, 'observations': 4949, 'prroduct': 4950, 'powergood': 4951, 'shoots': 4952, 'civil': 4953, 'febrici': 4954, 'superbmust': 4955, 'ads': 4956, 'writes': 4957, 'suprised': 4958, 'waw': 4959, 'portrait': 4960, 'goggle': 4961, 'tasking': 4962, 'industry': 4963, 'breakage': 4964, 'excellentnoraml': 4965, 'hourswhile': 4966, 'hoursand': 4967, 'fou': 4968, 'niche': 4969, 'cualty': 4970, 'owsem': 4971, 'santosh': 4972, 'instillation': 4973, 'termite': 4974, 'chargerits': 4975, 'isvery': 4976, 'reproduction': 4977, 'fullfil': 4978, 'purposelong': 4979, 'backupdisplay': 4980, 'interestingly': 4981, 'productiam': 4982, 'adiyogi': 4983, 'showcase': 4984, 'qulaity': 4985, 'native': 4986, 'bpt': 4987, 'veryvery': 4988, 'usp': 4989, 'hrx': 4990, 'greatly': 4991, 'productu': 4992, 'volue': 4993, 'gaurav': 4994, 'qlity': 4995, 'blasterone': 4996, 'allround': 4997, 'printers': 4998, 'flipkert': 4999, 'listing': 5000, 'condtion': 5001, 'bestits': 5002, 'airpurifier': 5003, 'dented': 5004, 'earned': 5005, 'frnds': 5006, 'sera': 5007, 'setisfy': 5008, 'whatsapp': 5009, 'producthappy': 5010, 'timeoverall': 5011, 'allah': 5012, 'ankle': 5013, 'neudot': 5014, 'engineered': 5015, 'thik': 5016, 'amazingg': 5017, 'papilon': 5018, 'deliverygo': 5019, 'hoping': 5020, 'heusen': 5021, 'surprising': 5022, 'suppppppeer': 5023, 'promotion': 5024, 'pataka': 5025, 'primium': 5026, 'sbi': 5027, 'enhanced': 5028, 'arthritis': 5029, 'tooas': 5030, 'completes': 5031, 'phase': 5032, 'cormecast': 5033, 'needless': 5034, 'observation': 5035, 'outdoors': 5036, 'wt': 5037, 'buyyyvery': 5038, 'gooddesignexcellentgrindingthe': 5039, 'averagebut': 5040, 'afordable': 5041, 'excillent': 5042, 'prolonged': 5043, 'festivals': 5044, 'iss': 5045, 'priceso': 5046, 'lv': 5047, 'dependency': 5048, 'cherger': 5049, 'drl': 5050, 'vale': 5051, 'gi': 5052, 'presence': 5053, 'flipkat': 5054, 'ecart': 5055, 'headsets': 5056, 'educational': 5057, 'happily': 5058, 'weightgood': 5059, 'rub': 5060, 'february': 5061, 'sow': 5062, 'accha': 5063, 'bengaluru': 5064, 'partners': 5065, 'gamesframe': 5066, 'jitters': 5067, 'gamingover': 5068, 'wears': 5069, 'woowwww': 5070, 'servicing': 5071, 'peaking': 5072, 'okaythe': 5073, 'withing': 5074, 'fablous': 5075, 'converted': 5076, 'boon': 5077, 'wowmust': 5078, 'signature': 5079, 'goodlong': 5080, 'bare': 5081, 'bu': 5082, 'fridger': 5083, 'goodonly': 5084, 'slicer': 5085, 'mixers': 5086, 'yoga': 5087, 'complimentary': 5088, 'superbbbb': 5089, 'filipkat': 5090, 'vc': 5091, 'ery': 5092, 'niceexcellent': 5093, 'shaving': 5094, 'execellent': 5095, 'chhe': 5096, 'zoom': 5097, 'wasul': 5098, 'shortalso': 5099, 'tvi': 5100, 'arrive': 5101, 'fastthanks': 5102, 'divide': 5103, 'interruption': 5104, 'verd': 5105, 'yeras': 5106, 'productsnice': 5107, 'awesomecooling': 5108, 'honeycomb': 5109, 'okthe': 5110, 'goodmivi': 5111, 'brandi': 5112, 'dezine': 5113, 'vrry': 5114, 'doll': 5115, 'experince': 5116, 'greatful': 5117, 'servers': 5118, 'nicefast': 5119, 'goodosm': 5120, 'wuality': 5121, 'uhh': 5122, 'recommendi': 5123, 'robot': 5124, 'ther': 5125, 'goodfor': 5126, 'wintersize': 5127, 'veryfast': 5128, 'microtec': 5129, 'tooth': 5130, 'melts': 5131, 'waters': 5132, 'miney': 5133, 'rigorous': 5134, 'followups': 5135, 'misprint': 5136, 'reputation': 5137, 'drastically': 5138, 'hyderabad': 5139, 'purifies': 5140, 'gripe': 5141, 'idly': 5142, 'nutrient': 5143, 'construction': 5144, 'cont': 5145, 'respective': 5146, 'goodprice': 5147, 'toshiba': 5148, 'footballs': 5149, 'bored': 5150, 'nicego': 5151, 'audiovideo': 5152, 'generator': 5153, 'freez': 5154, 'velvet': 5155, 'cousins': 5156, 'nys': 5157, 'availablei': 5158, 'safer': 5159, 'cooks': 5160, 'equalizer': 5161, 'bomb': 5162, 'usebut': 5163, 'rotisserie': 5164, 'ajay': 5165, 'revital': 5166, 'rings': 5167, 'bodyno': 5168, 'projector': 5169, 'ine': 5170, 'hood': 5171, 'badthis': 5172, 'satisfie': 5173, 'ba': 5174, 'magical': 5175, 'birthdayhe': 5176, 'brief': 5177, 'rpm': 5178, 'machin': 5179, 'blazing': 5180, 'kard': 5181, 'bcs': 5182, 'qualityall': 5183, 'popping': 5184, 'pr': 5185, 'wagon': 5186, 'outage': 5187, 'prof': 5188, 'idouts': 5189, 'thr': 5190, 'multifunctional': 5191, 'houses': 5192, 'halls': 5193, 'adoptor': 5194, 'boxnice': 5195, 'hill': 5196, 'ubran': 5197, 'terrian': 5198, 'tokyo': 5199, 'moneyvery': 5200, 'expectedand': 5201, 'forcefully': 5202, 'text': 5203, 'designer': 5204, 'autocad': 5205, 'reccomend': 5206, 'ws': 5207, 'majorly': 5208, 'cookers': 5209, 'bhalo': 5210, 'seasons': 5211, 'scan': 5212, 'benefit': 5213, 'prelims': 5214, 'sectors': 5215, 'zolt': 5216, 'kms': 5217, 'alli': 5218, 'symptoms': 5219, 'rt': 5220, 'pcr': 5221, 'ct': 5222, 'momshe': 5223, 'cancle': 5224, 'purifieri': 5225, 'demerit': 5226, 'shells': 5227, 'milkshake': 5228, 'smoothie': 5229, 'osmmm': 5230, 'trending': 5231, 'lineup': 5232, 'portability': 5233, 'ecosystemelse': 5234, 'homepod': 5235, 'minibut': 5236, 'programmers': 5237, 'languages': 5238, 'locality': 5239, 'pakage': 5240, 'finding': 5241, 'fantastici': 5242, 'oldsolid': 5243, 'onebought': 5244, 'goodlike': 5245, 'drained': 5246, 'pumping': 5247, 'releasing': 5248, 'distribution': 5249, 'peeled': 5250, 'operationi': 5251, 'youth': 5252, 'selfi': 5253, 'conditioning': 5254, 'blows': 5255, 'exploring': 5256, 'diaper': 5257, 'rangego': 5258, 'headband': 5259, 'overthe': 5260, 'sporty': 5261, 'bearings': 5262, 'nowi': 5263, 'fur': 5264, 'smartphones': 5265, 'celsius': 5266, 'tuesday': 5267, 'ias': 5268, 'ortho': 5269, 'qwalty': 5270, 'licking': 5271, 'constraint': 5272, 'thk': 5273, 'veggies': 5274, 'smartly': 5275, 'randomly': 5276, 'productnd': 5277, 'khush': 5278, 'tor': 5279, 'chipset': 5280, 'harsh': 5281, 'productstorage': 5282, 'fuss': 5283, 'lappyi': 5284, 'pricequality': 5285, 'itemvery': 5286, 'tvstarting': 5287, 'yea': 5288, 'primarily': 5289, 'spectacular': 5290, 'roof': 5291, 'speedyou': 5292, 'productflipkart': 5293, 'evaluating': 5294, 'resived': 5295, 'superbthe': 5296, 'convertible': 5297, 'pricebut': 5298, 'obvious': 5299, 'fluctuations': 5300, 'circulation': 5301, 'equipments': 5302, 'usefulnice': 5303, 'uff': 5304, 'outfit': 5305, 'beside': 5306, 'loude': 5307, 'polished': 5308, 'picher': 5309, 'useno': 5310, 'boul': 5311, 'bigners': 5312, 'goodamazing': 5313, 'soundi': 5314, 'beginnersbut': 5315, 'deck': 5316, 'qualitybass': 5317, 'genshin': 5318, 'acchi': 5319, 'hain': 5320, 'colitis': 5321, 'shandar': 5322, 'effortlessly': 5323, 'pricenot': 5324, 'lovedit': 5325, 'knowing': 5326, 'brain': 5327, 'oxygen': 5328, 'cupboards': 5329, 'productwell': 5330, 'panels': 5331, 'lill': 5332, 'useproduct': 5333, 'cableuser': 5334, 'billhard': 5335, 'amplifier': 5336, 'lying': 5337, 'beloved': 5338, 'boxes': 5339, 'condenser': 5340, 'dought': 5341, 'celling': 5342, 'thisno': 5343, 'soooooo': 5344, 'approach': 5345, 'mei': 5346, 'callingdont': 5347, 'evermust': 5348, 'vento': 5349, 'sew': 5350, 'glides': 5351, 'square': 5352, 'suppr': 5353, 'survives': 5354, 'trucks': 5355, 'workthank': 5356, 'debit': 5357, 'verynice': 5358, 'usagethis': 5359, 'cleanerit': 5360, 'mineral': 5361, 'preferable': 5362, 'freak': 5363, 'afte': 5364, 'vain': 5365, 'girlfriend': 5366, 'superbbb': 5367, 'realistic': 5368, 'metals': 5369, 'picks': 5370, 'gentlemen': 5371, 'wouldve': 5372, 'weighty': 5373, 'protecting': 5374, 'enhances': 5375, 'internally': 5376, 'toolkit': 5377, 'tweezer': 5378, 'inthis': 5379, 'dramatic': 5380, 'initiative': 5381, 'productbuild': 5382, 'timebut': 5383, 'bestthank': 5384, 'brownie': 5385, 'convinced': 5386, 'segments': 5387, 'lekme': 5388, 'qualityexcellent': 5389, 'noiseoverall': 5390, 'intake': 5391, 'ossm': 5392, 'folded': 5393, 'behtrin': 5394, 'gray': 5395, 'disassemble': 5396, 'mixe': 5397, 'gorzeous': 5398, 'upright': 5399, 'di': 5400, 'performancegood': 5401, 'chiken': 5402, 'grilled': 5403, 'productworking': 5404, 'acuurate': 5405, 'altered': 5406, 'quad': 5407, 'wing': 5408, 'brandsthe': 5409, 'portronics': 5410, 'desing': 5411, 'sm': 5412, 'fulfill': 5413, 'rockers': 5414, 'pie': 5415, 'onefor': 5416, 'vara': 5417, 'impressedi': 5418, 'roomi': 5419, 'losing': 5420, 'intuitive': 5421, 'bangalore': 5422, 'advertising': 5423, 'shocking': 5424, 'priceordered': 5425, 'breaker': 5426, 'daysnice': 5427, 'tandoori': 5428, 'aswom': 5429, 'productall': 5430, 'goodness': 5431, 'formula': 5432, 'eggs': 5433, 'thia': 5434, 'experimenting': 5435, 'itdesign': 5436, 'dialogs': 5437, 'devilary': 5438, 'icon': 5439, 'supperb': 5440, 'waching': 5441, 'amaze': 5442, 'slimmer': 5443, 'moneythis': 5444, 'hospital': 5445, 'tactile': 5446, 'spillage': 5447, 'ventilated': 5448, 'soldring': 5449, 'disturb': 5450, 'floating': 5451, 'awesomelove': 5452, 'yep': 5453, 'fn': 5454, 'disappoints': 5455, 'flipkartthe': 5456, 'standered': 5457, 'gooddont': 5458, 'grown': 5459, 'mc': 5460, 'awesomenice': 5461, 'vangalam': 5462, 'vrey': 5463, 'medicines': 5464, 'fst': 5465, 'achieved': 5466, 'hoodie': 5467, 'itpros': 5468, 'chest': 5469, 'matel': 5470, 'retailer': 5471, 'kana': 5472, 'washi': 5473, 'canceled': 5474, 'plat': 5475, 'bachelor': 5476, 'weightmust': 5477, 'overflow': 5478, 'breath': 5479, 'pura': 5480, 'usul': 5481, 'foud': 5482, 'gooddd': 5483, 'disappeared': 5484, 'beet': 5485, 'awaiting': 5486, 'ayurvedic': 5487, 'appetite': 5488, 'requirment': 5489, 'ipaddelivery': 5490, 'parsal': 5491, 'struggled': 5492, 'transmission': 5493, 'mike': 5494, 'booted': 5495, 'accessing': 5496, 'prajapati': 5497, 'ramthe': 5498, 'yellowish': 5499, 'optimizationgaming': 5500, 'productthnku': 5501, 'recognized': 5502, 'thati': 5503, 'selecting': 5504, 'supervery': 5505, 'goodconnectivity': 5506, 'tactical': 5507, 'wellflipkart': 5508, 'cozy': 5509, 'handed': 5510, 'define': 5511, 'frustration': 5512, 'bai': 5513, 'qualityoverall': 5514, 'utensil': 5515, 'slide': 5516, 'perfact': 5517, 'thoughts': 5518, 'cabinets': 5519, 'accessible': 5520, 'tishart': 5521, 'registering': 5522, 'element': 5523, 'parson': 5524, 'analysing': 5525, 'numberthe': 5526, 'magnetic': 5527, 'rocking': 5528, 'thisdont': 5529, 'interference': 5530, 'strainers': 5531, 'roasting': 5532, 'significant': 5533, 'aesthetically': 5534, 'completing': 5535, 'punctual': 5536, 'productgreat': 5537, 'tbh': 5538, 'slideshow': 5539, 'legal': 5540, 'evev': 5541, 'heartily': 5542, 'atlanta': 5543, 'jaw': 5544, 'dropping': 5545, 'editor': 5546, 'travelling': 5547, 'buyflipkart': 5548, 'helpline': 5549, 'eventually': 5550, 'resources': 5551, 'studyiq': 5552, 'dayi': 5553, 'lt': 5554, 'clicking': 5555, 'jevees': 5556, 'stucked': 5557, 'negetive': 5558, 'mats': 5559, 'frist': 5560, 'qaulity': 5561, 'mature': 5562, 'moneysound': 5563, 'phenomenal': 5564, 'urgently': 5565, 'aged': 5566, 'couples': 5567, 'comparatively': 5568, 'modified': 5569, 'truely': 5570, 'compliments': 5571, 'middleclass': 5572, 'unavailability': 5573, 'mumbai': 5574, 'awesomeit': 5575, 'eventhough': 5576, 'patch': 5577, 'performanceno': 5578, 'issuescrystal': 5579, 'displaygreat': 5580, 'wattno': 5581, 'suchawesome': 5582, 'lookswhat': 5583, 'soundyou': 5584, 'tanq': 5585, 'hovers': 5586, 'mineraliser': 5587, 'disign': 5588, 'da': 5589, 'charginggood': 5590, 'attraction': 5591, 'pitch': 5592, 'thoda': 5593, 'foul': 5594, 'insala': 5595, 'vol': 5596, 'worthlow': 5597, 'darkness': 5598, 'vice': 5599, 'colored': 5600, 'newbies': 5601, 'chalk': 5602, 'sets': 5603, 'addicted': 5604, 'hesitationi': 5605, 'measure': 5606, 'poduct': 5607, 'baught': 5608, 'route': 5609, 'caps': 5610, 'introduced': 5611, 'mobility': 5612, 'ripple': 5613, 'karthik': 5614, 'ga': 5615, 'hevy': 5616, 'productplastic': 5617, 'hardisk': 5618, 'standerd': 5619, 'soundbass': 5620, 'hm': 5621, 'etios': 5622, 'whe': 5623, 'kurta': 5624, 'dts': 5625, 'applicable': 5626, 'rectify': 5627, 'desktops': 5628, 'registration': 5629, 'woo': 5630, 'monks': 5631, 'thqq': 5632, 'speaks': 5633, 'expectedits': 5634, 'vlo': 5635, 'demonstrated': 5636, 'noticing': 5637, 'qualitylooks': 5638, 'shoesgood': 5639, 'soundgood': 5640, 'operates': 5641, 'mandatory': 5642, 'airing': 5643, 'agarbatti': 5644, 'itdelivery': 5645, 'wobbly': 5646, 'soundits': 5647, 'esy': 5648, 'finei': 5649, 'grinded': 5650, 'coriander': 5651, 'assisted': 5652, 'conventional': 5653, 'disappointingthe': 5654, 'lifetime': 5655, 'validity': 5656, 'warrantyoverall': 5657, 'installable': 5658, 'complent': 5659, 'productone': 5660, 'productbuy': 5661, 'productfeel': 5662, 'furious': 5663, 'productperformance': 5664, 'geforce': 5665, 'chota': 5666, 'goodwriting': 5667, 'hardworking': 5668, 'prob': 5669, 'precise': 5670, 'buyand': 5671, 'filipcard': 5672, 'carrots': 5673, 'vanilla': 5674, 'chargethnq': 5675, 'celcius': 5676, 'exclusively': 5677, 'declined': 5678, 'diffuser': 5679, 'birth': 5680, 'granite': 5681, 'gaving': 5682, 'avengers': 5683, 'amps': 5684, 'tremendous': 5685, 'boils': 5686, 'delight': 5687, 'bedside': 5688, 'resetting': 5689, 'soun': 5690, 'caramel': 5691, 'immersion': 5692, 'fixable': 5693, 'nonstop': 5694, 'thanxxx': 5695, 'undamaged': 5696, 'secured': 5697, 'institution': 5698, 'held': 5699, 'effectiveness': 5700, 'picot': 5701, 'unwanted': 5702, 'utilize': 5703, 'bestone': 5704, 'compressed': 5705, 'expectedbut': 5706, 'oval': 5707, 'costomer': 5708, 'omnitech': 5709, 'objects': 5710, 'extensively': 5711, 'averages': 5712, 'trail': 5713, 'newly': 5714, 'deskjet': 5715, 'optimized': 5716, 'liv': 5717, 'pep': 5718, 'fipkart': 5719, 'sond': 5720, 'confirmed': 5721, 'guaranteed': 5722, 'sis': 5723, 'uptill': 5724, 'concrete': 5725, 'thou': 5726, 'candes': 5727, 'excel': 5728, 'flipkartbut': 5729, 'december': 5730, 'hanger': 5731, 'platesbut': 5732, 'boosts': 5733, 'significantly': 5734, 'moneyquality': 5735, 'wownice': 5736, 'pleasing': 5737, 'nevertheless': 5738, 'coupled': 5739, 'setupi': 5740, 'aliasing': 5741, 'ks': 5742, 'samegta': 5743, 'settingscomes': 5744, 'freeoverall': 5745, 'niceas': 5746, 'productnow': 5747, 'kajol': 5748, 'bhai': 5749, 'powerhouse': 5750, 'sentence': 5751, 'sonata': 5752, 'casio': 5753, 'tire': 5754, 'exceptionally': 5755, 'quoted': 5756, 'infinity': 5757, 'vent': 5758, 'versatile': 5759, 'inn': 5760, 'onida': 5761, 'scrape': 5762, 'flipkartfor': 5763, 'mints': 5764, 'productive': 5765, 'usa': 5766, 'seti': 5767, 'mee': 5768, 'locked': 5769, 'aswome': 5770, 'voices': 5771, 'reluctant': 5772, 'shooes': 5773, 'usagethe': 5774, 'oversize': 5775, 'arround': 5776, 'qu': 5777, 'cottonbut': 5778, 'nick': 5779, 'causing': 5780, 'readily': 5781, 'annual': 5782, 'bod': 5783, 'inexperienced': 5784, 'fellows': 5785, 'sky': 5786, 'loses': 5787, 'asks': 5788, 'soundvery': 5789, 'oki': 5790, 'shree': 5791, 'expired': 5792, 'glowing': 5793, 'pent': 5794, 'productfirst': 5795, 'experts': 5796, 'velu': 5797, 'brighter': 5798, 'daylight': 5799, 'bug': 5800, 'sorbet': 5801, 'priceperformance': 5802, 'slash': 5803, 'triggers': 5804, 'colourand': 5805, 'anytimeif': 5806, 'downplease': 5807, 'qualityin': 5808, 'childish': 5809, 'universal': 5810, 'attend': 5811, 'wellthis': 5812, 'junk': 5813, 'measuring': 5814, 'sessions': 5815, 'freely': 5816, 'admit': 5817, 'sem': 5818, 'sight': 5819, 'highlight': 5820, 'virus': 5821, 'cyclone': 5822, 'productspecially': 5823, 'chilling': 5824, 'edting': 5825, 'gamming': 5826, 'knotch': 5827, 'maps': 5828, 'government': 5829, 'lowbut': 5830, 'mobilevery': 5831, 'intrested': 5832, 'disply': 5833, 'patelraj': 5834, 'thermosteel': 5835, 'gysear': 5836, 'asom': 5837, 'dandruff': 5838, 'srushtideshmukhias': 5839, 'apartment': 5840, 'deliveryfast': 5841, 'achha': 5842, 'finishone': 5843, 'sane': 5844, 'folder': 5845, 'dates': 5846, 'tad': 5847, 'statistics': 5848, 'duel': 5849, 'mis': 5850, 'borders': 5851, 'flipkartvalue': 5852, 'usethank': 5853, 'mw': 5854, 'blink': 5855, 'albeit': 5856, 'issuei': 5857, 'supab': 5858, 'charing': 5859, 'bestyou': 5860, 'developer': 5861, 'peel': 5862, 'ss': 5863, 'foil': 5864, 'goodflipkart': 5865, 'moneyexcellent': 5866, 'adhesive': 5867, 'dashboard': 5868, 'batary': 5869, 'nights': 5870, 'duster': 5871, 'mp': 5872, 'understandable': 5873, 'lik': 5874, 'vibrate': 5875, 'supporter': 5876, 'denied': 5877, 'colur': 5878, 'rage': 5879, 'doubtfull': 5880, 'rotate': 5881, 'pricethanks': 5882, 'region': 5883, 'veey': 5884, 'awful': 5885, 'slightest': 5886, 'flavour': 5887, 'nicelooking': 5888, 'misconception': 5889, 'hollow': 5890, 'knobs': 5891, 'ignition': 5892, 'discription': 5893, 'bird': 5894, 'needful': 5895, 'pricesound': 5896, 'protects': 5897, 'silicon': 5898, 'communicating': 5899, 'chemical': 5900, 'awesomebattery': 5901, 'wishes': 5902, 'embroidery': 5903, 'rayon': 5904, 'python': 5905, 'modeonly': 5906, 'gestures': 5907, 'encounter': 5908, 'greater': 5909, 'thenks': 5910, 'guided': 5911, 'cos': 5912, 'hemmer': 5913, 'pricedelivery': 5914, 'afar': 5915, 'pushes': 5916, 'vaccume': 5917, 'spider': 5918, 'webs': 5919, 'germ': 5920, 'coins': 5921, 'relly': 5922, 'ly': 5923, 'nyccc': 5924, 'havy': 5925, 'productbetter': 5926, 'suggeston': 5927, 'stained': 5928, 'escape': 5929, 'certified': 5930, 'fluctuating': 5931, 'oled': 5932, 'sake': 5933, 'loveit': 5934, 'servicethanks': 5935, 'dessert': 5936, 'calibration': 5937, 'productgud': 5938, 'coiling': 5939, 'outstandingi': 5940, 'contactless': 5941, 'hieght': 5942, 'chunk': 5943, 'stopping': 5944, 'dx': 5945, 'markable': 5946, 'costally': 5947, 'minerals': 5948, 'producer': 5949, 'perfectlyit': 5950, 'unprofessional': 5951, 'rush': 5952, 'suffering': 5953, 'wrapped': 5954, 'goodyou': 5955, 'muscles': 5956, 'joined': 5957, 'nails': 5958, 'tgis': 5959, 'backed': 5960, 'innovation': 5961, 'thermocol': 5962, 'servicethank': 5963, 'footballi': 5964, 'workers': 5965, 'oneoverall': 5966, 'requesting': 5967, 'productmore': 5968, 'nut': 5969, 'qualified': 5970, 'fee': 5971, 'deadline': 5972, 'qlty': 5973, 'timeso': 5974, 'satisfieddelivery': 5975, 'goodusing': 5976, 'sprouted': 5977, 'tone': 5978, 'elaborated': 5979, 'cozz': 5980, 'underside': 5981, 'lence': 5982, 'flipcrt': 5983, 'layers': 5984, 'timeline': 5985, 'forward': 5986, 'buzzer': 5987, 'ran': 5988, 'contrast': 5989, 'particals': 5990, 'spark': 5991, 'chocolate': 5992, 'besti': 5993, 'goodgot': 5994, 'bionic': 5995, 'lajawab': 5996, 'motorcycle': 5997, 'slicing': 5998, 'dietitian': 5999, 'jee': 6000, 'emergency': 6001, 'business': 6002, 'shopin': 6003, 'organiser': 6004, 'benifits': 6005, 'deshmukh': 6006, 'oldest': 6007, 'smoothness': 6008, 'rangeif': 6009, 'botton': 6010, 'tends': 6011, 'chill': 6012, 'budge': 6013, 'nail': 6014, 'poking': 6015, 'atlest': 6016, 'fond': 6017, 'coool': 6018, 'shoping': 6019, 'decorating': 6020, 'mesmerising': 6021, 'listened': 6022, 'epic': 6023, 'methe': 6024, 'computers': 6025, 'casing': 6026, 'interrupted': 6027, 'reduces': 6028, 'orderedqualitycoloursize': 6029, 'goodworthy': 6030, 'stumps': 6031, 'plasma': 6032, 'crafts': 6033, 'lumbar': 6034, 'freedom': 6035, 'itm': 6036, 'buddy': 6037, 'balm': 6038, 'blur': 6039, 'moneynice': 6040, 'davangere': 6041, 'satified': 6042, 'jiffy': 6043, 'knew': 6044, 'definition': 6045, 'jump': 6046, 'bot': 6047, 'biginners': 6048, 'dries': 6049, 'productluv': 6050, 'wonders': 6051, 'rom': 6052, 'browser': 6053, 'alto': 6054, 'strudy': 6055, 'indoors': 6056, 'wherein': 6057, 'laid': 6058, 'goodbye': 6059, 'mobil': 6060, 'hexa': 6061, 'temprature': 6062, 'lte': 6063, 'dongle': 6064, 'outlook': 6065, 'researched': 6066, 'cooled': 6067, 'praise': 6068, 'upscguide': 6069, 'vare': 6070, 'shades': 6071, 'valu': 6072, 'rakshabandhan': 6073, 'itbattery': 6074, 'clr': 6075, 'productworks': 6076, 'flpkrt': 6077, 'cromecast': 6078, 'vast': 6079, 'kich': 6080, 'peddle': 6081, 'supreme': 6082, 'certificate': 6083, 'skit': 6084, 'designlight': 6085, 'mrf': 6086, 'quailty': 6087, 'descriptive': 6088, 'pdf': 6089, 'rangejust': 6090, 'economy': 6091, 'nowawesome': 6092, 'chargei': 6093, 'warp': 6094, 'adaptorsound': 6095, 'filpkard': 6096, 'timebest': 6097, 'amazingi': 6098, 'ratinghope': 6099, 'join': 6100, 'paratha': 6101, 'markets': 6102, 'success': 6103, 'oppo': 6104, 'earth': 6105, 'woods': 6106, 'jiofi': 6107, 'elegent': 6108, 'dated': 6109, 'tandoor': 6110, 'martial': 6111, 'thankx': 6112, 'smelljust': 6113, 'pp': 6114, 'xiomi': 6115, 'budjet': 6116, 'mudguards': 6117, 'tighten': 6118, 'producteverything': 6119, 'backing': 6120, 'moneygreat': 6121, 'deliveryno': 6122, 'spoon': 6123, 'wobbles': 6124, 'recepies': 6125, 'tore': 6126, 'slides': 6127, 'etcthe': 6128, 'treated': 6129, 'youd': 6130, 'le': 6131, 'fanspeed': 6132, 'twiceits': 6133, 'reported': 6134, 'kartthe': 6135, 'relay': 6136, 'personi': 6137, 'festive': 6138, 'keyboards': 6139, 'murti': 6140, 'appreciative': 6141, 'goodbuy': 6142, 'promote': 6143, 'neak': 6144, 'nyce': 6145, 'syncing': 6146, 'segmentno': 6147, 'upc': 6148, 'tweak': 6149, 'usageits': 6150, 'sanitizer': 6151, 'alpha': 6152, 'thankew': 6153, 'momentarily': 6154, 'young': 6155, 'oneeasy': 6156, 'rhino': 6157, 'refrigreter': 6158, 'qualitymust': 6159, 'otp': 6160, 'upgradable': 6161, 'assurance': 6162, 'teaching': 6163, 'capri': 6164, 'knees': 6165, 'rolling': 6166, 'watchthank': 6167, 'arrangement': 6168, 'unzip': 6169, 'samar': 6170, 'specifying': 6171, 'definately': 6172, 'woman': 6173, 'vere': 6174, 'fasting': 6175, 'thnkyou': 6176, 'originality': 6177, 'imp': 6178, 'metres': 6179, 'paining': 6180, 'woooow': 6181, 'prodict': 6182, 'coviself': 6183, 'proceed': 6184, 'moneybetter': 6185, 'tells': 6186, 'padded': 6187, 'stamp': 6188, 'hpy': 6189, 'deeply': 6190, 'emitting': 6191, 'useges': 6192, 'picturei': 6193, 'mahadev': 6194, 'har': 6195, 'suite': 6196, 'republic': 6197, 'protector': 6198, 'flipkrt': 6199, 'trackpad': 6200, 'veryyy': 6201, 'optic': 6202, 'deliverynot': 6203, 'wowwhen': 6204, 'volumemind': 6205, 'chimmey': 6206, 'jun': 6207, 'whatsoever': 6208, 'thankq': 6209, 'goodim': 6210, 'rim': 6211, 'banded': 6212, 'poordont': 6213, 'crafted': 6214, 'scrapper': 6215, 'workload': 6216, 'shutter': 6217, 'dude': 6218, 'compares': 6219, 'blown': 6220, 'ans': 6221, 'cd': 6222, 'detective': 6223, 'lived': 6224, 'igpu': 6225, 'chargingno': 6226, 'superd': 6227, 'thaks': 6228, 'views': 6229, 'iso': 6230, 'horizon': 6231, 'grips': 6232, 'steching': 6233, 'gather': 6234, 'naice': 6235, 'dir': 6236, 'hw': 6237, 'leptop': 6238, 'priority': 6239, 'conscious': 6240, 'drag': 6241, 'clour': 6242, 'bars': 6243, 'lake': 6244, 'rakhi': 6245, 'dinar': 6246, 'swim': 6247, 'staffs': 6248, 'improvised': 6249, 'wellbut': 6250, 'needing': 6251, 'indias': 6252, 'productplease': 6253, 'prodcuct': 6254, 'khan': 6255, 'standards': 6256, 'meena': 6257, 'banana': 6258, 'qualitythey': 6259, 'repeat': 6260, 'indiclub': 6261, 'rounded': 6262, 'awesomefast': 6263, 'anupama': 6264, 'helpfuloverall': 6265, 'panic': 6266, 'tailor': 6267, 'sheded': 6268, 'sizebest': 6269, 'timeit': 6270, 'serviceman': 6271, 'baddelivery': 6272, 'reaching': 6273, 'badits': 6274, 'cashback': 6275, 'thistoo': 6276, 'transparentwhen': 6277, 'shaped': 6278, 'ta': 6279, 'tutorials': 6280, 'resion': 6281, 'odisha': 6282, 'evident': 6283, 'gret': 6284, 'deliveried': 6285, 'packageing': 6286, 'exception': 6287, 'km': 6288, 'itcons': 6289, 'lenses': 6290, 'shifted': 6291, 'configured': 6292, 'pennypacking': 6293, 'mink': 6294, 'generally': 6295, 'convenience': 6296, 'stoching': 6297, 'paytern': 6298, 'struggle': 6299, 'wld': 6300, 'reader': 6301, 'isi': 6302, 'shell': 6303, 'forthe': 6304, 'simplicity': 6305, 'particle': 6306, 'arise': 6307, 'sweater': 6308, 'launched': 6309, 'prewash': 6310, 'pf': 6311, 'fades': 6312, 'reachable': 6313, 'guarantee': 6314, 'programs': 6315, 'goid': 6316, 'passwords': 6317, 'diswasher': 6318, 'suuuper': 6319, 'bonus': 6320, 'consumed': 6321, 'quik': 6322, 'wings': 6323, 'bent': 6324, 'blessed': 6325, 'indications': 6326, 'cream': 6327, 'compromised': 6328, 'appropriate': 6329, 'gooooood': 6330, 'monthsit': 6331, 'packagingand': 6332, 'nicesound': 6333, 'trips': 6334, 'thali': 6335, 'theyll': 6336, 'cartoon': 6337, 'outs': 6338, 'thankuuu': 6339, 'oneits': 6340, 'mnths': 6341, 'pains': 6342, 'wieght': 6343, 'multivitamin': 6344, 'wastes': 6345, 'coll': 6346, 'prodct': 6347, 'assure': 6348, 'badthe': 6349, 'tune': 6350, 'dot': 6351, 'benifit': 6352, 'cultsport': 6353, 'heavily': 6354, 'moneyoverall': 6355, 'averagenot': 6356, 'devicesound': 6357, 'etci': 6358, 'fluid': 6359, 'evey': 6360, 'jobs': 6361, 'minutesits': 6362, 'bust': 6363, 'pinoverall': 6364, 'avilable': 6365, 'hillgrove': 6366, 'tvnew': 6367, 'bedrooms': 6368, 'dislike': 6369, 'productwhile': 6370, 'skill': 6371, 'baas': 6372, 'isolation': 6373, 'betry': 6374, 'inputs': 6375, 'hopes': 6376, 'shocs': 6377, 'ho': 6378, 'mhz': 6379, 'subtle': 6380, 'bless': 6381, 'workingbut': 6382, 'weightless': 6383, 'hung': 6384, 'compartments': 6385, 'forest': 6386, 'ecom': 6387, 'organise': 6388, 'thermo': 6389, 'spinbot': 6390, 'thereafter': 6391, 'comfortablesuperb': 6392, 'shout': 6393, 'fati': 6394, 'dayit': 6395, 'easilythe': 6396, 'curd': 6397, 'timeits': 6398, 'qualityfor': 6399, 'hectic': 6400, 'coated': 6401, 'qnd': 6402, 'confuses': 6403, 'itsuper': 6404, 'pencils': 6405, 'rise': 6406, 'conection': 6407, 'strom': 6408, 'slime': 6409, 'striching': 6410, 'flipkartvery': 6411, 'intelligence': 6412, 'thisthe': 6413, 'bilt': 6414, 'watermelon': 6415, 'rome': 6416, 'ni': 6417, 'opted': 6418, 'installationdemo': 6419, 'pricea': 6420, 'crocs': 6421, 'development': 6422, 'grinde': 6423, 'safty': 6424, 'settled': 6425, 'elements': 6426, 'problemsmy': 6427, 'profast': 6428, 'dispenser': 6429, 'asmatic': 6430, 'industrial': 6431, 'batteryit': 6432, 'proving': 6433, 'proscons': 6434, 'batterys': 6435, 'premier': 6436, 'interior': 6437, 'voucher': 6438, 'servicei': 6439, 'catrage': 6440, 'introduce': 6441, 'avante': 6442, 'aftr': 6443, 'bycycle': 6444, 'maintaining': 6445, 'wo': 6446, 'selfie': 6447, 'moneydont': 6448, 'greatbass': 6449, 'flute': 6450, 'rode': 6451, 'childhood': 6452, 'moneyproduct': 6453, 'peice': 6454, 'followup': 6455, 'methanks': 6456, 'hack': 6457, 'tolerance': 6458, 'duplex': 6459, 'dilemma': 6460, 'extraction': 6461, 'learns': 6462, 'zing': 6463, 'metallic': 6464, 'bathing': 6465, 'geysers': 6466, 'surfaces': 6467, 'sprays': 6468, 'sho': 6469, 'shed': 6470, 'surojit': 6471, 'pe': 6472, 'presser': 6473, 'spreads': 6474, 'iteam': 6475, 'suites': 6476, 'alsoquality': 6477, 'superbass': 6478, 'chromcast': 6479, 'separation': 6480, 'specificationsso': 6481, 'tampered': 6482, 'upgradation': 6483, 'proves': 6484, 'installationthe': 6485, 'battrey': 6486, 'showpieces': 6487, 'itjust': 6488, 'mechanism': 6489, 'flipkartyou': 6490, 'disadvantages': 6491, 'fat': 6492, 'glitches': 6493, 'pressed': 6494, 'techlife': 6495, 'tatasky': 6496, 'credibility': 6497, 'onions': 6498, 'noted': 6499, 'itemit': 6500, 'lena': 6501, 'aaya': 6502, 'approaching': 6503, 'icecream': 6504, 'itordered': 6505, 'dusty': 6506, 'fortune': 6507, 'idol': 6508, 'gurantee': 6509, 'itwill': 6510, 'payment': 6511, 'yall': 6512, 'sonyliv': 6513, 'experienceafter': 6514, 'ugly': 6515, 'wore': 6516, 'frustrating': 6517, 'replesment': 6518, 'sattelite': 6519, 'wel': 6520, 'barbad': 6521, 'believed': 6522, 'worstno': 6523, 'bacterial': 6524, 'grains': 6525, 'itchy': 6526, 'throat': 6527, 'shutting': 6528, 'curve': 6529, 'timewaste': 6530, 'qualitywaste': 6531, 'chargeable': 6532, 'rudely': 6533, 'verybad': 6534, 'detached': 6535, 'roasted': 6536, 'spares': 6537, 'stander': 6538, 'wellwe': 6539, 'onlynot': 6540, 'swings': 6541, 'scam': 6542, 'cheaters': 6543, 'humming': 6544, 'puncture': 6545, 'performancebut': 6546, 'productpls': 6547, 'pictureand': 6548, 'letter': 6549, 'satellites': 6550, 'sparks': 6551, 'unsafe': 6552, 'qualty': 6553, 'marketing': 6554, 'rewashed': 6555, 'anchor': 6556, 'bolts': 6557, 'elasticity': 6558, 'beacuse': 6559, 'tipcial': 6560, 'salty': 6561, 'problemi': 6562, 'recharge': 6563, 'flipkartdont': 6564, 'mint': 6565, 'tide': 6566, 'circumstances': 6567, 'contrasting': 6568, 'flipkartplease': 6569, 'sunmica': 6570, 'largest': 6571, 'badno': 6572, 'clips': 6573, 'bade': 6574, 'workingplease': 6575, 'pooor': 6576, 'enoughmoney': 6577, 'warrant': 6578, 'beter': 6579, 'fed': 6580, 'rama': 6581, 'fraud': 6582, 'police': 6583, 'thrash': 6584, 'emptying': 6585, 'basketballthe': 6586, 'squeeze': 6587, 'repairing': 6588, 'cheater': 6589, 'ghatiya': 6590, 'productsome': 6591, 'mere': 6592, 'shole': 6593, 'sensing': 6594, 'leak': 6595, 'plain': 6596, 'pathwall': 6597, 'homehard': 6598, 'itdoes': 6599, 'fluke': 6600, 'abd': 6601, 'encourage': 6602, 'emails': 6603, 'qualityafter': 6604, 'dissappointed': 6605, 'veery': 6606, 'thred': 6607, 'sep': 6608, 'overlooked': 6609, 'unboxed': 6610, 'workbut': 6611, 'ginger': 6612, 'properlyafter': 6613, 'pan': 6614, 'worstdont': 6615, 'roadside': 6616, 'por': 6617, 'alll': 6618, 'stb': 6619, 'kicks': 6620, 'fraudster': 6621, 'hopeless': 6622, 'productnever': 6623, 'qr': 6624, 'dyson': 6625, 'eureka': 6626, 'jmg': 6627, 'pedal': 6628, 'bamboo': 6629, 'modify': 6630, 'monny': 6631, 'shrunk': 6632, 'serviceso': 6633, 'fibre': 6634, 'puriet': 6635, 'ultima': 6636, 'diagnosing': 6637, 'buywithin': 6638, 'mixy': 6639, 'badplease': 6640, 'wobbling': 6641, 'siemens': 6642, 'discomfort': 6643, 'stickers': 6644, 'regretting': 6645, 'metrial': 6646, 'unfit': 6647, 'yetvery': 6648, 'shame': 6649, 'freezing': 6650, 'brothers': 6651, 'simultaneously': 6652, 'hangs': 6653, 'nos': 6654, 'unfinished': 6655, 'cartrage': 6656, 'saige': 6657, 'sme': 6658, 'bubbles': 6659, 'prove': 6660, 'disconnects': 6661, 'battle': 6662, 'rotary': 6663, 'picking': 6664, 'predecessor': 6665, 'modd': 6666, 'backupif': 6667, 'afer': 6668, 'poori': 6669, 'foolish': 6670, 'corrupt': 6671, 'foots': 6672, 'goodstitches': 6673, 'ahmedabad': 6674, 'vadodara': 6675, 'networks': 6676, 'putify': 6677, 'crackers': 6678, 'gudjust': 6679, 'utterly': 6680, 'bites': 6681, 'qulati': 6682, 'adaptorfirst': 6683, 'tooooo': 6684, 'airtel': 6685, 'daysit': 6686, 'steches': 6687, 'wasteshown': 6688, 'dryer': 6689, 'returns': 6690, 'apparent': 6691, 'bezels': 6692, 'effectbetter': 6693, 'excessive': 6694, 'longerand': 6695, 'redirect': 6696, 'badonly': 6697, 'strictly': 6698, 'flight': 6699, 'caught': 6700, 'hurting': 6701, 'secondary': 6702, 'looting': 6703, 'tottaly': 6704, 'disapointing': 6705, 'bakwas': 6706, 'workingworst': 6707, 'dispointed': 6708, 'chaing': 6709, 'hardand': 6710, 'norlam': 6711, 'katori': 6712, 'chinesse': 6713, 'buffer': 6714, 'roller': 6715, 'usedit': 6716, 'forums': 6717, 'remained': 6718, 'badddddddddddddd': 6719, 'pacas': 6720, 'weste': 6721, 'unsatisfactory': 6722, 'substandard': 6723, 'pieceshave': 6724, 'buycheap': 6725, 'unuseful': 6726, 'batery': 6727, 'pop': 6728, 'vessle': 6729, 'amounti': 6730, 'unsure': 6731, 'plazo': 6732, 'inseam': 6733, 'battary': 6734, 'recerified': 6735, 'antennas': 6736, 'sowed': 6737, 'coarse': 6738, 'indicaterlight': 6739, 'weekdays': 6740, 'insects': 6741, 'smoll': 6742, 'goodplease': 6743, 'basses': 6744, 'ang': 6745, 'remarks': 6746, 'decant': 6747, 'projectors': 6748, 'hits': 6749, 'notspecified': 6750, 'tnstal': 6751, 'ohkk': 6752, 'relatively': 6753, 'pouring': 6754, 'maney': 6755, 'mass': 6756, 'okkbut': 6757, 'bedbecause': 6758, 'openvery': 6759, 'sleepy': 6760, 'lp': 6761, 'pillar': 6762, 'oxigen': 6763, 'concentrator': 6764, 'amazingkey': 6765, 'millions': 6766, 'keystrokescable': 6767, 'metrekeyboard': 6768, 'grams': 6769, 'featuresmi': 6770, 'yearit': 6771, 'tvconnect': 6772, 'optionyoutubewynk': 6773, 'reson': 6774, 'superbmade': 6775, 'philippines': 6776, 'ossssssssm': 6777, 'greatmaterial': 6778, 'earsoutside': 6779, 'offi': 6780, 'ocm': 6781, 'discounted': 6782, 'byed': 6783, 'blood': 6784, 'weeki': 6785, 'grinderapart': 6786, 'fluctuation': 6787, 'noisesatisfied': 6788, 'kinds': 6789, 'silence': 6790, 'functionsturdy': 6791, 'bodysmart': 6792, 'coolerthank': 6793, 'investedthis': 6794, 'productworthy': 6795, 'novice': 6796, 'usersbuild': 6797, 'sonthank': 6798, 'counter': 6799, 'clockwise': 6800, 'entrylevel': 6801, 'plane': 6802, 'kerala': 6803, 'kannur': 6804, 'distand': 6805, 'demos': 6806, 'looksure': 6807, 'basul': 6808, 'memultimedia': 6809, 'killeridk': 6810, 'determine': 6811, 'operable': 6812, 'remotelyvalue': 6813, 'wounderful': 6814, 'warmth': 6815, 'hott': 6816, 'ligt': 6817, 'sizedont': 6818, 'purchasedi': 6819, 'musicreasonable': 6820, 'properlydo': 6821, 'continuouslydo': 6822, 'offlinedo': 6823, 'timecustomers': 6824, 'callsneed': 6825, 'engagement': 6826, 'workvery': 6827, 'basssssss': 6828, 'originaland': 6829, 'faithful': 6830, 'hellow': 6831, 'stete': 6832, 'ponada': 6833, 'chandanam': 6834, 'productsounds': 6835, 'goodbass': 6836, 'lowbuild': 6837, 'floorsand': 6838, 'separates': 6839, 'leakege': 6840, 'markapart': 6841, 'satisfiedgo': 6842, 'deliveryfully': 6843, 'valvue': 6844, 'neededthis': 6845, 'deliveryo': 6846, 'fittinggrt': 6847, 'havevery': 6848, 'duckpipe': 6849, 'soundbarvalue': 6850, 'moneybuilt': 6851, 'voicebattery': 6852, 'connectivitynice': 6853, 'zhyak': 6854, 'hy': 6855, 'disrupted': 6856, 'bottomnice': 6857, 'suspected': 6858, 'carpets': 6859, 'speakersound': 6860, 'excellentbass': 6861, 'bestconnectivity': 6862, 'productprosdisplay': 6863, 'brilliantbattery': 6864, 'keyboardlooks': 6865, 'fantasticconsaudio': 6866, 'wrth': 6867, 'costt': 6868, 'beltmost': 6869, 'impit': 6870, 'waistbecause': 6871, 'oksmall': 6872, 'chairvery': 6873, 'productalsothe': 6874, 'medico': 6875, 'bigener': 6876, 'apparels': 6877, 'battel': 6878, 'gokarna': 6879, 'ankola': 6880, 'rent': 6881, 'dehliveryeven': 6882, 'dehlivery': 6883, 'itsamsung': 6884, 'goodlow': 6885, 'speedmotor': 6886, 'itoriginal': 6887, 'durablewater': 6888, 'cooleryou': 6889, 'desipointed': 6890, 'morninggo': 6891, 'tvnice': 6892, 'pictureloud': 6893, 'immediatelymiracast': 6894, 'playstoreamazing': 6895, 'featureif': 6896, 'soundthis': 6897, 'delhivery': 6898, 'moneytaste': 6899, 'pricingthe': 6900, 'mirroringcast': 6901, 'updatedusing': 6902, 'qeualty': 6903, 'matiriyal': 6904, 'ninety': 6905, 'centimetre': 6906, 'capabilityone': 6907, 'dealbreaker': 6908, 'optionally': 6909, 'moneylike': 6910, 'hassles': 6911, 'terrace': 6912, 'knowhow': 6913, 'wateralso': 6914, 'extr': 6915, 'bluetooththis': 6916, 'tikkis': 6917, 'tailors': 6918, 'rorating': 6919, 'highlighing': 6920, 'producut': 6921, 'lookingif': 6922, 'mashineeasy': 6923, 'engineerbought': 6924, 'cameraim': 6925, 'hes': 6926, 'nightand': 6927, 'crying': 6928, 'couplei': 6929, 'resolving': 6930, 'etectricals': 6931, 'oulet': 6932, 'installtional': 6933, 'fowl': 6934, 'superbmy': 6935, 'itquality': 6936, 'supurb': 6937, 'musiconce': 6938, 'daysthis': 6939, 'bestthanks': 6940, 'himexcellent': 6941, 'princess': 6942, 'glaze': 6943, 'cornerhappy': 6944, 'multifold': 6945, 'decleanser': 6946, 'healer': 6947, 'properties': 6948, 'residue': 6949, 'soldiring': 6950, 'plucker': 6951, 'useheated': 6952, 'weightthe': 6953, 'immersed': 6954, 'areatotally': 6955, 'bugget': 6956, 'batbutdelivery': 6957, 'radius': 6958, 'liners': 6959, 'qaulaity': 6960, 'changeover': 6961, 'monthsedit': 6962, 'foundation': 6963, 'flipkartquick': 6964, 'daysprosexact': 6965, 'detailsbig': 6966, 'roomwater': 6967, 'independently': 6968, 'knobwater': 6969, 'bash': 6970, 'movinginternal': 6971, 'fittedside': 6972, 'tankhoneycomb': 6973, 'bole': 6974, 'disburse': 6975, 'amejing': 6976, 'occupies': 6977, 'spacecleaning': 6978, 'scrapped': 6979, 'butterhigh': 6980, 'utilisation': 6981, 'installatio': 6982, 'risevad': 6983, 'helty': 6984, 'taskingsimulations': 6985, 'modelling': 6986, 'phd': 6987, 'engineersscientists': 6988, 'fassured': 6989, 'studypalying': 6990, 'gamesread': 6991, 'newspaperperfect': 6992, 'purposesgood': 6993, 'ratw': 6994, 'packedwithout': 6995, 'scrachit': 6996, 'wifegf': 6997, 'premiereps': 6998, 'cheery': 6999, 'gunjithicker': 7000, 'coursegood': 7001, 'washthen': 7002, 'thisyes': 7003, 'absolete': 7004, 'tankat': 7005, 'awesomequality': 7006, 'mostdont': 7007, 'waitgo': 7008, 'designonly': 7009, 'slowest': 7010, 'kbs': 7011, 'lovedthank': 7012, 'inflating': 7013, 'amazig': 7014, 'pandamic': 7015, 'vanheusen': 7016, 'twitters': 7017, 'sonyi': 7018, 'puch': 7019, 'loverunder': 7020, 'doubtloving': 7021, 'productbecause': 7022, 'bassmetallic': 7023, 'goesthank': 7024, 'betterberi': 7025, 'handelhandel': 7026, 'seperated': 7027, 'dilver': 7028, 'poorwhen': 7029, 'boxthank': 7030, 'candle': 7031, 'excelleny': 7032, 'sunnext': 7033, 'guiding': 7034, 'customerfriendly': 7035, 'flipkartregarding': 7036, 'scheduling': 7037, 'fellow': 7038, 'cutoff': 7039, 'hygienically': 7040, 'kadhai': 7041, 'misconceptions': 7042, 'contextuses': 7043, 'successfullyvery': 7044, 'rangeguys': 7045, 'sends': 7046, 'exami': 7047, 'booksthis': 7048, 'enrich': 7049, 'practicevery': 7050, 'preparationlots': 7051, 'soundin': 7052, 'pricesebastian': 7053, 'mundakayam': 7054, 'costely': 7055, 'coolingloved': 7056, 'soundthank': 7057, 'avails': 7058, 'inchthe': 7059, 'matlic': 7060, 'awsomethank': 7061, 'boxsound': 7062, 'impressiveconnectivity': 7063, 'avi': 7064, 'reachdelivery': 7065, 'accustomed': 7066, 'reflection': 7067, 'beautifulli': 7068, 'hphonethank': 7069, 'pb': 7070, 'memberson': 7071, 'barring': 7072, 'productuse': 7073, 'jobits': 7074, 'waterless': 7075, 'contributing': 7076, 'deviceavoid': 7077, 'voocsuperdart': 7078, 'tremendousi': 7079, 'reveiw': 7080, 'lent': 7081, 'machanical': 7082, 'itloved': 7083, 'brotrust': 7084, 'meyou': 7085, 'moneyyou': 7086, 'problemnow': 7087, 'muchchange': 7088, 'halli': 7089, 'negatively': 7090, 'experienceso': 7091, 'effected': 7092, 'surrounding': 7093, 'helpfullthank': 7094, 'periodtimex': 7095, 'bloothoot': 7096, 'hangers': 7097, 'supportable': 7098, 'dealgot': 7099, 'handleeven': 7100, 'vastu': 7101, 'treatment': 7102, 'excellentnice': 7103, 'timelly': 7104, 'alexajust': 7105, 'devicethanks': 7106, 'kinely': 7107, 'combinations': 7108, 'iern': 7109, 'reviewdelivery': 7110, 'prompti': 7111, 'deliverymany': 7112, 'cartnow': 7113, 'excellentfrost': 7114, 'freenoiselessdrawback': 7115, 'fridgeif': 7116, 'litrefreezer': 7117, 'minister': 7118, 'serviceable': 7119, 'bitover': 7120, 'depand': 7121, 'tobother': 7122, 'immediatly': 7123, 'setups': 7124, 'tasts': 7125, 'finefinally': 7126, 'nailed': 7127, 'pricings': 7128, 'useable': 7129, 'vehicles': 7130, 'twelve': 7131, 'fortyeight': 7132, 'wicket': 7133, 'onlytaking': 7134, 'cheapernot': 7135, 'flipkartalso': 7136, 'weat': 7137, 'lwono': 7138, 'addressed': 7139, 'reviewbelieve': 7140, 'pricewe': 7141, 'effecient': 7142, 'bagstylish': 7143, 'sparkles': 7144, 'waterexcept': 7145, 'eazy': 7146, 'usegood': 7147, 'qualityeazy': 7148, 'cleanworth': 7149, 'flipkartgo': 7150, 'youits': 7151, 'bevarages': 7152, 'tvetc': 7153, 'incorrect': 7154, 'hightits': 7155, 'mixergrinder': 7156, 'liquids': 7157, 'percolate': 7158, 'pointthe': 7159, 'charmhappy': 7160, 'indiakeep': 7161, 'poured': 7162, 'chargevalue': 7163, 'paesa': 7164, 'andproducts': 7165, 'laptopnice': 7166, 'performancelike': 7167, 'mohan': 7168, 'installationthanks': 7169, 'teamg': 7170, 'nagavenkatesh': 7171, 'thisfeel': 7172, 'ultraworks': 7173, 'purchaseoverall': 7174, 'bestcan': 7175, 'frothe': 7176, 'accumulate': 7177, 'geting': 7178, 'brick': 7179, 'mudguard': 7180, 'inmy': 7181, 'dipicted': 7182, 'barfast': 7183, 'nicebt': 7184, 'satisfiedabsolutely': 7185, 'modeflipkart': 7186, 'flagship': 7187, 'wars': 7188, 'jedi': 7189, 'borderlands': 7190, 'underwhelming': 7191, 'falt': 7192, 'intime': 7193, 'reviwing': 7194, 'daysbrakes': 7195, 'goodsuspension': 7196, 'shaft': 7197, 'legsno': 7198, 'seatsticker': 7199, 'qualityconclusion': 7200, 'marki': 7201, 'chapters': 7202, 'proudest': 7203, 'keyswell': 7204, 'mermerising': 7205, 'experiencethose': 7206, 'beatiful': 7207, 'sooperb': 7208, 'agowhen': 7209, 'itextra': 7210, 'andthe': 7211, 'qualitybamazingi': 7212, 'playingeach': 7213, 'compny': 7214, 'riveal': 7215, 'concentrate': 7216, 'studiness': 7217, 'haivery': 7218, 'cark': 7219, 'anta': 7220, 'plobrem': 7221, 'gods': 7222, 'frodect': 7223, 'niceone': 7224, 'concernas': 7225, 'singing': 7226, 'usablemoney': 7227, 'cupboard': 7228, 'producttq': 7229, 'hob': 7230, 'confidently': 7231, 'productsbest': 7232, 'labeled': 7233, 'weightonly': 7234, 'steadilyspeed': 7235, 'friendsi': 7236, 'frombellavitaluxuryofficial': 7237, 'usingthis': 7238, 'andeveryone': 7239, 'performanceusing': 7240, 'issuemust': 7241, 'installion': 7242, 'askin': 7243, 'gothe': 7244, 'bedsheets': 7245, 'clothesdoesnt': 7246, 'toothe': 7247, 'shin': 7248, 'bittry': 7249, 'appotherwise': 7250, 'watchthanks': 7251, 'wverybit': 7252, 'friended': 7253, 'pacakag': 7254, 'butnot': 7255, 'soubin': 7256, 'pariyaram': 7257, 'litilbit': 7258, 'hugo': 7259, 'barras': 7260, 'itselfmy': 7261, 'farexcellent': 7262, 'wondershepa': 7263, 'particulate': 7264, 'wifilastly': 7265, 'pirchase': 7266, 'favoritekajal': 7267, 'daysmy': 7268, 'gamings': 7269, 'bios': 7270, 'chasis': 7271, 'goodconsiderin': 7272, 'goodair': 7273, 'screensize': 7274, 'flowerno': 7275, 'hometheatre': 7276, 'nicem': 7277, 'datepackaging': 7278, 'donethank': 7279, 'awesomebest': 7280, 'plazzothank': 7281, 'yummy': 7282, 'pproductand': 7283, 'deliveredgood': 7284, 'performancefound': 7285, 'easytouse': 7286, 'dresh': 7287, 'phonepoco': 7288, 'soooooooooo': 7289, 'superball': 7290, 'shownplease': 7291, 'offerce': 7292, 'updateafter': 7293, 'smoothlyusing': 7294, 'monthperformance': 7295, 'noiselittle': 7296, 'writeread': 7297, 'writen': 7298, 'marketgo': 7299, 'weekit': 7300, 'alsoit': 7301, 'awesomesuperfast': 7302, 'thankuu': 7303, 'supergo': 7304, 'cautious': 7305, 'ihad': 7306, 'feeding': 7307, 'groceries': 7308, 'proformance': 7309, 'tarvellers': 7310, 'subscribtion': 7311, 'smoothproduct': 7312, 'suppar': 7313, 'battari': 7314, 'jully': 7315, 'healthier': 7316, 'ambience': 7317, 'pulls': 7318, 'allowed': 7319, 'bie': 7320, 'fastand': 7321, 'demoand': 7322, 'monthbefore': 7323, 'cx': 7324, 'boatbasically': 7325, 'giveup': 7326, 'dayssound': 7327, 'survice': 7328, 'conduction': 7329, 'asuusal': 7330, 'kidds': 7331, 'loue': 7332, 'pond': 7333, 'germs': 7334, 'frangrance': 7335, 'kuch': 7336, 'ekdum': 7337, 'jaadaacha': 7338, 'cs': 7339, 'apeakers': 7340, 'bday': 7341, 'suppermust': 7342, 'involve': 7343, 'detergentsthough': 7344, 'residues': 7345, 'sizesound': 7346, 'timelines': 7347, 'aspirent': 7348, 'thane': 7349, 'hopesreally': 7350, 'fantaatic': 7351, 'designdecent': 7352, 'colourgreat': 7353, 'performancecons': 7354, 'dissaipointed': 7355, 'grandfather': 7356, 'speech': 7357, 'weve': 7358, 'mwo': 7359, 'fancier': 7360, 'enthusiasm': 7361, 'usedthe': 7362, 'butlitle': 7363, 'wtloss': 7364, 'compareto': 7365, 'bying': 7366, 'musicotherwise': 7367, 'gossip': 7368, 'aunty': 7369, 'videosyou': 7370, 'blowingbut': 7371, 'formatsno': 7372, 'lgsony': 7373, 'yearsbut': 7374, 'expectednice': 7375, 'levelsheard': 7376, 'devicesprosgood': 7377, 'volumebass': 7378, 'goodbluetooth': 7379, 'connectivityconsnot': 7380, 'manyfm': 7381, 'antena': 7382, 'arrangeoverall': 7383, 'musical': 7384, 'highits': 7385, 'routes': 7386, 'productdoes': 7387, 'labcoat': 7388, 'reseanable': 7389, 'performancesound': 7390, 'priceam': 7391, 'ratei': 7392, 'prudect': 7393, 'custo': 7394, 'itlovely': 7395, 'performancefhd': 7396, 'favourit': 7397, 'jitendra': 7398, 'nawariya': 7399, 'crush': 7400, 'productsave': 7401, 'gorilla': 7402, 'measurement': 7403, 'alteration': 7404, 'worthygo': 7405, 'aspirantpage': 7406, 'flipkartpaper': 7407, 'itafter': 7408, 'wallvegetables': 7409, 'freshtimer': 7410, 'handlyeasy': 7411, 'peacock': 7412, 'njoy': 7413, 'trackpant': 7414, 'substitute': 7415, 'hersheys': 7416, 'dynamite': 7417, 'grenade': 7418, 'lunch': 7419, 'smalland': 7420, 'osmproduct': 7421, 'productcharging': 7422, 'autostop': 7423, 'mg': 7424, 'cartige': 7425, 'superbreally': 7426, 'highek': 7427, 'breasted': 7428, 'blazerbest': 7429, 'trylyfebcom': 7430, 'beddings': 7431, 'illiterate': 7432, 'thts': 7433, 'apporiate': 7434, 'bfl': 7435, 'hip': 7436, 'securely': 7437, 'facts': 7438, 'monthsand': 7439, 'cardsi': 7440, 'ithigh': 7441, 'workingthis': 7442, 'vacume': 7443, 'feetspray': 7444, 'mist': 7445, 'streamjust': 7446, 'wooooow': 7447, 'matrial': 7448, 'cleanvalue': 7449, 'tvthats': 7450, 'bbdand': 7451, 'supportthank': 7452, 'verymuch': 7453, 'awosem': 7454, 'carefree': 7455, 'loosening': 7456, 'juicervalue': 7457, 'dealgood': 7458, 'acer': 7459, 'nitro': 7460, 'counterpart': 7461, 'violet': 7462, 'cop': 7463, 'datedetailed': 7464, 'resulte': 7465, 'mana': 7466, 'leya': 7467, 'dilebry': 7468, 'burmood': 7469, 'kalse': 7470, 'deviceit': 7471, 'secondsbass': 7472, 'effectivemy': 7473, 'phoneexcellent': 7474, 'toflipkart': 7475, 'worthi': 7476, 'discountbest': 7477, 'amt': 7478, 'cowaltiy': 7479, 'findings': 7480, 'monthsreview': 7481, 'cares': 7482, 'behalf': 7483, 'schedulecolor': 7484, 'relationship': 7485, 'tightear': 7486, 'pricesatisfied': 7487, 'cutedressi': 7488, 'speakermind': 7489, 'vundhi': 7490, 'worker': 7491, 'speedrepeater': 7492, 'mke': 7493, 'possibility': 7494, 'receipt': 7495, 'imagenyc': 7496, 'qualitypicture': 7497, 'tempeture': 7498, 'dailygo': 7499, 'acording': 7500, 'enhancement': 7501, 'alsi': 7502, 'kjal': 7503, 'goodvalu': 7504, 'munny': 7505, 'commecial': 7506, 'taskingdisplay': 7507, 'fastbody': 7508, 'pepoles': 7509, 'beautifuli': 7510, 'jucer': 7511, 'dupatt': 7512, 'juicermixer': 7513, 'regulatory': 7514, 'approval': 7515, 'bookgood': 7516, 'asiprants': 7517, 'prevents': 7518, 'oxidization': 7519, 'pulpy': 7520, 'stealing': 7521, 'attention': 7522, 'public': 7523, 'lovef': 7524, 'tshirtnice': 7525, 'meshow': 7526, 'inchthis': 7527, 'budgetabout': 7528, 'gupta': 7529, 'delicateshould': 7530, 'weekly': 7531, 'perches': 7532, 'juicerafter': 7533, 'playng': 7534, 'enjoyng': 7535, 'chimneyinstallation': 7536, 'timesurprisingly': 7537, 'surp': 7538, 'producet': 7539, 'deflection': 7540, 'handfingers': 7541, 'flipkartsuper': 7542, 'buyingif': 7543, 'conviction': 7544, 'exalent': 7545, 'superits': 7546, 'oneand': 7547, 'ole': 7548, 'guyzz': 7549, 'panits': 7550, 'thanka': 7551, 'chargerim': 7552, 'tod': 7553, 'cromptoni': 7554, 'outlayer': 7555, 'brokenbut': 7556, 'voiceclearity': 7557, 'productpackeging': 7558, 'snob': 7559, 'fki': 7560, 'niceno': 7561, 'breakagevery': 7562, 'breakfast': 7563, 'youvso': 7564, 'nais': 7565, 'nicethis': 7566, 'moneythank': 7567, 'vaild': 7568, 'goodwireless': 7569, 'greatmore': 7570, 'masst': 7571, 'awesum': 7572, 'wfm': 7573, 'budoverall': 7574, 'finedelivery': 7575, 'verrrrrry': 7576, 'displayeasy': 7577, 'purchasethank': 7578, 'soundthe': 7579, 'sha': 7580, 'prizes': 7581, 'excellentall': 7582, 'taught': 7583, 'opend': 7584, 'relish': 7585, 'bht': 7586, 'segmentcustomer': 7587, 'picturesgo': 7588, 'pricehp': 7589, 'moneyy': 7590, 'obsessed': 7591, 'friendlybest': 7592, 'refrijareter': 7593, 'changedwe': 7594, 'ourshelves': 7595, 'featured': 7596, 'eh': 7597, 'soundbarvoice': 7598, 'cleardesign': 7599, 'attractivebig': 7600, 'faimily': 7601, 'phoneso': 7602, 'restarted': 7603, 'compulsion': 7604, 'rely': 7605, 'continuouslyi': 7606, 'remont': 7607, 'speedtill': 7608, 'consand': 7609, 'cooleroverall': 7610, 'flipfart': 7611, 'alsoworth': 7612, 'couldt': 7613, 'qlitety': 7614, 'fascinating': 7615, 'fantasticwell': 7616, 'parties': 7617, 'juicercentrifugal': 7618, 'musy': 7619, 'customersthanks': 7620, 'steaching': 7621, 'foundwaiting': 7622, 'againwidely': 7623, 'comunication': 7624, 'neraiya': 7625, 'eruku': 7626, 'othersvery': 7627, 'itnm': 7628, 'yipppiee': 7629, 'buckspurifier': 7630, 'lookwisero': 7631, 'storagewater': 7632, 'aloot': 7633, 'flouride': 7634, 'effectivelycurrent': 7635, 'differenence': 7636, 'eb': 7637, 'billsometimes': 7638, 'dryheat': 7639, 'aswam': 7640, 'gopinadhan': 7641, 'tvvery': 7642, 'usefullone': 7643, 'firendly': 7644, 'consistsy': 7645, 'guyx': 7646, 'guyworks': 7647, 'lyk': 7648, 'electricityotherwise': 7649, 'fazoolwaste': 7650, 'fant': 7651, 'eliminates': 7652, 'potassium': 7653, 'pdfs': 7654, 'mned': 7655, 'babyi': 7656, 'champ': 7657, 'sorraundcan': 7658, 'coolmy': 7659, 'exselent': 7660, 'purduct': 7661, 'extained': 7662, 'niceandbest': 7663, 'gooooddddddddd': 7664, 'skeatbord': 7665, 'frequentlycomfortabledont': 7666, 'spacegood': 7667, 'sanjeeda': 7668, 'productreasonable': 7669, 'happythankyou': 7670, 'lightsthey': 7671, 'din': 7672, 'pioneerbase': 7673, 'eon': 7674, 'filfkart': 7675, 'flowering': 7676, 'hotttt': 7677, 'awesomeproductbest': 7678, 'jat': 7679, 'osmjat': 7680, 'ligiting': 7681, 'batteryis': 7682, 'repeatbest': 7683, 'evn': 7684, 'musicam': 7685, 'whn': 7686, 'rupaesh': 7687, 'mistry': 7688, 'betteri': 7689, 'newsbhajans': 7690, 'tvbroadcast': 7691, 'phn': 7692, 'becos': 7693, 'mobmy': 7694, 'currier': 7695, 'himmy': 7696, 'flipkartgood': 7697, 'skat': 7698, 'boardi': 7699, 'flipcartmy': 7700, 'servicewish': 7701, 'prouduc': 7702, 'necessity': 7703, 'thumsup': 7704, 'bhut': 7705, 'kapdano': 7706, 'shart': 7707, 'uuuu': 7708, 'flipkartbest': 7709, 'clearty': 7710, 'speakerthanks': 7711, 'breads': 7712, 'yery': 7713, 'affortable': 7714, 'requiements': 7715, 'waswasher': 7716, 'andnut': 7717, 'keyboardit': 7718, 'delivers': 7719, 'expectedtop': 7720, 'proerly': 7721, 'demis': 7722, 'assemblelight': 7723, 'amazingonly': 7724, 'godvery': 7725, 'nicecame': 7726, 'flipkartthak': 7727, 'spill': 7728, 'tapwater': 7729, 'pricefast': 7730, 'disheartened': 7731, 'fatherhe': 7732, 'almira': 7733, 'iteasy': 7734, 'resemblequality': 7735, 'datejust': 7736, 'jk': 7737, 'ants': 7738, 'champion': 7739, 'greatno': 7740, 'author': 7741, 'sirvery': 7742, 'awsom': 7743, 'superthis': 7744, 'experiencewater': 7745, 'gem': 7746, 'homesmall': 7747, 'penetrates': 7748, 'fibernet': 7749, 'international': 7750, 'maulinex': 7751, 'japan': 7752, 'braun': 7753, 'aesthetics': 7754, 'silenthave': 7755, 'noisethe': 7756, 'deliverythe': 7757, 'tasterrest': 7758, 'shopsyvalue': 7759, 'smoothest': 7760, 'encounteredlow': 7761, 'minutesthanks': 7762, 'straps': 7763, 'shortcoming': 7764, 'deposited': 7765, 'conflict': 7766, 'fineuptill': 7767, 'blanketits': 7768, 'unhook': 7769, 'bluster': 7770, 'filpcat': 7771, 'verysoft': 7772, 'salad': 7773, 'sujata': 7774, 'buyreally': 7775, 'glovesits': 7776, 'purposelight': 7777, 'handfeel': 7778, 'productlittle': 7779, 'defined': 7780, 'assume': 7781, 'fantasticthanku': 7782, 'biking': 7783, 'squeezable': 7784, 'jackets': 7785, 'etcq': 7786, 'wl': 7787, 'screens': 7788, 'discountbut': 7789, 'onelow': 7790, 'wallafter': 7791, 'losse': 7792, 'bothersome': 7793, 'kneadingperfect': 7794, 'proportions': 7795, 'rightchoppermore': 7796, 'mincer': 7797, 'endgraterwould': 7798, 'gratingcitrus': 7799, 'juicerperfectcentrifugal': 7800, 'juicerjust': 7801, 'anythingblender': 7802, 'jarsjust': 7803, 'superiorvacuum': 7804, 'qualitysame': 7805, 'recomanded': 7806, 'gif': 7807, 'maity': 7808, 'kaku': 7809, 'sizebut': 7810, 'hoursi': 7811, 'unsheald': 7812, 'dayseach': 7813, 'bestif': 7814, 'basslover': 7815, 'viper': 7816, 'varientbuild': 7817, 'enoughand': 7818, 'remembered': 7819, 'verient': 7820, 'earpiece': 7821, 'rohini': 7822, 'beginnersgreat': 7823, 'featurs': 7824, 'movethank': 7825, 'bluetooths': 7826, 'oosssmm': 7827, 'finebut': 7828, 'lotion': 7829, 'wantin': 7830, 'filterwhich': 7831, 'usaging': 7832, 'bauuuuuuuuuj': 7833, 'saro': 7834, 'workvalue': 7835, 'pices': 7836, 'retain': 7837, 'answering': 7838, 'startcamera': 7839, 'blurryperformance': 7840, 'cartridgewhen': 7841, 'workingprice': 7842, 'productsupports': 7843, 'plugg': 7844, 'wastages': 7845, 'dispatched': 7846, 'earlypackaging': 7847, 'assembleand': 7848, 'excellentjust': 7849, 'mso': 7850, 'validitykeyboard': 7851, 'secondsconsbattery': 7852, 'functionalityoverall': 7853, 'easilythnks': 7854, 'convienent': 7855, 'buyersgreat': 7856, 'beginnersall': 7857, 'picturesfully': 7858, 'recommendtotal': 7859, 'autorotate': 7860, 'fresher': 7861, 'yaa': 7862, 'poonam': 7863, 'ages': 7864, 'formoney': 7865, 'sososo': 7866, 'nani': 7867, 'maga': 7868, 'qualms': 7869, 'iteven': 7870, 'connectionjust': 7871, 'ityou': 7872, 'gmlong': 7873, 'suraj': 7874, 'flowlook': 7875, 'nicewith': 7876, 'padi': 7877, 'fraction': 7878, 'denims': 7879, 'clothesoverall': 7880, 'simpleinstallation': 7881, 'wished': 7882, 'buyosm': 7883, 'cartilage': 7884, 'teamand': 7885, 'steamer': 7886, 'okmaterial': 7887, 'properlysatisfied': 7888, 'speakerbattery': 7889, 'chargeryou': 7890, 'mobilei': 7891, 'solding': 7892, 'betterbattery': 7893, 'lessbody': 7894, 'plastickeyboard': 7895, 'gei': 7896, 'timedelivery': 7897, 'distancing': 7898, 'que': 7899, 'infections': 7900, 'publicantigen': 7901, 'timetest': 7902, 'prep': 7903, 'acts': 7904, 'purchaselook': 7905, 'kad': 7906, 'laptopgood': 7907, 'tasksaverage': 7908, 'screencompact': 7909, 'thatn': 7910, 'poket': 7911, 'fragiledelivery': 7912, 'chargerfast': 7913, 'usualu': 7914, 'compitition': 7915, 'exammodrate': 7916, 'questionsvery': 7917, 'saurabh': 7918, 'tensh': 7919, 'freethe': 7920, 'costelectricity': 7921, 'otherssaves': 7922, 'entered': 7923, 'compelled': 7924, 'clinic': 7925, 'decisions': 7926, 'flaw': 7927, 'pricethanku': 7928, 'todayassembled': 7929, 'candidate': 7930, 'puepose': 7931, 'ater': 7932, 'badass': 7933, 'greatbest': 7934, 'blazers': 7935, 'markgo': 7936, 'thrice': 7937, 'monthstv': 7938, 'friendliness': 7939, 'fluctuates': 7940, 'flu': 7941, 'reflections': 7942, 'sach': 7943, 'earplugs': 7944, 'bokk': 7945, 'daytoday': 7946, 'tasksyou': 7947, 'title': 7948, 'settingswhile': 7949, 'finishind': 7950, 'easiness': 7951, 'firdge': 7952, 'worksatisfy': 7953, 'phona': 7954, 'nyse': 7955, 'parfume': 7956, 'rite': 7957, 'periodyou': 7958, 'upgrades': 7959, 'cleanermust': 7960, 'yeaterday': 7961, 'trynna': 7962, 'connectionstable': 7963, 'blockage': 7964, 'phonespower': 7965, 'smallprice': 7966, 'highthanks': 7967, 'fantasticthis': 7968, 'rangethank': 7969, 'paking': 7970, 'porselin': 7971, 'materialwell': 7972, 'boyfriend': 7973, 'performanceyou': 7974, 'accessoriesthe': 7975, 'obtained': 7976, 'obstruction': 7977, 'mbpsbut': 7978, 'buggy': 7979, 'someti': 7980, 'juggle': 7981, 'moisturised': 7982, 'therapy': 7983, 'extenders': 7984, 'watersuperb': 7985, 'purpuse': 7986, 'functionthen': 7987, 'neeed': 7988, 'sushami': 7989, 'holdar': 7990, 'advantages': 7991, 'thatbass': 7992, 'infinityboat': 7993, 'transaction': 7994, 'gstok': 7995, 'openingclosing': 7996, 'momliked': 7997, 'thisproduct': 7998, 'conditioncolour': 7999, 'goodperfectly': 8000, 'designedonly': 8001, 'wasthere': 8002, 'hometown': 8003, 'producedi': 8004, 'pho': 8005, 'buityfull': 8006, 'catcher': 8007, 'ecpected': 8008, 'heatup': 8009, 'badlythis': 8010, 'charginggoes': 8011, 'minslastly': 8012, 'oem': 8013, 'phoneworking': 8014, 'breathing': 8015, 'buiilt': 8016, 'goodpacking': 8017, 'cleaningliked': 8018, 'productsno': 8019, 'niceadd': 8020, 'tsp': 8021, 'flavours': 8022, 'sectionjust': 8023, 'parform': 8024, 'pizzzzzas': 8025, 'sourceoutput': 8026, 'wherever': 8027, 'toolwhich': 8028, 'compatibility': 8029, 'descriptions': 8030, 'chutneysyet': 8031, 'nostaligate': 8032, 'refreshmentits': 8033, 'spk': 8034, 'fabrice': 8035, 'productfabric': 8036, 'productyet': 8037, 'ctype': 8038, 'karishama': 8039, 'skates': 8040, 'basak': 8041, 'vanitlated': 8042, 'niceproducts': 8043, 'worthliked': 8044, 'niz': 8045, 'upi': 8046, 'brokem': 8047, 'indicatorgood': 8048, 'outputmedium': 8049, 'audioconnectivity': 8050, 'goodsmall': 8051, 'portableoverall': 8052, 'jo': 8053, 'peeday': 8054, 'ter': 8055, 'sup': 8056, 'snugglyneeds': 8057, 'rodent': 8058, 'attecked': 8059, 'nicedelivery': 8060, 'behav': 8061, 'weightlength': 8062, 'strongthe': 8063, 'fabulousbut': 8064, 'hanlde': 8065, 'handlebut': 8066, 'materialso': 8067, 'productsand': 8068, 'flipk': 8069, 'foggy': 8070, 'seasonwinter': 8071, 'offerpower': 8072, 'upmy': 8073, 'attractivei': 8074, 'excellentlow': 8075, 'mmmy': 8076, 'tasteyummmmmmmmmmmmy': 8077, 'lakeme': 8078, 'mixgerbut': 8079, 'inbild': 8080, 'hopeful': 8081, 'minwith': 8082, 'hrsintial': 8083, 'envy': 8084, 'drivefitness': 8085, 'goodoveeall': 8086, 'meamazing': 8087, 'judge': 8088, 'ittouch': 8089, 'fare': 8090, 'ipod': 8091, 'tripping': 8092, 'fitfabric': 8093, 'nicemind': 8094, 'prosgood': 8095, 'qualitynote': 8096, 'mcafee': 8097, 'creaking': 8098, 'costed': 8099, 'pricehappy': 8100, 'onlyled': 8101, 'weigh': 8102, 'stripes': 8103, 'durablegood': 8104, 'indiai': 8105, 'archdmi': 8106, 'lightsjust': 8107, 'fantabulous': 8108, 'packeting': 8109, 'saller': 8110, 'menoy': 8111, 'ladder': 8112, 'youj': 8113, 'beatar': 8114, 'lac': 8115, 'productstylish': 8116, 'kill': 8117, 'ghost': 8118, 'rider': 8119, 'trusting': 8120, 'procute': 8121, 'loudoverall': 8122, 'essentialthat': 8123, 'themif': 8124, 'qualitysmooth': 8125, 'finishgood': 8126, 'weldingsgood': 8127, 'paintingpacking': 8128, 'es': 8129, 'productsuits': 8130, 'homely': 8131, 'purposerange': 8132, 'metersgood': 8133, 'lookingworth': 8134, 'expectedthank': 8135, 'mtrs': 8136, 'hesitating': 8137, 'uncomfortableheating': 8138, 'bookquality': 8139, 'clearit': 8140, 'bassfast': 8141, 'smallits': 8142, 'antic': 8143, 'tightso': 8144, 'submit': 8145, 'butdont': 8146, 'acits': 8147, 'barbass': 8148, 'soundlove': 8149, 'greatsame': 8150, 'nicethanks': 8151, 'architech': 8152, 'smothly': 8153, 'hdfc': 8154, 'qualityif': 8155, 'cemara': 8156, 'bacap': 8157, 'watchyou': 8158, 'strips': 8159, 'ton': 8160, 'experiences': 8161, 'rly': 8162, 'dindt': 8163, 'stationsnot': 8164, 'lgs': 8165, 'grabbed': 8166, 'studentsgamers': 8167, 'easilyspeakers': 8168, 'runninggood': 8169, 'displayamazing': 8170, 'productwifi': 8171, 'simbattery': 8172, 'goodandthanks': 8173, 'foodive': 8174, 'countless': 8175, 'muffins': 8176, 'pizzas': 8177, 'goodpicture': 8178, 'sone': 8179, 'computerset': 8180, 'everythingim': 8181, 'spongy': 8182, 'powersine': 8183, 'productinverter': 8184, 'stoping': 8185, 'subsidise': 8186, 'smith': 8187, 'tatacliq': 8188, 'brokenand': 8189, 'gandhinagar': 8190, 'thereworst': 8191, 'morningwith': 8192, 'packag': 8193, 'goodaudio': 8194, 'greatsuch': 8195, 'timepureit': 8196, 'wats': 8197, 'adaptive': 8198, 'workingvalue': 8199, 'trim': 8200, 'deliveryboy': 8201, 'secondschop': 8202, 'kilos': 8203, 'minutesand': 8204, 'pomegranatecarrotapples': 8205, 'morphy': 8206, 'richards': 8207, 'watchvalue': 8208, 'hisense': 8209, 'collar': 8210, 'uploader': 8211, 'transistors': 8212, 'shoulders': 8213, 'bes': 8214, 'pattner': 8215, 'moneythat': 8216, 'monitori': 8217, 'tableim': 8218, 'sanyashi': 8219, 'scrapperin': 8220, 'okneedle': 8221, 'nil': 8222, 'eluga': 8223, 'qualityhappy': 8224, 'heeting': 8225, 'barwould': 8226, 'arrangementi': 8227, 'tamilnadu': 8228, 'kundli': 8229, 'maind': 8230, 'wastest': 8231, 'expecteda': 8232, 'clothgo': 8233, 'sarvis': 8234, 'powerbanks': 8235, 'processorblender': 8236, 'dicer': 8237, 'gringing': 8238, 'fineand': 8239, 'reserched': 8240, 'descided': 8241, 'belev': 8242, 'availble': 8243, 'tim': 8244, 'hometheatr': 8245, 'entertainmentso': 8246, 'materialsnice': 8247, 'lookingpaisa': 8248, 'arises': 8249, 'smout': 8250, 'qualitity': 8251, 'timming': 8252, 'productthnqu': 8253, 'flipkartfast': 8254, 'experiencesome': 8255, 'bypass': 8256, 'serial': 8257, 'belong': 8258, 'cooleronce': 8259, 'wheelsediting': 8260, 'oni': 8261, 'fifkart': 8262, 'productp': 8263, 'laptopcons': 8264, 'applicationsbatterythe': 8265, 'issuesno': 8266, 'ssdi': 8267, 'ssdbut': 8268, 'lier': 8269, 'itl': 8270, 'budgeteasy': 8271, 'usego': 8272, 'budgetlight': 8273, 'affordablesustainablegood': 8274, 'rangelight': 8275, 'deduction': 8276, 'musicbut': 8277, 'arepros': 8278, 'marvel': 8279, 'bestmust': 8280, 'buckbought': 8281, 'thro': 8282, 'itfrankly': 8283, 'exemplary': 8284, 'unbeleivable': 8285, 'frankly': 8286, 'baattry': 8287, 'costimpressive': 8288, 'jordarsarasnice': 8289, 'bachlers': 8290, 'formoneyok': 8291, 'butone': 8292, 'audioquality': 8293, 'notgood': 8294, 'viry': 8295, 'niceiam': 8296, 'baget': 8297, 'awaome': 8298, 'diapers': 8299, 'qualitative': 8300, 'perfectlyvery': 8301, 'vooce': 8302, 'hourswriting': 8303, 'motivate': 8304, 'technicianwill': 8305, 'canonand': 8306, 'improvedthey': 8307, 'differing': 8308, 'happeningthough': 8309, 'pmi': 8310, 'rangesound': 8311, 'bassi': 8312, 'roomdesign': 8313, 'kub': 8314, 'podoct': 8315, 'ling': 8316, 'pricethanx': 8317, 'inevitable': 8318, 'okaylook': 8319, 'comprised': 8320, 'awsoeme': 8321, 'storke': 8322, 'yah': 8323, 'patla': 8324, 'workingloved': 8325, 'ithighly': 8326, 'handa': 8327, 'expection': 8328, 'bpl': 8329, 'whic': 8330, 'personand': 8331, 'cosplay': 8332, 'goodinsta': 8333, 'lookinggood': 8334, 'visibility': 8335, 'sunlightaverage': 8336, 'dishwashing': 8337, 'detergents': 8338, 'scoop': 8339, 'ireally': 8340, 'alarms': 8341, 'crispness': 8342, 'cyberpunk': 8343, 'easilycons': 8344, 'ramprocessors': 8345, 'qualityim': 8346, 'machineflipcart': 8347, 'strategize': 8348, 'bucketsoverall': 8349, 'runningthank': 8350, 'footsteps': 8351, 'wirless': 8352, 'playits': 8353, 'comforts': 8354, 'morenot': 8355, 'portabily': 8356, 'overallme': 8357, 'gamingwatch': 8358, 'movieslong': 8359, 'lastin': 8360, 'topicsreally': 8361, 'evrything': 8362, 'goodimportant': 8363, 'topics': 8364, 'desserts': 8365, 'pramjeet': 8366, 'dayssuper': 8367, 'happyfreezer': 8368, 'tooooooo': 8369, 'sufficientits': 8370, 'sof': 8371, 'finesh': 8372, 'diamond': 8373, 'tu': 8374, 'assamble': 8375, 'itselfthankyou': 8376, 'howzz': 8377, 'mtb': 8378, 'sea': 8379, 'flilpkart': 8380, 'productsaves': 8381, 'pesticides': 8382, 'usagei': 8383, 'inter': 8384, 'modemhope': 8385, 'qualitybesr': 8386, 'servicebest': 8387, 'controlreally': 8388, 'flipkarttfor': 8389, 'useworth': 8390, 'geographytrust': 8391, 'formgo': 8392, 'havay': 8393, 'oneworking': 8394, 'smoothlyhappy': 8395, 'janseller': 8396, 'featureverry': 8397, 'dil': 8398, 'jewellery': 8399, 'durablewe': 8400, 'durablelovely': 8401, 'tensor': 8402, 'statesjust': 8403, 'glistening': 8404, 'shose': 8405, 'furnish': 8406, 'wooww': 8407, 'darker': 8408, 'addled': 8409, 'battersscrapper': 8410, 'fulfilling': 8411, 'perfectprofessional': 8412, 'prettysimple': 8413, 'manpower': 8414, 'bolester': 8415, 'termly': 8416, 'adjustablejust': 8417, 'adjustmentthanks': 8418, 'thinkinggood': 8419, 'qulaty': 8420, 'purchaseprice': 8421, 'itembuilt': 8422, 'twigs': 8423, 'shoper': 8424, 'chimni': 8425, 'ifbnext': 8426, 'bonkers': 8427, 'tamperingone': 8428, 'fragrant': 8429, 'prudct': 8430, 'rules': 8431, 'ecofriendly': 8432, 'occupying': 8433, 'cleanoverall': 8434, 'allbig': 8435, 'combos': 8436, 'outher': 8437, 'wsm': 8438, 'protocolproduct': 8439, 'requirementno': 8440, 'decisbles': 8441, 'geeting': 8442, 'tje': 8443, 'conditionvery': 8444, 'utilities': 8445, 'suck': 8446, 'uninstalled': 8447, 'internetthe': 8448, 'en': 8449, 'eagerly': 8450, 'fish': 8451, 'breadkulcha': 8452, 'naan': 8453, 'potatoes': 8454, 'packaginggood': 8455, 'wounded': 8456, 'assemblying': 8457, 'increaseboost': 8458, 'backups': 8459, 'vert': 8460, 'coolerair': 8461, 'hereloved': 8462, 'eighth': 8463, 'editionproduct': 8464, 'noe': 8465, 'washingi': 8466, 'fittingthanks': 8467, 'productsbut': 8468, 'productsatisfiedfair': 8469, 'formed': 8470, 'whiteness': 8471, 'aswel': 8472, 'telephone': 8473, 'tvenjoyable': 8474, 'etcfull': 8475, 'filing': 8476, 'warming': 8477, 'vgoode': 8478, 'srilangovan': 8479, 'attur': 8480, 'salem': 8481, 'picturi': 8482, 'goodsuperb': 8483, 'purposesinger': 8484, 'fadeout': 8485, 'shivexim': 8486, 'assist': 8487, 'disappointedas': 8488, 'forgets': 8489, 'roomfor': 8490, 'googleplz': 8491, 'apples': 8492, 'maamthe': 8493, 'presented': 8494, 'oiln': 8495, 'oilits': 8496, 'oilmust': 8497, 'vac': 8498, 'enterprise': 8499, 'prasadthe': 8500, 'prose': 8501, 'driv': 8502, 'suppress': 8503, 'filepcart': 8504, 'amplification': 8505, 'reveals': 8506, 'premiere': 8507, 'smallbut': 8508, 'wellfinishing': 8509, 'racker': 8510, 'suppersd': 8511, 'qualityremort': 8512, 'nicefinal': 8513, 'cleanalmost': 8514, 'operationwash': 8515, 'dzire': 8516, 'sink': 8517, 'awesomehowthe': 8518, 'sebin': 8519, 'isthe': 8520, 'deleivered': 8521, 'fqulty': 8522, 'deleiver': 8523, 'daysand': 8524, 'fatasticawsomevalue': 8525, 'responds': 8526, 'peopleyouths': 8527, 'vise': 8528, 'excess': 8529, 'olive': 8530, 'usageit': 8531, 'removal': 8532, 'anymy': 8533, 'demossuggested': 8534, 'picsgot': 8535, 'osssmm': 8536, 'nonelectric': 8537, 'echos': 8538, 'shouting': 8539, 'anyways': 8540, 'itmind': 8541, 'avove': 8542, 'machineworth': 8543, 'moneypaisa': 8544, 'vasooland': 8545, 'wanderfull': 8546, 'highalexa': 8547, 'googlo': 8548, 'alexatoo': 8549, 'musicprime': 8550, 'deliverygoogle': 8551, 'appssome': 8552, 'minilike': 8553, 'musicnetflix': 8554, 'linkchoice': 8555, 'pey': 8556, 'materialistic': 8557, 'priceryzen': 8558, 'needonly': 8559, 'hzbut': 8560, 'beastgames': 8561, 'stablepubg': 8562, 'cbse': 8563, 'keepgud': 8564, 'materiallooks': 8565, 'microsd': 8566, 'relatedproductivity': 8567, 'module': 8568, 'soundsjust': 8569, 'filipcurti': 8570, 'vi': 8571, 'sweitch': 8572, 'recommendthis': 8573, 'boxesnice': 8574, 'alsobut': 8575, 'tie': 8576, 'pleasure': 8577, 'favour': 8578, 'gajar': 8579, 'thinkjust': 8580, 'xaimoumi': 8581, 'hesitatego': 8582, 'autoclean': 8583, 'daysno': 8584, 'closer': 8585, 'standardsdon': 8586, 'optionand': 8587, 'wella': 8588, 'science': 8589, 'occupied': 8590, 'awesomethere': 8591, 'transporting': 8592, 'manners': 8593, 'triks': 8594, 'raing': 8595, 'passage': 8596, 'fani': 8597, 'packedgood': 8598, 'rangeas': 8599, 'opinionjust': 8600, 'awesomeheating': 8601, 'ref': 8602, 'frds': 8603, 'fantasticthe': 8604, 'goodfull': 8605, 'timebuy': 8606, 'itlength': 8607, 'productfastest': 8608, 'deliverys': 8609, 'benefitted': 8610, 'aim': 8611, 'mhc': 8612, 'hifi': 8613, 'impedance': 8614, 'ohms': 8615, 'woofers': 8616, 'waves': 8617, 'scorpio': 8618, 'wirin': 8619, 'noisemaking': 8620, 'briz': 8621, 'priceits': 8622, 'wellif': 8623, 'gymno': 8624, 'doubtsno': 8625, 'confusedno': 8626, 'compromisedtry': 8627, 'colourmy': 8628, 'problemyou': 8629, 'methanksfor': 8630, 'quickworking': 8631, 'nicelypure': 8632, 'heaven': 8633, 'waterlove': 8634, 'exchangeflipkart': 8635, 'eight': 8636, 'retrieving': 8637, 'delaywhich': 8638, 'desirable': 8639, 'gamerwireless': 8640, 'casebutif': 8641, 'excellently': 8642, 'datewhat': 8643, 'competitivei': 8644, 'testy': 8645, 'wale': 8646, 'unclehv': 8647, 'shininny': 8648, 'vivobook': 8649, 'consecutivelysmooth': 8650, 'fastdisplay': 8651, 'expandable': 8652, 'guarranty': 8653, 'kolkata': 8654, 'winterservice': 8655, 'reccomended': 8656, 'fomoney': 8657, 'ramba': 8658, 'ramai': 8659, 'mick': 8660, 'playful': 8661, 'goodneed': 8662, 'vw': 8663, 'proofmy': 8664, 'glassthey': 8665, 'screenconsonly': 8666, 'initiallybut': 8667, 'destroyed': 8668, 'outlets': 8669, 'alittle': 8670, 'kicthen': 8671, 'comfortableyou': 8672, 'glen': 8673, 'anion': 8674, 'hepacarbon': 8675, 'responsiveglen': 8676, 'phillipshoneywell': 8677, 'asthm': 8678, 'roduct': 8679, 'leeds': 8680, 'leakproof': 8681, 'productusing': 8682, 'sofayou': 8683, 'tum': 8684, 'fortnight': 8685, 'attracts': 8686, 'fingerprints': 8687, 'ollie': 8688, 'kickflip': 8689, 'decathlon': 8690, 'onlycost': 8691, 'storageits': 8692, 'amazingand': 8693, 'lastingi': 8694, 'unader': 8695, 'effectivenice': 8696, 'superp': 8697, 'disput': 8698, 'glade': 8699, 'dilivered': 8700, 'produed': 8701, 'functioned': 8702, 'dustpet': 8703, 'hairetceasy': 8704, 'useperfect': 8705, 'everyonespecial': 8706, 'srusthi': 8707, 'sufficientgo': 8708, 'nicccccc': 8709, 'esay': 8710, 'toolsthe': 8711, 'pricefor': 8712, 'heightfor': 8713, 'brakesfor': 8714, 'sleak': 8715, 'desktop': 8716, 'germinationvery': 8717, 'gilterry': 8718, 'karat': 8719, 'doubted': 8720, 'oknyc': 8721, 'birthdaybefore': 8722, 'juicesafter': 8723, 'spendit': 8724, 'issuesbut': 8725, 'scraper': 8726, 'stationerybag': 8727, 'coliti': 8728, 'valyou': 8729, 'supersupersupervery': 8730, 'itemprice': 8731, 'instantlyno': 8732, 'rangebut': 8733, 'costlydont': 8734, 'bookthank': 8735, 'ulta': 8736, 'purposeoverall': 8737, 'catia': 8738, 'autoform': 8739, 'misgivings': 8740, 'toughned': 8741, 'camelia': 8742, 'productsolar': 8743, 'todayquiet': 8744, 'strongits': 8745, 'levelyou': 8746, 'everage': 8747, 'sood': 8748, 'productam': 8749, 'derailed': 8750, 'tnku': 8751, 'backlog': 8752, 'comparision': 8753, 'conclusion': 8754, 'jacketbut': 8755, 'aprrox': 8756, 'timewater': 8757, 'proudak': 8758, 'designthankyou': 8759, 'handover': 8760, 'mouldbaking': 8761, 'missingit': 8762, 'interlock': 8763, 'oter': 8764, 'blackblakest': 8765, 'blackit': 8766, 'claimsit': 8767, 'proofi': 8768, 'waterline': 8769, 'timethanks': 8770, 'lofted': 8771, 'producttop': 8772, 'itproduct': 8773, 'zabardast': 8774, 'fantasticmy': 8775, 'worries': 8776, 'productpic': 8777, 'goodconsonly': 8778, 'precisely': 8779, 'pcbs': 8780, 'okaygood': 8781, 'hangsbattery': 8782, 'beginnersworst': 8783, 'sideshould': 8784, 'powar': 8785, 'averagely': 8786, 'screenplay': 8787, 'lowi': 8788, 'expressed': 8789, 'verma': 8790, 'themand': 8791, 'thatthanks': 8792, 'carona': 8793, 'fitment': 8794, 'clever': 8795, 'brust': 8796, 'wrinkle': 8797, 'calco': 8798, 'batteryno': 8799, 'voltagei': 8800, 'sence': 8801, 'bata': 8802, 'ind': 8803, 'agreed': 8804, 'costoverall': 8805, 'sowftware': 8806, 'productconsidering': 8807, 'hitch': 8808, 'buye': 8809, 'fanfast': 8810, 'warrantythank': 8811, 'balyu': 8812, 'confirm': 8813, 'deliverybattery': 8814, 'skips': 8815, 'vedio': 8816, 'designers': 8817, 'thoughtful': 8818, 'accesories': 8819, 'functionsespically': 8820, 'spindle': 8821, 'flyin': 8822, 'shouldve': 8823, 'boxand': 8824, 'ignored': 8825, 'kawlity': 8826, 'productband': 8827, 'awesomehigh': 8828, 'everythingmakes': 8829, 'usesatisfied': 8830, 'alphabets': 8831, 'bestresults': 8832, 'gobar': 8833, 'khad': 8834, 'vermi': 8835, 'compost': 8836, 'earsjust': 8837, 'thinkbuy': 8838, 'passive': 8839, 'diliveryawesome': 8840, 'cautiously': 8841, 'damagedtorn': 8842, 'descriptionhoweverwater': 8843, 'gooddoor': 8844, 'moreexcept': 8845, 'satisfiedmy': 8846, 'expectingim': 8847, 'itemsand': 8848, 'goodcalling': 8849, 'finebuild': 8850, 'overpricedi': 8851, 'itscreen': 8852, 'atmostrust': 8853, 'beforeyour': 8854, 'levelonly': 8855, 'woul': 8856, 'boyits': 8857, 'parsion': 8858, 'infnix': 8859, 'peddling': 8860, 'posture': 8861, 'stress': 8862, 'osmi': 8863, 'rit': 8864, 'stichting': 8865, 'recamanded': 8866, 'pcb': 8867, 'mashin': 8868, 'washspecial': 8869, 'productback': 8870, 'monthsperforming': 8871, 'tangled': 8872, 'glory': 8873, 'grillingor': 8874, 'panner': 8875, 'metarial': 8876, 'meaccuracy': 8877, 'municipal': 8878, 'respectivelyborewell': 8879, 'ghugha': 8880, 'receieved': 8881, 'regulator': 8882, 'rectified': 8883, 'dislodged': 8884, 'productterificc': 8885, 'dishwashersuitable': 8886, 'washthe': 8887, 'utensilswonderful': 8888, 'dishwash': 8889, 'expectedgo': 8890, 'protonics': 8891, 'drummivis': 8892, 'weeksdelivered': 8893, 'dayso': 8894, 'powwrful': 8895, 'moro': 8896, 'oreo': 8897, 'alsowhen': 8898, 'laval': 8899, 'upgradeble': 8900, 'routervery': 8901, 'reasonablebut': 8902, 'recipies': 8903, 'technique': 8904, 'lessdelivery': 8905, 'alsothanku': 8906, 'datebut': 8907, 'usedright': 8908, 'boxfollowing': 8909, 'reviewsand': 8910, 'bagunavi': 8911, 'kf': 8912, 'aloy': 8913, 'rangeamazingevery': 8914, 'jeevas': 8915, 'surprisedfast': 8916, 'serviceflipkart': 8917, 'servicesthanks': 8918, 'childrensand': 8919, 'productpros': 8920, 'maneuver': 8921, 'presets': 8922, 'bounded': 8923, 'ovenperfect': 8924, 'grinderits': 8925, 'niceflipcart': 8926, 'lound': 8927, 'combinati': 8928, 'promises': 8929, 'otgmaking': 8930, 'barbeque': 8931, 'easierthanks': 8932, 'decore': 8933, 'scheduledish': 8934, 'conditioninstallation': 8935, 'ifbifb': 8936, 'timedish': 8937, 'givendish': 8938, 'sidesgood': 8939, 'marketjust': 8940, 'fantasy': 8941, 'ployster': 8942, 'conncetivity': 8943, 'responses': 8944, 'pushpendra': 8945, 'sarma': 8946, 'itthnxxx': 8947, 'valuesble': 8948, 'coolingbut': 8949, 'accupy': 8950, 'wao': 8951, 'pjama': 8952, 'beutifulit': 8953, 'footballit': 8954, 'happyeverything': 8955, 'producthe': 8956, 'instructors': 8957, 'auxiliary': 8958, 'downer': 8959, 'stickyness': 8960, 'nourish': 8961, 'repaire': 8962, 'moneyamazing': 8963, 'restrained': 8964, 'varanasi': 8965, 'mobileapplications': 8966, 'nonsmart': 8967, 'choppy': 8968, 'vy': 8969, 'superexcellent': 8970, 'flipkartdemo': 8971, 'oneordered': 8972, 'anotherarriving': 8973, 'vvgood': 8974, 'jbrdst': 8975, 'soundthanku': 8976, 'consultantion': 8977, 'onefitplus': 8978, 'conducted': 8979, 'flipkartloved': 8980, 'decades': 8981, 'connective': 8982, 'facilitiy': 8983, 'modal': 8984, 'thatbut': 8985, 'masterpieces': 8986, 'guysgoing': 8987, 'conducting': 8988, 'guid': 8989, 'operatednormally': 8990, 'occur': 8991, 'hvy': 8992, 'toster': 8993, 'trouserlittle': 8994, 'weekthanks': 8995, 'issuethe': 8996, 'doneso': 8997, 'karket': 8998, 'amz': 8999, 'istrumel': 9000, 'innen': 9001, 'helbeko': 9002, 'gottagthilla': 9003, 'matra': 9004, 'thullare': 9005, 'aithappa': 9006, 'peoplefamilywe': 9007, 'carpentar': 9008, 'pricesloved': 9009, 'soundbarthe': 9010, 'sou': 9011, 'connecters': 9012, 'plasticfor': 9013, 'itemthanks': 9014, 'yee': 9015, 'transfering': 9016, 'awesomemotion': 9017, 'igeam': 9018, 'bills': 9019, 'keyboardthe': 9020, 'amplify': 9021, 'rauter': 9022, 'moneyworking': 9023, 'noisetotally': 9024, 'mopping': 9025, 'unexpectedly': 9026, 'productused': 9027, 'nikalta': 9028, 'qualityweight': 9029, 'strongas': 9030, 'descriptiongood': 9031, 'productjuicer': 9032, 'mixersoverall': 9033, 'coole': 9034, 'faults': 9035, 'sizzling': 9036, 'shortok': 9037, 'thanki': 9038, 'mutchthank': 9039, 'shids': 9040, 'excellentone': 9041, 'comprimise': 9042, 'standardsthanks': 9043, 'pakcingthank': 9044, 'flipcartkeep': 9045, 'boast': 9046, 'degrade': 9047, 'flawlessbut': 9048, 'attracted': 9049, 'dammmm': 9050, 'productsafedesignerand': 9051, 'productsmust': 9052, 'stationery': 9053, 'biled': 9054, 'verity': 9055, 'techniques': 9056, 'fertilizer': 9057, 'improvise': 9058, 'mskeerthana': 9059, 'premiumlooks': 9060, 'crossed': 9061, 'soothingly': 9062, 'riskybut': 9063, 'itfan': 9064, 'billafter': 9065, 'repost': 9066, 'didi': 9067, 'speedpoor': 9068, 'processorworried': 9069, 'handwash': 9070, 'woven': 9071, 'dedicating': 9072, 'spinned': 9073, 'quanlity': 9074, 'ironflipkart': 9075, 'designits': 9076, 'antennasbest': 9077, 'apparatus': 9078, 'shedding': 9079, 'flattened': 9080, 'props': 9081, 'easi': 9082, 'allway': 9083, 'productif': 9084, 'nambi': 9085, 'productwould': 9086, 'heightmore': 9087, 'intruder': 9088, 'paramedical': 9089, 'chargesmachine': 9090, 'cyclegood': 9091, 'rupee': 9092, 'pest': 9093, 'difficultweight': 9094, 'sutiable': 9095, 'vents': 9096, 'eliminate': 9097, 'mny': 9098, 'comfortablegood': 9099, 'qualityfit': 9100, 'amazinglaptop': 9101, 'openram': 9102, 'updateios': 9103, 'simulator': 9104, 'egde': 9105, 'wheather': 9106, 'muffled': 9107, 'etccons': 9108, 'cal': 9109, 'jin': 9110, 'backupits': 9111, 'paly': 9112, 'sideu': 9113, 'grap': 9114, 'regretmicroshot': 9115, 'onesvalue': 9116, 'tjen': 9117, 'freshness': 9118, 'transfers': 9119, 'teamcheap': 9120, 'needmust': 9121, 'sould': 9122, 'purcahsetill': 9123, 'abnormility': 9124, 'colourlove': 9125, 'lightsmust': 9126, 'musiccast': 9127, 'audiobluetooth': 9128, 'awulesome': 9129, 'quickgood': 9130, 'gpod': 9131, 'assassins': 9132, 'creed': 9133, 'oddessey': 9134, 'wre': 9135, 'screenotherwise': 9136, 'screensharing': 9137, 'amo': 9138, 'enjoyment': 9139, 'overtime': 9140, 'appeal': 9141, 'launches': 9142, 'micr': 9143, 'amazingreally': 9144, 'productmade': 9145, 'scketbod': 9146, 'finecharges': 9147, 'formatted': 9148, 'needsand': 9149, 'knowanyway': 9150, 'stylest': 9151, 'deliverylivpure': 9152, 'roinstallation': 9153, 'random': 9154, 'discouraged': 9155, 'qualityy': 9156, 'farudlent': 9157, 'workingled': 9158, 'easilyone': 9159, 'metall': 9160, 'musambi': 9161, 'niceam': 9162, 'happythnku': 9163, 'watchand': 9164, 'bicyclelight': 9165, 'daughters': 9166, 'colouring': 9167, 'priorly': 9168, 'pointonly': 9169, 'submitted': 9170, 'feed': 9171, 'sanjivani': 9172, 'slender': 9173, 'malnourished': 9174, 'steroids': 9175, 'pig': 9176, 'monththe': 9177, 'windowthe': 9178, 'saree': 9179, 'sushil': 9180, 'nirala': 9181, 'namely': 9182, 'moviemusic': 9183, 'brandcons': 9184, 'hallconclusionbetter': 9185, 'productrating': 9186, 'atlist': 9187, 'lm': 9188, 'flipkartwow': 9189, 'boxdelivery': 9190, 'timethere': 9191, 'seedsi': 9192, 'megha': 9193, 'gouthamk': 9194, 'tomuch': 9195, 'enabledisable': 9196, 'keythe': 9197, 'pricesuper': 9198, 'cabel': 9199, 'relatable': 9200, 'recommendable': 9201, 'deviceexcellent': 9202, 'googlevery': 9203, 'deviceeasy': 9204, 'upno': 9205, 'hassleeven': 9206, 'hotspotnice': 9207, 'castingcontrol': 9208, 'mobilemake': 9209, 'tvanything': 9210, 'mirrored': 9211, 'gamegot': 9212, 'tvhdmi': 9213, 'requiredyou': 9214, 'sendal': 9215, 'proctet': 9216, 'manish': 9217, 'demonstrating': 9218, 'thisgo': 9219, 'roomthe': 9220, 'bargain': 9221, 'excellentoven': 9222, 'customersthank': 9223, 'itgud': 9224, 'stolen': 9225, 'limps': 9226, 'patches': 9227, 'newits': 9228, 'soundconnected': 9229, 'wifipatch': 9230, 'installationsame': 9231, 'installationonly': 9232, 'flatmust': 9233, 'dattery': 9234, 'productprice': 9235, 'obvio': 9236, 'speedeverything': 9237, 'assemblemissed': 9238, 'packagebut': 9239, 'moneyrecommended': 9240, 'broking': 9241, 'matireal': 9242, 'naxt': 9243, 'death': 9244, 'bitterness': 9245, 'flefkart': 9246, 'nicesuperrrrr': 9247, 'badat': 9248, 'thinkgo': 9249, 'thisbt': 9250, 'thermos': 9251, 'fanatics': 9252, 'helpfuldefinitely': 9253, 'exyract': 9254, 'soups': 9255, 'conctete': 9256, 'hols': 9257, 'upapart': 9258, 'allover': 9259, 'venting': 9260, 'checkered': 9261, 'shading': 9262, 'qualityworthy': 9263, 'cramped': 9264, 'huyi': 9265, 'productspicture': 9266, 'toohd': 9267, 'channeljust': 9268, 'balue': 9269, 'borewell': 9270, 'goodfastest': 9271, 'monthsam': 9272, 'guud': 9273, 'meansbut': 9274, 'pivot': 9275, 'rotatory': 9276, 'revolvingbut': 9277, 'jordar': 9278, 'defactive': 9279, 'treable': 9280, 'smallrest': 9281, 'lightens': 9282, 'journeythe': 9283, 'overwhelming': 9284, 'kudus': 9285, 'carsofa': 9286, 'nozzles': 9287, 'oile': 9288, 'itsuch': 9289, 'quicker': 9290, 'shinier': 9291, 'gudi': 9292, 'getwe': 9293, 'encrypt': 9294, 'passportspeed': 9295, 'didt': 9296, 'budgeted': 9297, 'unilever': 9298, 'cauvery': 9299, 'ppp': 9300, 'smps': 9301, 'installationm': 9302, 'fipkartthanks': 9303, 'lotreally': 9304, 'ifbs': 9305, 'gm': 9306, 'smoth': 9307, 'booksgreat': 9308, 'rangethanks': 9309, 'arriving': 9310, 'combogot': 9311, 'detailing': 9312, 'daysgreat': 9313, 'boati': 9314, 'phoneadapter': 9315, 'butonly': 9316, 'cablecable': 9317, 'tightcharging': 9318, 'oknd': 9319, 'featuresgood': 9320, 'designaffordable': 9321, 'priceseamless': 9322, 'connectivitymagnetic': 9323, 'separating': 9324, 'earbudsdual': 9325, 'timelatest': 9326, 'chargingaac': 9327, 'supportedfast': 9328, 'playback': 9329, 'timetheres': 9330, 'pipesif': 9331, 'topsuggestion': 9332, 'ncy': 9333, 'expectedthe': 9334, 'apartotherwise': 9335, 'sloweralso': 9336, 'seriesif': 9337, 'badall': 9338, 'nowjuice': 9339, 'smoothieand': 9340, 'fruitnice': 9341, 'disasseming': 9342, 'correctely': 9343, 'onethis': 9344, 'distinctive': 9345, 'fragrancesi': 9346, 'reveal': 9347, 'featuresthe': 9348, 'atmosphere': 9349, 'opulent': 9350, 'wrapping': 9351, 'coloursproduct': 9352, 'osmmmmworth': 9353, 'moneyyy': 9354, 'rangedoes': 9355, 'pleasinghowever': 9356, 'eyecatching': 9357, 'ironed': 9358, 'thakur': 9359, 'lakshya': 9360, 'raghav': 9361, 'jod': 9362, 'youtuber': 9363, 'moments': 9364, 'excellentand': 9365, 'productsgo': 9366, 'speeder': 9367, 'amazingas': 9368, 'picsno': 9369, 'defectsgood': 9370, 'salemy': 9371, 'scores': 9372, 'rangebrand': 9373, 'bluetoothbluetooth': 9374, 'fluidbattery': 9375, 'hoursfully': 9376, 'headsetboat': 9377, 'headsetflipkart': 9378, 'supportreally': 9379, 'awesomemore': 9380, 'chetan': 9381, 'manju': 9382, 'goodtnq': 9383, 'soundbest': 9384, 'purifiermi': 9385, 'thatit': 9386, 'realtime': 9387, 'selary': 9388, 'luved': 9389, 'ossmmm': 9390, 'notthis': 9391, 'appealtrendy': 9392, 'castor': 9393, 'advertisedcons': 9394, 'docotor': 9395, 'recommationdecent': 9396, 'deodrant': 9397, 'senses': 9398, 'mo': 9399, 'ulervry': 9400, 'earlynot': 9401, 'usesuction': 9402, 'productcord': 9403, 'timesuitable': 9404, 'usealso': 9405, 'filpkartafter': 9406, 'castings': 9407, 'superbonce': 9408, 'solvedguys': 9409, 'prosuperb': 9410, 'smoothlythanks': 9411, 'shyam': 9412, 'perioddisclaimerim': 9413, 'gamingive': 9414, 'scenarios': 9415, 'proxy': 9416, 'train': 9417, 'stripsi': 9418, 'watchdesign': 9419, 'goodglass': 9420, 'watchleather': 9421, 'okayand': 9422, 'denial': 9423, 'instalationthen': 9424, 'googlethen': 9425, 'occasionally': 9426, 'juicermeets': 9427, 'productsvalue': 9428, 'plesent': 9429, 'ehen': 9430, 'studioand': 9431, 'chaudhary': 9432, 'shivam': 9433, 'softwarecons': 9434, 'needreally': 9435, 'astounding': 9436, 'j': 9437, 'happiest': 9438, 'sometimesno': 9439, 'foulted': 9440, 'sparklelow': 9441, 'detailsit': 9442, 'togetherbattery': 9443, 'continuesly': 9444, 'whitish': 9445, 'flstudio': 9446, 'techy': 9447, 'parallax': 9448, 'subscribe': 9449, 'banks': 9450, 'connectivityreally': 9451, 'dayshockingly': 9452, 'equilizer': 9453, 'manufactures': 9454, 'healthso': 9455, 'backbecause': 9456, 'misinformation': 9457, 'hided': 9458, 'counterparts': 9459, 'helpless': 9460, 'sliding': 9461, 'productconnectivity': 9462, 'crd': 9463, 'anc': 9464, 'philiphs': 9465, 'okayworthy': 9466, 'expanded': 9467, 'valiya': 9468, 'kuzhappam': 9469, 'ellaa': 9470, 'extraoverall': 9471, 'interlocks': 9472, 'viewcons': 9473, 'problemmay': 9474, 'centres': 9475, 'goodquite': 9476, 'stuffedcushion': 9477, 'designe': 9478, 'buld': 9479, 'po': 9480, 'coco': 9481, 'hose': 9482, 'choco': 9483, 'qt': 9484, 'occasionsreceived': 9485, 'familiespros': 9486, 'samsunglow': 9487, 'costfeatures': 9488, 'songsgreat': 9489, 'starits': 9490, 'sooooooo': 9491, 'frndsss': 9492, 'productsize': 9493, 'downloaded': 9494, 'supernow': 9495, 'storethanks': 9496, 'slunf': 9497, 'rangeim': 9498, 'storei': 9499, 'prizei': 9500, 'nameotherwise': 9501, 'flipcartoverall': 9502, 'ith': 9503, 'mahesh': 9504, 'vishwakarma': 9505, 'branch': 9506, 'brifed': 9507, 'tensed': 9508, 'qlitiy': 9509, 'floting': 9510, 'mechin': 9511, 'keybordi': 9512, 'whts': 9513, 'fotography': 9514, 'yougo': 9515, 'biddings': 9516, 'owsme': 9517, 'flipkartdelivery': 9518, 'careok': 9519, 'alldont': 9520, 'offif': 9521, 'enoughtanq': 9522, 'nowits': 9523, 'constructed': 9524, 'areausb': 9525, 'gimmick': 9526, 'nuisance': 9527, 'ben': 9528, 'ten': 9529, 'feasible': 9530, 'calculator': 9531, 'supervision': 9532, 'tiring': 9533, 'cushioningcons': 9534, 'inaslsa': 9535, 'coequal': 9536, 'noticable': 9537, 'scream': 9538, 'yar': 9539, 'anyexam': 9540, 'faith': 9541, 'finesafely': 9542, 'packedair': 9543, 'speedice': 9544, 'itconnecting': 9545, 'lengtha': 9546, 'hrsmoving': 9547, 'reliablewheel': 9548, 'coder': 9549, 'programmer': 9550, 'goodd': 9551, 'flips': 9552, 'plasticsyntheticrubber': 9553, 'dnot': 9554, 'wana': 9555, 'worthit': 9556, 'stylishi': 9557, 'bf': 9558, 'purposessuitable': 9559, 'gatherings': 9560, 'onr': 9561, 'kurtis': 9562, 'deliverythough': 9563, 'enoughbest': 9564, 'copter': 9565, 'nixe': 9566, 'pens': 9567, 'chalks': 9568, 'eraser': 9569, 'sharpener': 9570, 'requirementdefrosting': 9571, 'spaciousbest': 9572, 'microwavethe': 9573, 'squishy': 9574, 'microwaveupdate': 9575, 'deciding': 9576, 'basefawlish': 9577, 'disiningpremium': 9578, 'sailant': 9579, 'gudas': 9580, 'uplifts': 9581, 'perfumethere': 9582, 'capthe': 9583, 'superbvalue': 9584, 'mone': 9585, 'fiesfalx': 9586, 'anther': 9587, 'goodlightweightbass': 9588, 'romantic': 9589, 'productbattery': 9590, 'greatand': 9591, 'rangedelivery': 9592, 'mentionedjust': 9593, 'lure': 9594, 'sennheissers': 9595, 'las': 9596, 'thora': 9597, 'virat': 9598, 'kohli': 9599, 'nicequality': 9600, 'goodvut': 9601, 'industries': 9602, 'qualitycheap': 9603, 'comfortableand': 9604, 'indicating': 9605, 'controlsyou': 9606, 'assign': 9607, 'householdthe': 9608, 'wallthree': 9609, 'microphones': 9610, 'noisyif': 9611, 'multiroom': 9612, 'setupit': 9613, 'prouct': 9614, 'auper': 9615, 'lproduct': 9616, 'expectationsoverall': 9617, 'inviter': 9618, 'installationnice': 9619, 'mare': 9620, 'flats': 9621, 'balcony': 9622, 'elegantly': 9623, 'hone': 9624, 'mentionied': 9625, 'db': 9626, 'sprey': 9627, 'goodcooks': 9628, 'buyingbattery': 9629, 'amazingscreen': 9630, 'moneycamera': 9631, 'disappointedso': 9632, 'wellinstallation': 9633, 'exame': 9634, 'noon': 9635, 'speakeryou': 9636, 'hojaye': 9637, 'cheyochhu': 9638, 'gorgious': 9639, 'mnts': 9640, 'sweaters': 9641, 'catagory': 9642, 'edited': 9643, 'monthstarted': 9644, 'lockdownvery': 9645, 'reassuring': 9646, 'bermuda': 9647, 'ordercool': 9648, 'expectedlook': 9649, 'chimneygood': 9650, 'shubham': 9651, 'pawargood': 9652, 'frankie': 9653, 'faberbest': 9654, 'flop': 9655, 'superbme': 9656, 'cablemotorola': 9657, 'sounbarr': 9658, 'userfriendly': 9659, 'backupsound': 9660, 'monthfirst': 9661, 'soundloss': 9662, 'pubgits': 9663, 'govt': 9664, 'illustrations': 9665, 'fonts': 9666, 'texts': 9667, 'categorize': 9668, 'attrire': 9669, 'paijama': 9670, 'nfc': 9671, 'endorse': 9672, 'paise': 9673, 'bobblings': 9674, 'goode': 9675, 'atoms': 9676, 'goodsuction': 9677, 'productresolution': 9678, 'impressivelittle': 9679, 'qualtiy': 9680, 'stamped': 9681, 'thankfull': 9682, 'singh': 9683, 'whatch': 9684, 'bulit': 9685, 'absorber': 9686, 'desion': 9687, 'programingnot': 9688, 'purposeno': 9689, 'capasity': 9690, 'compatate': 9691, 'arguments': 9692, 'displayrtx': 9693, 'settingsits': 9694, 'segmentsit': 9695, 'laptopsound': 9696, 'clutch': 9697, 'supep': 9698, 'stole': 9699, 'gp': 9700, 'barsound': 9701, 'soundbarthanks': 9702, 'constriction': 9703, 'materialsturdy': 9704, 'beautifuldrawer': 9705, 'hairfall': 9706, 'qualityrecommended': 9707, 'breathe': 9708, 'unturned': 9709, 'usebest': 9710, 'allso': 9711, 'sriramanasolvex': 9712, 'warms': 9713, 'excellentspace': 9714, 'okayi': 9715, 'operationcolour': 9716, 'temperamental': 9717, 'storesit': 9718, 'flipkartwe': 9719, 'itconsless': 9720, 'pricegot': 9721, 'menbers': 9722, 'sugarcane': 9723, 'bus': 9724, 'uselove': 9725, 'lookingand': 9726, 'depicted': 9727, 'jobbattery': 9728, 'ligh': 9729, 'fyi': 9730, 'itnow': 9731, 'ithappy': 9732, 'itworths': 9733, 'sige': 9734, 'lowmakes': 9735, 'midst': 9736, 'trackers': 9737, 'buyingartbook': 9738, 'eos': 9739, 'productfull': 9740, 'ikon': 9741, 'pune': 9742, 'fabulously': 9743, 'excellentthank': 9744, 'seasoni': 9745, 'actuality': 9746, 'thankuflipkart': 9747, 'complet': 9748, 'luckyas': 9749, 'averagethough': 9750, 'glosssy': 9751, 'wrest': 9752, 'buyingthis': 9753, 'basswould': 9754, 'bassalso': 9755, 'heavyoverall': 9756, 'cery': 9757, 'minimizing': 9758, 'professionalgood': 9759, 'baadworks': 9760, 'opinions': 9761, 'daal': 9762, 'parboiled': 9763, 'cumin': 9764, 'tomatoes': 9765, 'decentnice': 9766, 'choicedelivery': 9767, 'informedpacking': 9768, 'greatin': 9769, 'iitansi': 9770, 'eagarly': 9771, 'lowkey': 9772, 'relies': 9773, 'algorithm': 9774, 'toolset': 9775, 'prominently': 9776, 'fasted': 9777, 'thatall': 9778, 'forit': 9779, 'oneryzen': 9780, 'efficientlyits': 9781, 'thatthat': 9782, 'thisbuild': 9783, 'decentdisplay': 9784, 'ii': 9785, 'welldone': 9786, 'yait': 9787, 'nicelylow': 9788, 'engaged': 9789, 'mechanics': 9790, 'electricians': 9791, 'plumbers': 9792, 'sizzler': 9793, 'osowm': 9794, 'pricetry': 9795, 'officially': 9796, 'laptopprocessor': 9797, 'radeon': 9798, 'integrated': 9799, 'okaylets': 9800, 'properlynever': 9801, 'interconnected': 9802, 'deviceswall': 9803, 'tqss': 9804, 'recovered': 9805, 'hatet': 9806, 'flipkartinstallation': 9807, 'ensuring': 9808, 'feedbackthanks': 9809, 'clening': 9810, 'vacuume': 9811, 'miniute': 9812, 'usagebut': 9813, 'pappa': 9814, 'briefly': 9815, 'crushing': 9816, 'rotorsimply': 9817, 'flipkartthey': 9818, 'smoothfor': 9819, 'niceuse': 9820, 'beetroots': 9821, 'cinnamon': 9822, 'cigarette': 9823, 'wellmade': 9824, 'usageyoutube': 9825, 'settingdisplay': 9826, 'laptopperformancegaming': 9827, 'highdefault': 9828, 'slowness': 9829, 'qualitytemperature': 9830, 'omen': 9831, 'crossselling': 9832, 'stylishdisplay': 9833, 'hipsize': 9834, 'sheer': 9835, 'seevice': 9836, 'doesbits': 9837, 'reflectors': 9838, 'montha': 9839, 'wondersthe': 9840, 'petty': 9841, 'myselfanamika': 9842, 'geniuinly': 9843, 'partsuction': 9844, 'powerprice': 9845, 'economiceasy': 9846, 'carryworks': 9847, 'socketcan': 9848, 'partwheels': 9849, 'unstableheats': 9850, 'usecommon': 9851, 'odur': 9852, 'refiting': 9853, 'exlandhappy': 9854, 'purchasevalue': 9855, 'satifisfiee': 9856, 'installationthank': 9857, 'clunky': 9858, 'rangeactual': 9859, 'innocent': 9860, 'te': 9861, 'requirementsonly': 9862, 'chouse': 9863, 'qualcomm': 9864, 'collections': 9865, 'activate': 9866, 'regional': 9867, 'processorrtx': 9868, 'resultsgrest': 9869, 'rateperformance': 9870, 'powerhousegaving': 9871, 'maxed': 9872, 'csgoit': 9873, 'released': 9874, 'mafia': 9875, 'definitive': 9876, 'marvels': 9877, 'raytracing': 9878, 'presume': 9879, 'battey': 9880, 'terr': 9881, 'notify': 9882, 'enemy': 9883, 'cou': 9884, 'choosen': 9885, 'extention': 9886, 'plugand': 9887, 'descaling': 9888, 'accumulated': 9889, 'golu': 9890, 'sonu': 9891, 'innovative': 9892, 'routines': 9893, 'prerecorded': 9894, 'twoway': 9895, 'customeroriented': 9896, 'headphonesuper': 9897, 'stylem': 9898, 'headphonebut': 9899, 'intrupt': 9900, 'perfectlyim': 9901, 'usepower': 9902, 'crystale': 9903, 'productsremoves': 9904, 'tapping': 9905, 'premiumit': 9906, 'exptation': 9907, 'hve': 9908, 'balances': 9909, 'batch': 9910, 'himmachines': 9911, 'usagereview': 9912, 'monthsstill': 9913, 'rinseaid': 9914, 'everyonekam': 9915, 'supercomnet': 9916, 'sandalwood': 9917, 'moody': 9918, 'vintage': 9919, 'vibesi': 9920, 'supportso': 9921, 'greatnice': 9922, 'colourvalue': 9923, 'ratepicture': 9924, 'connectionim': 9925, 'smoothgood': 9926, 'nyci': 9927, 'likhe': 9928, 'featuresbut': 9929, 'qualtay': 9930, 'weaks': 9931, 'welli': 9932, 'yearswell': 9933, 'processorcame': 9934, 'compactdoes': 9935, 'sucktion': 9936, 'abdulla': 9937, 'haji': 9938, 'kadavathur': 9939, 'collity': 9940, 'lakh': 9941, 'rangedisplay': 9942, 'outstandingthis': 9943, 'complainsoftware': 9944, 'outlast': 9945, 'doori': 9946, 'zones': 9947, 'alerts': 9948, 'entrancealso': 9949, 'viewthe': 9950, 'friendlythe': 9951, 'processorthanks': 9952, 'dealkeep': 9953, 'offersaddicted': 9954, 'plees': 9955, 'knight': 9956, 'onegives': 9957, 'packagingone': 9958, 'korck': 9959, 'trading': 9960, 'interfering': 9961, 'anac': 9962, 'issy': 9963, 'hadset': 9964, 'phonethanks': 9965, 'experienceneed': 9966, 'theaterit': 9967, 'itotherwise': 9968, 'curving': 9969, 'knuckle': 9970, 'trick': 9971, 'yrrr': 9972, 'moneytotally': 9973, 'settle': 9974, 'cze': 9975, 'bachuer': 9976, 'valua': 9977, 'badgets': 9978, 'aunts': 9979, 'impressedthe': 9980, 'clothlike': 9981, 'properlythx': 9982, 'worty': 9983, 'therebut': 9984, 'intervals': 9985, 'refilledink': 9986, 'disrecognized': 9987, 'printquality': 9988, 'stages': 9989, 'fews': 9990, 'raisedhope': 9991, 'rests': 9992, 'enought': 9993, 'appriciate': 9994, 'dedicate': 9995, 'laging': 9996, 'nw': 9997, 'serching': 9998, 'productupper': 9999, 'portionnice': 10000, 'needgood': 10001, 'toogets': 10002, 'productqulity': 10003, 'properlylike': 10004, 'genuineness': 10005, 'maintainvery': 10006, 'impressionoverall': 10007, 'wellnote': 10008, 'itremoved': 10009, 'hellofirst': 10010, 'awesomeaudio': 10011, 'extraordinaryperformance': 10012, 'lastingfinal': 10013, 'useawesome': 10014, 'playwhite': 10015, 'bargained': 10016, 'osamm': 10017, 'sooooper': 10018, 'scroll': 10019, 'everthing': 10020, 'flex': 10021, 'cordial': 10022, 'surds': 10023, 'dishwashe': 10024, 'bowles': 10025, 'timeusing': 10026, 'daysurreal': 10027, 'develope': 10028, 'mts': 10029, 'enters': 10030, 'velcro': 10031, 'productso': 10032, 'applyi': 10033, 'tailoring': 10034, 'developments': 10035, 'bajajvery': 10036, 'blowingreally': 10037, 'musky': 10038, 'categoryi': 10039, 'hardmusic': 10040, 'astoundingalso': 10041, 'plusdont': 10042, 'proudet': 10043, 'papar': 10044, 'gemitate': 10045, 'areseeds': 10046, 'bluetoot': 10047, 'nik': 10048, 'pice': 10049, 'amaging': 10050, 'deliveryim': 10051, 'weekperformance': 10052, 'pricetaste': 10053, 'wastagewater': 10054, 'btery': 10055, 'lifefor': 10056, 'batterno': 10057, 'cleanable': 10058, 'rileted': 10059, 'peking': 10060, 'guuud': 10061, 'cyclesame': 10062, 'cablesaux': 10063, 'siteand': 10064, 'tvlooks': 10065, 'itthere': 10066, 'statement': 10067, 'thanksss': 10068, 'adjusts': 10069, 'itselfbass': 10070, 'providingbest': 10071, 'greyish': 10072, 'ussage': 10073, 'absorbent': 10074, 'excellentin': 10075, 'priceworth': 10076, 'mtr': 10077, 'actully': 10078, 'awesomemind': 10079, 'experiencesuper': 10080, 'refills': 10081, 'maa': 10082, 'happierthe': 10083, 'givenafter': 10084, 'oneweek': 10085, 'excellentvary': 10086, 'leakagethanks': 10087, 'aquanza': 10088, 'lateroverall': 10089, 'invverter': 10090, 'dressed': 10091, 'organics': 10092, 'rightnow': 10093, 'phonescant': 10094, 'standcant': 10095, 'coves': 10096, 'aweeeeeesome': 10097, 'backupi': 10098, 'plasticover': 10099, 'malayali': 10100, 'sambavam': 10101, 'pwoli': 10102, 'goodcomfortable': 10103, 'mothers': 10104, 'ruppee': 10105, 'toasts': 10106, 'leftovers': 10107, 'qualitydisplayand': 10108, 'hoursamazing': 10109, 'goodpurchase': 10110, 'livpuire': 10111, 'rsgreat': 10112, 'experiencelight': 10113, 'reznable': 10114, 'miracle': 10115, 'satisfiedit': 10116, 'faste': 10117, 'qualityz': 10118, 'amazingthankyou': 10119, 'convient': 10120, 'thnqq': 10121, 'wooowthanks': 10122, 'stylist': 10123, 'bah': 10124, 'oney': 10125, 'resting': 10126, 'vitrified': 10127, 'floorings': 10128, 'irdering': 10129, 'origjnalitybut': 10130, 'happensan': 10131, 'perspire': 10132, 'seas': 10133, 'irs': 10134, 'handing': 10135, 'verybeady': 10136, 'amound': 10137, 'nourishment': 10138, 'perfumei': 10139, 'exceeding': 10140, 'ohh': 10141, 'unbroken': 10142, 'crockeries': 10143, 'pictured': 10144, 'dimmed': 10145, 'canceling': 10146, 'birds': 10147, 'chirping': 10148, 'mrpit': 10149, 'outdated': 10150, 'warmwhite': 10151, 'revise': 10152, 'laying': 10153, 'burglar': 10154, 'prodectcerant': 10155, 'fafect': 10156, 'cubsul': 10157, 'motherand': 10158, 'drone': 10159, 'etcadopter': 10160, 'elseand': 10161, 'luks': 10162, 'nowdont': 10163, 'hasitate': 10164, 'febulas': 10165, 'colourfuland': 10166, 'hb': 10167, 'variables': 10168, 'deliverey': 10169, 'someday': 10170, 'superas': 10171, 'recommendedto': 10172, 'headaches': 10173, 'sleeper': 10174, 'stuffed': 10175, 'wrongly': 10176, 'rally': 10177, 'alrams': 10178, 'flipkartthx': 10179, 'proso': 10180, 'quantityeasy': 10181, 'usecons': 10182, 'cripsp': 10183, 'rep': 10184, 'oriented': 10185, 'monthsothers': 10186, 'pricecolour': 10187, 'styleaveragefinishing': 10188, 'averageantislippery': 10189, 'nothickness': 10190, 'averagepurpose': 10191, 'servinggoodcost': 10192, 'sixes': 10193, 'tilted': 10194, 'litl': 10195, 'coling': 10196, 'shelvs': 10197, 'increasequality': 10198, 'productthak': 10199, 'decribe': 10200, 'miits': 10201, 'cinemabest': 10202, 'feelingfor': 10203, 'priceexcellent': 10204, 'exceptedcloth': 10205, 'itlol': 10206, 'flipkartready': 10207, 'budgetprice': 10208, 'reliance': 10209, 'giftso': 10210, 'nodoubt': 10211, 'materialsound': 10212, 'goodis': 10213, 'bellabox': 10214, 'restocked': 10215, 'scents': 10216, 'ione': 10217, 'onesthe': 10218, 'toostill': 10219, 'pricebought': 10220, 'combine': 10221, 'grapes': 10222, 'sweetlimes': 10223, 'mercy': 10224, 'bhagwan': 10225, 'bhakti': 10226, 'scticheable': 10227, 'osmperformance': 10228, 'thnxx': 10229, 'thnxxx': 10230, 'wanderful': 10231, 'learing': 10232, 'enjoing': 10233, 'rumours': 10234, 'metalother': 10235, 'meanwhile': 10236, 'expectedinstallation': 10237, 'scheduledexcellent': 10238, 'juicernever': 10239, 'batterytq': 10240, 'looook': 10241, 'packaginglonger': 10242, 'costwise': 10243, 'dimmer': 10244, 'animation': 10245, 'comfirt': 10246, 'imagequalty': 10247, 'morebest': 10248, 'notedaverage': 10249, 'fields': 10250, 'lampfinally': 10251, 'neve': 10252, 'trigger': 10253, 'jobprice': 10254, 'mspooja': 10255, 'clarified': 10256, 'motivated': 10257, 'flipzon': 10258, 'wantedreally': 10259, 'mashallah': 10260, 'rockz': 10261, 'impressedjst': 10262, 'awesomemy': 10263, 'itnd': 10264, 'frst': 10265, 'heatingits': 10266, 'proofvalue': 10267, 'consultants': 10268, 'cancell': 10269, 'pvt': 10270, 'ltd': 10271, 'involved': 10272, 'chromecastthis': 10273, 'lenght': 10274, 'interiors': 10275, 'backyard': 10276, 'wotch': 10277, 'thoughtits': 10278, 'moneylook': 10279, 'kk': 10280, 'teflon': 10281, 'mickey': 10282, 'beby': 10283, 'soundbarand': 10284, 'versionalso': 10285, 'behindnot': 10286, 'cleanrefill': 10287, 'watercable': 10288, 'itanybody': 10289, 'speciality': 10290, 'satisfyed': 10291, 'moneyconnectivity': 10292, 'nowif': 10293, 'happyhappy': 10294, 'transparentalso': 10295, 'torndont': 10296, 'yeh': 10297, 'excellentdisplay': 10298, 'awsomei': 10299, 'readingsbut': 10300, 'xiaomis': 10301, 'hints': 10302, 'sma': 10303, 'bled': 10304, 'moneyu': 10305, 'waysawesome': 10306, 'cyclewith': 10307, 'overallworth': 10308, 'comfartvery': 10309, 'softvery': 10310, 'apprehensive': 10311, 'giants': 10312, 'marketed': 10313, 'conveniently': 10314, 'werent': 10315, 'aswoom': 10316, 'purchesing': 10317, 'throttlestop': 10318, 'issuesoverall': 10319, 'stampedthe': 10320, 'casts': 10321, 'salute': 10322, 'epidemic': 10323, 'goodtrainers': 10324, 'dieticians': 10325, 'priceloved': 10326, 'gogglesworth': 10327, 'reyal': 10328, 'worstttttttttt': 10329, 'coats': 10330, 'celebration': 10331, 'wax': 10332, 'roughoverall': 10333, 'itworth': 10334, 'maze': 10335, 'soundwith': 10336, 'flood': 10337, 'thns': 10338, 'masti': 10339, 'prodocts': 10340, 'speedabout': 10341, 'weapon': 10342, 'sourceok': 10343, 'ghatnachkara': 10344, 'dore': 10345, 'refrigerators': 10346, 'favoured': 10347, 'gana': 10348, 'saavn': 10349, 'ugo': 10350, 'examseven': 10351, 'harddiskgot': 10352, 'goodcopy': 10353, 'rundoesnt': 10354, 'caseand': 10355, 'usedo': 10356, 'orderedand': 10357, 'itemsuperb': 10358, 'pri': 10359, 'ade': 10360, 'giddings': 10361, 'productramakrishna': 10362, 'nnavanambadu': 10363, 'amudalavalasasrikakulam': 10364, 'ap': 10365, 'walkingjogging': 10366, 'luking': 10367, 'productthsnks': 10368, 'operatingbut': 10369, 'siting': 10370, 'qualitycotton': 10371, 'thexxx': 10372, 'notits': 10373, 'rupeesbuy': 10374, 'hoped': 10375, 'goodpurchased': 10376, 'petelraj': 10377, 'productvreey': 10378, 'qualitychoose': 10379, 'multitasker': 10380, 'kazal': 10381, 'buildup': 10382, 'safey': 10383, 'oilreally': 10384, 'muchtimely': 10385, 'leakproofapprox': 10386, 'fluidfinishing': 10387, 'greatone': 10388, 'nust': 10389, 'mater': 10390, 'bore': 10391, 'instal': 10392, 'lapi': 10393, 'bestfrom': 10394, 'goodthose': 10395, 'cad': 10396, 'gysearinstallation': 10397, 'professionalsi': 10398, 'gysearthe': 10399, 'plugangle': 10400, 'coupler': 10401, 'wallnot': 10402, 'pipesnot': 10403, 'pril': 10404, 'onlydesign': 10405, 'retention': 10406, 'anywherethank': 10407, 'aspirents': 10408, 'throughput': 10409, 'flipart': 10410, 'showngo': 10411, 'atspaciousmy': 10412, 'beautifullydo': 10413, 'waterback': 10414, 'feelblewould': 10415, 'understanding': 10416, 'hospot': 10417, 'daam': 10418, 'rts': 10419, 'itinstallation': 10420, 'allsound': 10421, 'loudconnectivitydidnt': 10422, 'connectivitychrome': 10423, 'finebit': 10424, 'fineyoutube': 10425, 'productsafely': 10426, 'farvalue': 10427, 'amazingfeeling': 10428, 'pvr': 10429, 'indescribable': 10430, 'perfectquality': 10431, 'awasm': 10432, 'performanceproduct': 10433, 'wonderfulvalue': 10434, 'keybord': 10435, 'germinationwill': 10436, 'scandisk': 10437, 'qwalityim': 10438, 'utilitywise': 10439, 'fabolous': 10440, 'kitgoggles': 10441, 'leakageit': 10442, 'cgl': 10443, 'pets': 10444, 'reasonslight': 10445, 'awm': 10446, 'parentsif': 10447, 'aousom': 10448, 'itclose': 10449, 'requiredi': 10450, 'productis': 10451, 'approved': 10452, 'ministry': 10453, 'reverts': 10454, 'hussaingoa': 10455, 'dasting': 10456, 'designlooks': 10457, 'fregnance': 10458, 'wellbuy': 10459, 'coonect': 10460, 'crown': 10461, 'workingeasy': 10462, 'segmentbut': 10463, 'watermark': 10464, 'slowmo': 10465, 'draing': 10466, 'fasthoping': 10467, 'experienceshould': 10468, 'confusionactually': 10469, 'swith': 10470, 'functioningjust': 10471, 'splashed': 10472, 'taprest': 10473, 'leas': 10474, 'renouned': 10475, 'pinching': 10476, 'carato': 10477, 'pixma': 10478, 'draft': 10479, 'military': 10480, 'heredoes': 10481, 'carrier': 10482, 'aggregation': 10483, 'mentionm': 10484, 'recommendthanks': 10485, 'epson': 10486, 'laxmikant': 10487, 'polity': 10488, 'illustrated': 10489, 'contents': 10490, 'newborn': 10491, 'clothesi': 10492, 'moner': 10493, 'bur': 10494, 'combines': 10495, 'twitter': 10496, 'moneyprice': 10497, 'moneygud': 10498, 'tqqq': 10499, 'community': 10500, 'rosetta': 10501, 'heads': 10502, 'otherside': 10503, 'derised': 10504, 'url': 10505, 'googlecrome': 10506, 'bettry': 10507, 'kia': 10508, 'seltos': 10509, 'geysergo': 10510, 'ppt': 10511, 'dabba': 10512, 'devicefamily': 10513, 'stubborn': 10514, 'youdelivery': 10515, 'missingno': 10516, 'avaialblewe': 10517, 'gage': 10518, 'wellregarding': 10519, 'paperthe': 10520, 'provisioned': 10521, 'itthats': 10522, 'daysbattery': 10523, 'hourscamera': 10524, 'decentperformance': 10525, 'wowlooking': 10526, 'punto': 10527, 'ri': 10528, 'nicefabulous': 10529, 'baglooks': 10530, 'roomhall': 10531, 'thinnot': 10532, 'producl': 10533, 'ecellent': 10534, 'purchasefeatures': 10535, 'valuenice': 10536, 'vgd': 10537, 'cadr': 10538, 'approxyou': 10539, 'totel': 10540, 'bess': 10541, 'vedrid': 10542, 'packagingproduct': 10543, 'doe': 10544, 'superrbbb': 10545, 'semidry': 10546, 'airy': 10547, 'crossventilated': 10548, 'roomhealth': 10549, 'warning': 10550, 'lungsbreathing': 10551, 'performerno': 10552, 'meits': 10553, 'mans': 10554, 'haptic': 10555, 'allsince': 10556, 'louderiam': 10557, 'pantnice': 10558, 'moneygot': 10559, 'quietly': 10560, 'amplifire': 10561, 'zenaltosentro': 10562, 'balenotiago': 10563, 'micra': 10564, 'livepurecons': 10565, 'swipe': 10566, 'ken': 10567, 'softest': 10568, 'warmest': 10569, 'songsi': 10570, 'sails': 10571, 'installationnow': 10572, 'sportsoul': 10573, 'malta': 10574, 'onerecived': 10575, 'packagingno': 10576, 'disadvantagea': 10577, 'drippings': 10578, 'mapping': 10579, 'alsoso': 10580, 'kiti': 10581, 'extras': 10582, 'buyshas': 10583, 'againpicture': 10584, 'rangeone': 10585, 'adjustments': 10586, 'needif': 10587, 'xiao': 10588, 'attatchments': 10589, 'equaliserbattery': 10590, 'usagesound': 10591, 'hearpubg': 10592, 'footstep': 10593, 'gloomy': 10594, 'sweating': 10595, 'designable': 10596, 'polycotton': 10597, 'fabricsize': 10598, 'describedprice': 10599, 'reassures': 10600, 'unknown': 10601, 'goodfirst': 10602, 'wayoverall': 10603, 'bookpaper': 10604, 'saguest': 10605, 'ciling': 10606, 'inputsound': 10607, 'codthe': 10608, 'gery': 10609, 'circumstance': 10610, 'deliveryplates': 10611, 'intended': 10612, 'fathom': 10613, 'illustrator': 10614, 'translates': 10615, 'blazi': 10616, 'kajalmust': 10617, 'muchi': 10618, 'satisfiedvery': 10619, 'deeeeeep': 10620, 'hotcool': 10621, 'beveragesgood': 10622, 'hardsoft': 10623, 'stabilizers': 10624, 'coolonly': 10625, 'aways': 10626, 'forwarding': 10627, 'bugaet': 10628, 'belief': 10629, 'osadoron': 10630, 'osom': 10631, 'asm': 10632, 'pennynice': 10633, 'buybolo': 10634, 'aloevera': 10635, 'smoothens': 10636, 'foods': 10637, 'flipkartbajaj': 10638, 'safelyhv': 10639, 'cheke': 10640, 'headphonemust': 10641, 'buylooks': 10642, 'comparative': 10643, 'marketbut': 10644, 'birthdayvery': 10645, 'beautifulshe': 10646, 'surpriseif': 10647, 'womanu': 10648, 'perfumeperfume': 10649, 'comfertabule': 10650, 'envisaged': 10651, 'colety': 10652, 'pricehighly': 10653, 'goodbetter': 10654, 'nich': 10655, 'frontcons': 10656, 'individually': 10657, 'burner': 10658, 'surya': 10659, 'theator': 10660, 'frequentlyexcept': 10661, 'za': 10662, 'oosam': 10663, 'awesomeneed': 10664, 'prfomence': 10665, 'sterdy': 10666, 'cutei': 10667, 'boombox': 10668, 'directions': 10669, 'beginnersexcellent': 10670, 'deliveryvalve': 10671, 'boatboat': 10672, 'ampoule': 10673, 'sart': 10674, 'wristgood': 10675, 'polister': 10676, 'ilove': 10677, 'bace': 10678, 'productat': 10679, 'amazingworking': 10680, 'mmcfm': 10681, 'finedefinitely': 10682, 'productus': 10683, 'promising': 10684, 'toll': 10685, 'paints': 10686, 'aditya': 10687, 'messaged': 10688, 'makercompare': 10689, 'fc': 10690, 'oill': 10691, 'timecons': 10692, 'unfoldableu': 10693, 'goodsmart': 10694, 'bestthis': 10695, 'bootup': 10696, 'builds': 10697, 'etcits': 10698, 'proi': 10699, 'wellscreen': 10700, 'ballsthis': 10701, 'productapt': 10702, 'dustthe': 10703, 'heaten': 10704, 'skatebord': 10705, 'responce': 10706, 'powerbi': 10707, 'mysql': 10708, 'itemlooking': 10709, 'swiping': 10710, 'sirf': 10711, 'pani': 10712, 'garm': 10713, 'dilewary': 10714, 'chanals': 10715, 'combothe': 10716, 'qualitycooling': 10717, 'olednext': 10718, 'othersthis': 10719, 'gaminglike': 10720, 'spoked': 10721, 'mentionedthe': 10722, 'workingcamera': 10723, 'qualityvary': 10724, 'headphonei': 10725, 'heavenalso': 10726, 'tooall': 10727, 'improper': 10728, 'platformjust': 10729, 'properlythis': 10730, 'coatthe': 10731, 'naren': 10732, 'embroid': 10733, 'soundbars': 10734, 'unbox': 10735, 'worthbass': 10736, 'thistotally': 10737, 'inc': 10738, 'petern': 10739, 'fatherand': 10740, 'othersanyways': 10741, 'modelbut': 10742, 'flexibility': 10743, 'orderd': 10744, 'lelo': 10745, 'rows': 10746, 'bookyou': 10747, 'disguisea': 10748, 'everyonethe': 10749, 'umis': 10750, 'nechance': 10751, 'broom': 10752, 'collects': 10753, 'smiling': 10754, 'spiders': 10755, 'performanceso': 10756, 'usesoverall': 10757, 'doubtexcellent': 10758, 'goodinstallation': 10759, 'raju': 10760, 'pipehence': 10761, 'alongwith': 10762, 'itis': 10763, 'exceeded': 10764, 'againwhat': 10765, 'laptopthe': 10766, 'batteryyou': 10767, 'chargerunbelievablethanks': 10768, 'anythingyou': 10769, 'thnkuuu': 10770, 'sequence': 10771, 'workeddidnt': 10772, 'purcjase': 10773, 'forsure': 10774, 'bicycling': 10775, 'awesomegear': 10776, 'shifter': 10777, 'shimano': 10778, 'qualitybrakes': 10779, 'goodbur': 10780, 'prodoct': 10781, 'enjoyd': 10782, 'priceplates': 10783, 'cardvalue': 10784, 'moneyread': 10785, 'goodwrite': 10786, 'kichen': 10787, 'surt': 10788, 'fulfils': 10789, 'heavier': 10790, 'segmenteven': 10791, 'breadcake': 10792, 'drees': 10793, 'nowhas': 10794, 'mt': 10795, 'pordekt': 10796, 'metireal': 10797, 'winterbest': 10798, 'oveegeating': 10799, 'largerit': 10800, 'silliest': 10801, 'supob': 10802, 'materialit': 10803, 'transparentbt': 10804, 'slit': 10805, 'grander': 10806, 'fragrancei': 10807, 'heaveni': 10808, 'bbdbody': 10809, 'comaprable': 10810, 'synchronizationmsi': 10811, 'tufapart': 10812, 'chudi': 10813, 'suprise': 10814, 'railwire': 10815, 'routeri': 10816, 'conditionthanku': 10817, 'onereceived': 10818, 'moneysecondly': 10819, 'amateurlastly': 10820, 'deliverythank': 10821, 'notbut': 10822, 'superbgifted': 10823, 'installment': 10824, 'ecard': 10825, 'okthis': 10826, 'podckt': 10827, 'brrakfast': 10828, 'ls': 10829, 'studyto': 10830, 'deliveryman': 10831, 'blacked': 10832, 'touched': 10833, 'miracast': 10834, 'easyloved': 10835, 'supportit': 10836, 'conumes': 10837, 'parcheched': 10838, 'bigand': 10839, 'trolley': 10840, 'packagingjust': 10841, 'resuse': 10842, 'conservation': 10843, 'toughest': 10844, 'reappointment': 10845, 'overif': 10846, 'prerequisite': 10847, 'sellerhighly': 10848, 'professionallythank': 10849, 'goodplant': 10850, 'fresf': 10851, 'enoughafter': 10852, 'hows': 10853, 'googlewill': 10854, 'usagefirst': 10855, 'woh': 10856, 'averageu': 10857, 'gaplack': 10858, 'bluestar': 10859, 'aquaguardand': 10860, 'fs': 10861, 'risky': 10862, 'ouput': 10863, 'bestgreenery': 10864, 'crashed': 10865, 'finejust': 10866, 'custamer': 10867, 'efective': 10868, 'useliked': 10869, 'keshu': 10870, 'saini': 10871, 'describes': 10872, 'lotand': 10873, 'coinsupdateworking': 10874, 'bobbin': 10875, 'placemt': 10876, 'stitiching': 10877, 'hasitation': 10878, 'charjing': 10879, 'onegenuine': 10880, 'experiencepicture': 10881, 'wonderfulworth': 10882, 'plipkart': 10883, 'js': 10884, 'voltagecurrent': 10885, 'detol': 10886, 'steals': 10887, 'apron': 10888, 'podack': 10889, 'testicles': 10890, 'warrantynot': 10891, 'buzzy': 10892, 'cartriy': 10893, 'cleanextracts': 10894, 'squeezed': 10895, 'strainergood': 10896, 'impressiontoo': 10897, 'expensivewhen': 10898, 'resanabulrate': 10899, 'gan': 10900, 'qualityfast': 10901, 'affordableeasy': 10902, 'phenomenonthis': 10903, 'amazingvery': 10904, 'jobmy': 10905, 'groth': 10906, 'unbelivable': 10907, 'ultimatel': 10908, 'speedly': 10909, 'satisfiedand': 10910, 'minimalistic': 10911, 'filpkartfast': 10912, 'sharpnessvery': 10913, 'regularlyits': 10914, 'oneread': 10915, 'belly': 10916, 'fatarm': 10917, 'fatshoulderchest': 10918, 'thighten': 10919, 'screwdrivers': 10920, 'miracles': 10921, 'paroduct': 10922, 'amy': 10923, 'thrones': 10924, 'mustt': 10925, 'buyy': 10926, 'darkest': 10927, 'sprb': 10928, 'gamingworth': 10929, 'recevied': 10930, 'gabric': 10931, 'fkrt': 10932, 'gamingalthough': 10933, 'tiptop': 10934, 'bestgo': 10935, 'muf': 10936, 'recomt': 10937, 'conn': 10938, 'supplyingradio': 10939, 'okusb': 10940, 'yubicast': 10941, 'damageinitially': 10942, 'hesitated': 10943, 'grinderbuild': 10944, 'outstand': 10945, 'superthanks': 10946, 'willow': 10947, 'elimination': 10948, 'butvery': 10949, 'stylishbigeasy': 10950, 'cleansuperb': 10951, 'sucessfully': 10952, 'othe': 10953, 'balli': 10954, 'onlywaste': 10955, 'piesgood': 10956, 'mummyn': 10957, 'ull': 10958, 'pricethnk': 10959, 'piku': 10960, 'stationary': 10961, 'documenttion': 10962, 'puchase': 10963, 'usageexcellent': 10964, 'capacitycovered': 10965, 'safetygood': 10966, 'peopleno': 10967, 'draweralmost': 10968, 'equals': 10969, 'cfl': 10970, 'deliverer': 10971, 'denim': 10972, 'wooooooow': 10973, 'wowwww': 10974, 'otgoverall': 10975, 'timeyou': 10976, 'moneyfabullous': 10977, 'tabel': 10978, 'gradually': 10979, 'packednice': 10980, 'deficult': 10981, 'barrel': 10982, 'troubled': 10983, 'installationhe': 10984, 'demonstrate': 10985, 'knowhows': 10986, 'bittubhagat': 10987, 'boltotherwise': 10988, 'cushionsvery': 10989, 'smoothwish': 10990, 'osmm': 10991, 'nimal': 10992, 'looksgreat': 10993, 'rekarding': 10994, 'moral': 10995, 'ethics': 10996, 'filledgood': 10997, 'acess': 10998, 'bliss': 10999, 'srusti': 11000, 'introducing': 11001, 'chargerbest': 11002, 'moy': 11003, 'aon': 11004, 'disturbs': 11005, 'vocalsso': 11006, 'helpbut': 11007, 'earsbattery': 11008, 'producted': 11009, 'denser': 11010, 'purposeas': 11011, 'conform': 11012, 'teamfantasti': 11013, 'equality': 11014, 'goodfeature': 11015, 'feautres': 11016, 'qualitie': 11017, 'cabinate': 11018, 'moneyonly': 11019, 'jbhara': 11020, 'thinkingi': 11021, 'adata': 11022, 'rami': 11023, 'antiglare': 11024, 'eaten': 11025, 'smallotherwise': 11026, 'kenstar': 11027, 'marketprosit': 11028, 'noisehuge': 11029, 'tankpowerful': 11030, 'airthrowconsno': 11031, 'bettare': 11032, 'beutiyfull': 11033, 'compactable': 11034, 'laglo': 11035, 'speakeronly': 11036, 'crackle': 11037, 'twicebut': 11038, 'alhamdulillah': 11039, 'twin': 11040, 'itsss': 11041, 'goodthankyou': 11042, 'clothesalthough': 11043, 'woolen': 11044, 'smudgehappy': 11045, 'upgaradble': 11046, 'clarify': 11047, 'ping': 11048, 'stacked': 11049, 'goodled': 11050, 'nightoverall': 11051, 'centric': 11052, 'excellentdont': 11053, 'dealgamig': 11054, 'qualityrgb': 11055, 'coolgreat': 11056, 'designconsbattery': 11057, 'parkinda': 11058, 'disappointingbut': 11059, 'relaxing': 11060, 'finishingnice': 11061, 'slicinggreeding': 11062, 'cores': 11063, 'vms': 11064, 'docker': 11065, 'pocs': 11066, 'skyrim': 11067, 'ed': 11068, 'oneamazing': 11069, 'profitable': 11070, 'ncee': 11071, 'daimej': 11072, 'metariyal': 11073, 'starand': 11074, 'dhirty': 11075, 'constemar': 11076, 'aosm': 11077, 'kajals': 11078, 'agaroimperial': 11079, 'juicerthe': 11080, 'tastejuice': 11081, 'itemsbut': 11082, 'monthother': 11083, 'li': 11084, 'ining': 11085, 'hellogood': 11086, 'complexity': 11087, 'habituaded': 11088, 'xlent': 11089, 'lockunlock': 11090, 'protruding': 11091, 'wowthank': 11092, 'waa': 11093, 'useabble': 11094, 'smoothlyvgaurd': 11095, 'inverterproduct': 11096, 'verification': 11097, 'gaurd': 11098, 'appreceived': 11099, 'essense': 11100, 'okmust': 11101, 'bouncingouter': 11102, 'hardotherwise': 11103, 'regulators': 11104, 'cyclei': 11105, 'everawesome': 11106, 'backlightit': 11107, 'expandableoverall': 11108, 'continuosly': 11109, 'asowme': 11110, 'momey': 11111, 'visualisation': 11112, 'penney': 11113, 'satisfiedawillguru': 11114, 'patent': 11115, 'soooooooo': 11116, 'facilitypolicy': 11117, 'sefty': 11118, 'productjuss': 11119, 'lengthbut': 11120, 'mehines': 11121, 'superrrbb': 11122, 'cushionsgood': 11123, 'polyfill': 11124, 'verey': 11125, 'donegood': 11126, 'purit': 11127, 'goodones': 11128, 'affectloved': 11129, 'amateur': 11130, 'purchaseit': 11131, 'eased': 11132, 'cleanhygienic': 11133, 'drinks': 11134, 'syrup': 11135, 'mesh': 11136, 'tighter': 11137, 'milkshakes': 11138, 'bestno': 11139, 'lookingblindly': 11140, 'sand': 11141, 'diskso': 11142, 'verrryy': 11143, 'productsensor': 11144, 'nourishes': 11145, 'chipping': 11146, 'yahh': 11147, 'conditionusing': 11148, 'monthshappy': 11149, 'onesatisfied': 11150, 'grinderjust': 11151, 'tnk': 11152, 'superrrrrr': 11153, 'bemesal': 11154, 'shandaar': 11155, 'thankyu': 11156, 'processingthanks': 11157, 'daysthank': 11158, 'clearif': 11159, 'sambar': 11160, 'urben': 11161, 'downfood': 11162, 'improveddrum': 11163, 'consumptionsoft': 11164, 'pictorial': 11165, 'diagram': 11166, 'intresting': 11167, 'readthis': 11168, 'unavoidable': 11169, 'ventilator': 11170, 'serivcego': 11171, 'usefulllland': 11172, 'booksgood': 11173, 'superelarum': 11174, 'foelr': 11175, 'wbcs': 11176, 'sizedavailability': 11177, 'enoughinstead': 11178, 'pictureservice': 11179, 'richness': 11180, 'effordable': 11181, 'bookthnks': 11182, 'starbass': 11183, 'stardesign': 11184, 'starbattery': 11185, 'starconnectivity': 11186, 'starvalue': 11187, 'rugged': 11188, 'offersthankyou': 11189, 'airi': 11190, 'earpads': 11191, 'confort': 11192, 'genuineproduct': 11193, 'ging': 11194, 'richif': 11195, 'screenshot': 11196, 'buit': 11197, 'qualityheadphone': 11198, 'hourp': 11199, 'finishingwhen': 11200, 'pushedpulled': 11201, 'popwings': 11202, 'nicevery': 11203, 'wearmaterial': 11204, 'pull': 11205, 'flipkartsmart': 11206, 'helpfulvery': 11207, 'alsomost': 11208, 'bog': 11209, 'checkout': 11210, 'goodfinally': 11211, 'hardiskpassword': 11212, 'suprbsuprb': 11213, 'qualitysuprnb': 11214, 'cadbury': 11215, 'sweatshirts': 11216, 'thnaks': 11217, 'attempt': 11218, 'straightforward': 11219, 'transformed': 11220, 'couch': 11221, 'spotify': 11222, 'fre': 11223, 'vessles': 11224, 'perfrom': 11225, 'brandsbest': 11226, 'stapler': 11227, 'preface': 11228, 'fictional': 11229, 'ppi': 11230, 'woody': 11231, 'temples': 11232, 'superbwatch': 11233, 'lookswhich': 11234, 'continous': 11235, 'useoverall': 11236, 'aroe': 11237, 'greenery': 11238, 'elder': 11239, 'plying': 11240, 'productpackaged': 11241, 'opaque': 11242, 'budgetfriendly': 11243, 'preoduct': 11244, 'goodvest': 11245, 'daythis': 11246, 'experiment': 11247, 'ironvery': 11248, 'hostels': 11249, 'singles': 11250, 'careless': 11251, 'differencevalue': 11252, 'coolingconssound': 11253, 'qualityproduct': 11254, 'nikkon': 11255, 'niceloved': 11256, 'fragranceits': 11257, 'usueful': 11258, 'delegate': 11259, 'enhancing': 11260, 'sweeter': 11261, 'bislery': 11262, 'kinley': 11263, 'timethank': 11264, 'awesomeai': 11265, 'awesomelooks': 11266, 'awesomeas': 11267, 'accessibility': 11268, 'musicvideo': 11269, 'celebrations': 11270, 'childern': 11271, 'edgemeans': 11272, 'zyada': 11273, 'ummeed': 11274, 'khara': 11275, 'utrai': 11276, 'doomedobviously': 11277, 'driversvoice': 11278, 'casebass': 11279, 'lobesnoise': 11280, 'goodgamers': 11281, 'headphonego': 11282, 'bellavita': 11283, 'perfumegives': 11284, 'deliveryshipment': 11285, 'peaks': 11286, 'smoothlydefinitely': 11287, 'superrrb': 11288, 'problemreasonable': 11289, 'prodcat': 11290, 'literature': 11291, 'goodsame': 11292, 'packingsworth': 11293, 'thak': 11294, 'bbs': 11295, 'preparationeverything': 11296, 'socets': 11297, 'qualityotherwise': 11298, 'definatly': 11299, 'tannis': 11300, 'sscrrband': 11301, 'competative': 11302, 'bankthe': 11303, 'finishvery': 11304, 'pocketis': 11305, 'inputit': 11306, 'chargedit': 11307, 'havecomplete': 11308, 'upgradability': 11309, 'micron': 11310, 'performancelook': 11311, 'premiumbattery': 11312, 'pricebuilt': 11313, 'weekends': 11314, 'expectedi': 11315, 'handmade': 11316, 'continious': 11317, 'bassy': 11318, 'choicethe': 11319, 'fasta': 11320, 'cluttering': 11321, 'giggling': 11322, 'operationits': 11323, 'masksperfect': 11324, 'fascinated': 11325, 'modelim': 11326, 'deducting': 11327, 'vaule': 11328, 'sessionshad': 11329, 'personalized': 11330, 'davinci': 11331, 'renders': 11332, 'minutesthere': 11333, 'warmi': 11334, 'fortnite': 11335, 'immaculate': 11336, 'playingi': 11337, 'comfortablebut': 11338, 'topples': 11339, 'film': 11340, 'moist': 11341, 'humid': 11342, 'climate': 11343, 'blacks': 11344, 'blacknow': 11345, 'grace': 11346, 'positives': 11347, 'trustly': 11348, 'alike': 11349, 'armrests': 11350, 'spine': 11351, 'taller': 11352, 'mixieneed': 11353, 'productfist': 11354, 'disbut': 11355, 'learninghope': 11356, 'aousam': 11357, 'zandu': 11358, 'potraid': 11359, 'foto': 11360, 'qualitybattery': 11361, 'itd': 11362, 'aswame': 11363, 'listings': 11364, 'fabriccomfortablegood': 11365, 'jai': 11366, 'vijay': 11367, 'realty': 11368, 'cinimatic': 11369, 'adjuster': 11370, 'speedthanks': 11371, 'simpley': 11372, 'goat': 11373, 'delhito': 11374, 'usethe': 11375, 'waterinstallation': 11376, 'itplease': 11377, 'peoplehe': 11378, 'questionshe': 11379, 'dirtywe': 11380, 'feetplease': 11381, 'groomed': 11382, 'quolityexcellent': 11383, 'particularly': 11384, 'remotely': 11385, 'rechive': 11386, 'bapithank': 11387, 'cheapo': 11388, 'alloy': 11389, 'bags': 11390, 'ecnomics': 11391, 'economics': 11392, 'aster': 11393, 'chrysanthemum': 11394, 'veryy': 11395, 'pricein': 11396, 'competetive': 11397, 'threshold': 11398, 'errorr': 11399, 'againin': 11400, 'paychwall': 11401, 'thirdparty': 11402, 'consumingpicture': 11403, 'levelbut': 11404, 'purhase': 11405, 'awesomedilivery': 11406, 'fatigue': 11407, 'ifbi': 11408, 'bawol': 11409, 'exallant': 11410, 'alsoflipcart': 11411, 'voicefull': 11412, 'bsuse': 11413, 'experiencebought': 11414, 'phonepee': 11415, 'walet': 11416, 'cashbackfinal': 11417, 'prettythanks': 11418, 'settles': 11419, 'mumma': 11420, 'ignorable': 11421, 'harry': 11422, 'potter': 11423, 'xpon': 11424, 'aquatic': 11425, 'ra': 11426, 'ge': 11427, 'timeif': 11428, 'projection': 11429, 'doorsliving': 11430, 'choke': 11431, 'cough': 11432, 'frequentlythis': 11433, 'satisfactorily': 11434, 'fullfills': 11435, 'goooooood': 11436, 'wickets': 11437, 'opinionpros': 11438, 'samsungs': 11439, 'windowsspecifications': 11440, 'libre': 11441, 'watchlist': 11442, 'remoteps': 11443, 'tcl': 11444, 'desoldering': 11445, 'wix': 11446, 'remarkable': 11447, 'maggy': 11448, 'pasta': 11449, 'washable': 11450, 'scrubber': 11451, 'betterzebronics': 11452, 'bawalllll': 11453, 'flpcrt': 11454, 'attack': 11455, 'plated': 11456, 'okaypackaging': 11457, 'styrofoam': 11458, 'inserted': 11459, 'ghosting': 11460, 'keysoverall': 11461, 'gamingedit': 11462, 'supperr': 11463, 'dupperr': 11464, 'inkjet': 11465, 'jobgreat': 11466, 'greatgot': 11467, 'doent': 11468, 'finsh': 11469, 'awesometq': 11470, 'aaj': 11471, 'subah': 11472, 'apun': 11473, 'chai': 11474, 'bnaya': 11475, 'noodles': 11476, 'soup': 11477, 'gender': 11478, 'cloththrutly': 11479, 'finising': 11480, 'outdoorsbeen': 11481, 'speedeg': 11482, 'tar': 11483, 'bonfires': 11484, 'society': 11485, 'floorthe': 11486, 'itme': 11487, 'superbbbbb': 11488, 'bp': 11489, 'experics': 11490, 'finethanks': 11491, 'clipart': 11492, 'cardi': 11493, 'stylishsimply': 11494, 'remoces': 11495, 'deg': 11496, 'wif': 11497, 'resumes': 11498, 'culture': 11499, 'garg': 11500, 'woowww': 11501, 'sizlar': 11502, 'nat': 11503, 'repeaters': 11504, 'baf': 11505, 'betterall': 11506, 'qualityquality': 11507, 'stylishvery': 11508, 'organizeddelivered': 11509, 'damagesprice': 11510, 'finalised': 11511, 'modelusing': 11512, 'effectivewe': 11513, 'rinsing': 11514, 'infact': 11515, 'easytrust': 11516, 'coolpad': 11517, 'fam': 11518, 'mivithe': 11519, 'soundbuild': 11520, 'hussle': 11521, 'wearthank': 11522, 'fanatic': 11523, 'proforma': 11524, 'curtons': 11525, 'helper': 11526, 'coolingworth': 11527, 'pricedelivered': 11528, 'cakewalk': 11529, 'jiofibre': 11530, 'earbud': 11531, 'reviewover': 11532, 'wirelss': 11533, 'boatso': 11534, 'movieand': 11535, 'percentagered': 11536, 'offblue': 11537, 'onthe': 11538, 'bestcalling': 11539, 'withoutany': 11540, 'amako': 11541, 'handlelong': 11542, 'sarika': 11543, 'enterprises': 11544, 'pinch': 11545, 'amazine': 11546, 'itn': 11547, 'suparv': 11548, 'minutei': 11549, 'disignes': 11550, 'nacked': 11551, 'insted': 11552, 'caramelly': 11553, 'bougie': 11554, 'sensational': 11555, 'events': 11556, 'geogle': 11557, 'circles': 11558, 'voilet': 11559, 'masha': 11560, 'conditionoriginal': 11561, 'niceim': 11562, 'deliveryjust': 11563, 'farjust': 11564, 'installationthey': 11565, 'costproduct': 11566, 'greatlooking': 11567, 'worklove': 11568, 'disinfection': 11569, 'fhilifcart': 11570, 'suppp': 11571, 'awesomeeasy': 11572, 'usejust': 11573, 'adviced': 11574, 'onlinethere': 11575, 'bestand': 11576, 'iis': 11577, 'bestp': 11578, 'alaways': 11579, 'sloved': 11580, 'okbetter': 11581, 'woek': 11582, 'furry': 11583, 'dinneri': 11584, 'heighted': 11585, 'chimneydelivery': 11586, 'pincode': 11587, 'flipkartoverall': 11588, 'speedotherwise': 11589, 'affordablequality': 11590, 'goodaccuracy': 11591, 'coolingsimply': 11592, 'rupay': 11593, 'weighteasy': 11594, 'andlow': 11595, 'roombedroom': 11596, 'machineheavy': 11597, 'suger': 11598, 'beets': 11599, 'etcand': 11600, 'pricethats': 11601, 'amazingthe': 11602, 'rangenice': 11603, 'lookfilter': 11604, 'cleanif': 11605, 'thisandabout': 11606, 'installationno': 11607, 'technicianjust': 11608, 'chimneycan': 11609, 'wearlight': 11610, 'dazzle': 11611, 'dinnerset': 11612, 'chairgood': 11613, 'preetybut': 11614, 'appseven': 11615, 'wikipedia': 11616, 'therebluetooth': 11617, 'correctedremote': 11618, 'irritatingchrome': 11619, 'aweosme': 11620, 'coolerits': 11621, 'goodrecomonded': 11622, 'qualitysuperbest': 11623, 'autoplay': 11624, 'senior': 11625, 'citizens': 11626, 'lessdidnt': 11627, 'contractor': 11628, 'deliveryreasonable': 11629, 'oneworks': 11630, 'perfectlymany': 11631, 'feedbackits': 11632, 'usingim': 11633, 'photographerits': 11634, 'swatshirt': 11635, 'examinations': 11636, 'muchit': 11637, 'atrective': 11638, 'secrets': 11639, 'customizing': 11640, 'convince': 11641, 'persail': 11642, 'donevery': 11643, 'juicergood': 11644, 'pushing': 11645, 'satisfyingits': 11646, 'awome': 11647, 'brandand': 11648, 'feelings': 11649, 'overturn': 11650, 'beautifulvery': 11651, 'floater': 11652, 'layback': 11653, 'awesomeworst': 11654, 'spece': 11655, 'goodclear': 11656, 'callingmust': 11657, 'researchservice': 11658, 'fussfor': 11659, 'comfortablejust': 11660, 'coushions': 11661, 'ahed': 11662, 'physic': 11663, 'fastgreat': 11664, 'daysvalue': 11665, 'moneylets': 11666, 'kandipa': 11667, 'vangavum': 11668, 'goodsema': 11669, 'experiencewe': 11670, 'taboverall': 11671, 'wirelesslyworth': 11672, 'relatedi': 11673, 'nightit': 11674, 'homei': 11675, 'watchblack': 11676, 'bigginers': 11677, 'vheri': 11678, 'swivel': 11679, 'thigh': 11680, 'perfectimprovements': 11681, 'searcing': 11682, 'clearance': 11683, 'speacial': 11684, 'guidebook': 11685, 'nandlal': 11686, 'reaally': 11687, 'amazinghappy': 11688, 'bails': 11689, 'lok': 11690, 'interest': 11691, 'toward': 11692, 'antidote': 11693, 'pressurised': 11694, 'studiesi': 11695, 'musicsbut': 11696, 'qualiy': 11697, 'goodmostly': 11698, 'farak': 11699, 'sorted': 11700, 'politethnku': 11701, 'preheating': 11702, 'valuethanks': 11703, 'aitam': 11704, 'airan': 11705, 'roi': 11706, 'justification': 11707, 'gosame': 11708, 'south': 11709, 'productcheck': 11710, 'soundshappiness': 11711, 'goodperformance': 11712, 'chargertwo': 11713, 'groundedyou': 11714, 'laptopit': 11715, 'willingness': 11716, 'curriar': 11717, 'applicationproduct': 11718, 'ship': 11719, 'expecteddelivery': 11720, 'aswm': 11721, 'goodloved': 11722, 'absolutly': 11723, 'strech': 11724, 'doneoverall': 11725, 'experiencego': 11726, 'reallybut': 11727, 'longibity': 11728, 'kile': 11729, 'farand': 11730, 'flawless': 11731, 'beatable': 11732, 'itspeed': 11733, 'restaurants': 11734, 'helpdesk': 11735, 'colous': 11736, 'vevery': 11737, 'productwarm': 11738, 'dryed': 11739, 'minsother': 11740, 'bestevercontent': 11741, 'samsungthank': 11742, 'polishes': 11743, 'resulting': 11744, 'classs': 11745, 'familyi': 11746, 'superbalso': 11747, 'ausx': 11748, 'feautures': 11749, 'itefficiency': 11750, 'alltype': 11751, 'chukundar': 11752, 'kinnu': 11753, 'qunatity': 11754, 'okas': 11755, 'grindersthe': 11756, 'rd': 11757, 'rosalie': 11758, 'vooc': 11759, 'qualityrealy': 11760, 'torant': 11761, 'vcbought': 11762, 'workinghope': 11763, 'upstairs': 11764, 'sensetive': 11765, 'auam': 11766, 'cargoplease': 11767, 'molded': 11768, 'applies': 11769, 'downwards': 11770, 'oneloved': 11771, 'tabletfor': 11772, 'luckas': 11773, 'chancesooo': 11774, 'deliveredcoming': 11775, 'partthe': 11776, 'updatepicture': 11777, 'goodfew': 11778, 'usagehad': 11779, 'unwilling': 11780, 'purchasem': 11781, 'perfectwith': 11782, 'thisenjoy': 11783, 'adaptersame': 11784, 'vallue': 11785, 'conenice': 11786, 'fragrancedevine': 11787, 'feelingmust': 11788, 'spaceotherwise': 11789, 'suffocatetotally': 11790, 'buyngtotally': 11791, 'cones': 11792, 'ifbgot': 11793, 'daydishwasher': 11794, 'spotless': 11795, 'cleanrecommended': 11796, 'utensilsgood': 11797, 'promotly': 11798, 'stalled': 11799, 'filteration': 11800, 'worjing': 11801, 'amongst': 11802, 'dealdont': 11803, 'morego': 11804, 'soundneed': 11805, 'awesom': 11806, 'resultnice': 11807, 'flowosm': 11808, 'goos': 11809, 'onefeeling': 11810, 'freshnessmight': 11811, 'longercost': 11812, 'thissound': 11813, 'bcse': 11814, 'orderingthis': 11815, 'expectedchecked': 11816, 'graphicsits': 11817, 'budgetcons': 11818, 'whi': 11819, 'ds': 11820, 'flickcart': 11821, 'compert': 11822, 'descriptionis': 11823, 'missingif': 11824, 'hassel': 11825, 'spinach': 11826, 'usagesnot': 11827, 'esports': 11828, 'anilkumar': 11829, 'gk': 11830, 'chandra': 11831, 'nayak': 11832, 'toi': 11833, 'internetthis': 11834, 'enrichment': 11835, 'ofnot': 11836, 'noticeable': 11837, 'trebleif': 11838, 'shattering': 11839, 'heavybass': 11840, 'mouch': 11841, 'mattresscurtainswindow': 11842, 'minutesthen': 11843, 'productfully': 11844, 'havell': 11845, 'airhavells': 11846, 'purifiernow': 11847, 'muchthe': 11848, 'pricelove': 11849, 'happyits': 11850, 'jeeva': 11851, 'lodge': 11852, 'dissatisfaction': 11853, 'concise': 11854, 'doorwriting': 11855, 'noiseusefulmay': 11856, 'toughness': 11857, 'productkids': 11858, 'productregularly': 11859, 'walk': 11860, 'levelled': 11861, 'receivebut': 11862, 'fastplease': 11863, 'om': 11864, 'sai': 11865, 'everyonethank': 11866, 'entitles': 11867, 'knock': 11868, 'informing': 11869, 'outsourcing': 11870, 'unscrupulous': 11871, 'confusingnot': 11872, 'properlythere': 11873, 'mot': 11874, 'timemy': 11875, 'papa': 11876, 'hut': 11877, 'installationbest': 11878, 'featureseasy': 11879, 'mechanismthanks': 11880, 'mannered': 11881, 'trimble': 11882, 'controlplastic': 11883, 'designedcons': 11884, 'surge': 11885, 'invetar': 11886, 'notu': 11887, 'gudu': 11888, 'expectetions': 11889, 'arguably': 11890, 'differencesound': 11891, 'expectedboth': 11892, 'pointgot': 11893, 'valuablei': 11894, 'looknice': 11895, 'hafele': 11896, 'kailh': 11897, 'duo': 11898, 'broadcasting': 11899, 'messages': 11900, 'premiumgaana': 11901, 'microwavewith': 11902, 'featuresfreebies': 11903, 'recipe': 11904, 'boxesa': 11905, 'standsa': 11906, 'traya': 11907, 'spoonand': 11908, 'rotates': 11909, 'dilewer': 11910, 'laptopexcellent': 11911, 'ratiobest': 11912, 'awesomeu': 11913, 'fastlittle': 11914, 'indain': 11915, 'doorselse': 11916, 'rhig': 11917, 'fkart': 11918, 'immense': 11919, 'usagein': 11920, 'summerin': 11921, 'floormat': 11922, 'thankss': 11923, 'asam': 11924, 'zips': 11925, 'goodfitting': 11926, 'consumers': 11927, 'expectednot': 11928, 'materialyou': 11929, 'thanksstudyiq': 11930, 'nicel': 11931, 'daysdrive': 11932, 'nowwill': 11933, 'awesomedelivery': 11934, 'laptopand': 11935, 'carryif': 11936, 'javathen': 11937, 'filcart': 11938, 'pradect': 11939, 'laptopfully': 11940, 'itwould': 11941, 'thsnku': 11942, 'suggestions': 11943, 'sanitize': 11944, 'wellneed': 11945, 'cyclethanks': 11946, 'dealership': 11947, 'mead': 11948, 'teast': 11949, 'celebrate': 11950, 'featuresthank': 11951, 'goodthaku': 11952, 'filip': 11953, 'nicehappy': 11954, 'metabolism': 11955, 'digestive': 11956, 'pricesit': 11957, 'fifth': 11958, 'voltages': 11959, 'broght': 11960, 'exange': 11961, 'handsquick': 11962, 'deepsound': 11963, 'roombluetooth': 11964, 'worthand': 11965, 'hponly': 11966, 'eyesoothing': 11967, 'sobera': 11968, 'peripheral': 11969, 'renowned': 11970, 'hpin': 11971, 'precautionary': 11972, 'goodlet': 11973, 'itemsvery': 11974, 'otherso': 11975, 'beautythey': 11976, 'recoding': 11977, 'footballthanks': 11978, 'surfacegood': 11979, 'priceybut': 11980, 'sleekundoubtedly': 11981, 'batterfly': 11982, 'noisehigh': 11983, 'motormy': 11984, 'lovelyit': 11985, 'youvalue': 11986, 'jobcharges': 11987, 'timestakes': 11988, 'fastsuperfast': 11989, 'coustmer': 11990, 'itthanx': 11991, 'bermudas': 11992, 'priceperfectly': 11993, 'fitseasy': 11994, 'washabletying': 11995, 'qualitycolour': 11996, 'ausom': 11997, 'imagei': 11998, 'dateinstallation': 11999, 'fittingnice': 12000, 'alsono': 12001, 'issueoverall': 12002, 'qualityas': 12003, 'vll': 12004, 'peoplequality': 12005, 'daysworking': 12006, 'enthralling': 12007, 'installvery': 12008, 'heigh': 12009, 'charting': 12010, 'nices': 12011, 'setthank': 12012, 'oli': 12013, 'ranger': 12014, 'performancebuilt': 12015, 'biasedperformance': 12016, 'gitternote': 12017, 'greatscreen': 12018, 'gamingdont': 12019, 'hail': 12020, 'florescent': 12021, 'qualitybof': 12022, 'banner': 12023, 'pce': 12024, 'krishna': 12025, 'grainder': 12026, 'modecompeting': 12027, 'rereview': 12028, 'unbelievablejust': 12029, 'verrryyy': 12030, 'acne': 12031, 'osmotg': 12032, 'bigif': 12033, 'litersthe': 12034, 'hexacore': 12035, 'priceoh': 12036, 'slick': 12037, 'intch': 12038, 'moneytumba': 12039, 'chenagi': 12040, 'annok': 12041, 'agolla': 12042, 'nadiyutte': 12043, 'kannadiga': 12044, 'teach': 12045, 'technics': 12046, 'goodbattry': 12047, 'cooli': 12048, 'jhakaas': 12049, 'vibratre': 12050, 'beeter': 12051, 'availaible': 12052, 'dezire': 12053, 'transperent': 12054, 'secret': 12055, 'currency': 12056, 'wiselyand': 12057, 'shu': 12058, 'mai': 12059, 'apki': 12060, 'dekhti': 12061, 'ye': 12062, 'wiil': 12063, 'kurte': 12064, 'itv': 12065, 'ratemust': 12066, 'lowcost': 12067, 'badsomeone': 12068, 'rote': 12069, 'expectedlarge': 12070, 'whr': 12071, 'amazingfabulous': 12072, 'figured': 12073, 'collapsible': 12074, 'neutral': 12075, 'shapes': 12076, 'waoow': 12077, 'packingworth': 12078, 'mbsecbut': 12079, 'restarts': 12080, 'cleen': 12081, 'perfom': 12082, 'battarry': 12083, 'verryy': 12084, 'veeek': 12085, 'regards': 12086, 'mohammad': 12087, 'ghalib': 12088, 'packand': 12089, 'abs': 12090, 'chop': 12091, 'onion': 12092, 'installationportableconsdelicate': 12093, 'bench': 12094, 'conditioners': 12095, 'osmvry': 12096, 'hpyyy': 12097, 'equipmentwith': 12098, 'fangood': 12099, 'cleanerbuild': 12100, 'softoverall': 12101, 'everyworking': 12102, 'smelli': 12103, 'teste': 12104, 'featues': 12105, 'onlyno': 12106, 'exellencei': 12107, 'crisis': 12108, 'buyhonestly': 12109, 'guidence': 12110, 'turnout': 12111, 'thngyousomach': 12112, 'pixal': 12113, 'toolswith': 12114, 'propose': 12115, 'budgetlooking': 12116, 'ifyou': 12117, 'submitting': 12118, 'mont': 12119, 'dissapointthe': 12120, 'snacksthe': 12121, 'aswellflipkart': 12122, 'usualthe': 12123, 'curtious': 12124, 'fittingdont': 12125, 'singale': 12126, 'dupatta': 12127, 'strings': 12128, 'smash': 12129, 'appplied': 12130, 'realised': 12131, 'readso': 12132, 'arjun': 12133, 'motivating': 12134, 'supercoins': 12135, 'antioxidants': 12136, 'olives': 12137, 'aleo': 12138, 'disturbances': 12139, 'produ': 12140, 'catrige': 12141, 'fabuloussound': 12142, 'bucksbass': 12143, 'greatbattery': 12144, 'monstertrust': 12145, 'monthsbuild': 12146, 'betterpersonally': 12147, 'cablerange': 12148, 'lagall': 12149, 'shouldnt': 12150, 'headpho': 12151, 'exactgood': 12152, 'pridect': 12153, 'flikartbest': 12154, 'assistantpro': 12155, 'sizevoice': 12156, 'superbgood': 12157, 'timepass': 12158, 'nowinstallation': 12159, 'shopcy': 12160, 'diffrent': 12161, 'requestplz': 12162, 'buyersplz': 12163, 'anyproduct': 12164, 'toyour': 12165, 'homeplzz': 12166, 'daysim': 12167, 'willconvert': 12168, 'starbcoz': 12169, 'weightnd': 12170, 'moreawsmi': 12171, 'chargebetter': 12172, 'usefulwashsanitize': 12173, 'nostril': 12174, 'roll': 12175, 'instructed': 12176, 'containi': 12177, 'afforded': 12178, 'thanksgiving': 12179, 'sheeds': 12180, 'lines': 12181, 'worthbale': 12182, 'pwd': 12183, 'sdhdnon': 12184, 'wifihdwith': 12185, 'fome': 12186, 'aeration': 12187, 'speedordered': 12188, 'niceits': 12189, 'fillup': 12190, 'quantum': 12191, 'shortened': 12192, 'ricethe': 12193, 'useing': 12194, 'treats': 12195, 'replies': 12196, 'goodcan': 12197, 'thumpin': 12198, 'wothble': 12199, 'steve': 12200, 'chargr': 12201, 'wowperfect': 12202, 'extending': 12203, 'gyserworth': 12204, 'articleswhat': 12205, 'causealso': 12206, 'nowa': 12207, 'challenging': 12208, 'cabledish': 12209, 'clicks': 12210, 'frustrate': 12211, 'agents': 12212, 'thankfully': 12213, 'sustains': 12214, 'longinstallation': 12215, 'delux': 12216, 'comfortnessthis': 12217, 'choiceno': 12218, 'soundled': 12219, 'goodremote': 12220, 'sweetit': 12221, 'looksbig': 12222, 'minimun': 12223, 'conditionyou': 12224, 'ocours': 12225, 'adivce': 12226, 'revert': 12227, 'marketplace': 12228, 'pairyou': 12229, 'cromcast': 12230, 'noisybut': 12231, 'completedit': 12232, 'abdominal': 12233, 'inguinal': 12234, 'hernia': 12235, 'langot': 12236, 'sam': 12237, 'weightwhen': 12238, 'friendlyi': 12239, 'gzb': 12240, 'porchesthank': 12241, 'deliveryso': 12242, 'wooo': 12243, 'properlygood': 12244, 'chargeafter': 12245, 'memeber': 12246, 'parject': 12247, 'vedios': 12248, 'excitements': 12249, 'threater': 12250, 'hardif': 12251, 'seggregate': 12252, 'categories': 12253, 'goodso': 12254, 'buyfeels': 12255, 'choicegood': 12256, 'pduct': 12257, 'conditionthanks': 12258, 'memorybattery': 12259, 'enoughdesign': 12260, 'sleekyrecommend': 12261, 'panal': 12262, 'cusion': 12263, 'wooferif': 12264, 'hopefullysound': 12265, 'otherwize': 12266, 'mpegg': 12267, 'fta': 12268, 'budgetworking': 12269, 'coaleti': 12270, 'podartc': 12271, 'obdlater': 12272, 'ofer': 12273, 'xomi': 12274, 'packagelittle': 12275, 'apptransparent': 12276, 'osw': 12277, 'moneywe': 12278, 'osmjust': 12279, 'aqurate': 12280, 'buguat': 12281, 'gaps': 12282, 'simplu': 12283, 'basss': 12284, 'rangereally': 12285, 'philipsbuy': 12286, 'multitask': 12287, 'removesignificant': 12288, 'carpetcustomer': 12289, 'segmentgo': 12290, 'itsuperb': 12291, 'owasam': 12292, 'awwwssmmmeeand': 12293, 'fastover': 12294, 'segmentscreen': 12295, 'createsuperb': 12296, 'flipkartthis': 12297, 'mamber': 12298, 'overloaded': 12299, 'tripped': 12300, 'normalise': 12301, 'divise': 12302, 'chromecasts': 12303, 'isolating': 12304, 'gamingyes': 12305, 'iffectprice': 12306, 'havingnoise': 12307, 'dayspretty': 12308, 'recommendedfor': 12309, 'datebest': 12310, 'rangehope': 12311, 'upcom': 12312, 'sucked': 12313, 'speakerloved': 12314, 'brownies': 12315, 'perfectsuperbb': 12316, 'assowme': 12317, 'productsaction': 12318, 'buysurely': 12319, 'wrongtrust': 12320, 'timebook': 12321, 'neatnessnow': 12322, 'practise': 12323, 'deliveryand': 12324, 'masterpiecei': 12325, 'itthanku': 12326, 'functionspoor': 12327, 'hps': 12328, 'moneyoperating': 12329, 'awesomecpu': 12330, 'pricecornssound': 12331, 'qualityoutdated': 12332, 'designspeaker': 12333, 'placement': 12334, 'wobly': 12335, 'manula': 12336, 'currencies': 12337, 'spaciousprasad': 12338, 'machinebut': 12339, 'lash': 12340, 'designcons': 12341, 'mommyyy': 12342, 'deepan': 12343, 'rectifications': 12344, 'begginers': 12345, 'profum': 12346, 'stitchingit': 12347, 'easyly': 12348, 'understandgo': 12349, 'blive': 12350, 'subbu': 12351, 'tirupathi': 12352, 'toasting': 12353, 'badgut': 12354, 'dosa': 12355, 'kneader': 12356, 'brimrating': 12357, 'expectationreally': 12358, 'flipkartno': 12359, 'osomme': 12360, 'happeningi': 12361, 'tvthe': 12362, 'poow': 12363, 'pioneer': 12364, 'installneed': 12365, 'wallworthy': 12366, 'trainee': 12367, 'thooth': 12368, 'si': 12369, 'ledge': 12370, 'spoiling': 12371, 'plnote': 12372, 'watchi': 12373, 'flipkartlook': 12374, 'nicereally': 12375, 'dbuild': 12376, 'moping': 12377, 'quwalti': 12378, 'soggy': 12379, 'residueoverall': 12380, 'imaginelap': 12381, 'goodscreen': 12382, 'prudent': 12383, 'intermediate': 12384, 'assesaries': 12385, 'pricedecreasing': 12386, 'installmentit': 12387, 'likingit': 12388, 'letdown': 12389, 'weakoverall': 12390, 'aseemble': 12391, 'blass': 12392, 'ness': 12393, 'complementary': 12394, 'convectiongrill': 12395, 'switchable': 12396, 'vica': 12397, 'versa': 12398, 'usability': 12399, 'shelve': 12400, 'entering': 12401, 'echoing': 12402, 'sanitized': 12403, 'dayvalue': 12404, 'inconclusive': 12405, 'retake': 12406, 'marketnot': 12407, 'boomi': 12408, 'colori': 12409, 'traffic': 12410, 'workking': 12411, 'deflated': 12412, 'fineok': 12413, 'berry': 12414, 'suond': 12415, 'pakeging': 12416, 'cetrifugal': 12417, 'planing': 12418, 'unmountstype': 12419, 'filein': 12420, 'exfat': 12421, 'makeset': 12422, 'ntfs': 12423, 'usetnz': 12424, 'chif': 12425, 'economically': 12426, 'exlant': 12427, 'vishram': 12428, 'badsound': 12429, 'muny': 12430, 'velyu': 12431, 'smellfantastic': 12432, 'microwaveand': 12433, 'sutable': 12434, 'ossssssam': 12435, 'drenched': 12436, 'sweaty': 12437, 'happyfast': 12438, 'plethora': 12439, 'tweaking': 12440, 'reliabl': 12441, 'servant': 12442, 'sync': 12443, 'supergood': 12444, 'materialpackaging': 12445, 'excellentdelivery': 12446, 'chummy': 12447, 'goodcapture': 12448, 'displayit': 12449, 'chargernormal': 12450, 'superbi': 12451, 'plete': 12452, 'bbut': 12453, 'curtainsmost': 12454, 'worm': 12455, 'calf': 12456, 'feedbacks': 12457, 'backthigh': 12458, 'margin': 12459, 'yesits': 12460, 'asum': 12461, 'pulplow': 12462, 'noiseslow': 12463, 'friction': 12464, 'losseshighly': 12465, 'juiceas': 12466, 'processeasy': 12467, 'cleanassemblingdissembling': 12468, 'parvalama': 12469, 'irukku': 12470, 'konjo': 12471, 'irukkuramathiri': 12472, 'aguthu': 12473, 'designplate': 12474, 'qualitypacking': 12475, 'mobilescons': 12476, 'productstay': 12477, 'divices': 12478, 'camers': 12479, 'aswsome': 12480, 'learnerit': 12481, 'easiergo': 12482, 'assmeble': 12483, 'sturdyan': 12484, 'advices': 12485, 'tablewhite': 12486, 'sanitizeroverall': 12487, 'piyour': 12488, 'usesize': 12489, 'tubers': 12490, 'bczz': 12491, 'clue': 12492, 'bassbut': 12493, 'mids': 12494, 'highs': 12495, 'gunshots': 12496, 'blasts': 12497, 'etcsound': 12498, 'bassheads': 12499, 'unpair': 12500, 'midal': 12501, 'flipkartand': 12502, 'natureflipkart': 12503, 'freezes': 12504, 'sockscringy': 12505, 'awesomi': 12506, 'excellentproduct': 12507, 'conditioncondition': 12508, 'hevily': 12509, 'packetno': 12510, 'craks': 12511, 'scratchesquality': 12512, 'oplaware': 12513, 'microwaveable': 12514, 'recommendedoverall': 12515, 'conditionthank': 12516, 'whait': 12517, 'productthnx': 12518, 'keyboardmouse': 12519, 'correctlythe': 12520, 'sunmyca': 12521, 'tabletop': 12522, 'screwdriverone': 12523, 'disbalanced': 12524, 'rig': 12525, 'goodlooking': 12526, 'nine': 12527, 'chemicalsdoes': 12528, 'stickynourishes': 12529, 'wellliked': 12530, 'issueearlier': 12531, 'nowim': 12532, 'profile': 12533, 'oversaturated': 12534, 'hlg': 12535, 'finesound': 12536, 'explicit': 12537, 'irony': 12538, 'amazoni': 12539, 'rumblings': 12540, 'recent': 12541, 'procuring': 12542, 'sincerely': 12543, 'shield': 12544, 'subscribed': 12545, 'ausm': 12546, 'purchaseplayed': 12547, 'respectivelyoverall': 12548, 'bottel': 12549, 'unsweetened': 12550, 'premiums': 12551, 'pricebuild': 12552, 'shelfs': 12553, 'nicea': 12554, 'homethanks': 12555, 'urbain': 12556, 'heath': 12557, 'ldlhdl': 12558, 'bmi': 12559, 'calories': 12560, 'calorie': 12561, 'dieticial': 12562, 'soundnow': 12563, 'bassincluding': 12564, 'refunding': 12565, 'immunity': 12566, 'goodandroid': 12567, 'moneyupdated': 12568, 'pixels': 12569, 'ambient': 12570, 'distraction': 12571, 'distancegoodgoogle': 12572, 'wellvisual': 12573, 'isto': 12574, 'adventurous': 12575, 'waoo': 12576, 'conditionexcellent': 12577, 'heavan': 12578, 'osssmmm': 12579, 'comprehensive': 12580, 'cargos': 12581, 'guddd': 12582, 'workinghave': 12583, 'parodect': 12584, 'railways': 12585, 'machineits': 12586, 'whirlefull': 12587, 'lgand': 12588, 'onlinenow': 12589, 'machinenow': 12590, 'gathers': 12591, 'thabks': 12592, 'chats': 12593, 'compromises': 12594, 'itsalman': 12595, 'smoothies': 12596, 'oiling': 12597, 'sameloving': 12598, 'styling': 12599, 'nonsti': 12600, 'apdventage': 12601, 'cooprative': 12602, 'lowthe': 12603, 'collate': 12604, 'issuetip': 12605, 'moblie': 12606, 'moneyreally': 12607, 'recd': 12608, 'compacf': 12609, 'sizethe': 12610, 'turnd': 12611, 'amazingeasy': 12612, 'controlseasy': 12613, 'fantasticproductas': 12614, 'strif': 12615, 'downneed': 12616, 'grib': 12617, 'ahuttle': 12618, 'lart': 12619, 'batbecause': 12620, 'latebut': 12621, 'proudectso': 12622, 'beautifulthankyou': 12623, 'wellshows': 12624, 'lavel': 12625, 'backsound': 12626, 'independence': 12627, 'trialbut': 12628, 'thishave': 12629, 'backupthank': 12630, 'minimumonly': 12631, 'hdds': 12632, 'encyrption': 12633, 'protectionit': 12634, 'porttransfer': 12635, 'bawal': 12636, 'cellular': 12637, 'nano': 12638, 'crysis': 12639, 'tshirtgood': 12640, 'veryyr': 12641, 'goot': 12642, 'colourshit': 12643, 'changebrightness': 12644, 'kitchenwares': 12645, 'exesorise': 12646, 'profm': 12647, 'laptopperformence': 12648, 'lowerbut': 12649, 'laic': 12650, 'designoverally': 12651, 'quallity': 12652, 'thiss': 12653, 'colar': 12654, 'beltand': 12655, 'machinichi': 12656, 'generating': 12657, 'folding': 12658, 'cylcle': 12659, 'snapy': 12660, 'scenario': 12661, 'speakersbass': 12662, 'courteous': 12663, 'choiceloved': 12664, 'lub': 12665, 'besttt': 12666, 'holiday': 12667, 'fragrancemust': 12668, 'nicebass': 12669, 'impressing': 12670, 'trousergo': 12671, 'eligant': 12672, 'giftbeautifulawe': 12673, 'smallquality': 12674, 'storng': 12675, 'bby': 12676, 'juicereasy': 12677, 'philipsbe': 12678, 'productneed': 12679, 'milkonly': 12680, 'speedo': 12681, 'productq': 12682, 'andbetter': 12683, 'alreadyit': 12684, 'elephant': 12685, 'crak': 12686, 'fittedfabric': 12687, 'studentsim': 12688, 'offeri': 12689, 'refined': 12690, 'usevery': 12691, 'smallso': 12692, 'goodfinish': 12693, 'ustq': 12694, 'looksgood': 12695, 'speedwell': 12696, 'boughtpacking': 12697, 'district': 12698, 'wks': 12699, 'stoppingmaybe': 12700, 'compton': 12701, 'greaves': 12702, 'acbut': 12703, 'trolly': 12704, 'provideddifficult': 12705, 'movingany': 12706, 'performace': 12707, 'usesettings': 12708, 'moneymoderate': 12709, 'havecleanibg': 12710, 'offroad': 12711, 'brakeing': 12712, 'wht': 12713, 'watchgo': 12714, 'itso': 12715, 'examples': 12716, 'competetor': 12717, 'pleasent': 12718, 'orver': 12719, 'cheapits': 12720, 'alredy': 12721, 'coloring': 12722, 'duber': 12723, 'clubbed': 12724, 'blaupunkt': 12725, 'approxly': 12726, 'jumped': 12727, 'bandwagon': 12728, 'smartness': 12729, 'thanksfillip': 12730, 'monthwill': 12731, 'cyclingnot': 12732, 'hiking': 12733, 'farriding': 12734, 'mostthe': 12735, 'breakseven': 12736, 'breaksas': 12737, 'saidit': 12738, 'effectivei': 12739, 'junctions': 12740, 'fasti': 12741, 'looklooks': 12742, 'conversations': 12743, 'jnow': 12744, 'lip': 12745, 'betryflipkart': 12746, 'dellivery': 12747, 'posivitive': 12748, 'productsin': 12749, 'overpowered': 12750, 'pokles': 12751, 'weightyou': 12752, 'protein': 12753, 'setbut': 12754, 'thinkq': 12755, 'deliveredmust': 12756, 'pricealso': 12757, 'munks': 12758, 'saviour': 12759, 'permenantly': 12760, 'glitching': 12761, 'liva': 12762, 'carsound': 12763, 'prefilters': 12764, 'dresses': 12765, 'matterial': 12766, 'onoffno': 12767, 'indicatesnot': 12768, 'problemsbut': 12769, 'plugfor': 12770, 'storybut': 12771, 'awesomeloved': 12772, 'jobthe': 12773, 'moktar': 12774, 'capdont': 12775, 'fleeek': 12776, 'wintersthank': 12777, 'daysone': 12778, 'occurshoneycomb': 12779, 'pores': 12780, 'calculate': 12781, 'hal': 12782, 'focuses': 12783, 'packedkent': 12784, 'beta': 12785, 'exceptionalstarting': 12786, 'flipkartperformance': 12787, 'highend': 12788, 'vectornator': 12789, 'garageband': 12790, 'urge': 12791, 'seasoned': 12792, 'doable': 12793, 'upd': 12794, 'symbol': 12795, 'productrice': 12796, 'sobai': 12797, 'korchi': 12798, 'thikness': 12799, 'bassquality': 12800, 'moneyopen': 12801, 'demopictures': 12802, 'hrsi': 12803, 'fells': 12804, 'chevrolet': 12805, 'alsogo': 12806, 'thoughti': 12807, 'nicefablous': 12808, 'productexcellentmy': 12809, 'happpy': 12810, 'schools': 12811, 'ofter': 12812, 'logging': 12813, 'donimalai': 12814, 'sutebal': 12815, 'nowso': 12816, 'fa': 12817, 'prepaid': 12818, 'discountprosi': 12819, 'pricenice': 12820, 'combinationgood': 12821, 'asusissueseverthing': 12822, 'okeybut': 12823, 'onealso': 12824, 'browsingbattery': 12825, 'enthusiasts': 12826, 'assuming': 12827, 'canditoin': 12828, 'issuespvc': 12829, 'divine': 12830, 'learned': 12831, 'unattractive': 12832, 'ar': 12833, 'qualitycan': 12834, 'scientifically': 12835, 'shutdown': 12836, 'pur': 12837, 'hearty': 12838, 'gowda': 12839, 'mamiasgiving': 12840, 'manualcleared': 12841, 'whichever': 12842, 'static': 12843, 'affairs': 12844, 'blunder': 12845, 'pertains': 12846, 'confined': 12847, 'complited': 12848, 'fantastically': 12849, 'daughterdelivery': 12850, 'comfirtable': 12851, 'childadults': 12852, 'ranging': 12853, 'boysgirls': 12854, 'breaksbut': 12855, 'commute': 12856, 'whybut': 12857, 'sipil': 12858, 'qualityheats': 12859, 'cookies': 12860, 'chkn': 12861, 'elaboratewhich': 12862, 'juicesworth': 12863, 'torrino': 12864, 'soiled': 12865, 'chaliba': 12866, 'compress': 12867, 'earning': 12868, 'classthankyou': 12869, 'priceexcellenti': 12870, 'packagingworth': 12871, 'profamace': 12872, 'exeilent': 12873, 'tokiyo': 12874, 'looksmi': 12875, 'rimote': 12876, 'opportunity': 12877, 'nicemust': 12878, 'melamine': 12879, 'bone': 12880, 'cenematic': 12881, 'nics': 12882, 'manpreet': 12883, 'interactive': 12884, 'rushing': 12885, 'explaining': 12886, 'damagewe': 12887, 'wellgo': 12888, 'amateurs': 12889, 'photographers': 12890, 'budegt': 12891, 'atmost': 12892, 'bycycal': 12893, 'recomment': 12894, 'growths': 12895, 'wellthanks': 12896, 'buyingdo': 12897, 'lightthe': 12898, 'produceslike': 12899, 'onperfect': 12900, 'validated': 12901, 'hears': 12902, 'aheadworking': 12903, 'experiments': 12904, 'perspective': 12905, 'relate': 12906, 'productpowerfull': 12907, 'socking': 12908, 'latesame': 12909, 'attractivefeatures': 12910, 'laisa': 12911, 'soundbarsound': 12912, 'microoven': 12913, 'commercial': 12914, 'recommendedthanks': 12915, 'appx': 12916, 'enoughoverall': 12917, 'submissions': 12918, 'pedestal': 12919, 'beautifu': 12920, 'thoughtif': 12921, 'amazes': 12922, 'vikram': 12923, 'everythingeverything': 12924, 'cristal': 12925, 'purchasetrue': 12926, 'dirts': 12927, 'grills': 12928, 'shake': 12929, 'lloyd': 12930, 'borderless': 12931, 'mojja': 12932, 'procuct': 12933, 'imageoveral': 12934, 'purchasefor': 12935, 'producthere': 12936, 'wed': 12937, 'sounding': 12938, 'pillo': 12939, 'kettlewater': 12940, 'sisters': 12941, 'processorgud': 12942, 'chummeshwari': 12943, 'potion': 12944, 'aavente': 12945, 'exdrodunary': 12946, 'tvit': 12947, 'installationpicture': 12948, 'greatonly': 12949, 'compliant': 12950, 'sherwani': 12951, 'ug': 12952, 'poorif': 12953, 'negetiveits': 12954, 'nici': 12955, 'seedsvery': 12956, 'goging': 12957, 'brass': 12958, 'fain': 12959, 'hoursthen': 12960, 'speedcustomer': 12961, 'responcedont': 12962, 'buyu': 12963, 'interview': 12964, 'examss': 12965, 'flipkartquality': 12966, 'awesomefunctions': 12967, 'nobs': 12968, 'machinehavent': 12969, 'afternoonpacking': 12970, 'dentsill': 12971, 'dayspanasonic': 12972, 'updatedeverything': 12973, 'thothe': 12974, 'errorif': 12975, 'niceworth': 12976, 'nvdia': 12977, 'map': 12978, 'itmy': 12979, 'ratethanks': 12980, 'havethe': 12981, 'wdize': 12982, 'handwriting': 12983, 'productway': 12984, 'intels': 12985, 'versionand': 12986, 'killeronly': 12987, 'adapters': 12988, 'thunderboltsoverall': 12989, 'horseback': 12990, 'thnkq': 12991, 'reseted': 12992, 'nicebit': 12993, 'stylishlooks': 12994, 'niceeverything': 12995, 'lookingbreaking': 12996, 'shouod': 12997, 'lotspecially': 12998, 'blow': 12999, 'damaging': 13000, 'cleanhigh': 13001, 'pulps': 13002, 'coocker': 13003, 'bestkart': 13004, 'slippery': 13005, 'supercolour': 13006, 'producy': 13007, 'lightnot': 13008, 'protacte': 13009, 'excilent': 13010, 'toooooooo': 13011, 'trimendus': 13012, 'guysuseful': 13013, 'situations': 13014, 'grate': 13015, 'upvery': 13016, 'mommy': 13017, 'thisthis': 13018, 'nowusing': 13019, 'grinderim': 13020, 'adder': 13021, 'awesomereason': 13022, 'ricemasala': 13023, 'bitroot': 13024, 'highin': 13025, 'specificationsi': 13026, 'quqlity': 13027, 'hitter': 13028, 'handbags': 13029, 'angel': 13030, 'unconfatable': 13031, 'shue': 13032, 'devicesmust': 13033, 'collage': 13034, 'usedi': 13035, 'bluetoothtigarfarmaanansari': 13036, 'singerreceived': 13037, 'categoryit': 13038, 'loudest': 13039, 'competitorsand': 13040, 'packaginghard': 13041, 'tbplug': 13042, 'chuna': 13043, 'finishinghandle': 13044, 'enoughu': 13045, 'paytm': 13046, 'cardbox': 13047, 'priceive': 13048, 'yearabsolutely': 13049, 'conducts': 13050, 'lowhigh': 13051, 'summers': 13052, 'beeps': 13053, 'multicolour': 13054, 'exter': 13055, 'rounds': 13056, 'stillness': 13057, 'cottan': 13058, 'theatersuper': 13059, 'strapchain': 13060, 'plating': 13061, 'sreen': 13062, 'prizeat': 13063, 'thinkno': 13064, 'hacker': 13065, 'lobby': 13066, 'inchminus': 13067, 'productapple': 13068, 'doubtgood': 13069, 'properlyalso': 13070, 'pricesdemo': 13071, 'issueskindly': 13072, 'solenoid': 13073, 'safeguard': 13074, 'coolar': 13075, 'rethink': 13076, 'lowevery': 13077, 'tvthank': 13078, 'powrbank': 13079, 'powerbackup': 13080, 'teshart': 13081, 'apks': 13082, 'aptoid': 13083, 'movieshd': 13084, 'fingerprint': 13085, 'juicy': 13086, 'shuttle': 13087, 'delvery': 13088, 'pricethe': 13089, 'easyit': 13090, 'bycyclethe': 13091, 'wedding': 13092, 'bazar': 13093, 'definable': 13094, 'nace': 13095, 'suj': 13096, 'pdkim': 13097, 'timepros': 13098, 'providedcons': 13099, 'tvbut': 13100, 'lowlevel': 13101, 'buffers': 13102, 'speedoverall': 13103, 'aspires': 13104, 'gained': 13105, 'achievement': 13106, 'meone': 13107, 'workouts': 13108, 'owssome': 13109, 'basssss': 13110, 'offlinewelcom': 13111, 'mnthusing': 13112, 'perfectawesome': 13113, 'productexcept': 13114, 'ifblove': 13115, 'picnics': 13116, 'washclean': 13117, 'kitchenlooks': 13118, 'materialdont': 13119, 'muze': 13120, 'tranfer': 13121, 'karaneme': 13122, 'hua': 13123, 'fotting': 13124, 'wark': 13125, 'strat': 13126, 'discountquality': 13127, 'excellentdelivered': 13128, 'strict': 13129, 'areayou': 13130, 'thislove': 13131, 'awesomeother': 13132, 'juicerwithout': 13133, 'zorp': 13134, 'ghee': 13135, 'thrilled': 13136, 'hove': 13137, 'objectskids': 13138, 'court': 13139, 'moneyfully': 13140, 'pifcart': 13141, 'thnakyou': 13142, 'flipkartsize': 13143, 'productsquality': 13144, 'producto': 13145, 'cyclesconsultation': 13146, 'flo': 13147, 'modelsame': 13148, 'flipkartbig': 13149, 'camerain': 13150, 'dslrim': 13151, 'donenice': 13152, 'degine': 13153, 'hudget': 13154, 'thinkingawesome': 13155, 'calcium': 13156, 'inverteri': 13157, 'farthest': 13158, 'thrust': 13159, 'righteous': 13160, 'grad': 13161, 'ratedwith': 13162, 'grilltoday': 13163, 'wonderfulli': 13164, 'dns': 13165, 'usehandling': 13166, 'smoothstiching': 13167, 'bassbuild': 13168, 'fount': 13169, 'verg': 13170, 'productrecommended': 13171, 'anywhereit': 13172, 'brushthis': 13173, 'usestill': 13174, 'imaze': 13175, 'buttonthats': 13176, 'flikpart': 13177, 'orignial': 13178, 'consists': 13179, 'mettalic': 13180, 'seperatin': 13181, 'morein': 13182, 'amazingafter': 13183, 'disputes': 13184, 'usingapprox': 13185, 'hoursday': 13186, 'delever': 13187, 'polishing': 13188, 'damagedmaterial': 13189, 'signs': 13190, 'wristif': 13191, 'suffers': 13192, 'recommendedgood': 13193, 'glorious': 13194, 'freshsafe': 13195, 'rsonly': 13196, 'bomber': 13197, 'beautifulmind': 13198, 'cyclevalue': 13199, 'fantasty': 13200, 'heavelyi': 13201, 'superbgo': 13202, 'nonetheless': 13203, 'sturdysuperior': 13204, 'qualitycame': 13205, 'tvso': 13206, 'uptheres': 13207, 'bellas': 13208, 'grownup': 13209, 'straddle': 13210, 'easeso': 13211, 'provid': 13212, 'hawy': 13213, 'rescue': 13214, 'itthnks': 13215, 'purchasekent': 13216, 'calarity': 13217, 'credited': 13218, 'domain': 13219, 'goahead': 13220, 'nicefatafatigood': 13221, 'pumparch': 13222, 'expand': 13223, 'guest': 13224, 'parental': 13225, 'brotherhe': 13226, 'moneyfull': 13227, 'exaptation': 13228, 'wellgood': 13229, 'wb': 13230, 'joband': 13231, 'estimate': 13232, 'monthy': 13233, 'ironit': 13234, 'imagequality': 13235, 'reviewfirst': 13236, 'macos': 13237, 'compactness': 13238, 'narrowed': 13239, 'marketall': 13240, 'meta': 13241, 'rodl': 13242, 'anamika': 13243, 'dait': 13244, 'hummble': 13245, 'favorable': 13246, 'definitelyoverall': 13247, 'respecfully': 13248, 'bicycleinstallation': 13249, 'improvementthanks': 13250, 'itwith': 13251, 'moneyon': 13252, 'marketbajaj': 13253, 'lovin': 13254, 'usageone': 13255, 'kadahi': 13256, 'dustbag': 13257, 'toppers': 13258, 'examsbest': 13259, 'designand': 13260, 'rbg': 13261, 'wealth': 13262, 'passion': 13263, 'photographyi': 13264, 'beginnergo': 13265, 'ratebetter': 13266, 'upscgo': 13267, 'awesomedisplay': 13268, 'rubbishsound': 13269, 'marriage': 13270, 'anniversary': 13271, 'photoshoot': 13272, 'soundsuitable': 13273, 'qualityis': 13274, 'tham': 13275, 'merchandise': 13276, 'repeating': 13277, 'cromptonpros': 13278, 'stringent': 13279, 'alkalization': 13280, 'sustainable': 13281, 'headsupport': 13282, 'pricy': 13283, 'alsoin': 13284, 'names': 13285, 'poojaher': 13286, 'reasoningit': 13287, 'difficultyeasymoderatedifficultwhich': 13288, 'examinationit': 13289, 'touchwood': 13290, 'rendering': 13291, 'humful': 13292, 'tku': 13293, 'excuses': 13294, 'thoughso': 13295, 'prodecut': 13296, 'basement': 13297, 'highall': 13298, 'loverssimple': 13299, 'watchvery': 13300, 'evrege': 13301, 'purifierthe': 13302, 'sleevesthanks': 13303, 'thoughtmoderate': 13304, 'gooddisplay': 13305, 'tcs': 13306, 'farsince': 13307, 'bachelorif': 13308, 'pimevideo': 13309, 'netflixsize': 13310, 'flipkurt': 13311, 'productamazing': 13312, 'featuresawesome': 13313, 'appliancesjust': 13314, 'guarantees': 13315, 'histories': 13316, 'myvbest': 13317, 'prosperity': 13318, 'onlyjuice': 13319, 'blasting': 13320, 'wowvery': 13321, 'camouflage': 13322, 'balack': 13323, 'easilygood': 13324, 'caster': 13325, 'idlis': 13326, 'behatrin': 13327, 'trendyi': 13328, 'givesit': 13329, 'utomatically': 13330, 'surfacethe': 13331, 'stablewhen': 13332, 'wearmust': 13333, 'gifti': 13334, 'poped': 13335, 'brandtheir': 13336, 'joke': 13337, 'wooow': 13338, 'respects': 13339, 'gmail': 13340, 'typed': 13341, 'tox': 13342, 'matirial': 13343, 'seasonprotects': 13344, 'familyfulfils': 13345, 'males': 13346, 'orhers': 13347, 'yayyyy': 13348, 'nonlovers': 13349, 'qualityaluminum': 13350, 'qualityswitches': 13351, 'flipcartthank': 13352, 'chep': 13353, 'styles': 13354, 'convinent': 13355, 'neccessary': 13356, 'robotic': 13357, 'seteverything': 13358, 'okayfast': 13359, 'sameday': 13360, 'tvgood': 13361, 'suberbreally': 13362, 'haithank': 13363, 'ufkt': 13364, 'siteflipkart': 13365, 'shelfwhich': 13366, 'cna': 13367, 'blowingpin': 13368, 'cemented': 13369, 'groundthanks': 13370, 'thanksagainflipkart': 13371, 'ant': 13372, 'segmentgot': 13373, 'dlss': 13374, 'medhigh': 13375, 'buttery': 13376, 'insaled': 13377, 'calrity': 13378, 'oweasome': 13379, 'overalo': 13380, 'bekup': 13381, 'multicolor': 13382, 'hdmiavi': 13383, 'corrects': 13384, 'expectedyou': 13385, 'lajawaab': 13386, 'asoundbarspeaker': 13387, 'multiconnectivity': 13388, 'usbmsdauxit': 13389, 'mediavolumevery': 13390, 'speekerbattery': 13391, 'fantasticmivi': 13392, 'microd': 13393, 'slotit': 13394, 'tvbest': 13395, 'kar': 13396, 'sakte': 13397, 'achievable': 13398, 'lookin': 13399, 'pricegood': 13400, 'vivid': 13401, 'usegot': 13402, 'sewings': 13403, 'carryi': 13404, 'daysthanku': 13405, 'reviewvery': 13406, 'producthighly': 13407, 'caramazing': 13408, 'worki': 13409, 'denver': 13410, 'csatno': 13411, 'coachingsave': 13412, 'suprits': 13413, 'tidy': 13414, 'ost': 13415, 'sona': 13416, 'awesomedelivered': 13417, 'tymdelivery': 13418, 'installim': 13419, 'spiral': 13420, 'injoy': 13421, 'coinsnavy': 13422, 'geniuine': 13423, 'allignment': 13424, 'horrific': 13425, 'pare': 13426, 'goooood': 13427, 'monthits': 13428, 'instolation': 13429, 'ducting': 13430, 'premiumfor': 13431, 'watchso': 13432, 'spearkers': 13433, 'deliveredand': 13434, 'installationgood': 13435, 'behavier': 13436, 'thompson': 13437, 'plasticeasy': 13438, 'cleanhappy': 13439, 'excitedso': 13440, 'noisywell': 13441, 'persontq': 13442, 'monthsall': 13443, 'awesoom': 13444, 'packagingbest': 13445, 'parfact': 13446, 'appear': 13447, 'ik': 13448, 'brandlg': 13449, 'itpicture': 13450, 'suckssound': 13451, 'soundbaronly': 13452, 'connectivitywhen': 13453, 'synchronization': 13454, 'wellwhich': 13455, 'machinebest': 13456, 'editinggamers': 13457, 'fees': 13458, 'prefare': 13459, 'cn': 13460, 'stencils': 13461, 'hankie': 13462, 'nottoo': 13463, 'noisei': 13464, 'butsmall': 13465, 'buckle': 13466, 'nostalgic': 13467, 'itexcellent': 13468, 'sideload': 13469, 'arised': 13470, 'moneymy': 13471, 'reflexes': 13472, 'joine': 13473, 'oneproduct': 13474, 'productsound': 13475, 'productdifficulty': 13476, 'fineafter': 13477, 'sidebut': 13478, 'donecoustomer': 13479, 'neevalle': 13480, 'germation': 13481, 'embroided': 13482, 'thisvalue': 13483, 'mifully': 13484, 'productpicture': 13485, 'supportedvolume': 13486, 'roomsoundbar': 13487, 'benefiti': 13488, 'highsound': 13489, 'flipcraft': 13490, 'hazzel': 13491, 'buckup': 13492, 'againhighly': 13493, 'timeand': 13494, 'lood': 13495, 'stove': 13496, 'productpaisa': 13497, 'thomsons': 13498, 'nicecan': 13499, 'hardtoreach': 13500, 'deposits': 13501, 'undersides': 13502, 'shortcomings': 13503, 'amazingmy': 13504, 'promice': 13505, 'comesnow': 13506, 'lotproduct': 13507, 'youshopsy': 13508, 'classgood': 13509, 'speedsuper': 13510, 'rangemotion': 13511, 'hamd': 13512, 'blackjust': 13513, 'prodouct': 13514, 'recommendedmy': 13515, 'watchers': 13516, 'enoughsince': 13517, 'dissaperaing': 13518, 'softthank': 13519, 'crawlers': 13520, 'quuality': 13521, 'interestingcan': 13522, 'partitioned': 13523, 'mirroringbut': 13524, 'formatit': 13525, 'sms': 13526, 'experiencethe': 13527, 'satisfactionthanks': 13528, 'echo': 13529, 'compressor': 13530, 'happinessto': 13531, 'sunand': 13532, 'cardiac': 13533, 'tummy': 13534, 'lightcompactuser': 13535, 'importantlyefficient': 13536, 'grindinda': 13537, 'budgetjust': 13538, 'papad': 13539, 'fry': 13540, 'maggi': 13541, 'superbworth': 13542, 'superbm': 13543, 'thnkyu': 13544, 'rangethe': 13545, 'fastthe': 13546, 'allowing': 13547, 'potential': 13548, 'effectivelytemp': 13549, 'xtraa': 13550, 'hadloved': 13551, 'recommendedits': 13552, 'wellnice': 13553, 'producttime': 13554, 'opinionno': 13555, 'resonable': 13556, 'productd': 13557, 'excellentvalue': 13558, 'reasnable': 13559, 'fliipcart': 13560, 'prepration': 13561, 'sanjeev': 13562, 'qualityclarity': 13563, 'samsungit': 13564, 'complimented': 13565, 'shadescooling': 13566, 'fastheight': 13567, 'experienceflipkart': 13568, 'damagesprosdesigncolordigital': 13569, 'pannelsamsung': 13570, 'supportconsno': 13571, 'drawerno': 13572, 'mestrionon': 13573, 'convertibleverdict': 13574, 'dilevry': 13575, 'moneysafe': 13576, 'asset': 13577, 'qwaliety': 13578, 'usageprons': 13579, 'exposable': 13580, 'dres': 13581, 'noisemuch': 13582, 'vibrationsits': 13583, 'housegharrrrrrrrr': 13584, 'vibe': 13585, 'buyingi': 13586, 'nicelywater': 13587, 'excellentoverall': 13588, 'instantaneously': 13589, 'excellentuseful': 13590, 'rangebass': 13591, 'chargeno': 13592, 'okyou': 13593, 'fliokart': 13594, 'ev': 13595, 'satisified': 13596, 'bajajand': 13597, 'absorption': 13598, 'valuvise': 13599, 'rangewi': 13600, 'distancevery': 13601, 'segmentnote': 13602, 'crooked': 13603, 'tilting': 13604, 'handwould': 13605, 'saleit': 13606, 'interaction': 13607, 'pakiging': 13608, 'jarur': 13609, 'kharide': 13610, 'pordcd': 13611, 'markstill': 13612, 'optionim': 13613, 'toomuch': 13614, 'spprrand': 13615, 'usefulgood': 13616, 'flipnite': 13617, 'obediently': 13618, 'thatfor': 13619, 'starsthe': 13620, 'surprized': 13621, 'putted': 13622, 'timeamazing': 13623, 'stair': 13624, 'nott': 13625, 'installationbut': 13626, 'alwys': 13627, 'signalling': 13628, 'itttt': 13629, 'thabkyou': 13630, 'yearvery': 13631, 'xlnt': 13632, 'nicei': 13633, 'sunder': 13634, 'oroduct': 13635, 'expectedhats': 13636, 'offencenice': 13637, 'ow': 13638, 'timethe': 13639, 'friendlycan': 13640, 'awesomelow': 13641, 'disponted': 13642, 'compitabl': 13643, 'expansive': 13644, 'bee': 13645, 'fue': 13646, 'nicelets': 13647, 'monthsperformance': 13648, 'packinghappy': 13649, 'exlentnice': 13650, 'sund': 13651, 'trusteble': 13652, 'looklight': 13653, 'document': 13654, 'greate': 13655, 'graceful': 13656, 'issuperb': 13657, 'datedbrightness': 13658, 'nits': 13659, 'ghaint': 13660, 'pordek': 13661, 'pointing': 13662, 'jammed': 13663, 'kotak': 13664, 'xll': 13665, 'raquet': 13666, 'nicebuy': 13667, 'lovelybattery': 13668, 'constructing': 13669, 'walt': 13670, 'fornite': 13671, 'ce': 13672, 'switchand': 13673, 'lbut': 13674, 'qualitypersonal': 13675, 'wifinice': 13676, 'designbest': 13677, 'googlebest': 13678, 'comfortablegreat': 13679, 'finegetting': 13680, 'storey': 13681, 'attire': 13682, 'frigh': 13683, 'ambrane': 13684, 'cableworking': 13685, 'displayi': 13686, 'verified': 13687, 'onlineoriginal': 13688, 'packinglooking': 13689, 'productthankqqq': 13690, 'normallasts': 13691, 'minimumworth': 13692, 'appriciable': 13693, 'cancels': 13694, 'tossing': 13695, 'valleyball': 13696, 'modernization': 13697, 'offff': 13698, 'itss': 13699, 'awesomeeeee': 13700, 'kidsawesome': 13701, 'modarate': 13702, 'learners': 13703, 'proinstead': 13704, 'decreasethe': 13705, 'changedsoi': 13706, 'itemlets': 13707, 'seewhat': 13708, 'givenow': 13709, 'ipadthank': 13710, 'productlook': 13711, 'sayi': 13712, 'speechlessbuild': 13713, 'qualitywood': 13714, 'qualityhook': 13715, 'beleive': 13716, 'fluff': 13717, 'transitioning': 13718, 'firsttime': 13719, 'kush': 13720, 'obviouslyeasy': 13721, 'wondered': 13722, 'everyoneand': 13723, 'itttttttttttt': 13724, 'pricejust': 13725, 'blondly': 13726, 'oasm': 13727, 'fabricgo': 13728, 'nicelydigital': 13729, 'drawings': 13730, 'risti': 13731, 'osmthank': 13732, 'productsgood': 13733, 'fittingvery': 13734, 'describedbut': 13735, 'kayalty': 13736, 'listenbass': 13737, 'smoothi': 13738, 'asphalt': 13739, 'segmentvery': 13740, 'noisecool': 13741, 'qualilty': 13742, 'awesomeusing': 13743, 'yearcovering': 13744, 'gentleman': 13745, 'flirtcard': 13746, 'comfrtbl': 13747, 'ment': 13748, 'het': 13749, 'watar': 13750, 'pathaticnever': 13751, 'vdo': 13752, 'conferencing': 13753, 'loveable': 13754, 'wordslove': 13755, 'mopits': 13756, 'isyes': 13757, 'connectionits': 13758, 'budgetthanks': 13759, 'ted': 13760, 'todayquality': 13761, 'stalk': 13762, 'grows': 13763, 'machinethis': 13764, 'perfectvery': 13765, 'negligibleover': 13766, 'fillpcard': 13767, 'programconsumes': 13768, 'okaynot': 13769, 'flue': 13770, 'cleanliness': 13771, 'cleansing': 13772, 'smothies': 13773, 'dirtyi': 13774, 'differencewastage': 13775, 'itsatisfied': 13776, 'corseca': 13777, 'performancegot': 13778, 'flipkartalways': 13779, 'leaning': 13780, 'itpeppy': 13781, 'exposed': 13782, 'startingjust': 13783, 'producd': 13784, 'bestgood': 13785, 'materialfulfill': 13786, 'purposevery': 13787, 'priceonly': 13788, 'moneythere': 13789, 'convenienced': 13790, 'boxs': 13791, 'tite': 13792, 'lowers': 13793, 'longterm': 13794, 'fabsalescorpupdate': 13795, 'inhaler': 13796, 'metro': 13797, 'enajoy': 13798, 'loolking': 13799, 'thatsuperb': 13800, 'productlight': 13801, 'prodeck': 13802, 'germinatedfelt': 13803, 'paddling': 13804, 'topside': 13805, 'grooves': 13806, 'performancebattery': 13807, 'workbuild': 13808, 'undoubtedlyconswebcam': 13809, 'grainy': 13810, 'expectedcolor': 13811, 'rose': 13812, 'tint': 13813, 'pinkish': 13814, 'goldgold': 13815, 'pinkishgoldps': 13816, 'upg': 13817, 'residence': 13818, 'gangtok': 13819, 'inspire': 13820, 'mora': 13821, 'nad': 13822, 'classyloved': 13823, 'soworthable': 13824, 'mediacamera': 13825, 'noiseeverything': 13826, 'metriyal': 13827, 'homeoiday': 13828, 'requsite': 13829, 'reviewit': 13830, 'hiccups': 13831, 'buygood': 13832, 'performers': 13833, 'washsalt': 13834, 'dispensing': 13835, 'tow': 13836, 'qualityfitting': 13837, 'satisfiedbest': 13838, 'yaarsound': 13839, 'rdfi': 13840, 'wanthighly': 13841, 'youngerits': 13842, 'eager': 13843, 'secmamte': 13844, 'helathy': 13845, 'sehat': 13846, 'bodybuild': 13847, 'bodyand': 13848, 'developmentamazing': 13849, 'beutifull': 13850, 'numpad': 13851, 'littile': 13852, 'dadaand': 13853, 'crawl': 13854, 'inthe': 13855, 'routerwifi': 13856, 'flipkartni': 13857, 'tbkq': 13858, 'sorts': 13859, 'nonlaminated': 13860, 'fineperformance': 13861, 'forim': 13862, 'biggerother': 13863, 'blends': 13864, 'monthno': 13865, 'issueit': 13866, 'delived': 13867, 'headsound': 13868, 'goodthats': 13869, 'productexactly': 13870, 'wantedsmall': 13871, 'insizelight': 13872, 'happ': 13873, 'otheri': 13874, 'fridg': 13875, 'persion': 13876, 'nois': 13877, 'gooddeodrizer': 13878, 'deepfridger': 13879, 'performancethank': 13880, 'fareed': 13881, 'beginnersperfect': 13882, 'flippant': 13883, 'productiitpaisa': 13884, 'relativesgood': 13885, 'todeliver': 13886, 'allign': 13887, 'properlyso': 13888, 'paidhero': 13889, 'herothanks': 13890, 'nicr': 13891, 'suuuuuuprb': 13892, 'deivery': 13893, 'deliveryed': 13894, 'sooooooooooomuch': 13895, 'decorations': 13896, 'experienceinitially': 13897, 'brande': 13898, 'comebut': 13899, 'smoothlywe': 13900, 'vyd': 13901, 'extraditedary': 13902, 'bagit': 13903, 'prodkt': 13904, 'experienceno': 13905, 'moneyat': 13906, 'unimaginable': 13907, 'easyalso': 13908, 'laundry': 13909, 'weightoverall': 13910, 'rangeat': 13911, 'optionsoptical': 13912, 'hdmiauxusb': 13913, 'bluetoothbass': 13914, 'anukannu': 13915, 'adachu': 13916, 'edukaam': 13917, 'hiring': 13918, 'awesomemoney': 13919, 'inconven': 13920, 'challengelater': 13921, 'pennybuilt': 13922, 'weighless': 13923, 'basket': 13924, 'flipkari': 13925, 'bothit': 13926, 'broad': 13927, 'aroun': 13928, 'everyones': 13929, 'deliverygenuine': 13930, 'productdnt': 13931, 'knw': 13932, 'serviceshope': 13933, 'kidsthank': 13934, 'downgrade': 13935, 'nicmy': 13936, 'cutelm': 13937, 'happytq': 13938, 'setu': 13939, 'brandthanks': 13940, 'supermy': 13941, 'noiselessair': 13942, 'acreally': 13943, 'insides': 13944, 'outsides': 13945, 'favorites': 13946, 'patiently': 13947, 'cutie': 13948, 'availablevalue': 13949, 'moneycons': 13950, 'appmost': 13951, 'actiondrama': 13952, 'scenes': 13953, 'prompting': 13954, 'moneyrange': 13955, 'wellmy': 13956, 'colleague': 13957, 'productamaazing': 13958, 'prescribed': 13959, 'reverse': 13960, 'pricefront': 13961, 'priceprocessor': 13962, 'goodface': 13963, 'unlock': 13964, 'itne': 13965, 'lucrative': 13966, 'cheers': 13967, 'thodi': 13968, 'barits': 13969, 'classysound': 13970, 'cumbersomethis': 13971, 'attachmentand': 13972, 'workstrongly': 13973, 'pish': 13974, 'highget': 13975, 'watercustomer': 13976, 'su': 13977, 'flidkard': 13978, 'kettli': 13979, 'adobe': 13980, 'exallent': 13981, 'experiencetotally': 13982, 'bassgreat': 13983, 'designoverall': 13984, 'yetgo': 13985, 'triggersthnx': 13986, 'weightsize': 13987, 'shoft': 13988, 'ward': 13989, 'exellant': 13990, 'newest': 13991, 'usbc': 13992, 'landscape': 13993, 'bulbsnot': 13994, 'identify': 13995, 'boo': 13996, 'usagevalue': 13997, 'awsomesize': 13998, 'awake': 13999, 'bater': 14000, 'genuin': 14001, 'downfall': 14002, 'weekbased': 14003, 'keypadgood': 14004, 'brightnessnot': 14005, 'prodecte': 14006, 'fliffcrt': 14007, 'qolity': 14008, 'amplyfir': 14009, 'jig': 14010, 'jag': 14011, 'oswm': 14012, 'expectedbuild': 14013, 'solidsome': 14014, 'fixconnectivity': 14015, 'meterlong': 14016, 'ricedal': 14017, 'chikenmotton': 14018, 'mageechatni': 14019, 'payes': 14020, 'prace': 14021, 'sizeawesome': 14022, 'materialthe': 14023, 'bassand': 14024, 'sideways': 14025, 'featuresoverall': 14026, 'marketgood': 14027, 'tabletswater': 14028, 'producttotally': 14029, 'dateapril': 14030, 'cleaningfor': 14031, 'adapt': 14032, 'trend': 14033, 'bluri': 14034, 'flippy': 14035, 'purchasehighly': 14036, 'soundbari': 14037, 'audiophile': 14038, 'inexpensive': 14039, 'cani': 14040, 'mucheven': 14041, 'pleasantly': 14042, 'surprisin': 14043, 'perfectproudly': 14044, 'headacheoverall': 14045, 'hilling': 14046, 'mellting': 14047, 'plusvery': 14048, 'chocolious': 14049, 'todayits': 14050, 'parfumi': 14051, 'superworthgood': 14052, 'jobgood': 14053, 'upvc': 14054, 'brig': 14055, 'overallits': 14056, 'extremetable': 14057, 'shakingoverall': 14058, 'lobe': 14059, 'supppppppppeeeeeerrrr': 14060, 'gooditem': 14061, 'comportable': 14062, 'happeni': 14063, 'witnessed': 14064, 'bias': 14065, 'butteringill': 14066, 'history': 14067, 'mii': 14068, 'desperate': 14069, 'absol': 14070, 'durty': 14071, 'fittingworth': 14072, 'philpkart': 14073, 'pointsbattery': 14074, 'pointscamera': 14075, 'onlywife': 14076, 'statisfied': 14077, 'oncen': 14078, 'cleanits': 14079, 'usful': 14080, 'niceand': 14081, 'packagingit': 14082, 'timeother': 14083, 'tingled': 14084, 'inlaw': 14085, 'gati': 14086, 'operative': 14087, 'serviceproduct': 14088, 'upswas': 14089, 'wellworth': 14090, 'downstoo': 14091, 'gramin': 14092, 'lightness': 14093, 'parda': 14094, 'arpit': 14095, 'stoic': 14096, 'nicenice': 14097, 'nanoray': 14098, 'muscle': 14099, 'woild': 14100, 'satisfyingbass': 14101, 'unpredictable': 14102, 'lastest': 14103, 'roomscan': 14104, 'waterteascoffees': 14105, 'soupsetccan': 14106, 'secondsonly': 14107, 'onlythis': 14108, 'productsthumbs': 14109, 'okkkkay': 14110, 'personthank': 14111, 'bati': 14112, 'laptopbattery': 14113, 'bestsellerthank': 14114, 'reqirement': 14115, 'consistency': 14116, 'legged': 14117, 'beaten': 14118, 'mivisound': 14119, 'yestetdayits': 14120, 'revisions': 14121, 'appreciation': 14122, 'powerfully': 14123, 'crashing': 14124, 'feee': 14125, 'packedit': 14126, 'kapoorhighly': 14127, 'finishes': 14128, 'apartmentso': 14129, 'speedit': 14130, 'kettlei': 14131, 'beforebut': 14132, 'perfectmust': 14133, 'goodyes': 14134, 'happythnx': 14135, 'therehope': 14136, 'mas': 14137, 'bajajthanks': 14138, 'basslove': 14139, 'hausen': 14140, 'utilized': 14141, 'partys': 14142, 'cookingi': 14143, 'openion': 14144, 'productsbutdinner': 14145, 'ooooosm': 14146, 'productslim': 14147, 'laopala': 14148, 'purchasebest': 14149, 'sprr': 14150, 'damageit': 14151, 'wellknown': 14152, 'threelayer': 14153, 'composite': 14154, 'filteruv': 14155, 'carbonnano': 14156, 'actibac': 14157, 'kills': 14158, 'viruses': 14159, 'pollutants': 14160, 'flexicable': 14161, 'suffur': 14162, 'thingvideo': 14163, 'hdyou': 14164, 'amazingit': 14165, 'fragrancetravel': 14166, 'awesomemust': 14167, 'productandcare': 14168, 'customerandcare': 14169, 'getan': 14170, 'revolutionary': 14171, 'handels': 14172, 'prolooks': 14173, 'marketmy': 14174, 'shortcuts': 14175, 'outers': 14176, 'bigsomewhat': 14177, 'platesit': 14178, 'embeded': 14179, 'paintingso': 14180, 'doubting': 14181, 'eatingsoif': 14182, 'tri': 14183, 'hubthe': 14184, 'daysexpected': 14185, 'beautyful': 14186, 'goodback': 14187, 'purchaseworth': 14188, 'braided': 14189, 'luvd': 14190, 'nuclear': 14191, 'tl': 14192, 'changeing': 14193, 'nies': 14194, 'designgo': 14195, 'ausome': 14196, 'datethe': 14197, 'praiseworthy': 14198, 'productusefull': 14199, 'khup': 14200, 'chane': 14201, 'aahet': 14202, 'aani': 14203, 'mde': 14204, 'lask': 14205, 'goodfeeling': 14206, 'cuttack': 14207, 'corporation': 14208, 'dossnt': 14209, 'awesomenow': 14210, 'serviceservice': 14211, 'neice': 14212, 'elementary': 14213, 'projects': 14214, 'hobby': 14215, 'automated': 14216, 'sameits': 14217, 'lineing': 14218, 'perfectcons': 14219, 'sunray': 14220, 'testanother': 14221, 'isolate': 14222, 'recievedi': 14223, 'purplecoming': 14224, 'toowas': 14225, 'pleass': 14226, 'excellentpaired': 14227, 'contrary': 14228, 'customernice': 14229, 'aditional': 14230, 'elaborate': 14231, 'conditionyet': 14232, 'understandablethe': 14233, 'changeit': 14234, 'fineno': 14235, 'leakagevalue': 14236, 'havefor': 14237, 'trivia': 14238, 'quiz': 14239, 'translator': 14240, 'fetch': 14241, 'mapsas': 14242, 'upgrad': 14243, 'motorlow': 14244, 'noisego': 14245, 'backupbut': 14246, 'dal': 14247, 'transport': 14248, 'chimneybut': 14249, 'delayedevrn': 14250, 'coolingnice': 14251, 'coolling': 14252, 'frameplastic': 14253, 'oii': 14254, 'ete': 14255, 'catching': 14256, 'clearits': 14257, 'phoneit': 14258, 'connectionrest': 14259, 'mricrofiber': 14260, 'sticy': 14261, 'delevary': 14262, 'timequality': 14263, 'flipkartworking': 14264, 'py': 14265, 'pedals': 14266, 'effortless': 14267, 'bateoom': 14268, 'goodregret': 14269, 'travelers': 14270, 'thatinstallation': 14271, 'goodexhaust': 14272, 'betterinstallation': 14273, 'flipyy': 14274, 'fasterosm': 14275, 'enoughlooks': 14276, 'mobail': 14277, 'yeri': 14278, 'relieved': 14279, 'sparkle': 14280, 'maidyou': 14281, 'earlierkitchen': 14282, 'gurgaon': 14283, 'holidays': 14284, 'levelsalso': 14285, 'effectivehave': 14286, 'dhoop': 14287, 'leve': 14288, 'latethe': 14289, 'efficientalmost': 14290, 'catthings': 14291, 'blurring': 14292, 'bis': 14293, 'certification': 14294, 'slybuss': 14295, 'planningoverall': 14296, 'mindset': 14297, 'selfreading': 14298, 'attentive': 14299, 'connectorconnected': 14300, 'facilit': 14301, 'colette': 14302, 'wen': 14303, 'travellers': 14304, 'callings': 14305, 'traffics': 14306, 'sc': 14307, 'tt': 14308, 'wearonly': 14309, 'rangefirst': 14310, 'usersreviewing': 14311, 'usagepros': 14312, 'satisfiedomg': 14313, 'polystyrene': 14314, 'alive': 14315, 'richer': 14316, 'conditionworth': 14317, 'meterialsatisfied': 14318, 'chargethanks': 14319, 'providerconclusion': 14320, 'perfumeboth': 14321, 'highwaisted': 14322, 'dilema': 14323, 'yesyou': 14324, 'consuke': 14325, 'purchasedbest': 14326, 'carrotbeetrootpineapplepomegranateappleorange': 14327, 'carryone': 14328, 'zbrdst': 14329, 'origin': 14330, 'buyawesome': 14331, 'requirementsbattery': 14332, 'reviewsthis': 14333, 'entranceit': 14334, 'breaches': 14335, 'breaching': 14336, 'celine': 14337, 'expectedbreadth': 14338, 'amazingbass': 14339, 'countertop': 14340, 'qn': 14341, 'makeup': 14342, 'zig': 14343, 'zag': 14344, 'chipku': 14345, 'mahroom': 14346, 'farm': 14347, 'diseases': 14348, 'spreading': 14349, 'mites': 14350, 'mouths': 14351, 'painsa': 14352, 'podact': 14353, 'juise': 14354, 'onranges': 14355, 'stirdy': 14356, 'functionsfor': 14357, 'performancelove': 14358, 'presently': 14359, 'fromthe': 14360, 'gogles': 14361, 'momdad': 14362, 'sick': 14363, 'melody': 14364, 'conne': 14365, 'kharid': 14366, 'litel': 14367, 'rangebest': 14368, 'performancewith': 14369, 'stingy': 14370, 'jolly': 14371, 'dryingthankful': 14372, 'coading': 14373, 'tqqqqs': 14374, 'chippest': 14375, 'hoursbattery': 14376, 'laptopdisplay': 14377, 'dopeoverall': 14378, 'otsel': 14379, 'problemscooling': 14380, 'storagestays': 14381, 'scenebuttons': 14382, 'operatevery': 14383, 'convenientthanks': 14384, 'lastingits': 14385, 'quantityits': 14386, 'prestigious': 14387, 'suitavle': 14388, 'pantsvery': 14389, 'pricealthough': 14390, 'minassembly': 14391, 'includedtable': 14392, 'residual': 14393, 'cleanuphighly': 14394, 'laptopnot': 14395, 'fullythe': 14396, 'hurdle': 14397, 'touches': 14398, 'spanner': 14399, 'itno': 14400, 'usageproduct': 14401, 'kitchenthis': 14402, 'enhancerbut': 14403, 'tasteso': 14404, 'bhaviour': 14405, 'badproduct': 14406, 'charmonly': 14407, 'sot': 14408, 'charjar': 14409, 'unmatchable': 14410, 'venkatesh': 14411, 'recommendedbut': 14412, 'settingspros': 14413, 'pricertx': 14414, 'studentsall': 14415, 'findcons': 14416, 'appreciatedoverall': 14417, 'etcl': 14418, 'rms': 14419, 'quicklay': 14420, 'deliveryfull': 14421, 'surving': 14422, 'hasbeen': 14423, 'resloved': 14424, 'alsoo': 14425, 'kenti': 14426, 'recommendedgreat': 14427, 'feviquik': 14428, 'gamesdesign': 14429, 'averagecant': 14430, 'carryand': 14431, 'grillinglarge': 14432, 'spaceoverall': 14433, 'ittotally': 14434, 'overself': 14435, 'flipcartsound': 14436, 'resultthanks': 14437, 'outputbattery': 14438, 'ballloved': 14439, 'score': 14440, 'administrator': 14441, 'equiptment': 14442, 'polycarbonate': 14443, 'sumup': 14444, 'matterialrecommended': 14445, 'gov': 14446, 'freebiesgood': 14447, 'optionssize': 14448, 'deliveryloving': 14449, 'weightcheapest': 14450, 'tyrenot': 14451, 'spring': 14452, 'higly': 14453, 'recommendvery': 14454, 'wxpected': 14455, 'angular': 14456, 'unusual': 14457, 'neture': 14458, 'nowmachine': 14459, 'worthinstallation': 14460, 'juggling': 14461, 'fro': 14462, 'speakersaux': 14463, 'wellhdmi': 14464, 'tvpremium': 14465, 'wellpoor': 14466, 'noisebought': 14467, 'moderately': 14468, 'rambo': 14469, 'machinevery': 14470, 'startersvalue': 14471, 'productlooking': 14472, 'absorbed': 14473, 'potted': 14474, 'wearhope': 14475, 'softi': 14476, 'elders': 14477, 'everyoneno': 14478, 'pleaae': 14479, 'addd': 14480, 'corona': 14481, 'cartthank': 14482, 'wonderfully': 14483, 'flipacrt': 14484, 'servicess': 14485, 'drawers': 14486, 'prov': 14487, 'fregrance': 14488, 'finishingi': 14489, 'besed': 14490, 'kindness': 14491, 'flipkartkent': 14492, 'activates': 14493, 'idling': 14494, 'prospective': 14495, 'flippcart': 14496, 'oilnon': 14497, 'majority': 14498, 'noisier': 14499, 'stayed': 14500, 'deviceswhich': 14501, 'sneaker': 14502, 'somehowits': 14503, 'cityamazewagonrdzire': 14504, 'moresony': 14505, 'carsit': 14506, 'honda': 14507, 'amazethanks': 14508, 'belongs': 14509, 'modelhence': 14510, 'accordinglymodel': 14511, 'individual': 14512, 'carries': 14513, 'kgs': 14514, 'accessoriesbrakes': 14515, 'awesomeperfect': 14516, 'productloud': 14517, 'bassthanku': 14518, 'dishwasheryou': 14519, 'extensions': 14520, 'recommends': 14521, 'productsthe': 14522, 'salary': 14523, 'theek': 14524, 'producttnq': 14525, 'stored': 14526, 'phonethis': 14527, 'encountered': 14528, 'redmenote': 14529, 'stari': 14530, 'earoverall': 14531, 'evething': 14532, 'beautifullove': 14533, 'purchasedexcellent': 14534, 'housegive': 14535, 'curl': 14536, 'atom': 14537, 'superblike': 14538, 'ignoring': 14539, 'replicate': 14540, 'ka': 14541, 'winds': 14542, 'bhe': 14543, 'addictivegot': 14544, 'usagefor': 14545, 'speakerit': 14546, 'moregd': 14547, 'santro': 14548, 'magna': 14549, 'owning': 14550, 'fingerprin': 14551, 'qualitytnq': 14552, 'backthe': 14553, 'inverterdesign': 14554, 'buetyful': 14555, 'productafter': 14556, 'sinningjust': 14557, 'newafter': 14558, 'monthsthe': 14559, 'productcrompton': 14560, 'awwsome': 14561, 'booktopic': 14562, 'concernedproduct': 14563, 'manualhappy': 14564, 'fog': 14565, 'knowledgethanks': 14566, 'gigantic': 14567, 'hoax': 14568, 'badyou': 14569, 'reber': 14570, 'deliverythis': 14571, 'offerings': 14572, 'flipkarttalking': 14573, 'tweaks': 14574, 'displaypicture': 14575, 'settingscustom': 14576, 'designinstant': 14577, 'processorone': 14578, 'kitchenknitting': 14579, 'tomatoesgreat': 14580, 'unbr': 14581, 'supportiveoverall': 14582, 'cultsports': 14583, 'inaccurate': 14584, 'pulse': 14585, 'medont': 14586, 'buystay': 14587, 'conditioneverything': 14588, 'camerabest': 14589, 'nicetq': 14590, 'dsicount': 14591, 'onethanks': 14592, 'usedining': 14593, 'peoplecomputer': 14594, 'tablestudy': 14595, 'shirttqq': 14596, 'fills': 14597, 'defenetly': 14598, 'niceeeee': 14599, 'simplified': 14600, 'heey': 14601, 'productcloth': 14602, 'smmoth': 14603, 'packingit': 14604, 'finishingawesome': 14605, 'fultu': 14606, 'ko': 14607, 'ignore': 14608, 'karo': 14609, 'hoto': 14610, 'kya': 14611, 'karne': 14612, 'wala': 14613, 'ip': 14614, 'subnet': 14615, 'manuals': 14616, 'circle': 14617, 'shear': 14618, 'performancedesign': 14619, 'losting': 14620, 'anather': 14621, 'machi': 14622, 'filipe': 14623, 'runningless': 14624, 'spacelow': 14625, 'consumptionless': 14626, 'productsvoice': 14627, 'froof': 14628, 'hardybut': 14629, 'productproperly': 14630, 'packedsatisfied': 14631, 'happythis': 14632, 'distances': 14633, 'pricethis': 14634, 'perfectas': 14635, 'alwaysreceive': 14636, 'conditionworking': 14637, 'indravelawesome': 14638, 'sankar': 14639, 'army': 14640, 'boxwithinabox': 14641, 'puposes': 14642, 'qualitylittle': 14643, 'weightgo': 14644, 'laptopsfor': 14645, 'everylikes': 14646, 'budgetfinally': 14647, 'troublenot': 14648, 'againsound': 14649, 'extrapicture': 14650, 'processingnet': 14651, 'converts': 14652, 'complected': 14653, 'screenmirroring': 14654, 'offlinethanks': 14655, 'bouncing': 14656, 'converting': 14657, 'realiastic': 14658, 'grindervalue': 14659, 'bowals': 14660, 'inchs': 14661, 'designsound': 14662, 'enoughideal': 14663, 'dill': 14664, 'shipin': 14665, 'deliverysecond': 14666, 'omnitechthanks': 14667, 'productnon': 14668, 'isit': 14669, 'apex': 14670, 'legends': 14671, 'looki': 14672, 'packagingamazing': 14673, 'zigzag': 14674, 'flipkartgoodbetter': 14675, 'dimension': 14676, 'goodeventough': 14677, 'dayafter': 14678, 'gudance': 14679, 'throgh': 14680, 'appafter': 14681, 'culfit': 14682, 'mrarpit': 14683, 'fitnessas': 14684, 'judt': 14685, 'profarmance': 14686, 'foodbut': 14687, 'vala': 14688, 'karna': 14689, 'griller': 14690, 'vaise': 14691, 'tablethanks': 14692, 'greatsuggestion': 14693, 'cheapbuy': 14694, 'deliveryhad': 14695, 'optionalthis': 14696, 'gamesbut': 14697, 'awesomeoh': 14698, 'myths': 14699, 'toocleans': 14700, 'wine': 14701, 'materialthough': 14702, 'dealshappy': 14703, 'tumpimg': 14704, 'boatdesign': 14705, 'fried': 14706, 'dishwasheradvantages': 14707, 'electricityfinish': 14708, 'jobapprox': 14709, 'famil': 14710, 'bagundhi': 14711, 'reviewas': 14712, 'aloso': 14713, 'wonderfulbut': 14714, 'problemwhen': 14715, 'gona': 14716, 'painbut': 14717, 'hea': 14718, 'juicelittle': 14719, 'eally': 14720, 'lord': 14721, 'shiva': 14722, 'tallest': 14723, 'coimbatore': 14724, 'compated': 14725, 'comsumption': 14726, 'sandar': 14727, 'purchaseand': 14728, 'scorehope': 14729, 'agosymphony': 14730, 'consecutively': 14731, 'buyhave': 14732, 'daysflipkarts': 14733, 'appeared': 14734, 'conditioni': 14735, 'beastyou': 14736, 'easemy': 14737, 'usebattery': 14738, 'melooks': 14739, 'stunningdont': 14740, 'shortly': 14741, 'babi': 14742, 'kus': 14743, 'producttnx': 14744, 'bathrooms': 14745, 'cylinder': 14746, 'ballonsvery': 14747, 'productthey': 14748, 'insole': 14749, 'installationit': 14750, 'goodbooks': 14751, 'servicethe': 14752, 'burnafter': 14753, 'ownvery': 14754, 'returnexchange': 14755, 'noo': 14756, 'dabol': 14757, 'smol': 14758, 'vari': 14759, 'brokes': 14760, 'frills': 14761, 'bitching': 14762, 'clothings': 14763, 'setindia': 14764, 'incorre': 14765, 'verieties': 14766, 'overcharging': 14767, 'normalnot': 14768, 'muchmissing': 14769, 'movienot': 14770, 'ret': 14771, 'eny': 14772, 'afterward': 14773, 'overflowing': 14774, 'userinterface': 14775, 'additionstill': 14776, 'dejection': 14777, 'statitics': 14778, 'slove': 14779, 'delaying': 14780, 'ahhh': 14781, 'bathed': 14782, 'xvery': 14783, 'complainant': 14784, 'shems': 14785, 'flipkartweast': 14786, 'liver': 14787, 'querystrongly': 14788, 'owni': 14789, 'refilled': 14790, 'probalam': 14791, 'grinddont': 14792, 'barbadmissing': 14793, 'batterycharger': 14794, 'hasnt': 14795, 'advisable': 14796, 'suffered': 14797, 'amh': 14798, 'piecesreally': 14799, 'disapointed': 14800, 'misses': 14801, 'shrinks': 14802, 'portinternet': 14803, 'disppointed': 14804, 'offas': 14805, 'reparing': 14806, 'bankit': 14807, 'hangging': 14808, 'expierence': 14809, 'risnebetter': 14810, 'downtotally': 14811, 'thease': 14812, 'atten': 14813, 'brablem': 14814, 'woshing': 14815, 'demez': 14816, 'flipkartbattery': 14817, 'anly': 14818, 'blanketpls': 14819, 'chasing': 14820, 'havnt': 14821, 'worts': 14822, 'untensils': 14823, 'noisesforget': 14824, 'rosewoodits': 14825, 'blackwood': 14826, 'qualitycomfort': 14827, 'easyyou': 14828, 'buyun': 14829, 'flitkart': 14830, 'capacitor': 14831, 'cromption': 14832, 'orient': 14833, 'awayfully': 14834, 'griding': 14835, 'transmitted': 14836, 'processand': 14837, 'antenas': 14838, 'fooled': 14839, 'airdry': 14840, 'inkvery': 14841, 'displayplastic': 14842, 'supportdisplay': 14843, 'purposesvery': 14844, 'cameraonly': 14845, 'allbattery': 14846, 'fevi': 14847, 'productsimmediately': 14848, 'repare': 14849, 'camedont': 14850, 'brightnesslow': 14851, 'inchprosprice': 14852, 'popr': 14853, 'lucent': 14854, 'superfluous': 14855, 'makeno': 14856, 'allvery': 14857, 'miui': 14858, 'featuresregretting': 14859, 'thishope': 14860, 'fixes': 14861, 'illnever': 14862, 'metoo': 14863, 'plugging': 14864, 'deplugging': 14865, 'avoided': 14866, 'remotethis': 14867, 'resume': 14868, 'marketand': 14869, 'disaster': 14870, 'thatatta': 14871, 'goodfrench': 14872, 'fries': 14873, 'goodblending': 14874, 'goodbeater': 14875, 'greatjuicer': 14876, 'greatcitrus': 14877, 'vomplete': 14878, 'productrequest': 14879, 'brandthis': 14880, 'noiseyou': 14881, 'produs': 14882, 'fliter': 14883, 'bearly': 14884, 'indocation': 14885, 'sume': 14886, 'expecteddevice': 14887, 'lengthyits': 14888, 'operationsearchchannel': 14889, 'customizetion': 14890, 'tiredfullits': 14891, 'priceanybody': 14892, 'deviceim': 14893, 'allthis': 14894, 'swinger': 14895, 'congested': 14896, 'cleanlyin': 14897, 'buyac': 14898, 'aut': 14899, 'thisloved': 14900, 'flashes': 14901, 'ttl': 14902, 'heresamsung': 14903, 'everwriting': 14904, 'waer': 14905, 'painfull': 14906, 'crossing': 14907, 'productfraud': 14908, 'rc': 14909, 'environmentoverall': 14910, 'menstrual': 14911, 'gently': 14912, 'policyfull': 14913, 'timereally': 14914, 'diss': 14915, 'appointment': 14916, 'soundtaking': 14917, 'gride': 14918, 'quantitycant': 14919, 'barded': 14920, 'prestigedont': 14921, 'salewaste': 14922, 'bating': 14923, 'acceptation': 14924, 'frequencys': 14925, 'desi': 14926, 'jugaddoes': 14927, 'seenit': 14928, 'dayswaste': 14929, 'customersdont': 14930, 'logos': 14931, 'scumsters': 14932, 'executives': 14933, 'requsted': 14934, 'tooks': 14935, 'preeti': 14936, 'comform': 14937, 'reaquest': 14938, 'tabletbcoz': 14939, 'allergies': 14940, 'badtime': 14941, 'goodbutfor': 14942, 'whyi': 14943, 'okayas': 14944, 'colourcheck': 14945, 'naturalbut': 14946, 'pluged': 14947, 'heati': 14948, 'longtime': 14949, 'expectationdoes': 14950, 'accepting': 14951, 'cartridgeplz': 14952, 'hse': 14953, 'setoff': 14954, 'testimg': 14955, 'faint': 14956, 'producthand': 14957, 'discomfortable': 14958, 'odd': 14959, 'alldisappointed': 14960, 'pathetici': 14961, 'atall': 14962, 'pappad': 14963, 'receivedit': 14964, 'afterwards': 14965, 'thatdont': 14966, 'tvmi': 14967, 'minimalsecond': 14968, 'incredibleyou': 14969, 'uniqueyou': 14970, 'overcome': 14971, 'obstacleloss': 14972, 'aloneyou': 14973, 'lovedyou': 14974, 'fullestim': 14975, 'universe': 14976, 'workingnow': 14977, 'servicewaste': 14978, 'comingonly': 14979, 'border': 14980, 'musicand': 14981, 'disappointmivi': 14982, 'welldont': 14983, 'thre': 14984, 'moneyas': 14985, 'distreb': 14986, 'matera': 14987, 'onward': 14988, 'wk': 14989, 'rk': 14990, 'unplug': 14991, 'mixturecustomer': 14992, 'mentionedshown': 14993, 'oldrepaired': 14994, 'itemsfli': 14995, 'okayinstallation': 14996, 'persuade': 14997, 'stabilityif': 14998, 'fullalways': 14999, 'niceproslooks': 15000, 'elegantgrinds': 15001, 'fastsupposedly': 15002, 'lastingconsthe': 15003, 'splashes': 15004, 'motorcleaning': 15005, 'cleanpremium': 15006, 'yearsno': 15007, 'heatthis': 15008, 'chairit': 15009, 'roo': 15010, 'endless': 15011, 'loop': 15012, 'comford': 15013, 'katha': 15014, 'sheesham': 15015, 'infested': 15016, 'spills': 15017, 'swells': 15018, 'disfigured': 15019, 'ohk': 15020, 'productproblem': 15021, 'installationlack': 15022, 'deliveredtremendous': 15023, 'harrasment': 15024, 'sidevery': 15025, 'usedtrack': 15026, 'insteadbattery': 15027, 'useheating': 15028, 'heatnot': 15029, 'beguns': 15030, 'resisting': 15031, 'brandbuy': 15032, 'broker': 15033, 'productstandard': 15034, 'pressured': 15035, 'pumpingcan': 15036, 'workmanship': 15037, 'gears': 15038, 'bridges': 15039, 'filler': 15040, 'slider': 15041, 'awaited': 15042, 'usebad': 15043, 'recycled': 15044, 'noicy': 15045, 'staricon': 15046, 'crippy': 15047, 'layes': 15048, 'tower': 15049, 'pisa': 15050, 'pyant': 15051, 'dipping': 15052, 'samescam': 15053, 'goodthey': 15054, 'tubeless': 15055, 'soundbut': 15056, 'qualitynoise': 15057, 'woofersonce': 15058, 'satellite': 15059, 'pointsgood': 15060, 'effectbig': 15061, 'tensionno': 15062, 'issueimprovement': 15063, 'outflow': 15064, 'quantitydull': 15065, 'printi': 15066, 'printstotaly': 15067, 'interms': 15068, 'improving': 15069, 'batterylife': 15070, 'wholes': 15071, 'againquality': 15072, 'landing': 15073, 'rian': 15074, 'wifiall': 15075, 'zio': 15076, 'mediumsized': 15077, 'capabilities': 15078, 'smallsized': 15079, 'overalli': 15080, 'microwa': 15081, 'electricalpoints': 15082, 'mdeim': 15083, 'moneydoesnt': 15084, 'expectationsand': 15085, 'reviewfor': 15086, 'avarageusing': 15087, 'babyits': 15088, 'avarageif': 15089, 'consult': 15090, 'qualitywasted': 15091, 'kookaburra': 15092, 'qualitymoney': 15093, 'wastedont': 15094, 'buyquality': 15095, 'speakerand': 15096, 'lows': 15097, 'memorize': 15098, 'nee': 15099, 'severe': 15100, 'transmitng': 15101, 'custom': 15102, 'possibleis': 15103, 'charmbetter': 15104, 'mitv': 15105, 'formers': 15106, 'usedont': 15107, 'wrostdont': 15108, 'anyonepls': 15109, 'coton': 15110, 'duarabiliy': 15111, 'escalate': 15112, 'bbad': 15113, 'lied': 15114, 'vanesaand': 15115, 'slowand': 15116, 'screwno': 15117, 'authorization': 15118, 'lightjust': 15119, 'mtvery': 15120, 'gettin': 15121, 'lovethen': 15122, 'rokerz': 15123, 'discharges': 15124, 'discounting': 15125, 'gymnastic': 15126, 'abilities': 15127, 'brokenwhen': 15128, 'schedules': 15129, 'sitch': 15130, 'tongue': 15131, 'muchafter': 15132, 'lowdontpurchase': 15133, 'customerdont': 15134, 'therads': 15135, 'poorstitchings': 15136, 'substances': 15137, 'sended': 15138, 'misguided': 15139, 'goodcons': 15140, 'systemfront': 15141, 'seating': 15142, 'properlygot': 15143, 'tasteless': 15144, 'tellings': 15145, 'viscos': 15146, 'gentlyputting': 15147, 'blanketwaste': 15148, 'kidney': 15149, 'problemgastic': 15150, 'screch': 15151, 'tears': 15152, 'runing': 15153, 'engg': 15154, 'goodupdate': 15155, 'soles': 15156, 'chef': 15157, 'swtch': 15158, 'watchpoor': 15159, 'exaust': 15160, 'irritate': 15161, 'printermy': 15162, 'moneyflipcart': 15163, 'unever': 15164, 'zippe': 15165, 'brakon': 15166, 'footballbad': 15167, 'churd': 15168, 'increasems': 15169, 'connectedalso': 15170, 'noisefit': 15171, 'muchif': 15172, 'cominglooks': 15173, 'ise': 15174, 'aacha': 15175, 'wildstone': 15176, 'lesscheap': 15177, 'workingits': 15178, 'hellicopter': 15179, 'wastebad': 15180, 'expiriance': 15181, 'whare': 15182, 'mausambi': 15183, 'versioni': 15184, 'brandhearing': 15185, 'walter': 15186, 'modei': 15187, 'hardwork': 15188, 'investmenti': 15189, 'workingonly': 15190, 'lifedont': 15191, 'meboat': 15192, 'toes': 15193, 'coilcleaning': 15194, 'guyi': 15195, 'goodwithin': 15196, 'etcso': 15197, 'aftersales': 15198, 'peoplehorrible': 15199, 'repaird': 15200, 'admin': 15201, 'login': 15202, 'againso': 15203, 'producttheyll': 15204, 'alsoand': 15205, 'moneyless': 15206, 'sounduser': 15207, 'receivedbad': 15208, 'freezed': 15209, 'alwaysdont': 15210, 'westing': 15211, 'vibrates': 15212, 'satisfiedbad': 15213, 'dustextremely': 15214, 'viewof': 15215, 'aseeing': 15216, 'letme': 15217, 'viru': 15218, 'thinnest': 15219, 'satisfiedover': 15220, 'hype': 15221, 'percormance': 15222, 'impurities': 15223, 'hangedsometimesmy': 15224, 'defeatedas': 15225, 'slowbattery': 15226, 'worstkeyboard': 15227, 'junck': 15228, 'goodaverage': 15229, 'wearer': 15230, 'fitinge': 15231, 'purchese': 15232, 'smallnyc': 15233, 'feetings': 15234, 'pclaptop': 15235, 'workingbad': 15236, 'workingmotor': 15237, 'cheatingit': 15238, 'expiredthere': 15239, 'baject': 15240, 'picsrealize': 15241, 'platformsabsolutely': 15242, 'discolored': 15243, 'wasteful': 15244, 'handloom': 15245, 'panipat': 15246, 'resolves': 15247, 'fadeup': 15248, 'poorsome': 15249, 'waisting': 15250, 'timelater': 15251, 'replacethey': 15252, 'dentnow': 15253, 'sheduled': 15254, 'timevery': 15255, 'enoughalso': 15256, 'monthsits': 15257, 'productlow': 15258, 'flipkatchange': 15259, 'footballrather': 15260, 'kicked': 15261, 'vanished': 15262, 'daysso': 15263, 'guyz': 15264, 'nike': 15265, 'waistage': 15266, 'noisey': 15267, 'oppening': 15268, 'kajols': 15269, 'proofe': 15270, 'wetty': 15271, 'highquality': 15272, 'descrpency': 15273, 'inspector': 15274, 'procedure': 15275, 'msg': 15276, 'abo': 15277, 'moneynoise': 15278, 'irritatung': 15279, 'swimmers': 15280, 'laptopim': 15281, 'janta': 15282, 'nagar': 15283, 'ludhianaand': 15284, 'productseller': 15285, 'ships': 15286, 'screams': 15287, 'establish': 15288, 'connectionwelcome': 15289, 'woos': 15290, 'pairbluetooth': 15291, 'successfullyand': 15292, 'wierd': 15293, 'accent': 15294, 'guests': 15295, 'homeend': 15296, 'rca': 15297, 'symptomatic': 15298, 'doc': 15299, 'viral': 15300, 'expectedheavy': 15301, 'issuevery': 15302, 'hired': 15303, 'honour': 15304, 'tvpicture': 15305, 'grandson': 15306, 'worost': 15307, 'smootha': 15308, 'comfertble': 15309, 'untested': 15310, 'depletes': 15311, 'hungry': 15312, 'los': 15313, 'worryif': 15314, 'somethingbut': 15315, 'cans': 15316, 'expiations': 15317, 'buyplzzzzit': 15318, 'sparked': 15319, 'monthwaste': 15320, 'awkward': 15321, 'bendbut': 15322, 'symmitryall': 15323, 'thingsprice': 15324, 'litile': 15325, 'wroost': 15326, 'noiseeno': 15327, 'givenno': 15328, 'zize': 15329, 'muc': 15330, 'tactilesome': 15331, 'notmultifunction': 15332, 'propersometimes': 15333, 'attends': 15334, 'googlesiri': 15335, 'annoyingi': 15336, 'tantra': 15337, 'experienceonce': 15338, 'screenshots': 15339, 'addon': 15340, 'snatched': 15341, 'nervous': 15342, 'naptol': 15343, 'powred': 15344, 'particalswhen': 15345, 'muddy': 15346, 'chewing': 15347, 'eatingnot': 15348, 'laptophandheld': 15349, 'skype': 15350, 'cley': 15351, 'flapping': 15352, 'gare': 15353, 'bhairava': 15354, 'associates': 15355, 'goodbottom': 15356, 'looksit': 15357, 'spoiledthe': 15358, 'productsit': 15359, 'badest': 15360, 'productsystem': 15361, 'slowcharging': 15362, 'earthing': 15363, 'febrik': 15364, 'unequal': 15365, 'automation': 15366, 'rout': 15367, 'rashes': 15368, 'clingy': 15369, 'damagedbroken': 15370, 'hell': 15371, 'chargerthis': 15372, 'wastesize': 15373, 'alan': 15374, 'jones': 15375, 'marble': 15376, 'flooring': 15377, 'skewers': 15378, 'toaster': 15379, 'seenbut': 15380, 'purchas': 15381, 'ts': 15382, 'usewill': 15383, 'recomender': 15384, 'weeksdidnt': 15385, 'scary': 15386, 'resistancegood': 15387, 'comparitively': 15388, 'jali': 15389, 'spots': 15390, 'oneeven': 15391, 'leakwe': 15392, 'cellarnot': 15393, 'powerinternet': 15394, 'goodspeed': 15395, 'proccer': 15396, 'instalment': 15397, 'themself': 15398, 'accessorise': 15399, 'menace': 15400, 'highchild': 15401, 'overplease': 15402, 'moneyused': 15403, 'chips': 15404, 'worstcolor': 15405, 'badplz': 15406, 'itonly': 15407, 'firebolt': 15408, 'burst': 15409, 'promoted': 15410, 'perpetually': 15411, 'haste': 15412, 'resive': 15413, 'scrue': 15414, 'slowwest': 15415, 'deside': 15416, 'resist': 15417, 'itreplacement': 15418, 'wheal': 15419, 'oxello': 15420, 'worthcloth': 15421, 'fullythis': 15422, 'chargersmy': 15423, 'bankdont': 15424, 'producttry': 15425, 'intex': 15426, 'practicing': 15427, 'penalty': 15428, 'monthexpecelly': 15429, 'stitchingover': 15430, 'bab': 15431, 'thire': 15432, 'practically': 15433, 'servicebut': 15434, 'wifitill': 15435, 'hasnot': 15436, 'maduppanu': 15437, 'connectednot': 15438, 'producteven': 15439, 'productmi': 15440, 'bump': 15441, 'intstall': 15442, 'goodmeet': 15443, 'expectationsclean': 15444, 'blocking': 15445, 'productstart': 15446, 'freezercool': 15447, 'disturbed': 15448, 'workingplz': 15449, 'peoplethis': 15450, 'committing': 15451, 'consulting': 15452, 'fillings': 15453, 'moneyover': 15454, 'nonsensetotally': 15455, 'badtried': 15456, 'thisnow': 15457, 'annoyingnot': 15458, 'orking': 15459, 'dump': 15460, 'itemdont': 15461, 'numerous': 15462, 'glance': 15463, 'nagging': 15464, 'failur': 15465, 'babu': 15466, 'eaxctly': 15467, 'cattle': 15468, 'akward': 15469, 'flipcartand': 15470, 'everit': 15471, 'reassemble': 15472, 'wad': 15473, 'melting': 15474, 'wellearlier': 15475, 'morphys': 15476, 'mango': 15477, 'tomatos': 15478, 'grindibg': 15479, 'policyproduct': 15480, 'wastealso': 15481, 'wifiits': 15482, 'issuebad': 15483, 'dismatching': 15484, 'honesty': 15485, 'fasteners': 15486, 'andpedals': 15487, 'threadingonly': 15488, 'assembledleft': 15489, 'buildupif': 15490, 'refundreturn': 15491, 'wasteprodact': 15492, 'verest': 15493, 'technishan': 15494, 'footage': 15495, 'blurry': 15496, 'woresst': 15497, 'watse': 15498, 'comeing': 15499, 'eletrical': 15500, 'flipcartafter': 15501, 'availablewarranty': 15502, 'meaninglesscompany': 15503, 'qukiti': 15504, 'installationi': 15505, 'conditionproduct': 15506, 'cookbook': 15507, 'presenthad': 15508, 'paused': 15509, 'buyalthough': 15510, 'perfumewasted': 15511, 'sqfeet': 15512, 'chenge': 15513, 'kwalityi': 15514, 'legstand': 15515, 'skid': 15516, 'dost': 15517, 'jab': 15518, 'brokeplease': 15519, 'buyutter': 15520, 'beg': 15521, 'readable': 15522, 'pipeps': 15523, 'overcharged': 15524, 'thisits': 15525, 'cartage': 15526, 'clay': 15527, 'buyingpros': 15528, 'onecons': 15529, 'missingcrusty': 15530, 'customersif': 15531, 'unusable': 15532, 'policyreutun': 15533, 'customarbecause': 15534, 'injury': 15535, 'lecture': 15536, 'spigen': 15537, 'splash': 15538, 'mosttttttttttttttt': 15539, 'horribleeeeeeeeeeeee': 15540, 'loot': 15541, 'forcing': 15542, 'acidic': 15543, 'tillit': 15544, 'sinks': 15545, 'thingdont': 15546, 'abit': 15547, 'toxic': 15548, 'allwaste': 15549, 'leathertoo': 15550, 'smallyou': 15551, 'rowhight': 15552, 'buyplease': 15553, 'markthe': 15554, 'poorit': 15555, 'fittingsnot': 15556, 'qualityn': 15557, 'placesvery': 15558, 'consumable': 15559, 'warenty': 15560, 'noisematerial': 15561, 'bound': 15562, 'lowand': 15563, 'chambers': 15564, 'equipped': 15565, 'noiseit': 15566, 'designall': 15567, 'brokensatisfactory': 15568, 'meterit': 15569, 'valuefor': 15570, 'ppmso': 15571, 'wastepls': 15572, 'farce': 15573, 'cheeep': 15574, 'butflipkart': 15575, 'breakable': 15576, 'wares': 15577, 'friday': 15578, 'promisedhappy': 15579, 'plot': 15580, 'wednesday': 15581, 'usin': 15582, 'digestion': 15583, 'itibs': 15584, 'rspain': 15585, 'marktoo': 15586, 'surfacenot': 15587, 'packso': 15588, 'glep': 15589, 'jul': 15590, 'cominghh': 15591, 'wearingafter': 15592, 'pinning': 15593, 'productmotor': 15594, 'spoke': 15595, 'sizei': 15596, 'samsunglg': 15597, 'suppoted': 15598, 'productdo': 15599, 'arrival': 15600, 'negativeso': 15601, 'varey': 15602, 'allthe': 15603, 'fastplus': 15604, 'malfunctions': 15605, 'actions': 15606, 'flipka': 15607, 'cooh': 15608, 'pcgoogle': 15609, 'appit': 15610, 'momentbad': 15611, 'faar': 15612, 'expansion': 15613, 'financing': 15614, 'proparly': 15615, 'performanceworst': 15616, 'deceived': 15617, 'recvomended': 15618, 'tecklife': 15619, 'apr': 15620, 'catchy': 15621, 'taglines': 15622, 'attracting': 15623, 'itselfremote': 15624, 'reng': 15625, 'coking': 15626, 'sens': 15627, 'usageim': 15628, 'waking': 15629, 'morningone': 15630, 'instance': 15631, 'alert': 15632, 'moneybe': 15633, 'probuct': 15634, 'fealt': 15635, 'hospitals': 15636, 'goodlengthy': 15637, 'superstar': 15638, 'toch': 15639, 'productplz': 15640, 'onlyalways': 15641, 'compatable': 15642, 'filthy': 15643, 'loudplease': 15644, 'restatry': 15645, 'coordination': 15646, 'unacceptable': 15647, 'terribly': 15648, 'properif': 15649, 'shatter': 15650, 'detachable': 15651, 'disad': 15652, 'wasteuseless': 15653, 'thischeating': 15654, 'marathon': 15655, 'mental': 15656, 'pleaselight': 15657, 'tye': 15658, 'whaste': 15659, 'enhancements': 15660, 'layout': 15661, 'notchy': 15662, 'clipsworst': 15663, 'bulid': 15664, 'plank': 15665, 'productbe': 15666, 'cheeters': 15667, 'manufacture': 15668, 'boz': 15669, 'hase': 15670, 'showes': 15671, 'baid': 15672, 'coulity': 15673, 'anythingbut': 15674, 'sumwhat': 15675, 'tyress': 15676, 'desgn': 15677, 'dey': 15678, 'sogs': 15679, 'inktank': 15680, 'allit': 15681, 'fittingcustomer': 15682, 'ipads': 15683, 'circumference': 15684, 'sharpe': 15685, 'varast': 15686, 'itemquality': 15687, 'frequentlywrost': 15688, 'ceremic': 15689, 'epoxy': 15690, 'faking': 15691, 'markbefore': 15692, 'rotated': 15693, 'alex': 15694, 'marketvery': 15695, 'asume': 15696, 'aluminumiron': 15697, 'portnow': 15698, 'shoose': 15699, 'trustablemany': 15700, 'clueless': 15701, 'freeice': 15702, 'freezerso': 15703, 'conncet': 15704, 'refils': 15705, 'headphonebluetooth': 15706, 'onlysound': 15707, 'feuters': 15708, 'ousoms': 15709, 'flittering': 15710, 'audiable': 15711, 'outperforms': 15712, 'aspectson': 15713, 'portonly': 15714, 'thunderbolt': 15715, 'betterscreen': 15716, 'byt': 15717, 'incense': 15718, 'cone': 15719, 'singel': 15720, 'germinatedworst': 15721, 'goodcoil': 15722, 'useand': 15723, 'matall': 15724, 'screenthen': 15725, 'openthese': 15726, 'poweron': 15727, 'receomed': 15728, 'duplict': 15729, 'lightly': 15730, 'bitter': 15731, 'plastictechnician': 15732, 'vbad': 15733, 'vwrry': 15734, 'chord': 15735, 'daysprosvery': 15736, 'productbig': 15737, 'accomodate': 15738, 'easesolid': 15739, 'movementconsnothing': 15740, 'circular': 15741, 'veryyyyyyyyyyy': 15742, 'chaging': 15743, 'prdouct': 15744, 'toyi': 15745, 'cavityand': 15746, 'cavityworst': 15747, 'ifbnot': 15748, 'dealif': 15749, 'soumd': 15750, 'slipping': 15751, 'attachmentscomplete': 15752, 'clarty': 15753, 'spekers': 15754, 'resound': 15755, 'nonsenseworthless': 15756, 'prostitutedthare': 15757, 'income': 15758, 'prostitutions': 15759, 'grindingand': 15760, 'neared': 15761, 'expiredwaste': 15762, 'costomers': 15763, 'destenceand': 15764, 'gett': 15765, 'squeezing': 15766, 'poorpoor': 15767, 'connectivityhowever': 15768, 'dustomer': 15769, 'doel': 15770, 'rectification': 15771, 'throttle': 15772, 'brokeni': 15773, 'timethat': 15774, 'loudspeaker': 15775, 'indirectly': 15776, 'ganna': 15777, 'wync': 15778, 'rost': 15779, 'younger': 15780, 'childworst': 15781, 'accidently': 15782, 'tihis': 15783, 'issuesonly': 15784, 'includedplaying': 15785, 'bulp': 15786, 'rejecting': 15787, 'concerning': 15788, 'noises': 15789, 'onplugged': 15790, 'sockets': 15791, 'coshion': 15792, 'usbsome': 15793, 'lyt': 15794, 'interval': 15795, 'phonedont': 15796, 'parchesh': 15797, 'prodauct': 15798, 'moneyam': 15799, 'itemproduct': 15800, 'daysnot': 15801, 'productproduct': 15802, 'baddd': 15803, 'slating': 15804, 'damagednow': 15805, 'tapenever': 15806, 'camparer': 15807, 'fulling': 15808, 'glitch': 15809, 'terminals': 15810, 'thenthis': 15811, 'swear': 15812, 'sooooo': 15813, 'hige': 15814, 'listed': 15815, 'dum': 15816, 'takewastage': 15817, 'unclean': 15818, 'acidity': 15819, 'experiece': 15820, 'slowdont': 15821, 'blunt': 15822, 'powering': 15823, 'rave': 15824, 'radiussee': 15825, 'prodsct': 15826, 'align': 15827, 'heatsup': 15828, 'seance': 15829, 'poorafter': 15830, 'pleas': 15831, 'tshirtvery': 15832, 'bengal': 15833, 'scroos': 15834, 'pach': 15835, 'coad': 15836, 'haver': 15837, 'everworst': 15838, 'backupauto': 15839, 'minutesheat': 15840, 'qualitylot': 15841, 'leakages': 15842, 'atm': 15843, 'markplastic': 15844, 'goodafter': 15845, 'mewest': 15846, 'cheatedreally': 15847, 'nachine': 15848, 'upim': 15849, 'elgi': 15850, 'toheavy': 15851, 'abnormal': 15852, 'tinted': 15853, 'vaest': 15854, 'workinglow': 15855, 'productwest': 15856, 'stucking': 15857, 'safedont': 15858, 'shoddy': 15859, 'uncooked': 15860, 'showned': 15861, 'ordeal': 15862, 'serviceswaste': 15863, 'wakes': 15864, 'sleepalso': 15865, 'timebetter': 15866, 'broomstick': 15867, 'sonot': 15868, 'medias': 15869, 'slows': 15870, 'runningwaste': 15871, 'pached': 15872, 'insufficient': 15873, 'quck': 15874, 'skyworth': 15875, 'fussy': 15876, 'rigorously': 15877, 'workingdon': 15878, 'bilow': 15879, 'onlyits': 15880, 'nakli': 15881, 'lowquality': 15882, 'madeinchina': 15883, 'blaming': 15884, 'connectorsame': 15885, 'incidence': 15886, 'costafter': 15887, 'mobiletotally': 15888, 'servicebeggars': 15889, 'diligues': 15890, 'brite': 15891, 'lodged': 15892, 'inspect': 15893, 'goodcolors': 15894, 'hearter': 15895, 'upside': 15896, 'workingcomplained': 15897, 'caresflipkart': 15898, 'castso': 15899, 'itflipkart': 15900, 'honestyflipkart': 15901, 'terrorist': 15902, 'flooding': 15903, 'indiawhy': 15904, 'takenstill': 15905, 'controv': 15906, 'itcheap': 15907, 'ruppes': 15908, 'calli': 15909, 'ruff': 15910, 'gonenow': 15911, 'nipples': 15912, 'juicermixergrinder': 15913, 'comparativesize': 15914, 'sugar': 15915, 'containersinlet': 15916, 'piecescleaning': 15917, 'goodsmell': 15918, 'leacage': 15919, 'sodont': 15920, 'pocophone': 15921, 'productmost': 15922, 'watchnot': 15923, 'watchnotification': 15924, 'onceactivity': 15925, 'accurateand': 15926, 'worstplease': 15927, 'experiencestart': 15928, 'missingflipkart': 15929, 'filly': 15930, 'batterybut': 15931, 'discharging': 15932, 'ratingsplease': 15933, 'deeper': 15934, 'soundproofing': 15935, 'drown': 15936, 'murmurs': 15937, 'twist': 15938, 'defectiveplease': 15939, 'phonei': 15940, 'clothyou': 15941, 'onlinebad': 15942, 'backupworks': 15943, 'assembeld': 15944, 'disruption': 15945, 'roung': 15946, 'wattand': 15947, 'returnworst': 15948, 'cushionn': 15949, 'elbows': 15950, 'doubled': 15951, 'hospitalized': 15952, 'fevicol': 15953, 'mal': 15954, 'appointted': 15955, 'appoint': 15956, 'respo': 15957, 'prufier': 15958, 'productstopped': 15959, 'bedbrightnees': 15960, 'killed': 15961, 'displayyou': 15962, 'plzzz': 15963, 'powdered': 15964, 'steadily': 15965, 'parabolic': 15966, 'pcnot': 15967, 'descriptionbuilt': 15968, 'descriotionso': 15969, 'ourchase': 15970, 'expirence': 15971, 'dispatching': 15972, 'igot': 15973, 'workingwaste': 15974, 'nicemore': 15975, 'expectedno': 15976, 'horriblepicture': 15977, 'tvnot': 15978, 'channelremote': 15979, 'productplug': 15980, 'qualityeveryone': 15981, 'softnot': 15982, 'lam': 15983, 'mopper': 15984, 'sleeps': 15985, 'puncher': 15986, 'goodpoor': 15987, 'raha': 15988, 'smalli': 15989, 'denying': 15990, 'companyim': 15991, 'amazom': 15992, 'workingnot': 15993, 'troublei': 15994, 'picsplease': 15995, 'emptyeither': 15996, 'faultygreat': 15997, 'cartridgewhat': 15998, 'baker': 15999, 'speedso': 16000, 'extenderrepeater': 16001, 'servicedont': 16002, 'weso': 16003, 'vachhindhi': 16004, 'worrst': 16005, 'poorcalling': 16006, 'workingmic': 16007, 'flap': 16008, 'greenish': 16009, 'regretted': 16010, 'micno': 16011, 'tack': 16012, 'developed': 16013, 'systemdont': 16014, 'stripping': 16015, 'leaf': 16016, 'cornor': 16017, 'itworst': 16018, 'rog': 16019, 'connec': 16020, 'onlyi': 16021, 'itwithin': 16022, 'centers': 16023, 'chinanot': 16024, 'performanceslower': 16025, 'expecteddue': 16026, 'cfm': 16027, 'runningtechnician': 16028, 'resolvesucssion': 16029, 'leveloverall': 16030, 'tornednever': 16031, 'batchelors': 16032, 'satisfiedall': 16033, 'motive': 16034, 'january': 16035, 'fastrapid': 16036, 'refrain': 16037, 'der': 16038, 'wrists': 16039, 'holders': 16040, 'nottotal': 16041, 'moneynext': 16042, 'typeuseful': 16043, 'exast': 16044, 'watche': 16045, 'analogue': 16046, 'noyou': 16047, 'lifespan': 16048, 'lessif': 16049, 'flickering': 16050, 'unnecessarilyapps': 16051, 'ph': 16052, 'resistance': 16053, 'miror': 16054, 'deo': 16055, 'freshman': 16056, 'lever': 16057, 'bouls': 16058, 'earnestly': 16059, 'costworthless': 16060, 'daba': 16061, 'moneyregretting': 16062, 'conditionsonly': 16063, 'havels': 16064, 'purchage': 16065, 'knot': 16066, 'dhaga': 16067, 'crashes': 16068, 'gatya': 16069, 'patheticwork': 16070, 'orpat': 16071, 'vas': 16072, 'disappointingi': 16073, 'refrigeratorbut': 16074, 'monthfor': 16075, 'shameless': 16076, 'woundt': 16077, 'fortunately': 16078, 'timethen': 16079, 'noseits': 16080, 'ambipure': 16081, 'badpoor': 16082, 'recievedits': 16083, 'mountbut': 16084, 'poper': 16085, 'balancing': 16086, 'nonbendable': 16087, 'materialalso': 16088, 'frod': 16089, 'qualitywest': 16090, 'pakka': 16091, 'matchis': 16092, 'usr': 16093, 'ejected': 16094, 'diffective': 16095, 'aso': 16096, 'diffectivelast': 16097, 'machinethat': 16098, 'demothey': 16099, 'machineand': 16100, 'flipkartwaste': 16101, 'flipkartn': 16102, 'returnablewhich': 16103, 'selfnot': 16104, 'bealt': 16105, 'bakwassss': 16106, 'rmsonly': 16107, 'childsecond': 16108, 'lowdont': 16109, 'itdue': 16110, 'sleekno': 16111, 'ionizer': 16112, 'yetquick': 16113, 'flipkartmi': 16114, 'drainage': 16115, 'propar': 16116, 'bogus': 16117, 'reworks': 16118, 'badtwo': 16119, 'floskits': 16120, 'materia': 16121, 'hardor': 16122, 'possibilities': 16123, 'pusher': 16124, 'okbattery': 16125, 'superperformance': 16126, 'itempls': 16127, 'aply': 16128, 'someonce': 16129, 'throwen': 16130, 'pooralso': 16131, 'gyro': 16132, 'flipcarts': 16133, 'gms': 16134, 'companyotherwise': 16135, 'promoting': 16136, 'aquagaurd': 16137, 'abidas': 16138, 'poma': 16139, 'puma': 16140, 'skyland': 16141, 'visitation': 16142, 'unusually': 16143, 'idiot': 16144, 'productwire': 16145, 'badwast': 16146, 'itfirstly': 16147, 'reinstall': 16148, 'loli': 16149, 'hibernating': 16150, 'drunkedwork': 16151, 'betty': 16152, 'soal': 16153, 'productstaring': 16154, 'monthbetter': 16155, 'lickej': 16156, 'havey': 16157, 'foundthis': 16158, 'wellthere': 16159, 'worset': 16160, 'thisquality': 16161, 'recharging': 16162, 'chargedi': 16163, 'worsevery': 16164, 'throwing': 16165, 'productunfortunately': 16166, 'workingwadt': 16167, 'thete': 16168, 'callits': 16169, 'ftp': 16170, 'leakedalready': 16171, 'personif': 16172, 'workin': 16173, 'disappointedvery': 16174, 'wasteno': 16175, 'bakawas': 16176, 'sol': 16177, 'polithin': 16178, 'mixeris': 16179, 'performancescreen': 16180, 'referess': 16181, 'sizelike': 16182, 'toyif': 16183, 'thisthey': 16184, 'properlyunable': 16185, 'playstuff': 16186, 'plasticits': 16187, 'playingmoney': 16188, 'aither': 16189, 'shinex': 16190, 'canector': 16191, 'weakness': 16192, 'rotede': 16193, 'andbut': 16194, 'creat': 16195, 'presses': 16196, 'brokened': 16197, 'properlyit': 16198, 'nod': 16199, 'boxreally': 16200, 'deserted': 16201, 'pcdont': 16202, 'hundreds': 16203, 'maybelline': 16204, 'colossal': 16205, 'hearts': 16206, 'gyuz': 16207, 'lvl': 16208, 'qualitydoes': 16209, 'correctlydont': 16210, 'pitunia': 16211, 'merigold': 16212, 'sungold': 16213, 'exceletly': 16214, 'betar': 16215, 'aligned': 16216, 'germinates': 16217, 'refillable': 16218, 'isko': 16219, 'shadowed': 16220, 'telecom': 16221, 'providers': 16222, 'vodafone': 16223, 'monthspigeon': 16224, 'poorbad': 16225, 'productover': 16226, 'retune': 16227, 'tries': 16228, 'hide': 16229, 'conditiongood': 16230, 'qualitydid': 16231, 'explains': 16232, 'waykudos': 16233, 'contained': 16234, 'biiiggg': 16235, 'flibcard': 16236, 'merge': 16237, 'refurbished': 16238, 'inconsistent': 16239, 'tubeplease': 16240, 'qualitydisappointed': 16241, 'questionanswers': 16242, 'decapitated': 16243, 'qualitystuffed': 16244, 'clothnd': 16245, 'goodok': 16246, 'connectiona': 16247, 'casemi': 16248, 'matte': 16249, 'amazingbetter': 16250, 'optionthe': 16251, 'issueafter': 16252, 'deduct': 16253, 'flipkirtnice': 16254, 'flipkirt': 16255, 'persale': 16256, 'electricals': 16257, 'enquiry': 16258, 'issued': 16259, 'cheeter': 16260, 'damadge': 16261, 'methods': 16262, 'offon': 16263, 'cardbord': 16264, 'expectedextra': 16265, 'erning': 16266, 'statergy': 16267, 'pedometer': 16268, 'secnds': 16269, 'lagsdisappointed': 16270, 'satisfiedwashing': 16271, 'lair': 16272, 'aney': 16273, 'chiper': 16274, 'installationbetter': 16275, 'boxits': 16276, 'fiti': 16277, 'unwancise': 16278, 'describegreat': 16279, 'deliverydelivery': 16280, 'precautionsfully': 16281, 'maturely': 16282, 'bewareupdatedworst': 16283, 'contacting': 16284, 'productsmaller': 16285, 'sizefabric': 16286, 'hangingover': 16287, 'gijer': 16288, 'machinebuy': 16289, 'ittry': 16290, 'itnever': 16291, 'baja': 16292, 'ota': 16293, 'thiz': 16294, 'motorstill': 16295, 'thizz': 16296, 'lightworest': 16297, 'bakwwwas': 16298, 'operatingalso': 16299, 'plasticss': 16300, 'difficulties': 16301, 'gameing': 16302, 'describing': 16303, 'differenttheres': 16304, 'manualit': 16305, 'bulk': 16306, 'itrubbish': 16307, 'qualityitem': 16308, 'damagedquality': 16309, 'matchpicture': 16310, 'tvmost': 16311, 'compactits': 16312, 'restrict': 16313, 'constitute': 16314, 'gudbt': 16315, 'fixedreally': 16316, 'relacement': 16317, 'passedwasted': 16318, 'snapdeal': 16319, 'ideas': 16320, 'sponsored': 16321, 'freshener': 16322, 'bakwass': 16323, 'teddy': 16324, 'highnot': 16325, 'paidnot': 16326, 'damagerepair': 16327, 'soim': 16328, 'didint': 16329, 'timestoday': 16330, 'tvdish': 16331, 'upsupport': 16332, 'aromatic': 16333, 'beekaar': 16334, 'tvlipsing': 16335, 'characters': 16336, 'audiopicture': 16337, 'poorhad': 16338, 'tvbetter': 16339, 'purity': 16340, 'calibrated': 16341, 'testi': 16342, 'evernot': 16343, 'boli': 16344, 'milkthis': 16345, 'boling': 16346, 'onlyexcessive': 16347, 'alsowaste': 16348, 'goodcannot': 16349, 'disappointeddesign': 16350, 'ahhhh': 16351, 'mobiledont': 16352, 'prosbuild': 16353, 'excellentfan': 16354, 'phenomenalwater': 16355, 'tanknoise': 16356, 'acceptableair': 16357, 'sharpwheels': 16358, 'enoughvalue': 16359, 'recommendedconspackaging': 16360, 'betterdelivery': 16361, 'longmore': 16362, 'daysbehavior': 16363, 'illiteraterobberwas': 16364, 'misprints': 16365, 'morninghope': 16366, 'redone': 16367, 'sizecooling': 16368, 'badit': 16369, 'sizealso': 16370, 'delievered': 16371, 'specificationssize': 16372, 'sizerecommend': 16373, 'thistotal': 16374, 'fluctuate': 16375, 'feild': 16376, 'dragging': 16377, 'wastequickly': 16378, 'teami': 16379, 'clarification': 16380, 'yearissue': 16381, 'twisted': 16382, 'skins': 16383, 'sarkit': 16384, 'problam': 16385, 'brandthere': 16386, 'tipping': 16387, 'razor': 16388, 'raff': 16389, 'fartouch': 16390, 'avadi': 16391, 'incompetent': 16392, 'advising': 16393, 'standardwashers': 16394, 'monthblaid': 16395, 'workingone': 16396, 'computeryou': 16397, 'mbpsgot': 16398, 'dive': 16399, 'downtime': 16400, 'packer': 16401, 'partion': 16402, 'quelety': 16403, 'overl': 16404, 'motornow': 16405, 'abnormally': 16406, 'lw': 16407, 'adapterbox': 16408, 'applegot': 16409, 'cheatedand': 16410, 'retunable': 16411, 'qualitypoor': 16412, 'comany': 16413, 'refundable': 16414, 'installetion': 16415, 'hurried': 16416, 'mortime': 16417, 'soundit': 16418, 'tied': 16419, 'renesa': 16420, 'magnets': 16421, 'forbes': 16422, 'hurtful': 16423, 'darty': 16424, 'colr': 16425, 'unbelievably': 16426, 'thingnot': 16427, 'defectiveslow': 16428, 'problemproduct': 16429, 'waiste': 16430, 'nord': 16431, 'boual': 16432, 'terminal': 16433, 'lenth': 16434, 'petal': 16435, 'iltt': 16436, 'systemhe': 16437, 'stabilitylong': 16438, 'backupmaximum': 16439, 'losses': 16440, 'supplyidle': 16441, 'wattsi': 16442, 'homejust': 16443, 'upsswitch': 16444, 'precaution': 16445, 'tvset': 16446, 'img': 16447, 'germinatedl': 16448, 'causal': 16449, 'remotelike': 16450, 'alllet': 16451, 'clarifyflipkarts': 16452, 'hourswhich': 16453, 'nightmarei': 16454, 'undrinkable': 16455, 'collapsed': 16456, 'uncontrollable': 16457, 'justifiable': 16458, 'spinner': 16459, 'brokedlooks': 16460, 'bowlplz': 16461, 'speeddont': 16462, 'thisss': 16463, 'associated': 16464, 'arroganthe': 16465, 'moneyhe': 16466, 'expectationpoor': 16467, 'micis': 16468, 'nutbold': 16469, 'deallooks': 16470, 'decentit': 16471, 'okmiddle': 16472, 'paan': 16473, 'scolded': 16474, 'requi': 16475, 'qualityyes': 16476, 'toomilk': 16477, 'batbroken': 16478, 'markwaste': 16479, 'weeksmost': 16480, 'workthe': 16481, 'padhonestlya': 16482, 'unmanted': 16483, 'fedup': 16484, 'exchanging': 16485, 'againit': 16486, 'mar': 16487, 'consfm': 16488, 'poorpronshigh': 16489, 'qualityaverage': 16490, 'wort': 16491, 'fregence': 16492, 'wastee': 16493, 'cords': 16494, 'coulatiy': 16495, 'joins': 16496, 'responsei': 16497, 'itemi': 16498, 'proformation': 16499, 'proser': 16500, 'atteched': 16501, 'plywood': 16502, 'painted': 16503, 'hooks': 16504, 'expectable': 16505, 'flipkartworst': 16506, 'brandplease': 16507, 'vensa': 16508, 'nakes': 16509, 'pati': 16510, 'sari': 16511, 'nhati': 16512, 'problemmoter': 16513, 'atombergi': 16514, 'origional': 16515, 'dants': 16516, 'qoaliti': 16517, 'stoppee': 16518, 'buyit': 16519, 'modeli': 16520, 'onand': 16521, 'timei': 16522, 'amazons': 16523, 'productapp': 16524, 'infoi': 16525, 'garanteed': 16526, 'crayon': 16527, 'cwalty': 16528, 'beco': 16529, 'bbk': 16530, 'longprosnilconsider': 16531, 'cabul': 16532, 'aapyou': 16533, 'alsomy': 16534, 'giliter': 16535, 'stitchingbut': 16536, 'nicebetter': 16537, 'guysif': 16538, 'perfecti': 16539, 'yearim': 16540, 'filtrationi': 16541, 'moneydoes': 16542, 'depands': 16543, 'supplyif': 16544, 'corruptedwasted': 16545, 'daysfan': 16546, 'lowwasted': 16547, 'chimny': 16548, 'excerpted': 16549, 'waterpoof': 16550, 'nickl': 16551, 'flikart': 16552, 'retun': 16553, 'itemno': 16554, 'giventotal': 16555, 'pictureplease': 16556, 'damged': 16557, 'produtmust': 16558, 'changer': 16559, 'stupidity': 16560, 'supervise': 16561, 'aqlso': 16562, 'stared': 16563, 'pricking': 16564, 'moneywatch': 16565, 'machinewas': 16566, 'expectbetter': 16567, 'untrained': 16568, 'nightmarish': 16569, 'abundance': 16570, 'voltus': 16571, 'coleti': 16572, 'beyd': 16573, 'cartriage': 16574, 'smail': 16575, 'trees': 16576, 'overrated': 16577, 'coveragerange': 16578, 'mart': 16579, 'productwhat': 16580, 'differentfirst': 16581, 'waest': 16582, 'poorest': 16583, 'lick': 16584, 'businessfrankly': 16585, 'colorflipkart': 16586, 'vendoryou': 16587, 'vendorspathetic': 16588, 'moneyafter': 16589, 'jerminatewaste': 16590, 'withering': 16591, 'vapour': 16592, 'germinationedit': 16593, 'transplanting': 16594, 'potting': 16595, 'teashirt': 16596, 'cleard': 16597, 'tvalso': 16598, 'uialso': 16599, 'reameui': 16600, 'disable': 16601, 'workingat': 16602, 'weekvery': 16603, 'experienceagro': 16604, 'attemp': 16605, 'butterflyit': 16606, 'unhealthy': 16607, 'runned': 16608, 'unlink': 16609, 'reports': 16610, 'configuring': 16611, 'pops': 16612, 'performancerunning': 16613, 'donoy': 16614, 'tvmiracast': 16615, 'hardground': 16616, 'barefoot': 16617, 'halwa': 16618, 'stuffing': 16619, 'bladeattachment': 16620, 'excuse': 16621, 'rejectedthis': 16622, 'blended': 16623, 'reconsider': 16624, 'dayupdate': 16625, 'furnitures': 16626, 'ketal': 16627, 'favourable': 16628, 'accssories': 16629, 'embroidary': 16630, 'lazythey': 16631, 'addressit': 16632, 'mocking': 16633, 'teat': 16634, 'jogger': 16635, 'losen': 16636, 'buyno': 16637, 'policycheated': 16638, 'plasticthis': 16639, 'flowing': 16640, 'conect': 16641, 'bowels': 16642, 'dayskeys': 16643, 'backspace': 16644, 'deletes': 16645, 'presstyping': 16646, 'moneydo': 16647, 'jkwalit': 16648, 'properlyno': 16649, 'sendcharging': 16650, 'wheezing': 16651, 'antipollen': 16652, 'alsosatisfied': 16653, 'delhincr': 16654, 'fillter': 16655, 'dischage': 16656, 'empowerment': 16657, 'conduct': 16658, 'winding': 16659, 'demiz': 16660, 'monthsnot': 16661, 'soonproblems': 16662, 'beginningnot': 16663, 'dbwaste': 16664, 'parwaste': 16665, 'weightrods': 16666, 'dummy': 16667, 'noose': 16668, 'pleasedont': 16669, 'senttesting': 16670, 'kitafter': 16671, 'productdamage': 16672, 'buyturn': 16673, 'thenpurpose': 16674, 'productrunning': 16675, 'tyte': 16676, 'gyrinder': 16677, 'outuseless': 16678, 'gotand': 16679, 'flipt': 16680, 'cardfinally': 16681, 'hend': 16682, 'lowwithin': 16683, 'dischargedam': 16684, 'lenovofor': 16685, 'discharged': 16686, 'fastlyif': 16687, 'flutters': 16688, 'markget': 16689, 'rsso': 16690, 'priceon': 16691, 'goodmachine': 16692, 'inrwhite': 16693, 'disturbes': 16694, 'stunned': 16695, 'minitheaterlike': 16696, 'knives': 16697, 'fabrics': 16698, 'restore': 16699, 'weaste': 16700, 'smoking': 16701, 'attaches': 16702, 'usefuldue': 16703, 'pepsi': 16704, 'badeven': 16705, 'goodsoso': 16706, 'clearyou': 16707, 'toothen': 16708, 'machinekindly': 16709, 'twojar': 16710, 'flipcartthis': 16711, 'soff': 16712, 'minuterarely': 16713, 'goodstand': 16714, 'manjeera': 16715, 'volcano': 16716, 'faalthlooo': 16717, 'lowworthless': 16718, 'iske': 16719, 'myth': 16720, 'perception': 16721, 'properlyi': 16722, 'ragi': 16723, 'java': 16724, 'tollfree': 16725, 'applicableso': 16726, 'goodspeaker': 16727, 'goodotherwise': 16728, 'tvwastage': 16729, 'properlyvery': 16730, 'geaser': 16731, 'sucking': 16732, 'weeping': 16733, 'bassgood': 16734, 'basssmall': 16735, 'sinciarly': 16736, 'banglorebuy': 16737, 'rectifying': 16738, 'buyersthanks': 16739, 'cudnt': 16740, 'wud': 16741, 'threw': 16742, 'homejio': 16743, 'highqwality': 16744, 'havenbut': 16745, 'varanty': 16746, 'whiledont': 16747, 'weightbaby': 16748, 'diving': 16749, 'cardnot': 16750, 'brochure': 16751, 'qualitypl': 16752, 'bluring': 16753, 'duringvusage': 16754, 'offit': 16755, 'drama': 16756, 'outthe': 16757, 'persist': 16758, 'flame': 16759, 'lining': 16760, 'discolouring': 16761, 'bottomhonestlyits': 16762, 'emptyso': 16763, 'solvent': 16764, 'goodspacious': 16765, 'deliverymarq': 16766, 'pinvalve': 16767, 'wibe': 16768, 'revolving': 16769, 'freshner': 16770, 'expectabland': 16771, 'flupkart': 16772, 'unbending': 16773, 'straighti': 16774, 'heppi': 16775, 'supportwaste': 16776, 'banned': 16777, 'vendors': 16778, 'manipulating': 16779, 'cahrger': 16780, 'revitel': 16781, 'quicklysuction': 16782, 'acarding': 16783, 'whirring': 16784, 'bharathi': 16785, 'kents': 16786, 'jayanagar': 16787, 'constraints': 16788, 'dayif': 16789, 'locally': 16790, 'workingtank': 16791, 'oligodynamic': 16792, 'ion': 16793, 'disinfectant': 16794, 'agodidnt': 16795, 'insulationno': 16796, 'installationdont': 16797, 'problemm': 16798, 'gat': 16799, 'ipl': 16800, 'itaft': 16801, 'dissopointed': 16802, 'stitched': 16803, 'teaster': 16804, 'stiffit': 16805, 'dusting': 16806, 'rivet': 16807, 'monthpls': 16808, 'playstorewhat': 16809, 'linking': 16810, 'buysearch': 16811, 'roughed': 16812, 'buyhot': 16813, 'buybe': 16814, 'somthing': 16815, 'dots': 16816, 'wase': 16817, 'pricedesign': 16818, 'extheater': 16819, 'carefullydial': 16820, 'badpros': 16821, 'shakingfull': 16822, 'productsfack': 16823, 'ony': 16824, 'lifedisappointed': 16825, 'watever': 16826, 'satsify': 16827, 'exceptable': 16828, 'memories': 16829, 'demolished': 16830, 'proceeded': 16831, 'productsi': 16832, 'irritates': 16833, 'spoils': 16834, 'unfair': 16835, 'tr': 16836, 'pratanu': 16837, 'otherthe': 16838, 'sheered': 16839, 'inoperable': 16840, 'problemvery': 16841, 'recorder': 16842, 'records': 16843, 'glitched': 16844, 'fluxy': 16845, 'edi': 16846, 'machinepoor': 16847, 'servicesmachine': 16848, 'sectionmotor': 16849, 'yearspoor': 16850, 'partsvery': 16851, 'parfomase': 16852, 'functionally': 16853, 'vertical': 16854, 'upward': 16855, 'wantvertical': 16856, 'uselesswater': 16857, 'jug': 16858, 'cube': 16859, 'instantlyit': 16860, 'bulge': 16861, 'muchbut': 16862, 'percentage': 16863, 'productsthis': 16864, 'boilbut': 16865, 'gurd': 16866, 'screenlow': 16867, 'phoneand': 16868, 'feath': 16869, 'lessit': 16870, 'vechlo': 16871, 'moths': 16872, 'dispense': 16873, 'combnot': 16874, 'airnot': 16875, 'summerjust': 16876, 'piecenot': 16877, 'kraft': 16878, 'thisbut': 16879, 'provoding': 16880, 'hanf': 16881, 'tvneed': 16882, 'stablizer': 16883, 'suport': 16884, 'spite': 16885, 'uploading': 16886, 'imagethe': 16887, 'positivewhich': 16888, 'moneyp': 16889, 'mbpsi': 16890, 'providerand': 16891, 'wasteits': 16892, 'alsomobile': 16893, 'disappointedi': 16894, 'trable': 16895, 'effectswe': 16896, 'hrsbut': 16897, 'wested': 16898, 'injured': 16899, 'handil': 16900, 'stikar': 16901, 'installationvery': 16902, 'uncooperative': 16903, 'staffnot': 16904, 'orginalhappy': 16905, 'marron': 16906, 'podac': 16907, 'watermilk': 16908, 'badmoney': 16909, 'alaram': 16910, 'highedit': 16911, 'monthvery': 16912, 'poar': 16913, 'piz': 16914, 'pafu': 16915, 'onlai': 16916, 'pafue': 16917, 'pore': 16918, 'satifactory': 16919, 'speedlyit': 16920, 'fungus': 16921, 'blootooth': 16922, 'xerox': 16923, 'catridges': 16924, 'oook': 16925, 'comeas': 16926, 'monthsexcellent': 16927, 'firstwash': 16928, 'accident': 16929, 'flamingo': 16930, 'sizeand': 16931, 'bestsellersgood': 16932, 'infinixgo': 16933, 'augustluckily': 16934, 'soundwhy': 16935, 'knowit': 16936, 'confusedrest': 16937, 'fata': 16938, 'comfert': 16939, 'ligth': 16940, 'adjustinfolding': 16941, 'topple': 16942, 'stat': 16943, 'soundcomfortable': 16944, 'airon': 16945, 'averagenext': 16946, 'wost': 16947, 'fff': 16948, 'alread': 16949, 'wandar': 16950, 'averege': 16951, 'ladt': 16952, 'amezzingggg': 16953, 'bcos': 16954, 'expectationsbcos': 16955, 'deliveries': 16956, 'levelsnow': 16957, 'investigation': 16958, 'streamingbut': 16959, 'kj': 16960, 'presentations': 16961, 'microseconds': 16962, 'observedall': 16963, 'youtub': 16964, 'anycast': 16965, 'incheslittle': 16966, 'worda': 16967, 'gpurchase': 16968, 'blindlyyou': 16969, 'regretthe': 16970, 'brushing': 16971, 'noticedthough': 16972, 'finishingits': 16973, 'amit': 16974, 'productslightly': 16975, 'aquaguard': 16976, 'smallthats': 16977, 'expetance': 16978, 'greatperformance': 16979, 'badfuse': 16980, 'automaticallyi': 16981, 'asusual': 16982, 'grest': 16983, 'amazingbut': 16984, 'dinesh': 16985, 'tublar': 16986, 'flawlesslybackup': 16987, 'hidden': 16988, 'itall': 16989, 'pending': 16990, 'appbut': 16991, 'ifor': 16992, 'doft': 16993, 'growswaste': 16994, 'coughingi': 16995, 'thiseven': 16996, 'quicklyi': 16997, 'filterdid': 16998, 'mecaused': 16999, 'brokr': 17000, 'lessits': 17001, 'excellentthanks': 17002, 'ua': 17003, 'descibe': 17004, 'smallsize': 17005, 'cater': 17006, 'sinewavae': 17007, 'switcover': 17008, 'byy': 17009, 'seel': 17010, 'explanationsome': 17011, 'questionless': 17012, 'averagefan': 17013, 'itcooling': 17014, 'tankthe': 17015, 'flyp': 17016, 'deferent': 17017, 'smalll': 17018, 'disposable': 17019, 'netter': 17020, 'jamming': 17021, 'reportcertificate': 17022, 'packagingi': 17023, 'bekar': 17024, 'victus': 17025, 'thingsthere': 17026, 'scanner': 17027, 'fitits': 17028, 'mountjust': 17029, 'happyi': 17030, 'optiondelivery': 17031, 'targeting': 17032, 'rubbered': 17033, 'therecheap': 17034, 'readingwhen': 17035, 'curved': 17036, 'assom': 17037, 'owing': 17038, 'veryr': 17039, 'thare': 17040, 'acceseries': 17041, 'qualityok': 17042, 'mkv': 17043, 'tared': 17044, 'widest': 17045, 'gram': 17046, 'midiyam': 17047, 'buti': 17048, 'notmy': 17049, 'stickn': 17050, 'vh': 17051, 'ggji': 17052, 'cure': 17053, 'levelam': 17054, 'byatari': 17055, 'suber': 17056, 'hourssound': 17057, 'kurava': 17058, 'satisfiedtakes': 17059, 'ticked': 17060, 'noquality': 17061, 'nothingno': 17062, 'maskno': 17063, 'worstwithin': 17064, 'completlydoes': 17065, 'messing': 17066, 'booksit': 17067, 'surfaceif': 17068, 'drumoverall': 17069, 'avearge': 17070, 'sensory': 17071, 'damagedvery': 17072, 'swich': 17073, 'ballbut': 17074, 'smaallll': 17075, 'progress': 17076, 'died': 17077, 'bruised': 17078, 'lokking': 17079, 'jobyou': 17080, 'sometging': 17081, 'overalls': 17082, 'pressurely': 17083, 'perfectstill': 17084, 'poir': 17085, 'handi': 17086, 'backupalthough': 17087, 'whild': 17088, 'hepiness': 17089, 'sastified': 17090, 'hotter': 17091, 'indicated': 17092, 'wakar': 17093, 'coloursome': 17094, 'propely': 17095, 'mebut': 17096, 'standardbhavna': 17097, 'agian': 17098, 'dart': 17099, 'traprealme': 17100, 'brandsvery': 17101, 'goodtake': 17102, 'overally': 17103, 'fittingshandy': 17104, 'ongood': 17105, 'productsucking': 17106, 'awsomewell': 17107, 'packedbit': 17108, 'delivey': 17109, 'puncturedit': 17110, 'sut': 17111, 'complicatedho': 17112, 'yetthax': 17113, 'noi': 17114, 'telephoto': 17115, 'chiep': 17116, 'fraudient': 17117, 'rangegood': 17118, 'kasa': 17119, 'goodwant': 17120, 'catarge': 17121, 'inernal': 17122, 'betterit': 17123, 'snapdealthe': 17124, 'oko': 17125, 'goodrevital': 17126, 'supplement': 17127, 'capsulesrevital': 17128, 'capsuleslaksh': 17129, 'slownot': 17130, 'onley': 17131, 'fet': 17132, 'ultraekart': 17133, 'nonsense': 17134, 'bead': 17135, 'ocks': 17136, 'cussion': 17137, 'timeinstalling': 17138, 'conditionvalue': 17139, 'moneyworthy': 17140, 'badbut': 17141, 'improvementeg': 17142, 'wkg': 17143, 'hesotation': 17144, 'chap': 17145, 'matarial': 17146, 'timers': 17147, 'parking': 17148, 'lighted': 17149, 'everyonethere': 17150, 'assisting': 17151, 'frameweather': 17152, 'pulled': 17153, 'stripe': 17154, 'bada': 17155, 'dhamaka': 17156, 'okpu': 17157, 'meterialonly': 17158, 'compartmentzip': 17159, 'smoothso': 17160, 'stumpher': 17161, 'stumphar': 17162, 'toe': 17163, 'besf': 17164, 'chape': 17165, 'lockal': 17166, 'goodcamera': 17167, 'isu': 17168, 'splitted': 17169, 'slowgrinding': 17170, 'typeprice': 17171, 'littel': 17172, 'fantasticbut': 17173, 'defaulty': 17174, 'noicey': 17175, 'daliveri': 17176, 'soundhard': 17177, 'wtnot': 17178, 'booys': 17179, 'muchrequiring': 17180, 'frengase': 17181, 'collecter': 17182, 'feather': 17183, 'clot': 17184, 'okego': 17185, 'prablam': 17186, 'proswell': 17187, 'okcloth': 17188, 'firs': 17189, 'useplz': 17190, 'freshnes': 17191, 'nowbattery': 17192, 'timeskeyboard': 17193, 'topprocessor': 17194, 'obliviously': 17195, 'codpubg': 17196, 'perfectit': 17197, 'rangewebcam': 17198, 'conwith': 17199, 'catridge': 17200, 'wastedlost': 17201, 'pincodes': 17202, 'oprate': 17203, 'vertically': 17204, 'afriad': 17205, 'satisfiedwas': 17206, 'toasted': 17207, 'voids': 17208, 'netflixs': 17209, 'yetbrightness': 17210, 'weired': 17211, 'primitive': 17212, 'clouth': 17213, 'originalquality': 17214, 'prescription': 17215, 'eng': 17216, 'acknowledgement': 17217, 'pinlight': 17218, 'gsm': 17219, 'cookingso': 17220, 'panasonichavells': 17221, 'rupaye': 17222, 'fevicolthe': 17223, 'playingand': 17224, 'dist': 17225, 'mediam': 17226, 'qood': 17227, 'bkwas': 17228, 'comleted': 17229, 'bulew': 17230, 'corgi': 17231, 'exepted': 17232, 'zeb': 17233, 'activation': 17234, 'validwaste': 17235, 'garminate': 17236, 'bassvalue': 17237, 'costley': 17238, 'amazingget': 17239, 'gyz': 17240, 'untold': 17241, 'niccc': 17242, 'fineworth': 17243, 'bottomwant': 17244, 'varying': 17245, 'seasonthere': 17246, 'givenfor': 17247, 'itrest': 17248, 'veriety': 17249, 'priceplanted': 17250, 'perfectonly': 17251, 'ballgood': 17252, 'avearage': 17253, 'booka': 17254, 'avrrage': 17255, 'muchotherwise': 17256, 'browse': 17257, 'nicebecause': 17258, 'badnice': 17259, 'scrathes': 17260, 'dood': 17261, 'digit': 17262, 'microfibre': 17263, 'clothits': 17264, 'vacation': 17265, 'ashok': 17266, 'laptopdont': 17267, 'discribed': 17268, 'shankarling': 17269, 'kadganchi': 17270, 'rajesh': 17271, 'excellentbut': 17272, 'powerbatrery': 17273, 'ending': 17274, 'thikthak': 17275, 'bended': 17276, 'qualitymaximum': 17277, 'spacy': 17278, 'dueto': 17279, 'completedi': 17280, 'customercare': 17281, 'rsnound': 17282, 'avrege': 17283, 'helful': 17284, 'awesomethis': 17285, 'smallespecially': 17286, 'ataa': 17287, 'workingby': 17288, 'hhh': 17289, 'pdt': 17290, 'lass': 17291, 'slipper': 17292, 'ridinggives': 17293, 'offter': 17294, 'shoo': 17295, 'heavyhard': 17296, 'airbecause': 17297, 'handsother': 17298, 'slowing': 17299, 'homebut': 17300, 'marketat': 17301, 'suremay': 17302, 'goodlarge': 17303, 'coverageeasy': 17304, 'tarmac': 17305, 'pllastic': 17306, 'thiknes': 17307, 'minnothing': 17308, 'chalebul': 17309, 'pana': 17310, 'madhri': 17311, 'irundhuchu': 17312, 'directlyi': 17313, 'dol': 17314, 'amzngg': 17315, 'qualitty': 17316, 'goodlot': 17317, 'butterflys': 17318, 'muccard': 17319, 'broblem': 17320, 'expetected': 17321, 'shabby': 17322, 'unstitched': 17323, 'avareage': 17324, 'flufy': 17325, 'wounder': 17326, 'verson': 17327, 'tats': 17328, 'spaceeasy': 17329, 'reflex': 17330, 'negligence': 17331, 'qualitylove': 17332, 'perice': 17333, 'utilised': 17334, 'trivandrum': 17335, 'jam': 17336, 'westage': 17337, 'okayishdrain': 17338, 'usebottle': 17339, 'inflation': 17340, 'studs': 17341, 'happend': 17342, 'generate': 17343, 'reportcustomer': 17344, 'entertain': 17345, 'kichian': 17346, 'tan': 17347, 'pproduct': 17348, 'sugesstion': 17349, 'potentiol': 17350, 'averag': 17351, 'tangling': 17352, 'troubles': 17353, 'fadu': 17354, 'finenfor': 17355, 'throughing': 17356, 'ferfect': 17357, 'tayer': 17358, 'enarji': 17359, 'woodjust': 17360, 'justifying': 17361, 'towel': 17362, 'rotational': 17363, 'glued': 17364, 'chipper': 17365, 'coolis': 17366, 'niceok': 17367, 'lengths': 17368, 'triangle': 17369, 'unfortunate': 17370, 'technological': 17371, 'advancements': 17372, 'badhe': 17373, 'espected': 17374, 'elergy': 17375, 'thinkbut': 17376, 'repairedbut': 17377, 'playgrounds': 17378, 'sepcifically': 17379, 'muchrealme': 17380, 'fetures': 17381, 'appo': 17382, 'rufunds': 17383, 'flown': 17384, 'concentratori': 17385, 'patientoxigen': 17386, 'peopleoxigen': 17387, 'cylender': 17388, 'peopledont': 17389, 'helpif': 17390, 'verrygood': 17391, 'leveland': 17392, 'rouderporikibad': 17393, 'behaviorworst': 17394, 'indolium': 17395, 'wrongplease': 17396, 'quali': 17397, 'ped': 17398, 'badbad': 17399, 'needfull': 17400, 'websitesif': 17401, 'packingbad': 17402, 'classworst': 17403, 'whisker': 17404, 'bigsound': 17405, 'slowwaste': 17406, 'typs': 17407, 'meltedbrokederoded': 17408, 'highbutafterall': 17409, 'likej': 17410, 'rims': 17411, 'unpleasant': 17412, 'torned': 17413, 'usefulquality': 17414}\n"
     ]
    }
   ],
   "source": [
    "data_process = process_data(12, 35000, 768)\n",
    "print(data_process[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "import numpy as np\n",
    "\n",
    "# Custom dataset class for loading and accessing the data for sentiment analysis\n",
    "class MyData(torch.utils.data.Dataset):\n",
    "    def __init__(self, dt, lb):\n",
    "        # Initialize the dataset with data (dt) and labels (lb)\n",
    "        self.dt = dt  # Data (input sentences, each represented by indices of words)\n",
    "        self.lb = lb  # Labels (sentiment labels for each sentence)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples in the dataset\n",
    "        return len(self.dt)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Return the label and data (sentence) at the given index\n",
    "        # Convert the data (sentence) to a numpy array and return it with the corresponding label\n",
    "        return self.lb[index], np.array(self.dt[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1 loss: 1.223637580871582\n",
      "class 0: acc 0.3438, precision 0.6250, recall 0.2174, f1 0.3226\n",
      "class 1: acc 0.4062, precision 0.2174, recall 0.8333, f1 0.3448\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 2 loss: 0.42308491468429565\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 3 loss: 0.6227771639823914\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 4 loss: 0.3275566101074219\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 5 loss: 0.5609424114227295\n",
      "class 0: acc 0.7812, precision 0.7812, recall 1.0000, f1 0.8772\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 6 loss: 0.6711332201957703\n",
      "class 0: acc 0.7188, precision 0.7188, recall 1.0000, f1 0.8364\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 7 loss: 0.4229479134082794\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 8 loss: 0.3376556932926178\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 9 loss: 0.5594401955604553\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 10 loss: 0.6454129815101624\n",
      "class 0: acc 0.7812, precision 0.7812, recall 1.0000, f1 0.8772\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 11 loss: 0.5727181434631348\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 12 loss: 0.387626975774765\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 13 loss: 0.5332291126251221\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 14 loss: 0.6466334462165833\n",
      "class 0: acc 0.7500, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 15 loss: 0.4163975119590759\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 16 loss: 0.36982670426368713\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 17 loss: 0.6828209161758423\n",
      "class 0: acc 0.6875, precision 0.6875, recall 1.0000, f1 0.8148\n",
      "class 1: acc 0.7188, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 18 loss: 0.5434849858283997\n",
      "class 0: acc 0.7812, precision 0.8065, recall 0.9615, f1 0.8772\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 19 loss: 0.7179356813430786\n",
      "class 0: acc 0.7188, precision 0.7419, recall 0.9583, f1 0.8364\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 20 loss: 0.4198693335056305\n",
      "class 0: acc 0.8750, precision 0.9600, recall 0.8889, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 21 loss: 0.47659361362457275\n",
      "class 0: acc 0.8750, precision 0.9167, recall 0.9167, f1 0.9167\n",
      "class 1: acc 0.9375, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 22 loss: 0.3213387727737427\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 23 loss: 0.39201080799102783\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 24 loss: 0.45003432035446167\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 25 loss: 0.4323963224887848\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 26 loss: 0.36458227038383484\n",
      "class 0: acc 0.9375, precision 0.9200, recall 1.0000, f1 0.9583\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 27 loss: 0.4695276916027069\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 28 loss: 0.3103325366973877\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 29 loss: 0.5624176859855652\n",
      "class 0: acc 0.7812, precision 0.8077, recall 0.9130, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 30 loss: 0.372759610414505\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 31 loss: 0.6441639065742493\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 32 loss: 0.40920290350914\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 33 loss: 0.537903904914856\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 34 loss: 0.4195035696029663\n",
      "class 0: acc 0.8125, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 35 loss: 0.3815374970436096\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 36 loss: 0.25484707951545715\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 37 loss: 0.46597108244895935\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 38 loss: 0.26474669575691223\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 39 loss: 0.6269974708557129\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 40 loss: 0.19597601890563965\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 41 loss: 0.710530698299408\n",
      "class 0: acc 0.7812, precision 0.8065, recall 0.9615, f1 0.8772\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 42 loss: 0.605985701084137\n",
      "class 0: acc 0.7188, precision 0.7188, recall 1.0000, f1 0.8364\n",
      "class 1: acc 0.7188, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 43 loss: 0.31591302156448364\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 44 loss: 0.46337416768074036\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 45 loss: 0.264945387840271\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 46 loss: 0.45847657322883606\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 47 loss: 0.4688347578048706\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.7812, precision 1.0000, recall 0.3636, f1 0.5333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 48 loss: 0.4713304936885834\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 49 loss: 0.5012609362602234\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 50 loss: 0.3607615828514099\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 51 loss: 0.2684701085090637\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8966, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 52 loss: 0.5467700362205505\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 53 loss: 0.3887464702129364\n",
      "class 0: acc 0.8750, precision 0.9643, recall 0.9000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 54 loss: 0.34017592668533325\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 55 loss: 0.28478243947029114\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 56 loss: 0.3058655261993408\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 57 loss: 0.14477035403251648\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 58 loss: 0.6028068661689758\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 59 loss: 0.6085606217384338\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 60 loss: 0.7853721380233765\n",
      "class 0: acc 0.7500, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 61 loss: 0.6190299987792969\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 62 loss: 0.37719103693962097\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 63 loss: 0.755277693271637\n",
      "class 0: acc 0.7500, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 64 loss: 0.48637285828590393\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 65 loss: 0.5194551944732666\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 66 loss: 0.4631572663784027\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 67 loss: 0.386838436126709\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 68 loss: 0.3959108591079712\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 69 loss: 0.42721107602119446\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 70 loss: 0.4789339303970337\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 71 loss: 0.4634052813053131\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 72 loss: 0.4224779009819031\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 73 loss: 0.4407157897949219\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 74 loss: 0.5822362899780273\n",
      "class 0: acc 0.8125, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.2000, recall 0.3333, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 75 loss: 0.5840083956718445\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 76 loss: 0.3519050180912018\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 77 loss: 0.41782209277153015\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 78 loss: 0.45346829295158386\n",
      "class 0: acc 0.8438, precision 0.9000, recall 0.9310, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 79 loss: 0.38122284412384033\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 80 loss: 0.5154209136962891\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 81 loss: 0.5125699639320374\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 82 loss: 0.3683028817176819\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 83 loss: 0.13455523550510406\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 84 loss: 0.46045026183128357\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 85 loss: 0.2712680995464325\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 86 loss: 0.20535071194171906\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 87 loss: 0.38816776871681213\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 88 loss: 0.6929959654808044\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 89 loss: 0.1469547152519226\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9259, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 90 loss: 0.5305295586585999\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 91 loss: 0.41685259342193604\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 92 loss: 0.6939808130264282\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 93 loss: 0.2372894138097763\n",
      "class 0: acc 0.9375, precision 0.9200, recall 1.0000, f1 0.9583\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8750, f1 0.9333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 94 loss: 0.6591839790344238\n",
      "class 0: acc 0.7500, precision 0.8148, recall 0.8800, f1 0.8462\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 95 loss: 0.4545535743236542\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 96 loss: 0.4452817440032959\n",
      "class 0: acc 0.8125, precision 0.9167, recall 0.8462, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 97 loss: 0.4673832654953003\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 98 loss: 0.4085376262664795\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 99 loss: 0.39099350571632385\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 100 loss: 0.5519917011260986\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 101 loss: 0.41987699270248413\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 102 loss: 0.451710045337677\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 103 loss: 0.47742611169815063\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 104 loss: 0.3029632568359375\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 105 loss: 0.20730863511562347\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 106 loss: 0.45125916600227356\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 107 loss: 0.32243919372558594\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 108 loss: 0.5964783430099487\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 109 loss: 0.27503764629364014\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 110 loss: 0.24566875398159027\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 111 loss: 0.672023594379425\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 112 loss: 0.18087102472782135\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 113 loss: 0.2395549863576889\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 114 loss: 0.3019168972969055\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 115 loss: 0.44268640875816345\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 116 loss: 0.3110284209251404\n",
      "class 0: acc 0.7812, precision 0.9231, recall 0.8276, f1 0.8727\n",
      "class 1: acc 0.7812, precision 0.1667, recall 0.3333, f1 0.2222\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 117 loss: 0.834587812423706\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.7812, precision 0.6667, recall 0.2500, f1 0.3636\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 118 loss: 0.24734379351139069\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 119 loss: 0.4151288568973541\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 120 loss: 0.5320919752120972\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 121 loss: 0.15527468919754028\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 122 loss: 0.2986684739589691\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 123 loss: 0.3765556514263153\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 124 loss: 0.2982301414012909\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 125 loss: 0.48370853066444397\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 126 loss: 0.8323418498039246\n",
      "class 0: acc 0.7188, precision 0.6800, recall 0.9444, f1 0.7907\n",
      "class 1: acc 0.7812, precision 0.7143, recall 0.5000, f1 0.5882\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 127 loss: 0.32713499665260315\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 128 loss: 0.5254493951797485\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 129 loss: 0.25266167521476746\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 130 loss: 0.5078151822090149\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 131 loss: 0.19561277329921722\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 132 loss: 0.4894101917743683\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 133 loss: 0.4800693094730377\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 134 loss: 0.3570398688316345\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 135 loss: 0.42068687081336975\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 136 loss: 0.20014461874961853\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 137 loss: 0.3917100727558136\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 138 loss: 0.2684616148471832\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 139 loss: 0.26239562034606934\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 140 loss: 0.3208564221858978\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 141 loss: 0.3959852159023285\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 142 loss: 0.2505580484867096\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 143 loss: 0.5138978362083435\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 144 loss: 0.7295259237289429\n",
      "class 0: acc 0.6875, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 145 loss: 0.5770729184150696\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 146 loss: 0.7629291415214539\n",
      "class 0: acc 0.7188, precision 0.7037, recall 0.9500, f1 0.8085\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 147 loss: 0.6016249060630798\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8125, precision 0.6000, recall 0.4286, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 148 loss: 0.3653011620044708\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 149 loss: 0.44415712356567383\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 150 loss: 0.34413018822669983\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 151 loss: 0.6141893863677979\n",
      "class 0: acc 0.7500, precision 0.7826, recall 0.8571, f1 0.8182\n",
      "class 1: acc 0.7188, precision 0.4444, recall 0.5000, f1 0.4706\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 152 loss: 0.4204818904399872\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 153 loss: 0.39017581939697266\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 154 loss: 0.4464317262172699\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 155 loss: 0.5558788776397705\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 156 loss: 0.3415735065937042\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 157 loss: 0.5162855982780457\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 158 loss: 0.42037487030029297\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 159 loss: 0.49406883120536804\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 160 loss: 0.1188884899020195\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 161 loss: 1.008999228477478\n",
      "class 0: acc 0.6875, precision 0.7000, recall 0.9545, f1 0.8077\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 162 loss: 0.5706436634063721\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 163 loss: 0.5960562825202942\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 164 loss: 0.5678541660308838\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 165 loss: 0.529866635799408\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 166 loss: 0.5208666324615479\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 167 loss: 0.48269355297088623\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 168 loss: 0.3751670718193054\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 169 loss: 0.5599708557128906\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 170 loss: 0.5065147280693054\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 171 loss: 0.5080861449241638\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 172 loss: 0.2951996922492981\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 173 loss: 0.5065174102783203\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 174 loss: 0.4328630864620209\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 175 loss: 0.24584221839904785\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 176 loss: 0.3997136354446411\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 177 loss: 0.34284400939941406\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 178 loss: 0.31062328815460205\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 179 loss: 0.5734440684318542\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 180 loss: 0.3591364920139313\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 181 loss: 0.3362064063549042\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 182 loss: 0.5344992280006409\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 183 loss: 0.5892650485038757\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 184 loss: 0.7419627904891968\n",
      "class 0: acc 0.7500, precision 0.7241, recall 1.0000, f1 0.8400\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 185 loss: 0.5162404179573059\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 186 loss: 0.27296721935272217\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 187 loss: 0.3983411192893982\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 188 loss: 0.4630056321620941\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 189 loss: 0.6859649419784546\n",
      "class 0: acc 0.7812, precision 0.8750, recall 0.8400, f1 0.8571\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 190 loss: 0.5763472318649292\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 191 loss: 0.4971289336681366\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 192 loss: 0.251779705286026\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 193 loss: 0.4102630913257599\n",
      "class 0: acc 0.8750, precision 0.9167, recall 0.9167, f1 0.9167\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.8571, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 194 loss: 1.1562659740447998\n",
      "class 0: acc 0.6562, precision 0.5769, recall 1.0000, f1 0.7317\n",
      "class 1: acc 0.7188, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.7500, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 195 loss: 0.6067111492156982\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 196 loss: 0.43479591608047485\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 197 loss: 0.4200191795825958\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 198 loss: 0.44830307364463806\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 199 loss: 0.38522017002105713\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 200 loss: 0.317146360874176\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 201 loss: 0.28728634119033813\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 202 loss: 0.25607413053512573\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 203 loss: 0.5453388094902039\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 204 loss: 0.397220253944397\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 205 loss: 0.5883402824401855\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 206 loss: 0.44684481620788574\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 207 loss: 0.4910111725330353\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 208 loss: 0.2139364629983902\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 209 loss: 0.36324095726013184\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 210 loss: 0.27885738015174866\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 211 loss: 0.31862467527389526\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 212 loss: 0.5244656205177307\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 213 loss: 0.45040515065193176\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 214 loss: 0.2284393310546875\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 215 loss: 0.28477320075035095\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 216 loss: 0.39378833770751953\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 217 loss: 0.48078256845474243\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 218 loss: 0.42594799399375916\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 219 loss: 0.332570880651474\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 220 loss: 0.4845465421676636\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 221 loss: 0.14762701094150543\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 222 loss: 0.4743168354034424\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 223 loss: 0.17640328407287598\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 224 loss: 0.4172704219818115\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 225 loss: 0.21219266951084137\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 226 loss: 0.510099470615387\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 227 loss: 0.4230016767978668\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 228 loss: 0.3165019452571869\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 229 loss: 0.42827308177948\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 230 loss: 0.24303244054317474\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 231 loss: 0.46302416920661926\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 232 loss: 0.31922370195388794\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 233 loss: 0.6527099609375\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 234 loss: 0.3370925486087799\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 235 loss: 0.3003350496292114\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 236 loss: 0.2734590470790863\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 237 loss: 0.5712408423423767\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 238 loss: 0.20464657247066498\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 239 loss: 0.43912434577941895\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 240 loss: 0.5055789351463318\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 241 loss: 0.6104340553283691\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 242 loss: 0.2630867660045624\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 243 loss: 0.27424725890159607\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 244 loss: 0.28910180926322937\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 245 loss: 0.5534418821334839\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 246 loss: 0.2013605833053589\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 247 loss: 0.35379770398139954\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 248 loss: 0.39880579710006714\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 249 loss: 0.5776713490486145\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 250 loss: 0.3090684413909912\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 251 loss: 0.30255985260009766\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 252 loss: 0.3891710937023163\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 253 loss: 0.3437786102294922\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 254 loss: 0.6734299659729004\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 255 loss: 0.5066933035850525\n",
      "class 0: acc 0.7812, precision 0.7812, recall 1.0000, f1 0.8772\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 256 loss: 0.3657609224319458\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 257 loss: 0.4045569896697998\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 258 loss: 0.21377398073673248\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 259 loss: 0.2932926416397095\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 260 loss: 0.43137314915657043\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 261 loss: 0.46900463104248047\n",
      "class 0: acc 0.8125, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 262 loss: 0.22360855340957642\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 263 loss: 0.2784818708896637\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 264 loss: 0.26432034373283386\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 265 loss: 0.3021447956562042\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 266 loss: 0.5876039266586304\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 267 loss: 0.46413180232048035\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 268 loss: 0.3298984169960022\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 269 loss: 0.41785019636154175\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 270 loss: 0.2542591392993927\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 271 loss: 0.3940397799015045\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 272 loss: 0.16391368210315704\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9677, f1 0.9836\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 273 loss: 0.5950826406478882\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 274 loss: 0.5866286754608154\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 275 loss: 0.7389411330223083\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 276 loss: 0.3356461822986603\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 277 loss: 0.8555922508239746\n",
      "class 0: acc 0.7188, precision 0.6897, recall 1.0000, f1 0.8163\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 278 loss: 0.3718928098678589\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 279 loss: 0.28204217553138733\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 280 loss: 0.4915357530117035\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 281 loss: 0.2681470513343811\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 282 loss: 0.4354981780052185\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 283 loss: 0.4502946436405182\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 284 loss: 0.4976364076137543\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 285 loss: 0.43645739555358887\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 286 loss: 0.6217331290245056\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 287 loss: 0.33215582370758057\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 288 loss: 0.349933922290802\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 289 loss: 0.4893902838230133\n",
      "class 0: acc 0.8438, precision 0.8333, recall 0.9524, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.8571, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 290 loss: 0.46532824635505676\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 291 loss: 0.6429870128631592\n",
      "class 0: acc 0.7188, precision 0.7000, recall 1.0000, f1 0.8235\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 292 loss: 0.37678349018096924\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 293 loss: 0.4700210690498352\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 294 loss: 0.6160933971405029\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 295 loss: 0.32047003507614136\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 296 loss: 0.40153446793556213\n",
      "class 0: acc 0.8438, precision 0.9167, recall 0.8800, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.6250, recall 0.7143, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 297 loss: 0.29073962569236755\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 298 loss: 0.3185228109359741\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 299 loss: 0.3927997052669525\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 300 loss: 0.2663148045539856\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 301 loss: 0.2753262221813202\n",
      "class 0: acc 0.8438, precision 0.9286, recall 0.8966, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 302 loss: 0.36273157596588135\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 303 loss: 0.30926427245140076\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 304 loss: 0.42616143822669983\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 305 loss: 0.3192957043647766\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 306 loss: 0.236383318901062\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 307 loss: 0.3066484034061432\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 308 loss: 0.8324764966964722\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 309 loss: 0.23492322862148285\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 310 loss: 0.5838134288787842\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 311 loss: 0.3068704605102539\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 312 loss: 0.3799522817134857\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 313 loss: 0.4231661260128021\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 314 loss: 0.3171843886375427\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 315 loss: 0.35286834836006165\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 316 loss: 0.4338489770889282\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 317 loss: 0.1841459572315216\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 318 loss: 0.38893982768058777\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 319 loss: 0.31603971123695374\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 320 loss: 0.7370123267173767\n",
      "class 0: acc 0.7500, precision 0.7667, recall 0.9583, f1 0.8519\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 321 loss: 0.40582168102264404\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 322 loss: 0.6043506860733032\n",
      "class 0: acc 0.7812, precision 0.7600, recall 0.9500, f1 0.8444\n",
      "class 1: acc 0.7812, precision 0.7143, recall 0.5000, f1 0.5882\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 323 loss: 0.5143518447875977\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 324 loss: 0.3955046534538269\n",
      "class 0: acc 0.8750, precision 0.8182, recall 1.0000, f1 0.9000\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.7692, f1 0.8696\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 325 loss: 0.2670458257198334\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 326 loss: 0.4814579486846924\n",
      "class 0: acc 0.8438, precision 0.8696, recall 0.9091, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.8571, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 327 loss: 0.38477781414985657\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 328 loss: 0.3813255727291107\n",
      "class 0: acc 0.8438, precision 0.9200, recall 0.8846, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.4286, recall 1.0000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 329 loss: 0.6188086867332458\n",
      "class 0: acc 0.7812, precision 0.8519, recall 0.8846, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.2000, recall 0.3333, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 330 loss: 0.5677528977394104\n",
      "class 0: acc 0.8125, precision 0.8800, recall 0.8800, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.5714, recall 0.6667, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 331 loss: 0.13464893400669098\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 332 loss: 0.4518584609031677\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 333 loss: 0.4253559708595276\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 334 loss: 0.28941667079925537\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 335 loss: 0.4237355589866638\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 336 loss: 0.2052835077047348\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 337 loss: 0.4126424789428711\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 338 loss: 0.2512483596801758\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 339 loss: 0.191038578748703\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 340 loss: 0.6261733770370483\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 341 loss: 0.2842138111591339\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 342 loss: 0.4202440083026886\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 343 loss: 0.3928683400154114\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 344 loss: 0.2436843067407608\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 345 loss: 0.27497217059135437\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 346 loss: 0.21814462542533875\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 347 loss: 0.432196706533432\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 348 loss: 0.2074865996837616\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 349 loss: 0.7019727230072021\n",
      "class 0: acc 0.7500, precision 0.7308, recall 0.9500, f1 0.8261\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 350 loss: 0.45578140020370483\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 351 loss: 0.7327597141265869\n",
      "class 0: acc 0.7500, precision 0.7407, recall 0.9524, f1 0.8333\n",
      "class 1: acc 0.7812, precision 0.6000, recall 0.3750, f1 0.4615\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 352 loss: 0.35318708419799805\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 353 loss: 0.2321968972682953\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9615, f1 0.9804\n",
      "class 1: acc 0.9688, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 354 loss: 0.6211264729499817\n",
      "class 0: acc 0.7500, precision 0.7857, recall 0.9167, f1 0.8462\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.2857, f1 0.3636\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 355 loss: 0.5672222375869751\n",
      "class 0: acc 0.8438, precision 0.8261, recall 0.9500, f1 0.8837\n",
      "class 1: acc 0.8750, precision 0.7778, recall 0.7778, f1 0.7778\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 356 loss: 0.45682278275489807\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 357 loss: 0.410785436630249\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 358 loss: 0.6258328557014465\n",
      "class 0: acc 0.7812, precision 0.8333, recall 0.8696, f1 0.8511\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 359 loss: 0.4423225522041321\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 360 loss: 0.5571227669715881\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 361 loss: 0.41071343421936035\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 362 loss: 0.41982463002204895\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.5714, recall 0.6667, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 363 loss: 0.42386627197265625\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 364 loss: 0.36035826802253723\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 365 loss: 0.3562471568584442\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 366 loss: 0.2878789007663727\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 367 loss: 0.22947902977466583\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 368 loss: 0.4414413571357727\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 369 loss: 0.3689807057380676\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 370 loss: 0.49419718980789185\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 371 loss: 0.22973498702049255\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 372 loss: 0.22553904354572296\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 373 loss: 0.6097657680511475\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 374 loss: 0.3273654282093048\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 375 loss: 0.377555251121521\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 376 loss: 0.21422523260116577\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 377 loss: 0.3830629587173462\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 378 loss: 0.4900307357311249\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 379 loss: 0.4507264196872711\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 380 loss: 0.4341140389442444\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 381 loss: 0.47171804308891296\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 382 loss: 0.5271444916725159\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 383 loss: 0.45420414209365845\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 384 loss: 0.3401876986026764\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 385 loss: 0.6630447506904602\n",
      "class 0: acc 0.7188, precision 0.7000, recall 1.0000, f1 0.8235\n",
      "class 1: acc 0.7500, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 386 loss: 0.387003093957901\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 387 loss: 0.3339287340641022\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 388 loss: 0.40618446469306946\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 389 loss: 0.41869914531707764\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 390 loss: 0.32715827226638794\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 391 loss: 0.5509611368179321\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 392 loss: 0.5466165542602539\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 393 loss: 0.49113595485687256\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 394 loss: 0.27615830302238464\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 395 loss: 0.4321191608905792\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 396 loss: 0.4913294315338135\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 397 loss: 0.2936337888240814\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 398 loss: 0.3797484338283539\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 399 loss: 0.3301752507686615\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 400 loss: 0.6907323002815247\n",
      "class 0: acc 0.7188, precision 0.7037, recall 0.9500, f1 0.8085\n",
      "class 1: acc 0.7812, precision 0.8000, recall 0.4000, f1 0.5333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 401 loss: 0.5819181799888611\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 402 loss: 0.3359050154685974\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 403 loss: 0.47304943203926086\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 404 loss: 0.35699009895324707\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 405 loss: 0.5544028282165527\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 406 loss: 0.32508039474487305\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9355, f1 0.9667\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 407 loss: 0.3645596504211426\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 408 loss: 0.34700649976730347\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 409 loss: 0.597562313079834\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 410 loss: 0.3379083573818207\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 411 loss: 0.26031193137168884\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 412 loss: 0.6211546063423157\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 413 loss: 0.2832529544830322\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 414 loss: 0.5025023818016052\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 415 loss: 0.6395665407180786\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 416 loss: 0.36329782009124756\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 417 loss: 0.2325044572353363\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 418 loss: 0.6333698034286499\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.1429, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 419 loss: 0.39692649245262146\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 420 loss: 0.4549561142921448\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 421 loss: 0.3381202816963196\n",
      "class 0: acc 0.8750, precision 0.9643, recall 0.9000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 422 loss: 0.3960475027561188\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 423 loss: 0.6354460120201111\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.7500, precision 0.7500, recall 0.3000, f1 0.4286\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 424 loss: 0.25432339310646057\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9615, f1 0.9804\n",
      "class 1: acc 0.9688, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 425 loss: 0.5481566190719604\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 426 loss: 0.3542749285697937\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 427 loss: 0.2539159655570984\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 428 loss: 0.18440145254135132\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 429 loss: 0.4888809323310852\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 430 loss: 0.4401247203350067\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 431 loss: 0.5256506204605103\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 432 loss: 0.3329077363014221\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 433 loss: 0.2655949592590332\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 434 loss: 0.5696575045585632\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 435 loss: 0.699599027633667\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 436 loss: 0.2742743194103241\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 437 loss: 0.6391589045524597\n",
      "class 0: acc 0.8438, precision 0.8400, recall 0.9545, f1 0.8936\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 438 loss: 0.4801085889339447\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 439 loss: 0.3204483985900879\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 440 loss: 0.36894822120666504\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 441 loss: 0.336841344833374\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 442 loss: 0.5975829362869263\n",
      "class 0: acc 0.7500, precision 0.7778, recall 0.9130, f1 0.8400\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 443 loss: 0.48676279187202454\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 444 loss: 0.4843234419822693\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 445 loss: 0.4466424584388733\n",
      "class 0: acc 0.8125, precision 0.8966, recall 0.8966, f1 0.8966\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 446 loss: 0.31839507818222046\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 447 loss: 0.3108934462070465\n",
      "class 0: acc 0.9062, precision 0.9667, recall 0.9355, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 448 loss: 0.3351143002510071\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 449 loss: 0.26603591442108154\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 450 loss: 0.25055256485939026\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 451 loss: 0.26858606934547424\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 452 loss: 0.3589051365852356\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 453 loss: 0.0988553911447525\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 454 loss: 0.2662840485572815\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 455 loss: 0.5486248135566711\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 456 loss: 0.7555646896362305\n",
      "class 0: acc 0.7188, precision 0.7308, recall 0.9048, f1 0.8085\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 457 loss: 0.2946268320083618\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 458 loss: 0.42379477620124817\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 459 loss: 0.3156779110431671\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 460 loss: 0.18896067142486572\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 461 loss: 0.356691837310791\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 462 loss: 0.5153619050979614\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 463 loss: 0.36659252643585205\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 464 loss: 0.2615779638290405\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 465 loss: 0.2645750939846039\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 466 loss: 0.7076122164726257\n",
      "class 0: acc 0.7500, precision 0.7667, recall 0.9583, f1 0.8519\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 467 loss: 0.2885493338108063\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 468 loss: 0.2507160007953644\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 469 loss: 0.2975180149078369\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 470 loss: 0.4558747708797455\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 471 loss: 0.28167277574539185\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 472 loss: 0.4539271295070648\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 473 loss: 0.23166048526763916\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 474 loss: 0.2623814046382904\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 475 loss: 0.1679070144891739\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 476 loss: 0.3016234338283539\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 477 loss: 0.1324044018983841\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 478 loss: 0.40342625975608826\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 479 loss: 0.517716646194458\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 480 loss: 0.19871707260608673\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 481 loss: 0.2004988044500351\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 482 loss: 0.2419959306716919\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 483 loss: 0.8948235511779785\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 484 loss: 0.42208001017570496\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 0.8438, precision 0.6250, recall 0.7143, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 485 loss: 0.3550993502140045\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 486 loss: 0.5138744711875916\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 487 loss: 0.37224701046943665\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 488 loss: 0.6136603951454163\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 489 loss: 0.24011629819869995\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 490 loss: 0.255277156829834\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 491 loss: 0.2657677233219147\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 492 loss: 0.3216181695461273\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 493 loss: 0.36038342118263245\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 494 loss: 0.4155998229980469\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 495 loss: 0.36187323927879333\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 496 loss: 0.39095592498779297\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 497 loss: 0.2033531665802002\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 498 loss: 0.3956584334373474\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 499 loss: 0.1307942271232605\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 500 loss: 0.5309089422225952\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 501 loss: 0.34472307562828064\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 502 loss: 0.5408479571342468\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 503 loss: 0.4953857362270355\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 504 loss: 0.221822127699852\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 505 loss: 0.487399697303772\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 506 loss: 0.32571715116500854\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 507 loss: 0.2552688717842102\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 508 loss: 0.5747433304786682\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 509 loss: 0.3615894317626953\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 510 loss: 0.2646586298942566\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 511 loss: 0.3445775806903839\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 512 loss: 0.28780585527420044\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 513 loss: 0.2528606355190277\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 514 loss: 0.6060330867767334\n",
      "class 0: acc 0.7500, precision 0.7308, recall 0.9500, f1 0.8261\n",
      "class 1: acc 0.8438, precision 0.8333, recall 0.5556, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 515 loss: 0.39694342017173767\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 516 loss: 0.21323458850383759\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 517 loss: 0.4738975167274475\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 518 loss: 0.6089639663696289\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 519 loss: 0.4040500521659851\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 520 loss: 0.2233290672302246\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 521 loss: 0.26421141624450684\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 522 loss: 0.38562145829200745\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.7143, recall 0.6250, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 523 loss: 0.19022133946418762\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 524 loss: 0.41308319568634033\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 525 loss: 0.5348223447799683\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 526 loss: 0.3988194167613983\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 527 loss: 0.374600887298584\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 528 loss: 0.29491952061653137\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 529 loss: 0.3230159878730774\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 530 loss: 0.18107502162456512\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 531 loss: 0.31280481815338135\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 532 loss: 0.4413518011569977\n",
      "class 0: acc 0.7812, precision 0.8333, recall 0.9259, f1 0.8772\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 533 loss: 0.2903173863887787\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 534 loss: 0.18594476580619812\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 535 loss: 0.4816971719264984\n",
      "class 0: acc 0.7812, precision 0.8065, recall 0.9615, f1 0.8772\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 536 loss: 0.292496919631958\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 537 loss: 0.18944622576236725\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 538 loss: 0.39819663763046265\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 539 loss: 0.2554430067539215\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 540 loss: 0.3344458341598511\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 541 loss: 0.24258224666118622\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 542 loss: 0.31668558716773987\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 543 loss: 0.4853242337703705\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 544 loss: 0.32622769474983215\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 545 loss: 0.33008381724357605\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 546 loss: 0.23730522394180298\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 547 loss: 0.17151504755020142\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9677, f1 0.9836\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 548 loss: 0.5310456156730652\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 549 loss: 0.3486120402812958\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 550 loss: 0.3678540289402008\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 551 loss: 0.39908507466316223\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 552 loss: 0.34242287278175354\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 553 loss: 0.5447534322738647\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.7812, precision 0.3333, recall 0.1667, f1 0.2222\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 554 loss: 0.5453816652297974\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 555 loss: 0.4936453700065613\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 556 loss: 0.3509410619735718\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 557 loss: 0.36968979239463806\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 558 loss: 0.7518893480300903\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 559 loss: 0.31669411063194275\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8966, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 560 loss: 0.3072017729282379\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 561 loss: 0.4977377653121948\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 562 loss: 0.30395233631134033\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 563 loss: 0.4791221618652344\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 564 loss: 0.46711793541908264\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 565 loss: 0.4222698211669922\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 566 loss: 0.3600577712059021\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 567 loss: 0.4822804927825928\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 568 loss: 0.4684664011001587\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 569 loss: 0.35465168952941895\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 570 loss: 0.4452950060367584\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 571 loss: 0.4165758788585663\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 572 loss: 0.31012865900993347\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 573 loss: 0.5826835632324219\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 574 loss: 0.18814852833747864\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 575 loss: 0.41818714141845703\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 576 loss: 0.5456433892250061\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 577 loss: 0.5922828912734985\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 578 loss: 0.4594411253929138\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 579 loss: 0.6890302896499634\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 580 loss: 0.32371821999549866\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 581 loss: 0.6491534113883972\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 582 loss: 0.10720575600862503\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 583 loss: 0.17492695152759552\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 584 loss: 0.4554459750652313\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 585 loss: 0.5427953600883484\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 586 loss: 0.41637247800827026\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 587 loss: 0.2632777690887451\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 588 loss: 0.18368636071681976\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 589 loss: 0.3833106756210327\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 590 loss: 0.2345634251832962\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 591 loss: 0.28913673758506775\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 592 loss: 0.2963694930076599\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 593 loss: 0.23737680912017822\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 594 loss: 0.4739975929260254\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 595 loss: 0.4629971385002136\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 596 loss: 0.10605154931545258\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 597 loss: 0.39416030049324036\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 598 loss: 0.7186141610145569\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 599 loss: 0.390970915555954\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 600 loss: 0.6420674920082092\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 601 loss: 0.47534194588661194\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 602 loss: 0.42368245124816895\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.8571, recall 0.6667, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 603 loss: 0.4728749990463257\n",
      "class 0: acc 0.8125, precision 0.8800, recall 0.8800, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.4286, recall 1.0000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 604 loss: 0.22022052109241486\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 605 loss: 0.5398738980293274\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 606 loss: 0.38279014825820923\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 607 loss: 0.711188554763794\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.7812, precision 1.0000, recall 0.3000, f1 0.4615\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 608 loss: 0.34213346242904663\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 609 loss: 0.42475005984306335\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 610 loss: 0.3575175702571869\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 611 loss: 0.5625491738319397\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 612 loss: 0.30949267745018005\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 613 loss: 0.3326747715473175\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 614 loss: 0.35167062282562256\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 615 loss: 0.412736177444458\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 616 loss: 0.5101082921028137\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 617 loss: 0.4577043950557709\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 618 loss: 0.4671389162540436\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 619 loss: 0.3137396275997162\n",
      "class 0: acc 0.8750, precision 0.9643, recall 0.9000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 620 loss: 0.4797378480434418\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 621 loss: 0.1447119265794754\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 622 loss: 0.6831878423690796\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 623 loss: 0.21633973717689514\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 624 loss: 0.30607837438583374\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 625 loss: 0.47972095012664795\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 626 loss: 0.23540276288986206\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 627 loss: 0.38494548201560974\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 628 loss: 0.5127460956573486\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 629 loss: 0.42045411467552185\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 630 loss: 0.384849488735199\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 631 loss: 0.3766104578971863\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 632 loss: 0.2398597151041031\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 633 loss: 0.22233401238918304\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 634 loss: 0.43040814995765686\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 635 loss: 0.7120341062545776\n",
      "class 0: acc 0.7812, precision 0.7500, recall 0.9474, f1 0.8372\n",
      "class 1: acc 0.7812, precision 0.6250, recall 0.5556, f1 0.5882\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 636 loss: 0.3650703728199005\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 0.9062, precision 0.8750, recall 0.7778, f1 0.8235\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 637 loss: 0.44255247712135315\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 638 loss: 0.34715792536735535\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 639 loss: 0.3212079703807831\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 640 loss: 0.33781298995018005\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 641 loss: 0.24997134506702423\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 642 loss: 0.38433903455734253\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 643 loss: 0.3674124479293823\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 644 loss: 0.4236924350261688\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 645 loss: 0.47850170731544495\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 646 loss: 0.3308276832103729\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 647 loss: 0.3406393826007843\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 648 loss: 0.5886891484260559\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 649 loss: 0.48850297927856445\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 650 loss: 0.625470757484436\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 651 loss: 0.4081084132194519\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 652 loss: 0.1834924966096878\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 653 loss: 0.3111947476863861\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 654 loss: 0.36281442642211914\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 655 loss: 0.14690357446670532\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 656 loss: 0.4423622190952301\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 657 loss: 0.3375973105430603\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 658 loss: 0.4767269492149353\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 659 loss: 0.34997811913490295\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 660 loss: 0.3957270681858063\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 661 loss: 0.4353141188621521\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 662 loss: 0.7793582677841187\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 663 loss: 0.4192546308040619\n",
      "class 0: acc 0.8438, precision 0.9167, recall 0.8800, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.8000, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 664 loss: 0.35599949955940247\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 665 loss: 0.2601572275161743\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 666 loss: 0.5266373753547668\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 667 loss: 0.32357504963874817\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 668 loss: 0.36186540126800537\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 669 loss: 0.5227099657058716\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 670 loss: 0.16028808057308197\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 671 loss: 0.43845030665397644\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 672 loss: 0.3139481842517853\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 673 loss: 0.31718677282333374\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 674 loss: 0.17537827789783478\n",
      "class 0: acc 0.9688, precision 0.9688, recall 1.0000, f1 0.9841\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 675 loss: 0.33920371532440186\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 676 loss: 0.5656265020370483\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 677 loss: 0.403889924287796\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 678 loss: 0.2517145574092865\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 679 loss: 0.41783347725868225\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 680 loss: 0.4673595130443573\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 681 loss: 0.2530813217163086\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 682 loss: 0.2335204780101776\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 683 loss: 0.44575807452201843\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 684 loss: 0.41861483454704285\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 685 loss: 0.4932997226715088\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 686 loss: 0.4734756052494049\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 687 loss: 0.6893733739852905\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 688 loss: 0.3926621079444885\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 689 loss: 0.43186989426612854\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 690 loss: 0.3601028323173523\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 691 loss: 0.45441898703575134\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 692 loss: 0.3885183334350586\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 693 loss: 0.4520570933818817\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 694 loss: 0.4228006899356842\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 695 loss: 0.28181740641593933\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 696 loss: 0.5357217788696289\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 697 loss: 0.4147781431674957\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 698 loss: 0.4472962021827698\n",
      "class 0: acc 0.8750, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.8750, recall 0.8750, f1 0.8750\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 699 loss: 0.4451403021812439\n",
      "class 0: acc 0.8438, precision 0.9286, recall 0.8966, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 700 loss: 0.49312299489974976\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 701 loss: 0.291525661945343\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 702 loss: 0.6120807528495789\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 703 loss: 0.3846243619918823\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 704 loss: 0.2160576581954956\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 705 loss: 0.2600301206111908\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 706 loss: 0.2385709136724472\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 707 loss: 0.21402475237846375\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 708 loss: 0.4496699273586273\n",
      "class 0: acc 0.8438, precision 0.8400, recall 0.9545, f1 0.8936\n",
      "class 1: acc 0.8750, precision 0.8571, recall 0.6667, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 709 loss: 0.19704651832580566\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 710 loss: 0.616878867149353\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 711 loss: 0.3252966105937958\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 712 loss: 0.2640743553638458\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 713 loss: 0.5353338122367859\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 714 loss: 0.3242752254009247\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 715 loss: 0.2691173553466797\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 716 loss: 0.5332997441291809\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 717 loss: 0.3437841832637787\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 718 loss: 0.4569891691207886\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 719 loss: 0.3782332241535187\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 720 loss: 0.3306350111961365\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 721 loss: 0.46949538588523865\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 722 loss: 0.4704751968383789\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 723 loss: 0.2449103742837906\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 724 loss: 0.23059499263763428\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 725 loss: 0.4437731206417084\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 726 loss: 0.342840313911438\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 727 loss: 0.7046526074409485\n",
      "class 0: acc 0.7500, precision 0.7586, recall 0.9565, f1 0.8462\n",
      "class 1: acc 0.7812, precision 0.6667, recall 0.2500, f1 0.3636\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 728 loss: 0.36189234256744385\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 729 loss: 0.5861330032348633\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 730 loss: 0.46795767545700073\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 731 loss: 0.7176949977874756\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 732 loss: 0.19301393628120422\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 733 loss: 0.4546232223510742\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 734 loss: 0.3355046510696411\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 735 loss: 0.4300476908683777\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 736 loss: 0.6439322233200073\n",
      "class 0: acc 0.7812, precision 0.8077, recall 0.9130, f1 0.8571\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 737 loss: 0.44427570700645447\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 738 loss: 0.35589924454689026\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 739 loss: 0.3169753849506378\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 740 loss: 0.414309561252594\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 741 loss: 0.37899503111839294\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 742 loss: 0.2086067944765091\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 743 loss: 0.28809240460395813\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 744 loss: 0.5209333300590515\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 745 loss: 0.2741428315639496\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 746 loss: 0.350576251745224\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 747 loss: 0.7801847457885742\n",
      "class 0: acc 0.6562, precision 0.6333, recall 1.0000, f1 0.7755\n",
      "class 1: acc 0.7500, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 748 loss: 0.40847012400627136\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 749 loss: 0.527391791343689\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 750 loss: 0.543660044670105\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 751 loss: 0.4493032693862915\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 752 loss: 0.38590991497039795\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 753 loss: 0.511699378490448\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 754 loss: 0.25669342279434204\n",
      "class 0: acc 0.9688, precision 0.9524, recall 1.0000, f1 0.9756\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.9167, f1 0.9565\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 755 loss: 0.6792258620262146\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 756 loss: 0.5535726547241211\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 757 loss: 0.3990882635116577\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 758 loss: 0.480590283870697\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 759 loss: 0.39476656913757324\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 760 loss: 0.25971519947052\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 761 loss: 0.29158276319503784\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8966, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 762 loss: 0.19197562336921692\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 763 loss: 0.4293367862701416\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 764 loss: 0.13696834444999695\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 765 loss: 0.4340396523475647\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 766 loss: 0.3046649694442749\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 767 loss: 0.2756834328174591\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 768 loss: 0.853719174861908\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 769 loss: 0.6421223282814026\n",
      "class 0: acc 0.7500, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 770 loss: 0.26291120052337646\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 771 loss: 0.0928848460316658\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 772 loss: 0.31616276502609253\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 773 loss: 0.2796076834201813\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 774 loss: 0.4312191605567932\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 775 loss: 0.23856747150421143\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 776 loss: 0.4625972509384155\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 777 loss: 0.35112282633781433\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 778 loss: 0.2916952967643738\n",
      "class 0: acc 0.8750, precision 0.9615, recall 0.8929, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 779 loss: 0.36851784586906433\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 780 loss: 0.36196988821029663\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 781 loss: 0.18770456314086914\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 782 loss: 0.5851355791091919\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 783 loss: 0.28504541516304016\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 784 loss: 0.24232126772403717\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 785 loss: 0.23918846249580383\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 786 loss: 0.46187102794647217\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 787 loss: 0.3604777455329895\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 788 loss: 0.4490334987640381\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 789 loss: 0.47074374556541443\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 790 loss: 0.21565550565719604\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 791 loss: 0.4836595952510834\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 792 loss: 0.19190345704555511\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 793 loss: 0.4823514521121979\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 794 loss: 0.29662075638771057\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 795 loss: 0.5589801073074341\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 796 loss: 0.20889800786972046\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 797 loss: 0.3400559425354004\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 798 loss: 0.2869794964790344\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 799 loss: 0.2885653078556061\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 800 loss: 0.4021493196487427\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 801 loss: 0.18293192982673645\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 802 loss: 0.5386461615562439\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 803 loss: 0.24313537776470184\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 804 loss: 0.40445566177368164\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 805 loss: 0.6497137546539307\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 806 loss: 0.2379681020975113\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 807 loss: 0.23668785393238068\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 808 loss: 0.5411072373390198\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 809 loss: 0.29569363594055176\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 810 loss: 0.2615170180797577\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 811 loss: 0.3686503767967224\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 812 loss: 0.3360544443130493\n",
      "class 0: acc 0.8750, precision 0.9630, recall 0.8966, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 813 loss: 0.2293907105922699\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 814 loss: 0.2739233076572418\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 815 loss: 0.1830870509147644\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 816 loss: 0.41542327404022217\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 817 loss: 0.40212467312812805\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 818 loss: 0.5137457251548767\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 819 loss: 0.5554747581481934\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.1429, f1 0.2500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 820 loss: 0.3525813817977905\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 821 loss: 0.6679846048355103\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 822 loss: 0.6431529521942139\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 823 loss: 0.40977001190185547\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 824 loss: 0.429867148399353\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 825 loss: 0.5283508896827698\n",
      "class 0: acc 0.8750, precision 0.9600, recall 0.8889, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.2857, recall 1.0000, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 826 loss: 0.42705997824668884\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 827 loss: 0.34828200936317444\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 828 loss: 0.3132438659667969\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 829 loss: 0.40799254179000854\n",
      "class 0: acc 0.8125, precision 0.8846, recall 0.8846, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 830 loss: 0.47699347138404846\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 831 loss: 0.31327134370803833\n",
      "class 0: acc 0.8438, precision 0.9615, recall 0.8621, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.6667, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 832 loss: 0.4536762535572052\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 833 loss: 0.6365637183189392\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.1429, f1 0.2222\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 834 loss: 0.45714715123176575\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 835 loss: 0.5464537143707275\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 836 loss: 0.1978960782289505\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 837 loss: 0.30872660875320435\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 838 loss: 0.5195015072822571\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 839 loss: 0.49728456139564514\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 840 loss: 0.4407823383808136\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 841 loss: 0.26460811495780945\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 842 loss: 0.5902741551399231\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 843 loss: 0.29797258973121643\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 844 loss: 0.21750670671463013\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 845 loss: 0.3948105573654175\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 846 loss: 0.313129186630249\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.7000, f1 0.8235\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 847 loss: 0.5406352281570435\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 848 loss: 0.3609047830104828\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 849 loss: 0.5042011141777039\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 850 loss: 0.29483330249786377\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 851 loss: 0.5159536004066467\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.6667, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 852 loss: 0.4816397428512573\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 853 loss: 0.29512858390808105\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 854 loss: 0.2806149423122406\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 855 loss: 0.4133201241493225\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 856 loss: 0.3176979422569275\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 857 loss: 0.2443193644285202\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 858 loss: 0.4736274480819702\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 859 loss: 0.5710875988006592\n",
      "class 0: acc 0.7812, precision 0.8571, recall 0.8889, f1 0.8727\n",
      "class 1: acc 0.8125, precision 0.2500, recall 0.2500, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 860 loss: 0.5108373165130615\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 861 loss: 0.2147662192583084\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 862 loss: 0.38333660364151\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 863 loss: 0.38971707224845886\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 864 loss: 0.49228933453559875\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 865 loss: 0.4419460594654083\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 866 loss: 0.45166006684303284\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 867 loss: 0.2322986125946045\n",
      "class 0: acc 0.9062, precision 0.9583, recall 0.9200, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 868 loss: 0.35603073239326477\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 869 loss: 0.3823775053024292\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 870 loss: 0.38003110885620117\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 871 loss: 0.6373618245124817\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 872 loss: 0.512454628944397\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 873 loss: 0.46499741077423096\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 874 loss: 0.2697226107120514\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 875 loss: 0.4883027672767639\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 876 loss: 0.44893038272857666\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 877 loss: 0.2474365234375\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 878 loss: 0.7679614424705505\n",
      "class 0: acc 0.7188, precision 0.7143, recall 0.9524, f1 0.8163\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 879 loss: 0.3450906276702881\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 880 loss: 0.414304256439209\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 881 loss: 0.35340428352355957\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 882 loss: 0.2218734323978424\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 883 loss: 0.28527095913887024\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 884 loss: 0.07535965740680695\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 885 loss: 0.522785484790802\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 886 loss: 0.7851297855377197\n",
      "class 0: acc 0.7188, precision 0.7000, recall 1.0000, f1 0.8235\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 887 loss: 0.38732752203941345\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 888 loss: 0.23418043553829193\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 889 loss: 0.4971257746219635\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.2857, f1 0.3636\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 890 loss: 0.6573267579078674\n",
      "class 0: acc 0.8125, precision 0.8400, recall 0.9130, f1 0.8750\n",
      "class 1: acc 0.7812, precision 0.4286, recall 0.5000, f1 0.4615\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 891 loss: 0.3655794858932495\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 892 loss: 0.4842813014984131\n",
      "class 0: acc 0.8125, precision 0.8800, recall 0.8800, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 893 loss: 0.33127400279045105\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 894 loss: 0.27212589979171753\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 895 loss: 0.2804734706878662\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 896 loss: 0.20265412330627441\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 897 loss: 0.2734808027744293\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 898 loss: 0.3696681261062622\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 899 loss: 0.4250548779964447\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 900 loss: 0.5279048085212708\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 901 loss: 0.22487245500087738\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 902 loss: 0.3226790130138397\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 903 loss: 0.32402583956718445\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 904 loss: 0.6351222395896912\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 905 loss: 0.3332565426826477\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 906 loss: 0.33194029331207275\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 907 loss: 0.1711837351322174\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 908 loss: 0.4878595173358917\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 909 loss: 0.47040441632270813\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 910 loss: 0.5889320969581604\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 911 loss: 0.22981037199497223\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 912 loss: 0.45340535044670105\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 913 loss: 0.4951109290122986\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 914 loss: 0.4277946352958679\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 915 loss: 0.3711658716201782\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 916 loss: 0.45956942439079285\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 917 loss: 0.3326292335987091\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 918 loss: 0.5364904999732971\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 919 loss: 0.4406783878803253\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 920 loss: 0.4164176285266876\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 921 loss: 0.30261722207069397\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 922 loss: 0.24345055222511292\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9677, f1 0.9836\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 923 loss: 0.33688589930534363\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 924 loss: 0.24143452942371368\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 925 loss: 0.5714763402938843\n",
      "class 0: acc 0.7500, precision 0.8000, recall 0.8696, f1 0.8333\n",
      "class 1: acc 0.8125, precision 0.5714, recall 0.5714, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 926 loss: 0.22834548354148865\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 927 loss: 0.44699421525001526\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 928 loss: 0.4056652784347534\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 929 loss: 0.32029369473457336\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 930 loss: 0.46648287773132324\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 931 loss: 0.7273345589637756\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 932 loss: 0.4157087802886963\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 933 loss: 0.45829838514328003\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 934 loss: 0.36362355947494507\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 935 loss: 0.43925654888153076\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 936 loss: 0.42617177963256836\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 937 loss: 0.36625435948371887\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 938 loss: 0.18533222377300262\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 939 loss: 0.46803027391433716\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 940 loss: 0.298879474401474\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 941 loss: 0.4708172380924225\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 942 loss: 0.5211182236671448\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 943 loss: 0.5641732811927795\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 944 loss: 0.1670212298631668\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 945 loss: 0.5626327991485596\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 946 loss: 0.3262058198451996\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 947 loss: 0.3223440945148468\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 948 loss: 0.40623724460601807\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 949 loss: 0.3288787603378296\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 950 loss: 0.436707079410553\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 951 loss: 0.35460978746414185\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 952 loss: 0.5434029698371887\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.7812, precision 0.2500, recall 0.2000, f1 0.2222\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 953 loss: 0.49744144082069397\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 954 loss: 0.244545578956604\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 955 loss: 0.3214114010334015\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 956 loss: 0.2708921730518341\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 957 loss: 0.19807225465774536\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 958 loss: 0.5790302753448486\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 959 loss: 0.3307609558105469\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 960 loss: 0.18459315598011017\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 961 loss: 0.40526846051216125\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 962 loss: 0.20593683421611786\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 963 loss: 0.29822322726249695\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 964 loss: 0.247721329331398\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 965 loss: 0.5394570231437683\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 966 loss: 0.6604073643684387\n",
      "class 0: acc 0.7812, precision 0.7812, recall 1.0000, f1 0.8772\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 967 loss: 0.5767226815223694\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 968 loss: 0.1705995500087738\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 969 loss: 0.42507457733154297\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 970 loss: 0.12429017573595047\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 971 loss: 0.7366182804107666\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 972 loss: 0.13148824870586395\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9688, f1 0.9841\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 973 loss: 0.24500584602355957\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 974 loss: 0.5198209881782532\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 975 loss: 0.24824748933315277\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 976 loss: 0.5544652342796326\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 977 loss: 0.20626342296600342\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 978 loss: 0.5498321056365967\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 979 loss: 0.705032229423523\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 980 loss: 0.17151355743408203\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 981 loss: 0.38247814774513245\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 982 loss: 0.28362733125686646\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 983 loss: 0.39246901869773865\n",
      "class 0: acc 0.8750, precision 0.9167, recall 0.9167, f1 0.9167\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.8571, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 984 loss: 0.33800798654556274\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 985 loss: 0.5731457471847534\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 986 loss: 0.1740691065788269\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 987 loss: 0.2855070233345032\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 988 loss: 0.3212078809738159\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 989 loss: 0.296351820230484\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 990 loss: 0.6781997680664062\n",
      "class 0: acc 0.7188, precision 0.7500, recall 0.9130, f1 0.8235\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.2857, f1 0.3636\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 991 loss: 0.15575507283210754\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 992 loss: 0.32684972882270813\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 993 loss: 0.39054274559020996\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 994 loss: 0.23857568204402924\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 995 loss: 0.42384693026542664\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 996 loss: 0.278510183095932\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 997 loss: 0.3925761878490448\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 998 loss: 0.42138785123825073\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 999 loss: 0.30839988589286804\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1000 loss: 0.3985162675380707\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1001 loss: 0.5679450035095215\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1002 loss: 0.46448445320129395\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1003 loss: 0.5675839185714722\n",
      "class 0: acc 0.7500, precision 0.7667, recall 0.9583, f1 0.8519\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1004 loss: 0.22971445322036743\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1005 loss: 0.3086850047111511\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1006 loss: 0.47042936086654663\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1007 loss: 0.6601845622062683\n",
      "class 0: acc 0.6562, precision 0.6429, recall 0.9474, f1 0.7660\n",
      "class 1: acc 0.7812, precision 0.7500, recall 0.3333, f1 0.4615\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1008 loss: 0.27617236971855164\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1009 loss: 0.17577986419200897\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1010 loss: 0.5258169770240784\n",
      "class 0: acc 0.7500, precision 0.7667, recall 0.9583, f1 0.8519\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1011 loss: 0.3468952775001526\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1012 loss: 0.4100603759288788\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1013 loss: 0.4441080689430237\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1014 loss: 0.19649432599544525\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1015 loss: 0.6001827120780945\n",
      "class 0: acc 0.7500, precision 0.7241, recall 1.0000, f1 0.8400\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1016 loss: 0.41562071442604065\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1017 loss: 0.3749505281448364\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1018 loss: 0.23309624195098877\n",
      "class 0: acc 0.9375, precision 0.9677, recall 0.9677, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1019 loss: 0.27325308322906494\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1020 loss: 0.48033958673477173\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1021 loss: 0.2743540108203888\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1022 loss: 0.4661283791065216\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1023 loss: 0.32228904962539673\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1024 loss: 0.433368057012558\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1025 loss: 0.7604685425758362\n",
      "class 0: acc 0.7500, precision 0.7037, recall 1.0000, f1 0.8261\n",
      "class 1: acc 0.7500, precision 0.6000, recall 0.3333, f1 0.4286\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1026 loss: 0.2593725025653839\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1027 loss: 0.39123910665512085\n",
      "class 0: acc 0.8438, precision 0.9200, recall 0.8846, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1028 loss: 0.38172146677970886\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1029 loss: 0.33218616247177124\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1030 loss: 0.39393484592437744\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1031 loss: 0.23149177432060242\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9677, f1 0.9836\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1032 loss: 0.4572702944278717\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1033 loss: 0.3853623569011688\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1034 loss: 0.4261211156845093\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1035 loss: 0.32254934310913086\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1036 loss: 0.2009500116109848\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1037 loss: 0.2975011169910431\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1038 loss: 0.3355008363723755\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1039 loss: 0.33119386434555054\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1040 loss: 0.2863311171531677\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1041 loss: 0.2513173520565033\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1042 loss: 0.4760529696941376\n",
      "class 0: acc 0.7812, precision 0.8065, recall 0.9615, f1 0.8772\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1043 loss: 0.463663250207901\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1044 loss: 0.212339848279953\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1045 loss: 0.3628745675086975\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1046 loss: 0.39537492394447327\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1047 loss: 0.7709891200065613\n",
      "class 0: acc 0.7812, precision 0.8077, recall 0.9130, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1048 loss: 0.5106504559516907\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1049 loss: 0.3622426986694336\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1050 loss: 0.7479841709136963\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.7812, precision 0.3333, recall 0.1667, f1 0.2222\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1051 loss: 0.4452835023403168\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1052 loss: 0.5505815744400024\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1053 loss: 0.33894258737564087\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1054 loss: 0.4439646899700165\n",
      "class 0: acc 0.7812, precision 0.7407, recall 1.0000, f1 0.8511\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1055 loss: 0.21669839322566986\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1056 loss: 0.1541142612695694\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1057 loss: 0.48072439432144165\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1058 loss: 0.5746650695800781\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1059 loss: 0.43743255734443665\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1060 loss: 0.2224803864955902\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1061 loss: 0.24325056374073029\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1062 loss: 0.7972888946533203\n",
      "class 0: acc 0.6875, precision 0.6897, recall 0.9524, f1 0.8000\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1063 loss: 0.5807381868362427\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1064 loss: 0.37152180075645447\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1065 loss: 0.457303911447525\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1066 loss: 0.3182865381240845\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1067 loss: 0.2161850929260254\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9677, f1 0.9836\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1068 loss: 0.4202565550804138\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1069 loss: 0.3300014138221741\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1070 loss: 0.40895235538482666\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1071 loss: 0.3633647561073303\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1072 loss: 0.2154942750930786\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1073 loss: 0.35413098335266113\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1074 loss: 0.4024045169353485\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1075 loss: 0.3416242301464081\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1076 loss: 0.33997029066085815\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1077 loss: 0.3435741662979126\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1078 loss: 0.8003658056259155\n",
      "class 0: acc 0.7188, precision 0.6897, recall 1.0000, f1 0.8163\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1079 loss: 0.39604565501213074\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1080 loss: 0.6194736957550049\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1081 loss: 0.49121588468551636\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1082 loss: 0.291174054145813\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1083 loss: 0.2517518699169159\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1084 loss: 0.4511348009109497\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1085 loss: 0.35663172602653503\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1086 loss: 0.48398956656455994\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1087 loss: 0.6406052112579346\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1088 loss: 0.5406635403633118\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1089 loss: 0.3194929361343384\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1090 loss: 0.37369903922080994\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1091 loss: 0.5294023752212524\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1092 loss: 0.497088223695755\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1093 loss: 0.295356422662735\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1094 loss: 0.2760632634162903\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1095 loss: 0.598520815372467\n",
      "class 0: acc 0.7500, precision 0.7586, recall 0.9565, f1 0.8462\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1096 loss: 0.4317169785499573\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1097 loss: 0.32604384422302246\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1098 loss: 0.7046386003494263\n",
      "class 0: acc 0.7500, precision 0.7241, recall 1.0000, f1 0.8400\n",
      "class 1: acc 0.7812, precision 1.0000, recall 0.3000, f1 0.4615\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1099 loss: 0.2434135377407074\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1100 loss: 0.5865185856819153\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1101 loss: 0.36000674962997437\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1102 loss: 0.1855895221233368\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1103 loss: 0.5428216457366943\n",
      "class 0: acc 0.7500, precision 0.7857, recall 0.9167, f1 0.8462\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1104 loss: 0.6020561456680298\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1105 loss: 0.37503454089164734\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1106 loss: 0.2908521294593811\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1107 loss: 0.2910160720348358\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1108 loss: 0.32370781898498535\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1109 loss: 0.24440105259418488\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1110 loss: 0.35970887541770935\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1111 loss: 0.28987279534339905\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1112 loss: 0.4357821047306061\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1113 loss: 0.18952402472496033\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1114 loss: 0.395302414894104\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1115 loss: 0.5854923725128174\n",
      "class 0: acc 0.7812, precision 0.8519, recall 0.8846, f1 0.8679\n",
      "class 1: acc 0.7500, precision 0.2000, recall 0.2000, f1 0.2000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1116 loss: 0.2189730703830719\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1117 loss: 0.6054254770278931\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1118 loss: 0.42806801199913025\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1119 loss: 0.3892418146133423\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1120 loss: 0.21994397044181824\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1121 loss: 0.2729440927505493\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1122 loss: 0.4233430027961731\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1123 loss: 0.1005963459610939\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1124 loss: 0.3315211832523346\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1125 loss: 0.4903472661972046\n",
      "class 0: acc 0.8438, precision 0.8333, recall 0.9524, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1126 loss: 0.19529753923416138\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1127 loss: 0.6095637083053589\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1128 loss: 0.5799471735954285\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1129 loss: 0.17773860692977905\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1130 loss: 0.37839555740356445\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1131 loss: 0.2958356738090515\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1132 loss: 0.3796522617340088\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1133 loss: 0.5849180221557617\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1134 loss: 0.6838424205780029\n",
      "class 0: acc 0.7812, precision 0.8400, recall 0.8750, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.5714, recall 0.6667, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1135 loss: 0.22221501171588898\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1136 loss: 0.4309728443622589\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1137 loss: 0.36169683933258057\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1138 loss: 0.2000039517879486\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1139 loss: 0.5978636741638184\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1140 loss: 0.8019006252288818\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1141 loss: 0.3571004271507263\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1142 loss: 0.5524113178253174\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1143 loss: 0.45542916655540466\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1144 loss: 0.4470713138580322\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1145 loss: 0.35233160853385925\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1146 loss: 0.3463524580001831\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1147 loss: 0.40975290536880493\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1148 loss: 0.4022597670555115\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1149 loss: 0.2219270020723343\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1150 loss: 0.29636260867118835\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1151 loss: 0.5186938643455505\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1152 loss: 0.4190220236778259\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1153 loss: 0.18255414068698883\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1154 loss: 0.21867980062961578\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1155 loss: 0.5691768527030945\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1156 loss: 0.21078728139400482\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1157 loss: 0.2950960099697113\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1158 loss: 0.3103177547454834\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1159 loss: 0.3705503046512604\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1160 loss: 0.45183709263801575\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1161 loss: 0.39989033341407776\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1162 loss: 0.2631767690181732\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1163 loss: 0.39264386892318726\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1164 loss: 0.4729594886302948\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1165 loss: 0.4470076560974121\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1166 loss: 0.3214755058288574\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1167 loss: 0.38442325592041016\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1168 loss: 0.23406314849853516\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.9000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1169 loss: 0.37519919872283936\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1170 loss: 0.3015172481536865\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1171 loss: 0.43950045108795166\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1172 loss: 0.3253435790538788\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1173 loss: 0.6162108182907104\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1174 loss: 0.37494975328445435\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1175 loss: 0.5038937926292419\n",
      "class 0: acc 0.9062, precision 0.9565, recall 0.9167, f1 0.9362\n",
      "class 1: acc 0.8438, precision 0.4444, recall 1.0000, f1 0.6154\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1176 loss: 0.2718163728713989\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1177 loss: 0.6056174635887146\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1178 loss: 0.24211278557777405\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1179 loss: 0.5145337581634521\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1180 loss: 0.3388662040233612\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1181 loss: 0.31865909695625305\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9259, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1182 loss: 0.22959184646606445\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1183 loss: 0.3883264660835266\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1184 loss: 0.2939773499965668\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1185 loss: 0.4019469916820526\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1186 loss: 0.24597956240177155\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1187 loss: 0.41930973529815674\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1188 loss: 0.20588503777980804\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1189 loss: 0.48097509145736694\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1190 loss: 0.32440224289894104\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1191 loss: 0.4063915014266968\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1192 loss: 0.24930380284786224\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1193 loss: 0.30947771668434143\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1194 loss: 0.43690741062164307\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1195 loss: 0.4661441743373871\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1196 loss: 0.18989801406860352\n",
      "class 0: acc 0.9688, precision 0.9688, recall 1.0000, f1 0.9841\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1197 loss: 0.17064909636974335\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1198 loss: 0.6782534718513489\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1199 loss: 0.6078431010246277\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1200 loss: 0.4534069001674652\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1201 loss: 0.4100465178489685\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1202 loss: 0.47736334800720215\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1203 loss: 0.47329095005989075\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1204 loss: 0.3163087069988251\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1205 loss: 0.23284423351287842\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1206 loss: 0.9146186113357544\n",
      "class 0: acc 0.6875, precision 0.7000, recall 0.9545, f1 0.8077\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1207 loss: 0.21634408831596375\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1208 loss: 0.12390182912349701\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1209 loss: 0.39240264892578125\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1210 loss: 0.2759684920310974\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1211 loss: 0.38492676615715027\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1212 loss: 0.25977271795272827\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1213 loss: 0.547782838344574\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1214 loss: 0.4847894608974457\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1215 loss: 0.24687117338180542\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1216 loss: 0.43197101354599\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1217 loss: 0.47419241070747375\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1218 loss: 0.6773776412010193\n",
      "class 0: acc 0.7500, precision 0.7241, recall 1.0000, f1 0.8400\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1219 loss: 0.42749279737472534\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1220 loss: 0.22875648736953735\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1221 loss: 0.4048647880554199\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1222 loss: 0.5999046564102173\n",
      "class 0: acc 0.7812, precision 0.8333, recall 0.9259, f1 0.8772\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1223 loss: 0.32607582211494446\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1224 loss: 0.47141018509864807\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1225 loss: 0.357388436794281\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1226 loss: 0.6017087697982788\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1227 loss: 0.5249509215354919\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1228 loss: 0.2536185085773468\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1229 loss: 0.21016575396060944\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1230 loss: 0.4418332278728485\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1231 loss: 0.6434210538864136\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1232 loss: 0.41504451632499695\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1233 loss: 0.4956810474395752\n",
      "class 0: acc 0.7812, precision 0.8077, recall 0.9130, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1234 loss: 0.2919033169746399\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1235 loss: 0.4628341495990753\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1236 loss: 0.40522533655166626\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1237 loss: 0.6060669422149658\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1238 loss: 0.48113471269607544\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1239 loss: 0.5438254475593567\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1240 loss: 0.3436603546142578\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1241 loss: 0.768671452999115\n",
      "class 0: acc 0.7188, precision 0.7000, recall 1.0000, f1 0.8235\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1242 loss: 0.2688412368297577\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1243 loss: 0.497905969619751\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1244 loss: 0.2815280258655548\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1245 loss: 0.2550148367881775\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1246 loss: 0.5030032992362976\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1247 loss: 0.37268900871276855\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1248 loss: 0.40238937735557556\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1249 loss: 0.08922300487756729\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 1 step: 1250 loss: 0.3717433512210846\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1 loss: 0.5298064947128296\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 2 loss: 0.510104775428772\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 3 loss: 0.1809629499912262\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 4 loss: 0.30231720209121704\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 5 loss: 0.36957529187202454\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 6 loss: 0.49547454714775085\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 7 loss: 0.21257582306861877\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 8 loss: 0.5803304314613342\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 9 loss: 0.3097648024559021\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 10 loss: 0.2819654941558838\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 11 loss: 0.2725003659725189\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 12 loss: 0.5918917655944824\n",
      "class 0: acc 0.7500, precision 0.7742, recall 0.9600, f1 0.8571\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 13 loss: 0.3214977979660034\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 14 loss: 0.3392666280269623\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 15 loss: 0.16073258221149445\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 16 loss: 0.5416375398635864\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 17 loss: 0.34769922494888306\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 18 loss: 0.45511725544929504\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 19 loss: 0.329073965549469\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 20 loss: 0.2509363889694214\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 21 loss: 0.7420752644538879\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 22 loss: 0.19141210615634918\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 23 loss: 0.10203788429498672\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 24 loss: 0.26187950372695923\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 25 loss: 0.40079227089881897\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 26 loss: 0.6734732985496521\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 27 loss: 0.2884621024131775\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 28 loss: 0.24446889758110046\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 29 loss: 0.35484230518341064\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 30 loss: 0.2028771936893463\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 31 loss: 0.46908265352249146\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 32 loss: 0.5089910626411438\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 33 loss: 0.4227818250656128\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 34 loss: 0.25988635420799255\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 35 loss: 0.5134797692298889\n",
      "class 0: acc 0.7812, precision 0.7308, recall 1.0000, f1 0.8444\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5455, f1 0.7059\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 36 loss: 0.22758091986179352\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 37 loss: 0.3572523891925812\n",
      "class 0: acc 0.8438, precision 0.9231, recall 0.8889, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 38 loss: 0.5045813322067261\n",
      "class 0: acc 0.8750, precision 0.9630, recall 0.8966, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.2000, recall 1.0000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 39 loss: 0.468278706073761\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 40 loss: 0.43089744448661804\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 41 loss: 0.47397956252098083\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 42 loss: 0.43539467453956604\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 43 loss: 0.5223003029823303\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 44 loss: 0.5183603763580322\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 45 loss: 0.2484026402235031\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 46 loss: 0.36130478978157043\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 47 loss: 0.27399253845214844\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 48 loss: 0.4902504086494446\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 49 loss: 0.23363517224788666\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 50 loss: 0.34992218017578125\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 51 loss: 0.39718642830848694\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 52 loss: 0.43687373399734497\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 53 loss: 0.2137283831834793\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 54 loss: 0.5080554485321045\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 55 loss: 0.4762156903743744\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 56 loss: 0.2683214843273163\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 57 loss: 0.46453505754470825\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 58 loss: 0.3730466961860657\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 59 loss: 0.4807952046394348\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 60 loss: 0.34011560678482056\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 61 loss: 0.35313260555267334\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 62 loss: 0.5626353025436401\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 63 loss: 0.26496902108192444\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 64 loss: 0.23047998547554016\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 65 loss: 0.3194252848625183\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 66 loss: 0.48271724581718445\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 67 loss: 0.15088607370853424\n",
      "class 0: acc 0.9688, precision 0.9600, recall 1.0000, f1 0.9796\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8750, f1 0.9333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 68 loss: 0.4042344093322754\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 69 loss: 0.6489167213439941\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.1429, f1 0.2222\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 70 loss: 0.573187530040741\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 71 loss: 0.33794549107551575\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 72 loss: 0.16965657472610474\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 73 loss: 0.25848037004470825\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 74 loss: 0.092525415122509\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 75 loss: 0.15071801841259003\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 76 loss: 0.33647486567497253\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 77 loss: 0.576521098613739\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 78 loss: 0.21697840094566345\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 79 loss: 0.19698217511177063\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 80 loss: 0.17924761772155762\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 81 loss: 0.14102566242218018\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 82 loss: 0.6812360286712646\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 83 loss: 0.6364009380340576\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 84 loss: 0.5728803277015686\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 85 loss: 0.40896880626678467\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 86 loss: 0.5950520634651184\n",
      "class 0: acc 0.7188, precision 0.7407, recall 0.9091, f1 0.8163\n",
      "class 1: acc 0.7812, precision 0.6000, recall 0.3750, f1 0.4615\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 87 loss: 0.37659627199172974\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 88 loss: 0.47983667254447937\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 89 loss: 0.37229275703430176\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 90 loss: 0.31592750549316406\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 91 loss: 0.290391206741333\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 92 loss: 0.37594419717788696\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 93 loss: 0.6019861698150635\n",
      "class 0: acc 0.7812, precision 0.8333, recall 0.9259, f1 0.8772\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 94 loss: 0.3275817334651947\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 95 loss: 0.42764028906822205\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 96 loss: 0.30529487133026123\n",
      "class 0: acc 0.9375, precision 0.9167, recall 1.0000, f1 0.9565\n",
      "class 1: acc 0.9375, precision 0.8750, recall 0.8750, f1 0.8750\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 97 loss: 0.6991828680038452\n",
      "class 0: acc 0.7500, precision 0.7667, recall 0.9583, f1 0.8519\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 98 loss: 0.29057419300079346\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 99 loss: 0.24471701681613922\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 100 loss: 0.17612865567207336\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 101 loss: 0.16793833673000336\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 102 loss: 0.2433503270149231\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 103 loss: 0.18179838359355927\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 104 loss: 0.2803279757499695\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 105 loss: 0.25574877858161926\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 106 loss: 0.37287381291389465\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 107 loss: 0.3799472153186798\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 108 loss: 0.33265626430511475\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 109 loss: 0.3971858620643616\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 110 loss: 0.6402105689048767\n",
      "class 0: acc 0.7812, precision 0.7407, recall 1.0000, f1 0.8511\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 111 loss: 0.2378939688205719\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 112 loss: 0.22833506762981415\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 113 loss: 0.6085622310638428\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 114 loss: 0.5136296153068542\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 115 loss: 0.4973689019680023\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 116 loss: 0.2934577167034149\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 117 loss: 0.3882189095020294\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 118 loss: 0.32391390204429626\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 119 loss: 0.2959018349647522\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 120 loss: 0.4756181240081787\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 121 loss: 0.1978989988565445\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 122 loss: 0.33220407366752625\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 123 loss: 0.5389930605888367\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 124 loss: 0.44816815853118896\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 125 loss: 0.23688142001628876\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 126 loss: 0.2732919454574585\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 127 loss: 0.22584456205368042\n",
      "class 0: acc 0.9062, precision 0.9667, recall 0.9355, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 128 loss: 0.5428745150566101\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 129 loss: 0.521429717540741\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 130 loss: 0.3946131467819214\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 131 loss: 0.3694135546684265\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 132 loss: 0.2552088797092438\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 133 loss: 0.2092083841562271\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 134 loss: 0.47527143359184265\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 135 loss: 0.42211195826530457\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 136 loss: 0.5288721919059753\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 137 loss: 0.16204914450645447\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 138 loss: 0.4973684251308441\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 139 loss: 0.20325897634029388\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 140 loss: 0.16274116933345795\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 141 loss: 0.37224721908569336\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 142 loss: 0.5869680047035217\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 143 loss: 0.5023330450057983\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 144 loss: 0.4378967881202698\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 145 loss: 0.3579670190811157\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 146 loss: 0.3759855329990387\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 147 loss: 0.3019629120826721\n",
      "class 0: acc 0.9062, precision 0.9667, recall 0.9355, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 148 loss: 0.21786490082740784\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 149 loss: 0.33267322182655334\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 150 loss: 0.30189162492752075\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 151 loss: 0.38445037603378296\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 152 loss: 0.4731495678424835\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 153 loss: 0.19810181856155396\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 154 loss: 0.38064736127853394\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 155 loss: 0.2853216230869293\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 156 loss: 0.5017988085746765\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 157 loss: 0.26688897609710693\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 158 loss: 0.35707834362983704\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 159 loss: 0.32786044478416443\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 160 loss: 0.37858617305755615\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 161 loss: 0.17458204925060272\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 162 loss: 0.2563825845718384\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 163 loss: 0.27588924765586853\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 164 loss: 0.4054001271724701\n",
      "class 0: acc 0.8125, precision 0.8800, recall 0.8800, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.4286, recall 0.6000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 165 loss: 0.595289409160614\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 166 loss: 0.3154391050338745\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 167 loss: 0.43062153458595276\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 168 loss: 0.6646822690963745\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.2500, recall 0.2500, f1 0.2500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 169 loss: 0.43075209856033325\n",
      "class 0: acc 0.8438, precision 0.9286, recall 0.8966, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 170 loss: 0.27783557772636414\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 171 loss: 0.26470234990119934\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 172 loss: 0.1615920215845108\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 173 loss: 0.4071888029575348\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 174 loss: 0.3232481777667999\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 175 loss: 0.4794492721557617\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 176 loss: 0.40384942293167114\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 177 loss: 0.22920405864715576\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 178 loss: 0.34226080775260925\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 179 loss: 0.2167213410139084\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 180 loss: 0.5459399223327637\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 181 loss: 0.713110089302063\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 182 loss: 0.2894279360771179\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 183 loss: 0.26322153210639954\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 184 loss: 0.34323590993881226\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 185 loss: 0.17158551514148712\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 186 loss: 0.5377067923545837\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 187 loss: 0.38649535179138184\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 188 loss: 0.31084346771240234\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 189 loss: 0.5481995344161987\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 190 loss: 0.3853704333305359\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 191 loss: 0.24166688323020935\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 192 loss: 0.2711452841758728\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9286, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 193 loss: 0.43553340435028076\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 194 loss: 0.4134083390235901\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 195 loss: 0.4291490316390991\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 196 loss: 0.20165914297103882\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 197 loss: 0.27648571133613586\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 198 loss: 0.5537757277488708\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 199 loss: 0.33135753870010376\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 200 loss: 0.29330238699913025\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 201 loss: 0.4151340126991272\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 202 loss: 0.44964101910591125\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 203 loss: 0.2058243304491043\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 204 loss: 0.24575623869895935\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 205 loss: 0.331551730632782\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 206 loss: 0.27434971928596497\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 207 loss: 0.34098249673843384\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 208 loss: 0.09604170173406601\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 209 loss: 0.2784138023853302\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 210 loss: 0.2796770930290222\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 211 loss: 0.65733802318573\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 212 loss: 0.5471428036689758\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 213 loss: 0.07637837529182434\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 214 loss: 0.12799449265003204\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 215 loss: 0.46848809719085693\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 216 loss: 0.39387014508247375\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 217 loss: 0.42205315828323364\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 218 loss: 0.5908260941505432\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 219 loss: 0.5261105895042419\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 220 loss: 0.18555113673210144\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 221 loss: 0.4017677903175354\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 222 loss: 0.31735116243362427\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 223 loss: 0.460763156414032\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 224 loss: 0.2745039463043213\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 0.9688, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 225 loss: 0.2733677327632904\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 226 loss: 0.1956155151128769\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 227 loss: 0.5154580473899841\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 228 loss: 0.17094604671001434\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 229 loss: 0.41339901089668274\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 230 loss: 0.4870389699935913\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 231 loss: 0.21466606855392456\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 232 loss: 0.26842737197875977\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 233 loss: 0.44058936834335327\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 234 loss: 0.21069785952568054\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 235 loss: 0.5494640469551086\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 236 loss: 0.6772545576095581\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 237 loss: 0.09482896327972412\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 238 loss: 0.4432828426361084\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 239 loss: 0.27326199412345886\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 240 loss: 0.23523996770381927\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 241 loss: 0.36325186491012573\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 242 loss: 0.3864847719669342\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 243 loss: 0.5770721435546875\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 244 loss: 0.6387714743614197\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 245 loss: 0.36513975262641907\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 246 loss: 0.4631003141403198\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 247 loss: 0.3117549419403076\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 248 loss: 0.34738636016845703\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 249 loss: 0.4147729277610779\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 250 loss: 0.16581736505031586\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9615, f1 0.9804\n",
      "class 1: acc 0.9688, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 251 loss: 0.3397406339645386\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 252 loss: 0.5657836198806763\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 253 loss: 0.7150121331214905\n",
      "class 0: acc 0.7812, precision 0.8519, recall 0.8846, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.2000, recall 0.3333, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 254 loss: 0.4609540104866028\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 255 loss: 0.2871831953525543\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 256 loss: 0.2993450462818146\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 257 loss: 0.31222617626190186\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 258 loss: 0.26540136337280273\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 259 loss: 0.2441595196723938\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 260 loss: 0.1619090586900711\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 261 loss: 0.1640724241733551\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 262 loss: 0.35246485471725464\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 263 loss: 0.12298131734132767\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 264 loss: 0.3381291925907135\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 265 loss: 0.370967835187912\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 266 loss: 0.5059871673583984\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 267 loss: 0.4303424060344696\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 268 loss: 0.3613262176513672\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 269 loss: 0.43647176027297974\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 270 loss: 0.26904112100601196\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 271 loss: 0.2624606788158417\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 272 loss: 0.46123844385147095\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 273 loss: 0.3123738169670105\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 274 loss: 0.28569677472114563\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 275 loss: 0.4843131899833679\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 276 loss: 0.42052018642425537\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 277 loss: 0.2595006227493286\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 278 loss: 0.3826953172683716\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 279 loss: 0.23999592661857605\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 280 loss: 0.321702778339386\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 281 loss: 0.22646033763885498\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 282 loss: 0.3128126263618469\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 283 loss: 0.2953425943851471\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 284 loss: 0.49140843749046326\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 285 loss: 0.36129409074783325\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 286 loss: 0.3702750504016876\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 287 loss: 0.358286052942276\n",
      "class 0: acc 0.8750, precision 0.8261, recall 1.0000, f1 0.9048\n",
      "class 1: acc 0.9375, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 288 loss: 0.38462331891059875\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 289 loss: 0.2824319303035736\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 290 loss: 0.38425302505493164\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 291 loss: 0.23177148401737213\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 292 loss: 0.2714039087295532\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 293 loss: 0.5870615839958191\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 294 loss: 0.26686984300613403\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 295 loss: 0.4973262846469879\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 296 loss: 0.1966397613286972\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 297 loss: 0.4669094681739807\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 298 loss: 0.44683146476745605\n",
      "class 0: acc 0.9062, precision 0.9000, recall 0.9474, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 299 loss: 0.4978431761264801\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 300 loss: 0.4837411940097809\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 301 loss: 0.21627533435821533\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 302 loss: 0.38745003938674927\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 303 loss: 0.501537024974823\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 304 loss: 0.40099281072616577\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 305 loss: 0.18682311475276947\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 306 loss: 0.5045483112335205\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 307 loss: 0.33685338497161865\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 308 loss: 0.2570270597934723\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 309 loss: 0.4308607876300812\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 310 loss: 0.4620552957057953\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.8125, precision 0.8333, recall 0.5000, f1 0.6250\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 311 loss: 0.22811205685138702\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 312 loss: 0.288185715675354\n",
      "class 0: acc 0.9375, precision 0.9565, recall 0.9565, f1 0.9565\n",
      "class 1: acc 0.9062, precision 0.7778, recall 0.8750, f1 0.8235\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 313 loss: 0.41523098945617676\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 314 loss: 0.4690384864807129\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 315 loss: 0.36390525102615356\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 316 loss: 0.5492997169494629\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 317 loss: 0.23341606557369232\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 318 loss: 0.28001052141189575\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9615, f1 0.9804\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 319 loss: 0.27303043007850647\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 320 loss: 0.2993462383747101\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 321 loss: 0.5265301465988159\n",
      "class 0: acc 0.7812, precision 0.8462, recall 0.8800, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 322 loss: 0.3137129545211792\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 323 loss: 0.3098468482494354\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 324 loss: 0.40530553460121155\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 325 loss: 0.3976685404777527\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 326 loss: 0.3363180160522461\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 327 loss: 0.34835392236709595\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 328 loss: 0.3558679521083832\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 329 loss: 0.4120729863643646\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 330 loss: 0.2587686777114868\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 331 loss: 0.5895741581916809\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 332 loss: 0.3039083778858185\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 333 loss: 0.6286115050315857\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 334 loss: 0.42969420552253723\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 335 loss: 0.21475230157375336\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 336 loss: 0.40868115425109863\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 337 loss: 0.32654809951782227\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 338 loss: 0.18650567531585693\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 339 loss: 0.4051108956336975\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 340 loss: 0.2333582639694214\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 341 loss: 0.47235211730003357\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 342 loss: 0.6310847401618958\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.7500, precision 0.3333, recall 0.1429, f1 0.2000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 343 loss: 0.3165242075920105\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 344 loss: 0.2966819703578949\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 345 loss: 0.4464443624019623\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 346 loss: 0.5370663404464722\n",
      "class 0: acc 0.7812, precision 0.8462, recall 0.8800, f1 0.8627\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 347 loss: 0.29516083002090454\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 348 loss: 0.5861083269119263\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 349 loss: 0.5954439043998718\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 350 loss: 0.4699150025844574\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 351 loss: 0.6108410358428955\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 352 loss: 0.3034950792789459\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 353 loss: 0.45110759139060974\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 354 loss: 0.3850577473640442\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 355 loss: 0.5289204716682434\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 356 loss: 0.35485953092575073\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 357 loss: 0.6763633489608765\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 358 loss: 0.3059418797492981\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 359 loss: 0.27627527713775635\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 360 loss: 0.38204503059387207\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 361 loss: 0.41220688819885254\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 362 loss: 0.21397103369235992\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 363 loss: 0.3231421411037445\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 364 loss: 0.28617286682128906\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 365 loss: 0.31706497073173523\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 366 loss: 0.41319531202316284\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 367 loss: 0.29248252511024475\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 368 loss: 0.19413959980010986\n",
      "class 0: acc 0.9688, precision 0.9600, recall 1.0000, f1 0.9796\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8750, f1 0.9333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 369 loss: 0.2827516198158264\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 370 loss: 0.3942446708679199\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 371 loss: 0.35755881667137146\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 372 loss: 0.5259535908699036\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 373 loss: 0.29012632369995117\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 374 loss: 0.5495039224624634\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 375 loss: 0.5149555206298828\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 376 loss: 0.23511835932731628\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 377 loss: 0.37056559324264526\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 378 loss: 0.3927692770957947\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 379 loss: 0.4556977450847626\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 380 loss: 0.5710830688476562\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 381 loss: 0.17675404250621796\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 382 loss: 0.4606018662452698\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 383 loss: 0.516841471195221\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 384 loss: 0.6327865719795227\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 385 loss: 0.2729967534542084\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 386 loss: 0.14910364151000977\n",
      "class 0: acc 0.9688, precision 0.9688, recall 1.0000, f1 0.9841\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 387 loss: 0.3884180188179016\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.7000, f1 0.8235\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 388 loss: 0.3595876097679138\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 389 loss: 0.2739923298358917\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 390 loss: 0.32683780789375305\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 391 loss: 0.2537173926830292\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 392 loss: 0.3178245425224304\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 393 loss: 0.48604616522789\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 394 loss: 0.5819522142410278\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 395 loss: 0.27535706758499146\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 396 loss: 0.30305781960487366\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 397 loss: 0.4419640302658081\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 398 loss: 0.3877459168434143\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 399 loss: 0.339961975812912\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 400 loss: 0.5704809427261353\n",
      "class 0: acc 0.8438, precision 0.9200, recall 0.8846, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 401 loss: 0.5581182241439819\n",
      "class 0: acc 0.8125, precision 0.8800, recall 0.8800, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.4286, recall 0.7500, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 402 loss: 0.5096907615661621\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 403 loss: 0.47064921259880066\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8125, precision 0.2500, recall 0.2500, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 404 loss: 0.1757069230079651\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 405 loss: 0.16711828112602234\n",
      "class 0: acc 0.9688, precision 0.9688, recall 1.0000, f1 0.9841\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 406 loss: 0.3888186514377594\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 407 loss: 0.6344024538993835\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 408 loss: 0.5687193274497986\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 409 loss: 0.3670581579208374\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 410 loss: 0.4938226640224457\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 411 loss: 0.2663527727127075\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 412 loss: 0.3626328706741333\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 2 step: 413 loss: 0.2259090542793274\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 414 loss: 0.506532609462738\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 415 loss: 0.3757762908935547\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 416 loss: 0.22827774286270142\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 417 loss: 0.4734155237674713\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 418 loss: 0.40073251724243164\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 2 step: 419 loss: 0.5029369592666626\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 420 loss: 0.5028411746025085\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 421 loss: 0.38890567421913147\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 422 loss: 0.5291215777397156\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 423 loss: 0.5884636640548706\n",
      "class 0: acc 0.7812, precision 0.7407, recall 1.0000, f1 0.8511\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 424 loss: 0.22968941926956177\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 425 loss: 0.3191746175289154\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 426 loss: 0.27879247069358826\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 427 loss: 0.17533870041370392\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 428 loss: 0.40320658683776855\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 429 loss: 0.4383591115474701\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 430 loss: 0.4919470250606537\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 431 loss: 0.37005817890167236\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 432 loss: 0.10575244575738907\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 433 loss: 0.16990379989147186\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 434 loss: 0.33022838830947876\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 435 loss: 0.3751864433288574\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 436 loss: 0.16084375977516174\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 437 loss: 0.5305973291397095\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 438 loss: 0.25758883357048035\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 439 loss: 0.2669029235839844\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 440 loss: 0.2803308665752411\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 441 loss: 0.38573697209358215\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 442 loss: 0.13473354279994965\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 443 loss: 0.323490709066391\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 444 loss: 0.2135261744260788\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 445 loss: 0.541090726852417\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 446 loss: 0.3889482617378235\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 447 loss: 0.416386216878891\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 448 loss: 0.7268955707550049\n",
      "class 0: acc 0.7812, precision 0.7391, recall 0.9444, f1 0.8293\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 449 loss: 0.5507935285568237\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 450 loss: 0.3795769214630127\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 451 loss: 0.37527063488960266\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 452 loss: 0.3966588079929352\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 453 loss: 0.20814672112464905\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 454 loss: 0.24628125131130219\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 2 step: 455 loss: 0.6998292803764343\n",
      "class 0: acc 0.7188, precision 0.7037, recall 0.9500, f1 0.8085\n",
      "class 1: acc 0.7500, precision 0.8000, recall 0.3636, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 456 loss: 0.35621434450149536\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 2 step: 457 loss: 0.3558172285556793\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 458 loss: 0.28636524081230164\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 459 loss: 0.3378429114818573\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 460 loss: 0.5941213965415955\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.7812, precision 0.4000, recall 0.3333, f1 0.3636\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 461 loss: 0.3148168921470642\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 462 loss: 0.28150683641433716\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 463 loss: 0.5035814642906189\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 464 loss: 0.33523648977279663\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 465 loss: 0.3529738485813141\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 466 loss: 0.32149478793144226\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 467 loss: 0.28239956498146057\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 468 loss: 0.1659531444311142\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 469 loss: 0.49070602655410767\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 470 loss: 0.8627073168754578\n",
      "class 0: acc 0.7500, precision 0.7037, recall 1.0000, f1 0.8261\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 471 loss: 0.11005537956953049\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 472 loss: 0.4656417667865753\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 473 loss: 0.279219388961792\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 474 loss: 0.36841726303100586\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9286, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 475 loss: 0.6177964806556702\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 476 loss: 0.24185208976268768\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 477 loss: 0.23798806965351105\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 478 loss: 0.5152862071990967\n",
      "class 0: acc 0.7500, precision 0.8148, recall 0.8800, f1 0.8462\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 479 loss: 0.26767072081565857\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 480 loss: 0.5564664006233215\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 481 loss: 0.6237407326698303\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 482 loss: 0.44524136185646057\n",
      "class 0: acc 0.7812, precision 0.9200, recall 0.8214, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.2857, recall 1.0000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 483 loss: 0.3662700653076172\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 484 loss: 0.29949697852134705\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 485 loss: 0.30848199129104614\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 486 loss: 0.5063871741294861\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 487 loss: 0.3416961431503296\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 488 loss: 0.462299108505249\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 489 loss: 0.4457106590270996\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 490 loss: 0.4466403126716614\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 491 loss: 0.39453792572021484\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 492 loss: 0.24604952335357666\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 493 loss: 0.4567151665687561\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 494 loss: 0.30834057927131653\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 495 loss: 0.29631155729293823\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 496 loss: 0.4425075650215149\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 497 loss: 0.26894041895866394\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 498 loss: 0.23995591700077057\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 499 loss: 0.28065797686576843\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 500 loss: 0.4554891586303711\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 501 loss: 0.30887570977211\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 502 loss: 0.47303783893585205\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 503 loss: 0.42464005947113037\n",
      "class 0: acc 0.7812, precision 0.7812, recall 1.0000, f1 0.8772\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 504 loss: 0.2287004142999649\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 505 loss: 0.5632638931274414\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 506 loss: 0.21595437824726105\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 507 loss: 0.3622095286846161\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 508 loss: 0.5905249118804932\n",
      "class 0: acc 0.7500, precision 0.7692, recall 0.9091, f1 0.8333\n",
      "class 1: acc 0.7812, precision 0.6667, recall 0.4444, f1 0.5333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 509 loss: 0.4718654751777649\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 510 loss: 0.7285329103469849\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 511 loss: 0.28001755475997925\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 512 loss: 0.5018900036811829\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 513 loss: 0.26698920130729675\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 514 loss: 0.4428715407848358\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 515 loss: 0.2535935044288635\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 516 loss: 0.5621578693389893\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.8438, precision 0.7143, recall 0.6250, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 517 loss: 0.35219693183898926\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 518 loss: 0.6972719430923462\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 519 loss: 0.2034170776605606\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 520 loss: 0.48788589239120483\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 521 loss: 0.48021289706230164\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 522 loss: 0.34506428241729736\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 523 loss: 0.4357723593711853\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 524 loss: 0.35648301243782043\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 525 loss: 0.33717697858810425\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 526 loss: 0.3100367784500122\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 527 loss: 0.26775649189949036\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 528 loss: 0.4192042648792267\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 529 loss: 0.2175658643245697\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 530 loss: 0.35941269993782043\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 531 loss: 0.6629678606987\n",
      "class 0: acc 0.7188, precision 0.7000, recall 1.0000, f1 0.8235\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 532 loss: 0.33288347721099854\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 533 loss: 0.38606035709381104\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 534 loss: 0.24785606563091278\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 535 loss: 0.4675360321998596\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 536 loss: 0.28307992219924927\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 537 loss: 0.6912931203842163\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 538 loss: 0.4399465322494507\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 539 loss: 0.33450448513031006\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 540 loss: 0.4799022674560547\n",
      "class 0: acc 0.8750, precision 0.9130, recall 0.9130, f1 0.9130\n",
      "class 1: acc 0.9062, precision 0.7778, recall 0.8750, f1 0.8235\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 541 loss: 0.21373306214809418\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 542 loss: 0.3696887791156769\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 543 loss: 0.606612503528595\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.7500, precision 0.2500, recall 0.1667, f1 0.2000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 544 loss: 0.4372442662715912\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 545 loss: 0.3261847198009491\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 546 loss: 0.3532918095588684\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 547 loss: 0.15469934046268463\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 548 loss: 0.3339031934738159\n",
      "class 0: acc 0.8438, precision 0.9231, recall 0.8889, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 549 loss: 0.6054660677909851\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 550 loss: 0.4934304356575012\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 551 loss: 0.30369606614112854\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 552 loss: 0.5642213821411133\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 553 loss: 0.3945997953414917\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 554 loss: 0.35368385910987854\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 555 loss: 0.2885403037071228\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 556 loss: 0.4037505090236664\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 557 loss: 0.6484869122505188\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 558 loss: 0.6757877469062805\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 559 loss: 0.5304036736488342\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8125, precision 0.2500, recall 0.2500, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 560 loss: 0.3682181239128113\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 561 loss: 0.4810032844543457\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 562 loss: 0.1690618097782135\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 563 loss: 0.3020849823951721\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 564 loss: 0.47368499636650085\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 565 loss: 0.3597421646118164\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 566 loss: 0.445291668176651\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 567 loss: 0.4285188615322113\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 568 loss: 0.6167598962783813\n",
      "class 0: acc 0.7500, precision 0.7778, recall 0.9130, f1 0.8400\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 569 loss: 0.381521999835968\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 570 loss: 0.4551195502281189\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 571 loss: 0.4565345346927643\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 572 loss: 0.2944319546222687\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 573 loss: 0.2527560889720917\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 574 loss: 0.1778516173362732\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 575 loss: 0.23385170102119446\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 576 loss: 0.36125504970550537\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 577 loss: 0.5353469848632812\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 578 loss: 0.41819819808006287\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 579 loss: 0.6475616097450256\n",
      "class 0: acc 0.7812, precision 0.8333, recall 0.9259, f1 0.8772\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 580 loss: 0.5107813477516174\n",
      "class 0: acc 0.7500, precision 0.7419, recall 1.0000, f1 0.8519\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 581 loss: 0.5627278089523315\n",
      "class 0: acc 0.7812, precision 0.8519, recall 0.8846, f1 0.8679\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 582 loss: 0.2763456106185913\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 583 loss: 0.2750653028488159\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 584 loss: 0.44660550355911255\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 585 loss: 0.3157162666320801\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 586 loss: 0.20157745480537415\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 587 loss: 0.2888612151145935\n",
      "class 0: acc 0.8750, precision 0.9333, recall 0.9333, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 588 loss: 0.22865547239780426\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 589 loss: 0.4377537965774536\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 590 loss: 0.3325090706348419\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 591 loss: 0.5644708871841431\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.6000, recall 0.4286, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 592 loss: 0.3413591682910919\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 593 loss: 0.29778406023979187\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 594 loss: 0.4750528335571289\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 595 loss: 0.3471416234970093\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 596 loss: 0.3007260859012604\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 597 loss: 0.18884427845478058\n",
      "class 0: acc 0.8750, precision 1.0000, recall 0.8667, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 598 loss: 0.2294444739818573\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 599 loss: 0.3694022595882416\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 600 loss: 0.631773829460144\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 601 loss: 0.4802996814250946\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 602 loss: 0.35976046323776245\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 603 loss: 0.32991182804107666\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 604 loss: 0.6610798239707947\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 605 loss: 0.21224279701709747\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 606 loss: 0.3575274348258972\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 607 loss: 0.36222246289253235\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 608 loss: 0.5907260179519653\n",
      "class 0: acc 0.7188, precision 0.7500, recall 0.9130, f1 0.8235\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.2857, f1 0.3636\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 609 loss: 0.5609955191612244\n",
      "class 0: acc 0.7188, precision 0.7692, recall 0.8696, f1 0.8163\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.4286, f1 0.4615\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 610 loss: 0.5122483968734741\n",
      "class 0: acc 0.7812, precision 0.9091, recall 0.8000, f1 0.8511\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.8333, f1 0.6250\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 611 loss: 0.4079506993293762\n",
      "class 0: acc 0.8750, precision 0.9615, recall 0.8929, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.6667, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 612 loss: 0.3250971734523773\n",
      "class 0: acc 0.8750, precision 0.9615, recall 0.8929, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 613 loss: 0.45283403992652893\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 614 loss: 0.2991476058959961\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 615 loss: 0.5006702542304993\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 0.8438, precision 0.6250, recall 0.7143, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 616 loss: 0.5267165303230286\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 617 loss: 0.34970101714134216\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 618 loss: 0.43593835830688477\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 619 loss: 0.5883017778396606\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 620 loss: 0.4767319858074188\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 621 loss: 0.3722400665283203\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 622 loss: 0.40623700618743896\n",
      "class 0: acc 0.8438, precision 0.9231, recall 0.8889, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.6667, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 623 loss: 0.334727942943573\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9583, f1 0.9787\n",
      "class 1: acc 0.9375, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 624 loss: 0.5725455284118652\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 625 loss: 0.43274402618408203\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 626 loss: 0.2877447009086609\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 627 loss: 0.36890843510627747\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 628 loss: 0.23743613064289093\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 629 loss: 0.3920333981513977\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 630 loss: 0.3812565505504608\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 631 loss: 0.48393890261650085\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 632 loss: 0.3108013868331909\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 633 loss: 0.21849164366722107\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 634 loss: 0.16634468734264374\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 635 loss: 0.3362659811973572\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 636 loss: 0.2463720142841339\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 637 loss: 0.5076294541358948\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 638 loss: 0.1094251424074173\n",
      "class 0: acc 0.9688, precision 0.9688, recall 1.0000, f1 0.9841\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 639 loss: 0.37489527463912964\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 640 loss: 0.6848151683807373\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 641 loss: 0.45764634013175964\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 642 loss: 0.5323923826217651\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 643 loss: 0.32087817788124084\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 644 loss: 0.440218985080719\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 645 loss: 0.4469176232814789\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 646 loss: 0.361429899930954\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 647 loss: 0.5090595483779907\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 648 loss: 0.35940447449684143\n",
      "class 0: acc 0.8750, precision 0.9600, recall 0.8889, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 649 loss: 0.650614321231842\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 650 loss: 0.5158815383911133\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 651 loss: 0.46635788679122925\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 652 loss: 0.4158961772918701\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 653 loss: 0.36593756079673767\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 654 loss: 0.6293182373046875\n",
      "class 0: acc 0.7812, precision 0.8095, recall 0.8500, f1 0.8293\n",
      "class 1: acc 0.7812, precision 0.7273, recall 0.6667, f1 0.6957\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 655 loss: 0.4668844938278198\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 656 loss: 0.46351826190948486\n",
      "class 0: acc 0.8125, precision 0.8400, recall 0.9130, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 657 loss: 0.2960795760154724\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 658 loss: 0.3194383382797241\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 659 loss: 0.2883286774158478\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 660 loss: 0.46333831548690796\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 661 loss: 0.320319265127182\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 662 loss: 0.4894927442073822\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 663 loss: 0.29296091198921204\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 664 loss: 0.34728899598121643\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 665 loss: 0.4164610505104065\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 666 loss: 0.28992176055908203\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 667 loss: 0.16853931546211243\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 668 loss: 0.4620845913887024\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 669 loss: 0.4140699505805969\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 670 loss: 0.41059502959251404\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 671 loss: 0.4782831370830536\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 672 loss: 0.351893812417984\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 673 loss: 0.5842110514640808\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 674 loss: 0.5361739993095398\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 675 loss: 0.400235116481781\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 676 loss: 0.38859811425209045\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 677 loss: 0.27770283818244934\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 678 loss: 0.5991154313087463\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 679 loss: 0.38074594736099243\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 680 loss: 0.3862227201461792\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 681 loss: 0.4221859276294708\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 682 loss: 0.6137793660163879\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 683 loss: 0.532332181930542\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 684 loss: 0.18366338312625885\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 685 loss: 0.35305678844451904\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 686 loss: 0.2757749557495117\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 687 loss: 0.6612581610679626\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.6000, recall 0.4286, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 688 loss: 0.31042012572288513\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 689 loss: 0.14269787073135376\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 690 loss: 0.7209888696670532\n",
      "class 0: acc 0.6875, precision 0.6429, recall 1.0000, f1 0.7826\n",
      "class 1: acc 0.7812, precision 1.0000, recall 0.3636, f1 0.5333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 691 loss: 0.22365574538707733\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 692 loss: 0.5703950524330139\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 693 loss: 0.337516725063324\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 694 loss: 0.3160272240638733\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 695 loss: 0.5276849269866943\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 696 loss: 0.6256352066993713\n",
      "class 0: acc 0.6875, precision 0.7500, recall 0.8182, f1 0.7826\n",
      "class 1: acc 0.7500, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 697 loss: 0.3521203398704529\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 698 loss: 0.27624669671058655\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 699 loss: 0.4290536940097809\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 700 loss: 0.43530160188674927\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 701 loss: 0.5027722716331482\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 702 loss: 0.28043419122695923\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 703 loss: 0.32937711477279663\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 704 loss: 0.2353689968585968\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 705 loss: 0.37031233310699463\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 706 loss: 0.2645798921585083\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 707 loss: 0.3370019495487213\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.9000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 708 loss: 0.5068597793579102\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 709 loss: 0.22136037051677704\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 710 loss: 0.31924429535865784\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 711 loss: 0.48383983969688416\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 712 loss: 0.3503665328025818\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 713 loss: 0.5212801098823547\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 714 loss: 0.40926259756088257\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 715 loss: 0.20953597128391266\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 716 loss: 0.4531934857368469\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 717 loss: 0.3413587808609009\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 718 loss: 0.30237436294555664\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 719 loss: 0.5723322033882141\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 720 loss: 0.40555518865585327\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 721 loss: 0.31457051634788513\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 722 loss: 0.5320707559585571\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 723 loss: 0.26519063115119934\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 724 loss: 0.347194641828537\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 725 loss: 0.34926384687423706\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 726 loss: 0.4557817578315735\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 727 loss: 0.549659252166748\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 728 loss: 0.7006040811538696\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 729 loss: 0.7113911509513855\n",
      "class 0: acc 0.7188, precision 0.7407, recall 0.9091, f1 0.8163\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 730 loss: 0.3150935471057892\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 731 loss: 0.4234957695007324\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 732 loss: 0.29481035470962524\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 733 loss: 0.2651810646057129\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 734 loss: 0.2779709994792938\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 2 step: 735 loss: 0.7187877893447876\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 736 loss: 0.5989112854003906\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 737 loss: 0.3339424133300781\n",
      "class 0: acc 0.9375, precision 0.9167, recall 1.0000, f1 0.9565\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 738 loss: 0.7462171912193298\n",
      "class 0: acc 0.7188, precision 0.7419, recall 0.9583, f1 0.8364\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 739 loss: 0.25647640228271484\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 740 loss: 0.40835851430892944\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 741 loss: 0.317152738571167\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 742 loss: 0.5381949543952942\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 743 loss: 0.4171125590801239\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 744 loss: 0.21670983731746674\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 745 loss: 0.18956440687179565\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9333, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 746 loss: 0.4299929440021515\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 747 loss: 0.4089969992637634\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 748 loss: 0.7426339983940125\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 749 loss: 0.5536024570465088\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 750 loss: 0.4520837366580963\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 751 loss: 0.6119612455368042\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 752 loss: 0.6094380021095276\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 753 loss: 0.5552943348884583\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 754 loss: 0.21572570502758026\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 755 loss: 0.6732637882232666\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 756 loss: 0.360687792301178\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 757 loss: 0.32865285873413086\n",
      "class 0: acc 0.8750, precision 0.9615, recall 0.8929, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 758 loss: 0.4581737518310547\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 759 loss: 0.434375524520874\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 760 loss: 0.43091630935668945\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 761 loss: 0.5716026425361633\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 762 loss: 0.37198272347450256\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 763 loss: 0.45094436407089233\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 764 loss: 0.23322553932666779\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 765 loss: 0.21875044703483582\n",
      "class 0: acc 0.8750, precision 1.0000, recall 0.8710, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.2000, recall 1.0000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 766 loss: 0.24364851415157318\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 767 loss: 0.5154692530632019\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 768 loss: 0.25017881393432617\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 769 loss: 0.37233197689056396\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 770 loss: 0.2248339056968689\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 771 loss: 0.4217074513435364\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 772 loss: 0.4990517497062683\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 773 loss: 0.33240965008735657\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 774 loss: 0.46009889245033264\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 775 loss: 0.35935190320014954\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 776 loss: 0.1638622283935547\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 777 loss: 0.3487335741519928\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 778 loss: 0.2776661515235901\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 779 loss: 0.31117433309555054\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 780 loss: 0.44944334030151367\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 781 loss: 0.3684214949607849\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 782 loss: 0.43421584367752075\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 783 loss: 0.2673790454864502\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 784 loss: 0.3232806622982025\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 785 loss: 0.306253582239151\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 786 loss: 0.8154928684234619\n",
      "class 0: acc 0.6562, precision 0.6667, recall 0.9524, f1 0.7843\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.1429, f1 0.2222\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 787 loss: 0.4707961082458496\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 788 loss: 0.6942105293273926\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 789 loss: 0.3412015736103058\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 790 loss: 0.19894476234912872\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 791 loss: 0.34121498465538025\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 792 loss: 0.2500901520252228\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 793 loss: 0.3826443552970886\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 794 loss: 0.24764832854270935\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 795 loss: 0.45785728096961975\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 796 loss: 0.6622149348258972\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 797 loss: 0.5701620578765869\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 798 loss: 0.21767640113830566\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 799 loss: 0.7360581755638123\n",
      "class 0: acc 0.7500, precision 0.7308, recall 0.9500, f1 0.8261\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 800 loss: 0.4445096254348755\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 801 loss: 0.3918710947036743\n",
      "class 0: acc 0.8750, precision 0.8750, recall 0.9545, f1 0.9130\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.8571, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 802 loss: 0.40069401264190674\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 803 loss: 0.5084675550460815\n",
      "class 0: acc 0.8438, precision 0.8400, recall 0.9545, f1 0.8936\n",
      "class 1: acc 0.8438, precision 0.7143, recall 0.6250, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 804 loss: 0.31198030710220337\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 805 loss: 0.3991621732711792\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 806 loss: 0.2294672131538391\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 807 loss: 0.309440016746521\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 808 loss: 0.21747514605522156\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 809 loss: 0.3657345771789551\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 810 loss: 0.6470005512237549\n",
      "class 0: acc 0.7188, precision 0.7333, recall 0.9565, f1 0.8302\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 811 loss: 0.5352592468261719\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 812 loss: 0.1549200862646103\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 813 loss: 0.4651370346546173\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 814 loss: 0.429629921913147\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 815 loss: 0.5510748028755188\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 816 loss: 0.2764577269554138\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 817 loss: 0.42238011956214905\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 818 loss: 0.35280394554138184\n",
      "class 0: acc 0.8750, precision 0.9130, recall 0.9130, f1 0.9130\n",
      "class 1: acc 0.8750, precision 0.7778, recall 0.7778, f1 0.7778\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 819 loss: 0.3642696738243103\n",
      "class 0: acc 0.8438, precision 0.9000, recall 0.9310, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 820 loss: 0.5225825309753418\n",
      "class 0: acc 0.7812, precision 0.8462, recall 0.8800, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.6667, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 821 loss: 0.44880324602127075\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 822 loss: 0.1998191773891449\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 823 loss: 0.3544923663139343\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 824 loss: 0.41813182830810547\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 825 loss: 0.6612133979797363\n",
      "class 0: acc 0.7500, precision 0.7667, recall 0.9583, f1 0.8519\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 826 loss: 0.6202998161315918\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 827 loss: 0.3044050931930542\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 828 loss: 0.2852587103843689\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 829 loss: 0.16760481894016266\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9355, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 830 loss: 0.5040493011474609\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 831 loss: 0.3434678912162781\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 832 loss: 0.3355526924133301\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 833 loss: 0.4714285135269165\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 834 loss: 0.35429859161376953\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 835 loss: 0.17915810644626617\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 836 loss: 0.2803403437137604\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 837 loss: 0.34886279702186584\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 838 loss: 0.5067161917686462\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 839 loss: 0.44122058153152466\n",
      "class 0: acc 0.7812, precision 0.7812, recall 1.0000, f1 0.8772\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 840 loss: 0.34420686960220337\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 841 loss: 0.4042103886604309\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 842 loss: 0.8331354856491089\n",
      "class 0: acc 0.7188, precision 0.7600, recall 0.8636, f1 0.8085\n",
      "class 1: acc 0.7188, precision 0.4286, recall 0.3750, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 843 loss: 0.23971275985240936\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 844 loss: 0.31840601563453674\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 845 loss: 0.3043115437030792\n",
      "class 0: acc 0.8750, precision 0.9167, recall 0.9167, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 846 loss: 0.3171730041503906\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 847 loss: 0.4788593351840973\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 848 loss: 0.26952773332595825\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 849 loss: 0.3753882944583893\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 850 loss: 0.3702237010002136\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 851 loss: 0.32893502712249756\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 852 loss: 0.3503379225730896\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 853 loss: 0.3506730794906616\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 854 loss: 0.4575628936290741\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 855 loss: 0.27430182695388794\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 856 loss: 0.5285670757293701\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 857 loss: 0.5468927025794983\n",
      "class 0: acc 0.7188, precision 0.7000, recall 1.0000, f1 0.8235\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 858 loss: 0.33502477407455444\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 859 loss: 0.5123499035835266\n",
      "class 0: acc 0.7500, precision 0.7241, recall 1.0000, f1 0.8400\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 860 loss: 0.36834952235221863\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 861 loss: 0.32297247648239136\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 862 loss: 0.5139950513839722\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 863 loss: 0.3449634909629822\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 864 loss: 0.5086581707000732\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 865 loss: 0.39250755310058594\n",
      "class 0: acc 0.8125, precision 0.9167, recall 0.8462, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.3750, recall 0.7500, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 866 loss: 0.5870715975761414\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 867 loss: 0.44141054153442383\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 868 loss: 0.5434200167655945\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 869 loss: 0.2999182939529419\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 870 loss: 0.45285534858703613\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.2500, recall 0.2500, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 871 loss: 0.44605374336242676\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 872 loss: 0.38639411330223083\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 873 loss: 0.27956637740135193\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 874 loss: 0.34505537152290344\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 875 loss: 0.3298388123512268\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 876 loss: 0.4752536714076996\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 877 loss: 0.648468554019928\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 878 loss: 0.5660812258720398\n",
      "class 0: acc 0.7500, precision 0.7419, recall 1.0000, f1 0.8519\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 879 loss: 0.5125763416290283\n",
      "class 0: acc 0.7812, precision 0.7812, recall 1.0000, f1 0.8772\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 880 loss: 0.8078694343566895\n",
      "class 0: acc 0.7188, precision 0.6786, recall 1.0000, f1 0.8085\n",
      "class 1: acc 0.7812, precision 1.0000, recall 0.3636, f1 0.5333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 881 loss: 0.48570990562438965\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 882 loss: 0.5530856251716614\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 883 loss: 0.27490413188934326\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 884 loss: 0.553388774394989\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 885 loss: 0.20232105255126953\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 886 loss: 0.4208076000213623\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.7500, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 887 loss: 0.43601998686790466\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 888 loss: 0.35444188117980957\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 889 loss: 0.4680705964565277\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8125, precision 0.5714, recall 0.5714, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 890 loss: 0.31169959902763367\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 891 loss: 0.23147745430469513\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 892 loss: 0.48877283930778503\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 893 loss: 0.5025194883346558\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 894 loss: 0.48098650574684143\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.7812, precision 0.6000, recall 0.3750, f1 0.4615\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 895 loss: 0.22955837845802307\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 896 loss: 0.43462711572647095\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 897 loss: 0.95722895860672\n",
      "class 0: acc 0.7188, precision 0.7778, recall 0.8750, f1 0.8235\n",
      "class 1: acc 0.7188, precision 0.2000, recall 0.1667, f1 0.1818\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 898 loss: 0.5241246223449707\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 899 loss: 0.21886572241783142\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 900 loss: 0.39761248230934143\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 901 loss: 0.524668276309967\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 902 loss: 0.31440964341163635\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 903 loss: 0.38242074847221375\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 904 loss: 0.6289923191070557\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 905 loss: 0.20943108201026917\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 906 loss: 0.5779231786727905\n",
      "class 0: acc 0.7500, precision 0.7742, recall 0.9600, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 907 loss: 0.2980916202068329\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 908 loss: 0.4095943570137024\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 909 loss: 0.49018070101737976\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 910 loss: 0.35711148381233215\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 911 loss: 0.4155004322528839\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 912 loss: 1.0110732316970825\n",
      "class 0: acc 0.6875, precision 0.6774, recall 1.0000, f1 0.8077\n",
      "class 1: acc 0.7812, precision 1.0000, recall 0.1250, f1 0.2222\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 913 loss: 0.36884477734565735\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 914 loss: 0.3267362713813782\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 915 loss: 0.43246546387672424\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 916 loss: 0.5155590176582336\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 917 loss: 0.33655354380607605\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 918 loss: 0.26177647709846497\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 919 loss: 0.4100482761859894\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 920 loss: 0.3479115068912506\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 921 loss: 0.24147474765777588\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 922 loss: 0.2636813819408417\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 923 loss: 0.2941265106201172\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 924 loss: 0.385062038898468\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 925 loss: 0.5301104784011841\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 926 loss: 0.5922607779502869\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8125, precision 0.8000, recall 0.4444, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 927 loss: 0.5527829527854919\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 928 loss: 0.2832202613353729\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 929 loss: 0.19418103992938995\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 930 loss: 0.2854219079017639\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 931 loss: 0.4710889756679535\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 932 loss: 0.1420108526945114\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 933 loss: 0.6509591341018677\n",
      "class 0: acc 0.7500, precision 0.7407, recall 0.9524, f1 0.8333\n",
      "class 1: acc 0.7188, precision 0.6000, recall 0.3000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 934 loss: 0.2678491473197937\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 935 loss: 0.47945278882980347\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 936 loss: 0.43808087706565857\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 937 loss: 0.20735003054141998\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 938 loss: 0.3673707842826843\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 939 loss: 0.4372769892215729\n",
      "class 0: acc 0.8750, precision 0.9615, recall 0.8929, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 940 loss: 0.3878166377544403\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 941 loss: 0.5685175061225891\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 942 loss: 0.5711892247200012\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 943 loss: 0.43335944414138794\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 944 loss: 0.4447360932826996\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 945 loss: 0.5498671531677246\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 946 loss: 0.33716219663619995\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 947 loss: 0.4799524247646332\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 948 loss: 0.36370912194252014\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 949 loss: 0.3171399235725403\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 950 loss: 0.4590906798839569\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 951 loss: 0.3286389112472534\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 952 loss: 0.44706690311431885\n",
      "class 0: acc 0.8125, precision 0.8400, recall 0.9130, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 953 loss: 0.6384168863296509\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 954 loss: 0.22759440541267395\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 955 loss: 0.2990071177482605\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 956 loss: 0.6314301490783691\n",
      "class 0: acc 0.7500, precision 0.7692, recall 0.9091, f1 0.8333\n",
      "class 1: acc 0.7812, precision 0.6000, recall 0.3750, f1 0.4615\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 957 loss: 0.6466216444969177\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 958 loss: 0.37415245175361633\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 959 loss: 0.5451511740684509\n",
      "class 0: acc 0.7500, precision 0.7692, recall 0.9091, f1 0.8333\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 960 loss: 0.2715800404548645\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 961 loss: 0.32657590508461\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 962 loss: 0.36088743805885315\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 963 loss: 0.40544387698173523\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 964 loss: 0.2979113757610321\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 965 loss: 0.23033684492111206\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9259, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 966 loss: 0.32783570885658264\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 967 loss: 0.2706330120563507\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.9375, precision 0.8750, recall 0.8750, f1 0.8750\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 968 loss: 0.3513644337654114\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 969 loss: 0.4813089072704315\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 970 loss: 0.44337597489356995\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 971 loss: 0.4107958674430847\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 972 loss: 0.2525414824485779\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 973 loss: 0.510083794593811\n",
      "class 0: acc 0.7500, precision 0.7600, recall 0.9048, f1 0.8261\n",
      "class 1: acc 0.7812, precision 0.7143, recall 0.5000, f1 0.5882\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 974 loss: 0.5892395973205566\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 975 loss: 0.5174480676651001\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 976 loss: 0.8881815075874329\n",
      "class 0: acc 0.6875, precision 0.7037, recall 0.9048, f1 0.7917\n",
      "class 1: acc 0.6875, precision 0.4000, recall 0.2222, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 977 loss: 0.37885379791259766\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 978 loss: 0.20946767926216125\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 979 loss: 0.3704012930393219\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 980 loss: 0.575598418712616\n",
      "class 0: acc 0.8438, precision 0.9200, recall 0.8846, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.4286, recall 1.0000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 981 loss: 0.5616490244865417\n",
      "class 0: acc 0.7500, precision 0.7667, recall 0.9583, f1 0.8519\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 982 loss: 0.3078107535839081\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 983 loss: 0.5536842346191406\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 984 loss: 0.5062793493270874\n",
      "class 0: acc 0.8438, precision 0.8750, recall 0.9130, f1 0.8936\n",
      "class 1: acc 0.8438, precision 0.6250, recall 0.7143, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 985 loss: 0.3091592490673065\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 986 loss: 0.18065370619297028\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 987 loss: 0.2331201136112213\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 988 loss: 0.42188867926597595\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 989 loss: 0.6066534519195557\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 990 loss: 0.19850021600723267\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 991 loss: 0.1330488622188568\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 992 loss: 0.35892289876937866\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 993 loss: 0.27178341150283813\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 994 loss: 0.3687613010406494\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 2 step: 995 loss: 0.5038539171218872\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 996 loss: 0.24205930531024933\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 997 loss: 0.30275866389274597\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 998 loss: 0.3928152620792389\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 999 loss: 0.256091833114624\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1000 loss: 0.3137686252593994\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1001 loss: 0.7965891361236572\n",
      "class 0: acc 0.8125, precision 0.8000, recall 0.9524, f1 0.8696\n",
      "class 1: acc 0.8438, precision 0.8571, recall 0.6000, f1 0.7059\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1002 loss: 0.6189086437225342\n",
      "class 0: acc 0.7188, precision 0.7241, recall 0.9545, f1 0.8235\n",
      "class 1: acc 0.7812, precision 0.6667, recall 0.2500, f1 0.3636\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1003 loss: 0.41575145721435547\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1004 loss: 0.48782044649124146\n",
      "class 0: acc 0.7500, precision 0.8462, recall 0.8462, f1 0.8462\n",
      "class 1: acc 0.7812, precision 0.3333, recall 0.4000, f1 0.3636\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1005 loss: 0.5907567739486694\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1006 loss: 0.3252747356891632\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 0.9062, precision 0.8750, recall 0.7778, f1 0.8235\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1007 loss: 0.44596338272094727\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1008 loss: 0.38183873891830444\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1009 loss: 0.461338609457016\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1010 loss: 0.8134346604347229\n",
      "class 0: acc 0.7812, precision 0.8182, recall 0.8571, f1 0.8372\n",
      "class 1: acc 0.7500, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1011 loss: 0.34783467650413513\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1012 loss: 0.39898547530174255\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1013 loss: 0.4224874973297119\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1014 loss: 0.36724090576171875\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1015 loss: 0.3330895006656647\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1016 loss: 0.4338265061378479\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1017 loss: 0.2754669785499573\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1018 loss: 0.5820528864860535\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1019 loss: 0.6124733090400696\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1020 loss: 0.2768506407737732\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1021 loss: 0.12563514709472656\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1022 loss: 0.495597779750824\n",
      "class 0: acc 0.8125, precision 0.7692, recall 1.0000, f1 0.8696\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 2 step: 1023 loss: 0.3794599175453186\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1024 loss: 0.4846404492855072\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1025 loss: 0.4284406304359436\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1026 loss: 0.31893086433410645\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1027 loss: 0.40784505009651184\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1028 loss: 0.5744286179542542\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.7812, precision 0.2000, recall 0.2500, f1 0.2222\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1029 loss: 0.49824586510658264\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1030 loss: 0.34827038645744324\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1031 loss: 0.42093172669410706\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8125, precision 0.6000, recall 0.4286, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1032 loss: 0.465684711933136\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1033 loss: 0.44820255041122437\n",
      "class 0: acc 0.8125, precision 0.9231, recall 0.8571, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1034 loss: 0.48700517416000366\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1035 loss: 0.2251867651939392\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1036 loss: 0.23449444770812988\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1037 loss: 0.503928542137146\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1038 loss: 0.4179958701133728\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1039 loss: 0.2041751593351364\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1040 loss: 0.29491326212882996\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1041 loss: 0.17995746433734894\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1042 loss: 0.19469112157821655\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1043 loss: 0.4012112319469452\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1044 loss: 0.22120486199855804\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1045 loss: 0.19062578678131104\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1046 loss: 0.29823458194732666\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1047 loss: 0.20327742397785187\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1048 loss: 0.4288172721862793\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1049 loss: 0.5475127696990967\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.7812, precision 0.6667, recall 0.2500, f1 0.3636\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1050 loss: 0.44060295820236206\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1051 loss: 0.381451278924942\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1052 loss: 0.6930647492408752\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1053 loss: 0.5808340907096863\n",
      "class 0: acc 0.7500, precision 0.7742, recall 0.9600, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1054 loss: 0.5033421516418457\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1055 loss: 0.4436933994293213\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1056 loss: 0.17139482498168945\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1057 loss: 0.1945633441209793\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1058 loss: 0.2819395661354065\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1059 loss: 0.4150193929672241\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1060 loss: 0.22642379999160767\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1061 loss: 0.43646857142448425\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1062 loss: 0.4510989487171173\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1063 loss: 0.6690204739570618\n",
      "class 0: acc 0.7188, precision 0.7333, recall 0.9565, f1 0.8302\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1064 loss: 0.42796826362609863\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1065 loss: 0.1828198879957199\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1066 loss: 0.42515453696250916\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1067 loss: 0.36794185638427734\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1068 loss: 0.2187349498271942\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1069 loss: 0.33342063426971436\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1070 loss: 0.2665790319442749\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1071 loss: 0.5099639296531677\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1072 loss: 0.13611190021038055\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1073 loss: 0.29693910479545593\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1074 loss: 0.4813530445098877\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1075 loss: 0.34358319640159607\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1076 loss: 0.3244149088859558\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1077 loss: 0.602685809135437\n",
      "class 0: acc 0.7500, precision 0.7241, recall 1.0000, f1 0.8400\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1078 loss: 0.3683317005634308\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1079 loss: 0.4459591209888458\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1080 loss: 0.31521934270858765\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1081 loss: 0.3360987603664398\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1082 loss: 0.30896174907684326\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1083 loss: 0.5736801028251648\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1084 loss: 0.2956638038158417\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1085 loss: 0.5243072509765625\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1086 loss: 0.3297593295574188\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1087 loss: 0.3412318825721741\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1088 loss: 0.551476776599884\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1089 loss: 0.41479384899139404\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1090 loss: 0.4078351855278015\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1091 loss: 0.4276438057422638\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1092 loss: 0.43356889486312866\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1093 loss: 0.49977797269821167\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.8438, precision 0.8571, recall 0.6000, f1 0.7059\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1094 loss: 0.28100451827049255\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1095 loss: 0.3985822796821594\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1096 loss: 0.37457025051116943\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1097 loss: 0.3916098475456238\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1098 loss: 0.5063368678092957\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1099 loss: 0.3281491696834564\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1100 loss: 0.1729593425989151\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1101 loss: 0.36213600635528564\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1102 loss: 0.36845657229423523\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1103 loss: 0.3466102182865143\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7778, f1 0.8750\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1104 loss: 0.39495930075645447\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1105 loss: 0.3227737247943878\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1106 loss: 0.43835359811782837\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1107 loss: 0.2054208517074585\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1108 loss: 0.393256813287735\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1109 loss: 0.5362165570259094\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1110 loss: 0.27341994643211365\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1111 loss: 0.17841516435146332\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1112 loss: 0.8147613406181335\n",
      "class 0: acc 0.7500, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1113 loss: 0.37600231170654297\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1114 loss: 0.6033465266227722\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1115 loss: 0.5247048139572144\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1116 loss: 0.41103610396385193\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1117 loss: 0.44115400314331055\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1118 loss: 0.4773291349411011\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1119 loss: 0.36344343423843384\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1120 loss: 0.44102323055267334\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1121 loss: 0.5510848164558411\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1122 loss: 0.2641347646713257\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1123 loss: 0.2852173149585724\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1124 loss: 0.4500415623188019\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1125 loss: 0.3299332857131958\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1126 loss: 0.26175227761268616\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1127 loss: 0.2619321644306183\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1128 loss: 0.6053882837295532\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1129 loss: 0.48664137721061707\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1130 loss: 0.2999170422554016\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1131 loss: 0.4377061128616333\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1132 loss: 0.26819905638694763\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1133 loss: 0.3272179365158081\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1134 loss: 0.4224966764450073\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1135 loss: 0.14248298108577728\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1136 loss: 0.5069699883460999\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1137 loss: 0.42307862639427185\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1138 loss: 0.2747829258441925\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1139 loss: 0.39034155011177063\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1140 loss: 0.5593124628067017\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1141 loss: 0.5437184572219849\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1142 loss: 0.3104268014431\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1143 loss: 0.45781001448631287\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1144 loss: 0.38251793384552\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1145 loss: 0.4942786693572998\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1146 loss: 0.4236782193183899\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1147 loss: 0.4025387465953827\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1148 loss: 0.30349913239479065\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1149 loss: 0.41370639204978943\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1150 loss: 0.4705754518508911\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1151 loss: 0.27266132831573486\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1152 loss: 0.22703370451927185\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1153 loss: 0.19279779493808746\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1154 loss: 0.21339645981788635\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1155 loss: 0.41239824891090393\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1156 loss: 0.48525914549827576\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1157 loss: 0.15894509851932526\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1158 loss: 0.33660638332366943\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1159 loss: 0.37060117721557617\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1160 loss: 0.4939315915107727\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1161 loss: 0.4820154905319214\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1162 loss: 0.31659865379333496\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1163 loss: 0.2369806170463562\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1164 loss: 0.3292417526245117\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1165 loss: 0.21231655776500702\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1166 loss: 0.45673561096191406\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1167 loss: 0.5055016279220581\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1168 loss: 0.2618676424026489\n",
      "class 0: acc 0.8750, precision 0.9615, recall 0.8929, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1169 loss: 0.3163921535015106\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1170 loss: 0.3238025903701782\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1171 loss: 0.5134523510932922\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1172 loss: 0.18956561386585236\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1173 loss: 0.3381311595439911\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1174 loss: 0.44665098190307617\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1175 loss: 0.23541821539402008\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1176 loss: 0.5002760291099548\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1177 loss: 0.3142859935760498\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1178 loss: 0.3321744203567505\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1179 loss: 0.20400407910346985\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1180 loss: 0.28960493206977844\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1181 loss: 0.5131800770759583\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1182 loss: 0.3608334958553314\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1183 loss: 0.473965048789978\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1184 loss: 0.2750711739063263\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1185 loss: 0.4491664171218872\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1186 loss: 0.475181519985199\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1187 loss: 0.5561248064041138\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1188 loss: 0.5033172369003296\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "epoch: 2 step: 1189 loss: 0.604360818862915\n",
      "class 0: acc 0.7500, precision 0.7742, recall 0.9600, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1190 loss: 0.264093816280365\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1191 loss: 0.4039589464664459\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1192 loss: 0.30445533990859985\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1193 loss: 0.4081954061985016\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1194 loss: 0.371234267950058\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1195 loss: 0.4045892059803009\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1196 loss: 0.36318275332450867\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1197 loss: 0.48202475905418396\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1198 loss: 0.4943466782569885\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1199 loss: 0.44171759486198425\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1200 loss: 0.3712012767791748\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1201 loss: 0.23548001050949097\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1202 loss: 0.2819579541683197\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1203 loss: 0.2797539532184601\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1204 loss: 0.5111457109451294\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1205 loss: 0.5376265048980713\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1206 loss: 0.4280250668525696\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1207 loss: 0.5754198431968689\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1208 loss: 0.4525390863418579\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1209 loss: 0.40914973616600037\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1210 loss: 0.38481202721595764\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1211 loss: 0.48424220085144043\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1212 loss: 0.17265570163726807\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1213 loss: 0.3763654828071594\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1214 loss: 0.22272802889347076\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1215 loss: 0.3130955398082733\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1216 loss: 0.23215968906879425\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1217 loss: 0.3899276852607727\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1218 loss: 0.3249627947807312\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1219 loss: 0.37217384576797485\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1220 loss: 0.24559618532657623\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1221 loss: 0.6687508225440979\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1222 loss: 0.6951857209205627\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.7812, precision 0.2500, recall 0.2000, f1 0.2222\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1223 loss: 0.191367968916893\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1224 loss: 0.5860361456871033\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1225 loss: 0.39066097140312195\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1226 loss: 0.5734062790870667\n",
      "class 0: acc 0.7500, precision 0.8214, recall 0.8846, f1 0.8519\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1227 loss: 0.33141326904296875\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1228 loss: 0.32800933718681335\n",
      "class 0: acc 0.9062, precision 0.9667, recall 0.9355, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1229 loss: 0.3896372318267822\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1230 loss: 0.3538948595523834\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1231 loss: 0.23257724940776825\n",
      "class 0: acc 0.9688, precision 0.9600, recall 1.0000, f1 0.9796\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1232 loss: 0.5537514686584473\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1233 loss: 0.31289318203926086\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1234 loss: 0.34667688608169556\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1235 loss: 0.2639889121055603\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1236 loss: 0.3090433180332184\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1237 loss: 0.419772207736969\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1238 loss: 0.3457934558391571\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1239 loss: 0.41572853922843933\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1240 loss: 0.5043575763702393\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1241 loss: 0.3332686722278595\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1242 loss: 0.17747479677200317\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1243 loss: 0.43593651056289673\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1244 loss: 0.23853297531604767\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1245 loss: 0.5229930877685547\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1246 loss: 0.31787610054016113\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1247 loss: 0.3900707960128784\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1248 loss: 0.23546366393566132\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1249 loss: 0.36453473567962646\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 2 step: 1250 loss: 0.3062776029109955\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1 loss: 0.23772016167640686\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 2 loss: 0.26644936203956604\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 3 loss: 0.562785267829895\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 4 loss: 0.43366116285324097\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 5 loss: 0.3145412504673004\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 6 loss: 0.5039120316505432\n",
      "class 0: acc 0.8125, precision 0.8400, recall 0.9130, f1 0.8750\n",
      "class 1: acc 0.8438, precision 0.5714, recall 0.6667, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 7 loss: 0.37716034054756165\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 8 loss: 0.2271873950958252\n",
      "class 0: acc 0.9062, precision 0.9667, recall 0.9355, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 9 loss: 0.1743301898241043\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 10 loss: 0.40926095843315125\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 11 loss: 0.25469154119491577\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 12 loss: 0.6351836919784546\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 13 loss: 0.3978258967399597\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 14 loss: 0.3840380907058716\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 15 loss: 0.3128622770309448\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 16 loss: 0.427182674407959\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 17 loss: 0.3676164150238037\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 18 loss: 0.27064913511276245\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 19 loss: 0.3922524154186249\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 20 loss: 0.2776634097099304\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 21 loss: 0.4990873336791992\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 22 loss: 0.2793656587600708\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 23 loss: 0.3011128008365631\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 24 loss: 0.45170241594314575\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 25 loss: 0.3125762343406677\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 26 loss: 0.2944762408733368\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 27 loss: 0.411121666431427\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 28 loss: 0.28573933243751526\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 29 loss: 0.24377097189426422\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 30 loss: 0.4451812505722046\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.1429, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 31 loss: 0.28171366453170776\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 32 loss: 0.13100320100784302\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 33 loss: 0.5620088577270508\n",
      "class 0: acc 0.7812, precision 0.8571, recall 0.8889, f1 0.8727\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 34 loss: 0.2953563332557678\n",
      "class 0: acc 0.8438, precision 0.9200, recall 0.8846, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 35 loss: 0.32579782605171204\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.7143, recall 0.6250, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 36 loss: 0.367025226354599\n",
      "class 0: acc 0.8750, precision 0.9630, recall 0.8966, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 37 loss: 0.3717801868915558\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 38 loss: 0.31480467319488525\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 39 loss: 0.3180939853191376\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 40 loss: 0.38687214255332947\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 41 loss: 0.3468788266181946\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 42 loss: 0.19350166618824005\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 43 loss: 0.36354658007621765\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 44 loss: 0.3287690579891205\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 45 loss: 0.46794167160987854\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 46 loss: 0.4886583089828491\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 47 loss: 0.34194517135620117\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 48 loss: 0.4984748363494873\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 49 loss: 0.5219612717628479\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 50 loss: 0.3526870012283325\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 51 loss: 0.5807867646217346\n",
      "class 0: acc 0.7500, precision 0.7931, recall 0.9200, f1 0.8519\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 52 loss: 0.4210211932659149\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 53 loss: 0.5893324613571167\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 54 loss: 0.3076988756656647\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 55 loss: 0.24551232159137726\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 56 loss: 0.2705993354320526\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 57 loss: 0.4447070360183716\n",
      "class 0: acc 0.9062, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.8125, precision 0.6250, recall 0.6250, f1 0.6250\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 58 loss: 0.219760924577713\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 59 loss: 0.589269757270813\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 60 loss: 0.36340221762657166\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 61 loss: 0.5104304552078247\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 62 loss: 0.2626541256904602\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 63 loss: 0.6966698169708252\n",
      "class 0: acc 0.7500, precision 0.7857, recall 0.9167, f1 0.8462\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 64 loss: 0.18910816311836243\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 65 loss: 0.6659128069877625\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 66 loss: 0.2846965789794922\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 67 loss: 0.6208947896957397\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 68 loss: 0.2623785734176636\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 69 loss: 0.3528331220149994\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 70 loss: 0.3622060716152191\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 71 loss: 0.34300729632377625\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 72 loss: 0.22980694472789764\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 73 loss: 0.36017486453056335\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 74 loss: 0.5548949837684631\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 75 loss: 0.22410281002521515\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 76 loss: 0.28769809007644653\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 77 loss: 0.25781509280204773\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 78 loss: 0.1599048227071762\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 79 loss: 0.26208725571632385\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 80 loss: 0.28219860792160034\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 81 loss: 0.28593313694000244\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 82 loss: 0.5389891862869263\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.2000, recall 0.3333, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 83 loss: 0.5077648162841797\n",
      "class 0: acc 0.8125, precision 0.8696, recall 0.8696, f1 0.8696\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 84 loss: 0.30642056465148926\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 85 loss: 0.3794938027858734\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 86 loss: 0.43608972430229187\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 87 loss: 0.43138036131858826\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 88 loss: 0.3391026258468628\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 89 loss: 0.16050978004932404\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 90 loss: 0.4728114902973175\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 91 loss: 0.3099873661994934\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 92 loss: 0.4431018531322479\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 93 loss: 0.36065152287483215\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 94 loss: 0.46060216426849365\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 95 loss: 0.42444759607315063\n",
      "class 0: acc 0.8125, precision 0.8000, recall 0.9524, f1 0.8696\n",
      "class 1: acc 0.8750, precision 0.8571, recall 0.6667, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 96 loss: 0.37068215012550354\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 97 loss: 0.2193068265914917\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 98 loss: 0.4354560375213623\n",
      "class 0: acc 0.8125, precision 0.8800, recall 0.8800, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 99 loss: 0.37170374393463135\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 100 loss: 0.49486303329467773\n",
      "class 0: acc 0.8438, precision 0.9200, recall 0.8846, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.4286, recall 0.7500, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 101 loss: 0.3909561336040497\n",
      "class 0: acc 0.8125, precision 0.9600, recall 0.8276, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.2857, recall 1.0000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 102 loss: 0.5215973854064941\n",
      "class 0: acc 0.7500, precision 0.8214, recall 0.8846, f1 0.8519\n",
      "class 1: acc 0.8125, precision 0.2500, recall 0.2500, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 103 loss: 0.4036919176578522\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 104 loss: 0.5399338603019714\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 105 loss: 0.34473204612731934\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 106 loss: 0.44306454062461853\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 107 loss: 0.5360647439956665\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 108 loss: 0.5061205625534058\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 109 loss: 0.16350805759429932\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 110 loss: 0.14954891800880432\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 111 loss: 0.19005316495895386\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 112 loss: 0.2850862741470337\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 113 loss: 0.598511278629303\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 114 loss: 0.1865011751651764\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 115 loss: 0.5639780759811401\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 3 step: 116 loss: 0.4944913983345032\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 117 loss: 0.5581497550010681\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 3 step: 118 loss: 0.43158280849456787\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 119 loss: 0.3717697858810425\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 120 loss: 0.3612631857395172\n",
      "class 0: acc 0.8125, precision 0.9583, recall 0.8214, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.3750, recall 1.0000, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 121 loss: 0.543494462966919\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 122 loss: 0.4758835434913635\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.8571, recall 0.6667, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 123 loss: 0.2984461486339569\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 124 loss: 0.35758909583091736\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 125 loss: 0.325325608253479\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 126 loss: 0.22661849856376648\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 127 loss: 0.22152753174304962\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 128 loss: 0.3191286027431488\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 129 loss: 0.3432108461856842\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 130 loss: 0.3402578830718994\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 131 loss: 0.43992143869400024\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 132 loss: 0.44120797514915466\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 133 loss: 0.27838334441185\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 134 loss: 0.34676969051361084\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 135 loss: 0.5329437255859375\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 136 loss: 0.4683186411857605\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 137 loss: 0.32202309370040894\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 138 loss: 0.847701907157898\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 139 loss: 0.49762287735939026\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 140 loss: 0.5599628686904907\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 141 loss: 0.4160727858543396\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 142 loss: 0.6845691204071045\n",
      "class 0: acc 0.6250, precision 0.5833, recall 0.8750, f1 0.7000\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 143 loss: 0.3318535089492798\n",
      "class 0: acc 0.8125, precision 0.9259, recall 0.8621, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.2000, recall 0.5000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 144 loss: 0.47870999574661255\n",
      "class 0: acc 0.8125, precision 0.8750, recall 0.8750, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.6250, recall 0.8333, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 145 loss: 0.3905821442604065\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 146 loss: 0.6785134673118591\n",
      "class 0: acc 0.7188, precision 0.7333, recall 0.9565, f1 0.8302\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 147 loss: 0.39875075221061707\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 148 loss: 0.2357933223247528\n",
      "class 0: acc 0.8750, precision 1.0000, recall 0.8667, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 149 loss: 0.27694299817085266\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9259, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 150 loss: 0.28547245264053345\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 151 loss: 0.5468773245811462\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 152 loss: 0.5228880047798157\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 153 loss: 0.28182515501976013\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 154 loss: 0.5125361680984497\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 155 loss: 0.3679678440093994\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 156 loss: 0.18987630307674408\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 157 loss: 0.3624935448169708\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 158 loss: 0.6961984634399414\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 159 loss: 0.4192664623260498\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 160 loss: 0.4271380603313446\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 161 loss: 0.3275955617427826\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 162 loss: 0.4262606203556061\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 163 loss: 0.5034393668174744\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 164 loss: 0.4410170912742615\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 165 loss: 0.5064893960952759\n",
      "class 0: acc 0.7812, precision 0.8889, recall 0.8571, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.2000, recall 0.5000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 166 loss: 0.1920030266046524\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 167 loss: 0.5654887557029724\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 168 loss: 0.32756587862968445\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 169 loss: 0.3278891444206238\n",
      "class 0: acc 0.9062, precision 0.9583, recall 0.9200, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.8571, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 170 loss: 0.3783648908138275\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 171 loss: 0.4129302203655243\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 172 loss: 0.45855051279067993\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 173 loss: 0.35794442892074585\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 174 loss: 0.6496502757072449\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 175 loss: 0.5428040027618408\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 176 loss: 0.48063138127326965\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 177 loss: 0.2814558148384094\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 178 loss: 0.44314542412757874\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 179 loss: 0.4731646478176117\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 180 loss: 0.43728411197662354\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 181 loss: 0.26883870363235474\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 182 loss: 0.24814526736736298\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9333, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 183 loss: 0.4018371105194092\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 184 loss: 0.4704146087169647\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8438, precision 0.8333, recall 0.5556, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 185 loss: 0.3467991352081299\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 186 loss: 0.49190381169319153\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 187 loss: 0.34991663694381714\n",
      "class 0: acc 0.8750, precision 0.9333, recall 0.9333, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 188 loss: 0.37118589878082275\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 189 loss: 0.37761443853378296\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 190 loss: 0.6933517456054688\n",
      "class 0: acc 0.6875, precision 0.6897, recall 0.9524, f1 0.8000\n",
      "class 1: acc 0.7188, precision 0.6667, recall 0.2000, f1 0.3077\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 191 loss: 0.23760473728179932\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 192 loss: 0.3934158682823181\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 193 loss: 0.26873329281806946\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 194 loss: 0.34250935912132263\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 195 loss: 0.3546435534954071\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 196 loss: 0.3545561134815216\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 197 loss: 0.31081992387771606\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 198 loss: 0.4573824405670166\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.7812, precision 1.0000, recall 0.2222, f1 0.3636\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 199 loss: 0.4239087700843811\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 200 loss: 0.46894827485084534\n",
      "class 0: acc 0.8125, precision 0.8750, recall 0.8750, f1 0.8750\n",
      "class 1: acc 0.8438, precision 0.5714, recall 0.6667, f1 0.6154\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 3 step: 201 loss: 0.33011162281036377\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 202 loss: 0.39253994822502136\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 203 loss: 0.5461987853050232\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 204 loss: 0.4990559220314026\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 205 loss: 0.46011245250701904\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 206 loss: 0.1682436615228653\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 207 loss: 0.2251213937997818\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 208 loss: 0.19687624275684357\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 209 loss: 0.48616302013397217\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 210 loss: 0.21410278975963593\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 211 loss: 0.46341991424560547\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 212 loss: 0.4368016719818115\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 213 loss: 0.5585934519767761\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 214 loss: 0.38725927472114563\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 215 loss: 0.3282778561115265\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 216 loss: 0.5642291307449341\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 217 loss: 0.4866943657398224\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 218 loss: 0.3187410831451416\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 219 loss: 0.35727816820144653\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 220 loss: 0.3929310739040375\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 221 loss: 0.3857046961784363\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 222 loss: 0.4467372000217438\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 223 loss: 0.3522750437259674\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 224 loss: 0.5019977688789368\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 225 loss: 0.2818783223628998\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 226 loss: 0.30872994661331177\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 227 loss: 0.19124646484851837\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 3 step: 228 loss: 0.5374453663825989\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 229 loss: 0.40195921063423157\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 230 loss: 0.2708304822444916\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 231 loss: 0.5800572037696838\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 232 loss: 0.7145712971687317\n",
      "class 0: acc 0.7500, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 233 loss: 0.3342995345592499\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 234 loss: 0.45071861147880554\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 235 loss: 0.355633407831192\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 236 loss: 0.5054380297660828\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 3 step: 237 loss: 0.25614142417907715\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 238 loss: 0.31536656618118286\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 239 loss: 0.46694961190223694\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 240 loss: 0.3144277036190033\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 241 loss: 0.369479775428772\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 242 loss: 0.1307705044746399\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 243 loss: 0.14120180904865265\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 244 loss: 0.49573975801467896\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 245 loss: 0.24349115788936615\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 246 loss: 0.1311691850423813\n",
      "class 0: acc 0.9688, precision 0.9688, recall 1.0000, f1 0.9841\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 247 loss: 0.3422353267669678\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 248 loss: 0.3453493118286133\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 249 loss: 0.3675931394100189\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 250 loss: 0.3910198509693146\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 251 loss: 0.6562028527259827\n",
      "class 0: acc 0.7500, precision 0.7586, recall 0.9565, f1 0.8462\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 252 loss: 0.38152551651000977\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 253 loss: 0.24874994158744812\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 254 loss: 0.5000877380371094\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 255 loss: 0.43122005462646484\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 256 loss: 0.31754887104034424\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 257 loss: 0.28123071789741516\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 258 loss: 0.2712497413158417\n",
      "class 0: acc 0.9375, precision 0.9677, recall 0.9677, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 259 loss: 0.4242057502269745\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 260 loss: 0.17078731954097748\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 261 loss: 0.46605026721954346\n",
      "class 0: acc 0.8125, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.2000, recall 0.5000, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 262 loss: 0.17453597486019135\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 263 loss: 0.2482100874185562\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 264 loss: 0.2794633209705353\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 265 loss: 0.4059354066848755\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 266 loss: 0.41105711460113525\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 267 loss: 0.3009764552116394\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 268 loss: 0.20967912673950195\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 269 loss: 0.24792534112930298\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 270 loss: 0.20496833324432373\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 271 loss: 0.3472965955734253\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 272 loss: 0.5085762739181519\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 273 loss: 0.4353191554546356\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 274 loss: 0.25846755504608154\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 275 loss: 0.29139384627342224\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 276 loss: 0.26524367928504944\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 3 step: 277 loss: 0.49991074204444885\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 278 loss: 0.5121468305587769\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 279 loss: 0.21513161063194275\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 280 loss: 0.4774899184703827\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 281 loss: 0.3334790766239166\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 282 loss: 0.3456351161003113\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 283 loss: 0.48138299584388733\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 284 loss: 0.5596966743469238\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 285 loss: 0.33803191781044006\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 286 loss: 0.3675796687602997\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 287 loss: 0.37602517008781433\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 288 loss: 0.2913932800292969\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 289 loss: 0.3594234585762024\n",
      "class 0: acc 0.8125, precision 0.8846, recall 0.8846, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 290 loss: 0.20189201831817627\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 291 loss: 0.3928550183773041\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 292 loss: 0.657203197479248\n",
      "class 0: acc 0.7812, precision 0.8065, recall 0.9615, f1 0.8772\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 293 loss: 0.33826881647109985\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 294 loss: 0.49534279108047485\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 295 loss: 0.55058753490448\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 296 loss: 0.2600647807121277\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 3 step: 297 loss: 0.45183035731315613\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 3 step: 298 loss: 0.2505399286746979\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 299 loss: 0.30030620098114014\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 300 loss: 0.7792205810546875\n",
      "class 0: acc 0.7500, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 1: acc 0.7812, precision 1.0000, recall 0.3636, f1 0.5333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 301 loss: 0.570834755897522\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 302 loss: 0.24196091294288635\n",
      "class 0: acc 0.9375, precision 0.9167, recall 1.0000, f1 0.9565\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 303 loss: 0.303154855966568\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 304 loss: 0.45035719871520996\n",
      "class 0: acc 0.8438, precision 0.8333, recall 0.9524, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.8750, recall 0.7778, f1 0.8235\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 305 loss: 0.4298311173915863\n",
      "class 0: acc 0.8438, precision 0.9167, recall 0.8800, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.6250, recall 0.7143, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 306 loss: 0.35068389773368835\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 307 loss: 0.48248475790023804\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 308 loss: 0.5494264960289001\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 309 loss: 0.5008167028427124\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 310 loss: 0.6255104541778564\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 311 loss: 0.49212244153022766\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 312 loss: 0.4993818402290344\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 313 loss: 0.2627887427806854\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 314 loss: 0.18068890273571014\n",
      "class 0: acc 0.9375, precision 0.9130, recall 1.0000, f1 0.9545\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.9000, f1 0.9474\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 315 loss: 0.2283409833908081\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 316 loss: 0.6790575981140137\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.7812, precision 0.7500, recall 0.3333, f1 0.4615\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 317 loss: 0.22080422937870026\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 318 loss: 0.2767224907875061\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 319 loss: 0.4295281767845154\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 320 loss: 0.5704343318939209\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 321 loss: 0.46390262246131897\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 322 loss: 0.3078213930130005\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 323 loss: 0.3239537477493286\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 324 loss: 0.4398762285709381\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 325 loss: 0.3814622759819031\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 326 loss: 0.5804672837257385\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 327 loss: 0.4877605140209198\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 328 loss: 0.4042154848575592\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 329 loss: 0.48840177059173584\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 330 loss: 0.30880236625671387\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 331 loss: 0.31821152567863464\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 332 loss: 0.5304921269416809\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 333 loss: 0.2592101991176605\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 334 loss: 0.40491923689842224\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 335 loss: 0.19982843101024628\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 3 step: 336 loss: 0.4333699643611908\n",
      "class 0: acc 0.7812, precision 0.8519, recall 0.8846, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 337 loss: 0.5777517557144165\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 338 loss: 0.4693966805934906\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 339 loss: 0.3823079764842987\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 340 loss: 0.28484731912612915\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 341 loss: 0.07548213005065918\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 342 loss: 0.21322092413902283\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 343 loss: 0.3292029798030853\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 3 step: 344 loss: 0.4868137240409851\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 345 loss: 0.23629550635814667\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 346 loss: 0.32286426424980164\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 347 loss: 0.24491764605045319\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 348 loss: 0.28769153356552124\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 349 loss: 0.515033483505249\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 350 loss: 0.17676591873168945\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 351 loss: 0.4750891923904419\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 352 loss: 0.40497034788131714\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 353 loss: 0.34714654088020325\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 354 loss: 0.27782943844795227\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 355 loss: 0.3126732409000397\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 356 loss: 0.3084876239299774\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 357 loss: 0.3869907557964325\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 358 loss: 0.5263121724128723\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 359 loss: 0.449948251247406\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 360 loss: 0.25214171409606934\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 361 loss: 0.34243151545524597\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 362 loss: 0.22608736157417297\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 363 loss: 0.7882224321365356\n",
      "class 0: acc 0.7188, precision 0.7308, recall 0.9048, f1 0.8085\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 364 loss: 0.20073769986629486\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 365 loss: 0.3325085937976837\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 366 loss: 0.23603621125221252\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 367 loss: 0.44424358010292053\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 368 loss: 0.16467063128948212\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 369 loss: 0.6050720810890198\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 370 loss: 0.2911454439163208\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 371 loss: 0.30576446652412415\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 372 loss: 0.24171651899814606\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9355, f1 0.9667\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 373 loss: 0.25390446186065674\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 374 loss: 0.31566137075424194\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 375 loss: 0.2816689610481262\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 376 loss: 0.34684404730796814\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 377 loss: 0.2744133174419403\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 378 loss: 0.5789796710014343\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 379 loss: 0.305204838514328\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 380 loss: 0.5168338418006897\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 381 loss: 0.5763282775878906\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 382 loss: 0.5171927213668823\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 383 loss: 0.411337286233902\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 384 loss: 0.3979756832122803\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 385 loss: 0.2725057899951935\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 386 loss: 0.5137112736701965\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 387 loss: 0.3684084117412567\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 388 loss: 0.3698335886001587\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 389 loss: 0.498751163482666\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 390 loss: 0.277028888463974\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 391 loss: 0.3720175623893738\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 392 loss: 0.34598666429519653\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 393 loss: 0.4910415709018707\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 394 loss: 0.5694118738174438\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 395 loss: 0.3306434452533722\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 3 step: 396 loss: 0.42248591780662537\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 397 loss: 0.17009909451007843\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 398 loss: 0.4048325717449188\n",
      "class 0: acc 0.8438, precision 0.8182, recall 0.9474, f1 0.8780\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 399 loss: 0.35409557819366455\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 400 loss: 0.3464297652244568\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 401 loss: 0.40950682759284973\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 402 loss: 0.19872350990772247\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9615, f1 0.9804\n",
      "class 1: acc 0.9688, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 403 loss: 0.5095981359481812\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 404 loss: 0.38279274106025696\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 405 loss: 0.22207199037075043\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 406 loss: 0.1453801542520523\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 407 loss: 0.296385258436203\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 408 loss: 0.4586799740791321\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 409 loss: 0.4665270745754242\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 410 loss: 0.19544339179992676\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 411 loss: 0.22698521614074707\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 412 loss: 0.29213881492614746\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 413 loss: 0.49396371841430664\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 414 loss: 0.45404213666915894\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 415 loss: 0.5418375730514526\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 416 loss: 0.4203750789165497\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 417 loss: 0.2680823504924774\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 418 loss: 0.46877992153167725\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 419 loss: 0.2724135220050812\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 420 loss: 0.24397261440753937\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 421 loss: 0.6108517646789551\n",
      "class 0: acc 0.7500, precision 0.7742, recall 0.9600, f1 0.8571\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 422 loss: 0.2757343351840973\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 423 loss: 0.4866955578327179\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 424 loss: 0.25575461983680725\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 425 loss: 0.3804100453853607\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 426 loss: 0.30107372999191284\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 427 loss: 0.5264193415641785\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 428 loss: 0.45355674624443054\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 429 loss: 0.4549590051174164\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 430 loss: 0.44422808289527893\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 431 loss: 0.4893344044685364\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 432 loss: 0.23724707961082458\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 433 loss: 0.38429808616638184\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 434 loss: 0.43503108620643616\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 435 loss: 0.6611674427986145\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 436 loss: 0.4840847849845886\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 437 loss: 0.3950793445110321\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 438 loss: 0.27966222167015076\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 439 loss: 0.3968402147293091\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 440 loss: 0.2444608211517334\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 441 loss: 0.3533899784088135\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.6667, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 442 loss: 0.08463975787162781\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 443 loss: 0.39474380016326904\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 444 loss: 0.3810218870639801\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 445 loss: 0.14677061140537262\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 446 loss: 0.19487589597702026\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 447 loss: 0.37550076842308044\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 448 loss: 0.345016747713089\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 449 loss: 0.3976660668849945\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 450 loss: 0.256988525390625\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 451 loss: 0.3494645059108734\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 452 loss: 0.08799038082361221\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 453 loss: 0.25201138854026794\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 454 loss: 0.09913580119609833\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 455 loss: 0.498733252286911\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 456 loss: 0.3015519976615906\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 457 loss: 0.4569171369075775\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 458 loss: 0.41978734731674194\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 459 loss: 0.49387800693511963\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 460 loss: 0.19089554250240326\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 461 loss: 0.4978892505168915\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.7812, precision 0.6667, recall 0.2500, f1 0.3636\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 462 loss: 0.5391934514045715\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 463 loss: 0.21034130454063416\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 464 loss: 0.5833292007446289\n",
      "class 0: acc 0.7812, precision 0.8800, recall 0.8462, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.4286, recall 0.7500, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 465 loss: 0.6039915680885315\n",
      "class 0: acc 0.7812, precision 0.8077, recall 0.9130, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 466 loss: 0.3987490236759186\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 467 loss: 0.8596696257591248\n",
      "class 0: acc 0.6875, precision 0.7000, recall 0.9545, f1 0.8077\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 468 loss: 0.41204649209976196\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 469 loss: 0.48925724625587463\n",
      "class 0: acc 0.8125, precision 0.8000, recall 0.9524, f1 0.8696\n",
      "class 1: acc 0.8125, precision 0.7143, recall 0.5556, f1 0.6250\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 470 loss: 0.3100791573524475\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 471 loss: 0.6450446248054504\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.2857, f1 0.3636\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 472 loss: 0.4921954870223999\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 473 loss: 0.35468021035194397\n",
      "class 0: acc 0.8438, precision 0.9231, recall 0.8889, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 474 loss: 0.49254804849624634\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 475 loss: 0.41455280780792236\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 476 loss: 0.43424272537231445\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 477 loss: 0.43907517194747925\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 478 loss: 0.24362678825855255\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 479 loss: 0.2302759736776352\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 480 loss: 0.4112939238548279\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 481 loss: 0.5487647652626038\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 482 loss: 0.25736933946609497\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 483 loss: 0.14452135562896729\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 3 step: 484 loss: 0.4500349164009094\n",
      "class 0: acc 0.7812, precision 0.7812, recall 1.0000, f1 0.8772\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 485 loss: 0.41458579897880554\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 486 loss: 0.24379019439220428\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 487 loss: 0.6398288607597351\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 488 loss: 0.46157100796699524\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 489 loss: 0.26859042048454285\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 490 loss: 0.5497371554374695\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 491 loss: 0.3897884488105774\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 492 loss: 0.37073180079460144\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 493 loss: 0.4315469264984131\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 494 loss: 0.34781545400619507\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 495 loss: 0.5238662362098694\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 496 loss: 0.3832429051399231\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 497 loss: 0.4522545039653778\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 498 loss: 0.4122924506664276\n",
      "class 0: acc 0.8438, precision 0.9200, recall 0.8846, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 499 loss: 0.38885751366615295\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 500 loss: 0.42445021867752075\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 501 loss: 0.32448795437812805\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 502 loss: 0.3697906732559204\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 503 loss: 0.2827034592628479\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 504 loss: 0.2646487057209015\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 505 loss: 0.44437986612319946\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 506 loss: 0.5953027009963989\n",
      "class 0: acc 0.7812, precision 0.8571, recall 0.8889, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 507 loss: 0.4340333938598633\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 508 loss: 0.32214897871017456\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 509 loss: 0.4958556592464447\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 510 loss: 0.5229747891426086\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 511 loss: 0.28664541244506836\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 512 loss: 0.08877884596586227\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 513 loss: 0.31504324078559875\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 514 loss: 0.15768519043922424\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 515 loss: 0.32469508051872253\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 516 loss: 0.22160029411315918\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 517 loss: 0.2626667320728302\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 518 loss: 0.327140212059021\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 519 loss: 0.10991685092449188\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 520 loss: 0.7043813467025757\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 521 loss: 0.12515205144882202\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 522 loss: 0.11063022166490555\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 523 loss: 0.522384524345398\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 524 loss: 0.08024729788303375\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 525 loss: 0.33202338218688965\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 526 loss: 0.04438231885433197\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 527 loss: 0.35312116146087646\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 528 loss: 0.5086259841918945\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 529 loss: 0.2812894284725189\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 530 loss: 0.6004831790924072\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 531 loss: 0.1312013566493988\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 532 loss: 0.14126154780387878\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 533 loss: 0.49382221698760986\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 534 loss: 0.25137120485305786\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 535 loss: 0.279302716255188\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 536 loss: 0.34582528471946716\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 537 loss: 0.27043089270591736\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 538 loss: 0.27748197317123413\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 539 loss: 0.23789441585540771\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 540 loss: 0.3442815840244293\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 541 loss: 0.6855896711349487\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 542 loss: 0.3706859052181244\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 543 loss: 0.4698243737220764\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 544 loss: 0.35521748661994934\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 545 loss: 0.43519923090934753\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 546 loss: 0.3349013328552246\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 547 loss: 0.40638330578804016\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 548 loss: 0.2901405394077301\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 549 loss: 0.1280965805053711\n",
      "class 0: acc 0.9688, precision 0.9688, recall 1.0000, f1 0.9841\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 550 loss: 0.33675417304039\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 551 loss: 0.40535634756088257\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 552 loss: 0.49700501561164856\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 553 loss: 0.6808095574378967\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 554 loss: 0.3218533396720886\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 555 loss: 0.24187591671943665\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 556 loss: 0.39587467908859253\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 557 loss: 0.3443872332572937\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 558 loss: 0.2642800509929657\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 559 loss: 0.5900409817695618\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 3 step: 560 loss: 0.423652708530426\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 561 loss: 0.35482943058013916\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 562 loss: 0.17585885524749756\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 3 step: 563 loss: 0.4558834731578827\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 564 loss: 0.3762943744659424\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 565 loss: 0.3676401972770691\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 566 loss: 0.4186812937259674\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 567 loss: 0.3486265242099762\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 568 loss: 0.39387571811676025\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 569 loss: 0.5457874536514282\n",
      "class 0: acc 0.8125, precision 0.9259, recall 0.8621, f1 0.8929\n",
      "class 1: acc 0.8125, precision 0.2000, recall 0.3333, f1 0.2500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 570 loss: 0.29093024134635925\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 571 loss: 0.34121236205101013\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 572 loss: 0.22144849598407745\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 573 loss: 0.22600023448467255\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 574 loss: 0.34372350573539734\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 575 loss: 0.5767291784286499\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 576 loss: 0.2922127842903137\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 577 loss: 0.2747419774532318\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 578 loss: 0.20320889353752136\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 579 loss: 0.21497750282287598\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 580 loss: 0.3328660726547241\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 581 loss: 0.19707617163658142\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 582 loss: 0.24977058172225952\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 583 loss: 0.5448832511901855\n",
      "class 0: acc 0.7500, precision 0.7931, recall 0.9200, f1 0.8519\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 584 loss: 0.16789484024047852\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 585 loss: 0.3121449053287506\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 586 loss: 0.16950301826000214\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 587 loss: 0.4562210440635681\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 588 loss: 0.2615208029747009\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 589 loss: 0.1947605311870575\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 590 loss: 0.46186015009880066\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 591 loss: 0.5424109697341919\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 592 loss: 0.3640175461769104\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 593 loss: 0.2132168561220169\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 594 loss: 0.3547596037387848\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 595 loss: 0.4284157156944275\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.8571, recall 0.6667, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 596 loss: 0.37081894278526306\n",
      "class 0: acc 0.8438, precision 0.9565, recall 0.8462, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "epoch: 3 step: 597 loss: 0.31368887424468994\n",
      "class 0: acc 0.9062, precision 0.9583, recall 0.9200, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 598 loss: 0.14757990837097168\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8929, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "epoch: 3 step: 599 loss: 0.37422576546669006\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 3 step: 600 loss: 0.33158236742019653\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 601 loss: 0.5186008810997009\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 602 loss: 0.35156896710395813\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 603 loss: 0.39239662885665894\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 604 loss: 0.6423786878585815\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 605 loss: 0.5129094123840332\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 606 loss: 0.22864675521850586\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 607 loss: 0.3754086196422577\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 608 loss: 0.27143344283103943\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 609 loss: 0.1758977174758911\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 610 loss: 0.40620237588882446\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 611 loss: 0.35982653498649597\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 612 loss: 0.5403253436088562\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 613 loss: 0.17994508147239685\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 614 loss: 0.18615388870239258\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 615 loss: 0.49508145451545715\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 616 loss: 0.4076635241508484\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 617 loss: 0.29929766058921814\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 618 loss: 0.7334523797035217\n",
      "class 0: acc 0.6875, precision 0.7500, recall 0.8750, f1 0.8077\n",
      "class 1: acc 0.7500, precision 0.2500, recall 0.1667, f1 0.2000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 619 loss: 0.2749721109867096\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 620 loss: 0.3082287311553955\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 621 loss: 0.32146334648132324\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 622 loss: 0.2882947325706482\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 623 loss: 0.4757169187068939\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 3 step: 624 loss: 0.3441501259803772\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 625 loss: 0.32259124517440796\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 626 loss: 0.3432401418685913\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 627 loss: 0.38201436400413513\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 628 loss: 0.5991101861000061\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 629 loss: 0.44221487641334534\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 630 loss: 0.45167866349220276\n",
      "class 0: acc 0.9375, precision 0.9200, recall 1.0000, f1 0.9583\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 631 loss: 0.5844990015029907\n",
      "class 0: acc 0.7500, precision 0.7742, recall 0.9600, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 632 loss: 0.3374817669391632\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 633 loss: 0.387291818857193\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 634 loss: 0.5370349287986755\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.8438, precision 0.2000, recall 0.5000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 635 loss: 0.3349975645542145\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 636 loss: 0.22549858689308167\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 637 loss: 0.4549548923969269\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 638 loss: 0.27810388803482056\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 639 loss: 0.15817183256149292\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 640 loss: 0.3634530305862427\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 641 loss: 0.4462381601333618\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 642 loss: 0.4688549339771271\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 643 loss: 0.37297123670578003\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 644 loss: 0.3255865275859833\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 645 loss: 0.44536688923835754\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 646 loss: 0.09870866686105728\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 647 loss: 0.4037107825279236\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 648 loss: 0.21414338052272797\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 649 loss: 0.4227917194366455\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 650 loss: 0.5627239942550659\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 651 loss: 0.27644699811935425\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 652 loss: 0.4616950750350952\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 653 loss: 0.23660457134246826\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 654 loss: 0.33272475004196167\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 655 loss: 0.37342265248298645\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 656 loss: 0.2569129765033722\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 657 loss: 0.15632560849189758\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 658 loss: 0.34798744320869446\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 659 loss: 0.4160960614681244\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 660 loss: 0.1365644335746765\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 661 loss: 0.49525439739227295\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 662 loss: 0.38466688990592957\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 663 loss: 0.4583594501018524\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 664 loss: 0.6565017700195312\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.7812, precision 1.0000, recall 0.3636, f1 0.5333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 665 loss: 0.3911076486110687\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 666 loss: 0.18184995651245117\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 667 loss: 0.5164774060249329\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 668 loss: 0.1603897362947464\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 669 loss: 0.37297359108924866\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 670 loss: 0.4230199158191681\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 671 loss: 0.5106981992721558\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 672 loss: 0.5341498851776123\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 673 loss: 0.28741568326950073\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 674 loss: 0.3200516402721405\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 675 loss: 0.25249752402305603\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 676 loss: 0.5005100965499878\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 677 loss: 0.4062054455280304\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 678 loss: 0.2626987397670746\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 679 loss: 0.43420687317848206\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 680 loss: 0.33305108547210693\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 681 loss: 0.33579021692276\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 682 loss: 0.7125494480133057\n",
      "class 0: acc 0.7812, precision 0.8571, recall 0.8889, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 683 loss: 0.3876110315322876\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 684 loss: 0.3906846046447754\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 685 loss: 0.6495024561882019\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 686 loss: 0.5609458088874817\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.2857, f1 0.3636\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 687 loss: 0.5898796319961548\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 688 loss: 0.31938034296035767\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 689 loss: 0.3591136336326599\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 690 loss: 0.4640164375305176\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.2000, recall 1.0000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 691 loss: 0.28276970982551575\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 692 loss: 0.10190598666667938\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 693 loss: 0.35436946153640747\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 694 loss: 0.41974198818206787\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 695 loss: 0.4987978935241699\n",
      "class 0: acc 0.7812, precision 0.8065, recall 0.9615, f1 0.8772\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 696 loss: 0.43271878361701965\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 697 loss: 0.25872737169265747\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 698 loss: 0.26100391149520874\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 699 loss: 0.2939353287220001\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 700 loss: 0.2805160582065582\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 701 loss: 0.41555047035217285\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 3 step: 702 loss: 0.2893781065940857\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 3 step: 703 loss: 0.4387260377407074\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 704 loss: 0.3367238938808441\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 705 loss: 0.24493160843849182\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 706 loss: 0.5214682221412659\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 707 loss: 0.49118396639823914\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 708 loss: 0.3828056752681732\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 709 loss: 0.33655858039855957\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 710 loss: 0.22899657487869263\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 711 loss: 0.3837476670742035\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 712 loss: 0.4173199236392975\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 3 step: 713 loss: 0.28917554020881653\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 714 loss: 0.2597782015800476\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 715 loss: 0.378281831741333\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 716 loss: 0.20716357231140137\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 717 loss: 0.2964664697647095\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 718 loss: 0.3650815784931183\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 719 loss: 0.49817559123039246\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 720 loss: 0.30408769845962524\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 721 loss: 0.05978008732199669\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 722 loss: 0.29841941595077515\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 723 loss: 0.17443585395812988\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 724 loss: 0.43632838129997253\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 725 loss: 0.38345497846603394\n",
      "class 0: acc 0.8438, precision 0.8333, recall 0.9524, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 3 step: 726 loss: 0.4211990535259247\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 727 loss: 0.4506703019142151\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 728 loss: 0.41457119584083557\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 729 loss: 0.5917162299156189\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9091, f1 0.8511\n",
      "class 1: acc 0.8438, precision 0.5714, recall 0.6667, f1 0.6154\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 730 loss: 0.4688432216644287\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 731 loss: 0.5034775137901306\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 732 loss: 0.5155568718910217\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 733 loss: 0.31404393911361694\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 734 loss: 0.4554438591003418\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 735 loss: 0.13421452045440674\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 736 loss: 0.40791037678718567\n",
      "class 0: acc 0.8438, precision 0.9565, recall 0.8462, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.8000, f1 0.6154\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 3 step: 737 loss: 0.44343867897987366\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 738 loss: 0.29448503255844116\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 739 loss: 0.39361992478370667\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 740 loss: 0.3097646236419678\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 741 loss: 0.6315181255340576\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 742 loss: 0.6751090884208679\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 743 loss: 0.4509417414665222\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 3 step: 744 loss: 0.2895044982433319\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 745 loss: 0.24934403598308563\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 746 loss: 0.2660665810108185\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 747 loss: 0.45753175020217896\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 748 loss: 0.38398033380508423\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 749 loss: 0.5329965949058533\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 750 loss: 0.3724827170372009\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 751 loss: 0.2131476104259491\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 752 loss: 0.2853551506996155\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 753 loss: 0.34963035583496094\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 754 loss: 0.5296087861061096\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 755 loss: 0.41861748695373535\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 756 loss: 0.3602394759654999\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 757 loss: 0.3867764174938202\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 758 loss: 0.12595722079277039\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 759 loss: 0.5795860290527344\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 760 loss: 0.578445315361023\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 761 loss: 0.4459526240825653\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 762 loss: 0.34029820561408997\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 763 loss: 0.28935733437538147\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 764 loss: 0.45820876955986023\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 765 loss: 0.42466554045677185\n",
      "class 0: acc 0.8438, precision 0.9286, recall 0.8966, f1 0.9123\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 766 loss: 0.3176996111869812\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 767 loss: 0.27091699838638306\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 768 loss: 0.5406849980354309\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 769 loss: 0.2552706301212311\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 770 loss: 0.1478499323129654\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 771 loss: 0.47806820273399353\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 772 loss: 0.6386989951133728\n",
      "class 0: acc 0.8125, precision 0.8400, recall 0.9130, f1 0.8750\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 773 loss: 0.6697275042533875\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 774 loss: 0.361575722694397\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 775 loss: 0.09952864795923233\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 776 loss: 0.38744282722473145\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 777 loss: 0.6175662279129028\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 778 loss: 0.47022193670272827\n",
      "class 0: acc 0.7500, precision 0.8000, recall 0.9231, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 779 loss: 0.2748790681362152\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 780 loss: 0.5649195313453674\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 781 loss: 0.4762718379497528\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 782 loss: 0.22852103412151337\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 783 loss: 0.4153805673122406\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 784 loss: 0.27693650126457214\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 785 loss: 0.511318564414978\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 786 loss: 0.429181307554245\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 787 loss: 0.5066314339637756\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 788 loss: 0.23195762932300568\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 789 loss: 0.6006056070327759\n",
      "class 0: acc 0.7812, precision 0.8077, recall 0.9130, f1 0.8571\n",
      "class 1: acc 0.8125, precision 0.6000, recall 0.4286, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 3 step: 790 loss: 0.36547693610191345\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 791 loss: 0.460421085357666\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 792 loss: 0.5158967971801758\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 793 loss: 0.2783435583114624\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 794 loss: 0.46842530369758606\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 795 loss: 0.3180276155471802\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 796 loss: 0.5495701432228088\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 797 loss: 0.6263366937637329\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8125, precision 0.6000, recall 0.4286, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 798 loss: 0.45817697048187256\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 799 loss: 0.38856151700019836\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 800 loss: 0.5654247999191284\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 801 loss: 0.24942736327648163\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 802 loss: 0.37040525674819946\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 803 loss: 0.487387090921402\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 804 loss: 0.2669979929924011\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 805 loss: 0.4819044768810272\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 806 loss: 0.28930923342704773\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 807 loss: 0.3500354588031769\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 808 loss: 0.6550507545471191\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 809 loss: 0.6303313374519348\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 810 loss: 0.5849406719207764\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 811 loss: 0.31850844621658325\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 812 loss: 0.524762749671936\n",
      "class 0: acc 0.7812, precision 0.8077, recall 0.9130, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 813 loss: 0.36070072650909424\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 814 loss: 0.7012705206871033\n",
      "class 0: acc 0.7188, precision 0.7241, recall 0.9545, f1 0.8235\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 815 loss: 0.508823812007904\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 816 loss: 0.25269705057144165\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 817 loss: 0.4656694233417511\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 818 loss: 0.2665596604347229\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 819 loss: 0.4292304217815399\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 3 step: 820 loss: 0.3338606357574463\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 821 loss: 0.3838820159435272\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 822 loss: 0.5183305144309998\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 823 loss: 0.4028143584728241\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 824 loss: 0.3649924695491791\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 825 loss: 0.3644830882549286\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 826 loss: 0.25322434306144714\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 827 loss: 0.3201845586299896\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 828 loss: 0.3064710199832916\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 829 loss: 0.39608967304229736\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 830 loss: 0.3238319158554077\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 831 loss: 0.2792150676250458\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 832 loss: 0.41830888390541077\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 833 loss: 0.5597674250602722\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 834 loss: 0.6053544878959656\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 835 loss: 0.2629374861717224\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 836 loss: 0.36704444885253906\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 837 loss: 0.40304499864578247\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 838 loss: 0.2891865074634552\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 3 step: 839 loss: 0.26983848214149475\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 840 loss: 0.28061485290527344\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 841 loss: 0.31231650710105896\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 842 loss: 0.39929264783859253\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 843 loss: 0.49361538887023926\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 844 loss: 0.43827953934669495\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "epoch: 3 step: 845 loss: 0.565923810005188\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 846 loss: 0.36817634105682373\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 847 loss: 0.49255478382110596\n",
      "class 0: acc 0.8125, precision 0.8400, recall 0.9130, f1 0.8750\n",
      "class 1: acc 0.8438, precision 0.7143, recall 0.6250, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 848 loss: 0.4088377356529236\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 849 loss: 0.24930089712142944\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 850 loss: 0.34663107991218567\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 851 loss: 0.3467593491077423\n",
      "class 0: acc 0.9688, precision 0.9583, recall 1.0000, f1 0.9787\n",
      "class 1: acc 0.9375, precision 0.8750, recall 0.8750, f1 0.8750\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 852 loss: 0.49335557222366333\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 853 loss: 0.29217180609703064\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 854 loss: 0.2157311737537384\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 855 loss: 0.2861369252204895\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 856 loss: 0.3728458881378174\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 857 loss: 0.2380063235759735\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 858 loss: 0.24155813455581665\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 859 loss: 0.28850090503692627\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 860 loss: 0.4131546914577484\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 861 loss: 0.3196786344051361\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 862 loss: 0.242340087890625\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 863 loss: 0.5431193709373474\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 864 loss: 0.18098106980323792\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 865 loss: 0.1801815927028656\n",
      "class 0: acc 0.9375, precision 0.9677, recall 0.9677, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 866 loss: 0.5840446949005127\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 867 loss: 0.20295801758766174\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.9688, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 868 loss: 0.6689582467079163\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 869 loss: 0.21632544696331024\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 870 loss: 0.36534619331359863\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 871 loss: 0.3251110315322876\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 3 step: 872 loss: 0.5532406568527222\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.7812, precision 0.3333, recall 0.1667, f1 0.2222\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 873 loss: 0.4621759355068207\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 874 loss: 0.13032159209251404\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 875 loss: 0.4945392310619354\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 876 loss: 0.5726195573806763\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 877 loss: 0.4490067958831787\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 878 loss: 0.3379485309123993\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 879 loss: 0.4702552855014801\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 880 loss: 0.4982280135154724\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 881 loss: 0.44654595851898193\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 882 loss: 0.5977922081947327\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.7812, precision 0.2500, recall 0.2000, f1 0.2222\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 883 loss: 0.2952544689178467\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 884 loss: 0.37069791555404663\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 885 loss: 0.476703405380249\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 886 loss: 0.2700670063495636\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 887 loss: 0.2622711658477783\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 888 loss: 0.2201269268989563\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 889 loss: 0.27681154012680054\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 890 loss: 0.20916426181793213\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 891 loss: 0.2882162928581238\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 892 loss: 0.4382822513580322\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 893 loss: 0.7232722640037537\n",
      "class 0: acc 0.7188, precision 0.7333, recall 0.9565, f1 0.8302\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 894 loss: 0.38783660531044006\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 895 loss: 0.39489731192588806\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 896 loss: 0.46481284499168396\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 897 loss: 0.4666794240474701\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 898 loss: 0.3359043300151825\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 899 loss: 0.44932714104652405\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 900 loss: 0.450417160987854\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 901 loss: 0.711945652961731\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.7812, precision 0.3333, recall 0.1667, f1 0.2222\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 902 loss: 0.22560754418373108\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 903 loss: 0.3516450524330139\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 904 loss: 0.2527163326740265\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 905 loss: 0.4257475733757019\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 906 loss: 0.319400429725647\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8438, precision 0.8333, recall 0.5556, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 907 loss: 0.3546869456768036\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 908 loss: 0.33861300349235535\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 909 loss: 0.156455859541893\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 910 loss: 0.1677457094192505\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 911 loss: 0.23312783241271973\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 912 loss: 0.2249041348695755\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 913 loss: 0.2377147078514099\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 914 loss: 0.39189672470092773\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 915 loss: 0.4697601795196533\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 916 loss: 0.18637040257453918\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 917 loss: 0.4731864929199219\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 918 loss: 0.32008832693099976\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 919 loss: 0.2367623895406723\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 920 loss: 0.21515315771102905\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 921 loss: 0.44670167565345764\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 922 loss: 0.2304004430770874\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 923 loss: 0.33136650919914246\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 924 loss: 0.5238125324249268\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 925 loss: 0.5192916989326477\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 926 loss: 0.17657776176929474\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 927 loss: 0.35215041041374207\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 928 loss: 0.37532225251197815\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 929 loss: 0.13057363033294678\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 930 loss: 0.24731631577014923\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 931 loss: 0.6234169006347656\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 932 loss: 0.45562058687210083\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 933 loss: 0.36162373423576355\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 934 loss: 0.2993292808532715\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 935 loss: 0.23128412663936615\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 936 loss: 0.4064158797264099\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 937 loss: 0.16792811453342438\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 938 loss: 0.09714731574058533\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 939 loss: 0.5395952463150024\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 940 loss: 0.6908107399940491\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 941 loss: 0.4513588547706604\n",
      "class 0: acc 0.7812, precision 0.8065, recall 0.9615, f1 0.8772\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 942 loss: 0.2990560531616211\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 943 loss: 0.3923594355583191\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 944 loss: 0.30089035630226135\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 945 loss: 0.26947203278541565\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 946 loss: 0.6998408436775208\n",
      "class 0: acc 0.7500, precision 0.7586, recall 0.9565, f1 0.8462\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 947 loss: 0.20895589888095856\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 948 loss: 0.2038068324327469\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 949 loss: 0.5467919707298279\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 950 loss: 0.4758685827255249\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 951 loss: 0.32276010513305664\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 952 loss: 0.5121091604232788\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 3 step: 953 loss: 0.2737812101840973\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 954 loss: 0.38121485710144043\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 955 loss: 0.35276034474372864\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 956 loss: 0.4547271132469177\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 957 loss: 0.43294891715049744\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 958 loss: 0.3175877332687378\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 959 loss: 0.3284442722797394\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 960 loss: 0.32886242866516113\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 961 loss: 0.23695270717144012\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 962 loss: 0.3241938054561615\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 963 loss: 0.40504902601242065\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 964 loss: 0.7001984715461731\n",
      "class 0: acc 0.7188, precision 0.7188, recall 1.0000, f1 0.8364\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 965 loss: 0.4008350074291229\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 966 loss: 0.1870361864566803\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 967 loss: 0.2085050642490387\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 968 loss: 0.3435734510421753\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 969 loss: 0.29501819610595703\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 970 loss: 0.20678971707820892\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 971 loss: 0.22746577858924866\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 972 loss: 0.3960433006286621\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 973 loss: 0.2165406346321106\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 974 loss: 0.13479648530483246\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 975 loss: 0.2892698049545288\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 976 loss: 0.14649662375450134\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 977 loss: 0.6047154664993286\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 978 loss: 0.5091615915298462\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 979 loss: 0.24204377830028534\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 980 loss: 0.5290400981903076\n",
      "class 0: acc 0.7812, precision 0.7812, recall 1.0000, f1 0.8772\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 981 loss: 0.5955984592437744\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 982 loss: 0.24451373517513275\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 983 loss: 0.33765241503715515\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 984 loss: 0.2697575092315674\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 985 loss: 0.15208956599235535\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 986 loss: 0.3445802330970764\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 987 loss: 0.35138022899627686\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 988 loss: 0.4759831130504608\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 989 loss: 0.2680467963218689\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 990 loss: 0.4308004677295685\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 991 loss: 0.26492074131965637\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 992 loss: 0.4554932713508606\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 993 loss: 0.5794249176979065\n",
      "class 0: acc 0.7188, precision 0.7667, recall 0.9200, f1 0.8364\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 994 loss: 0.19096341729164124\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 995 loss: 0.37112319469451904\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 996 loss: 0.08911032974720001\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 997 loss: 0.44700291752815247\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 998 loss: 0.13430672883987427\n",
      "class 0: acc 0.9688, precision 0.9688, recall 1.0000, f1 0.9841\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 999 loss: 0.4351344108581543\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1000 loss: 0.4270477890968323\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1001 loss: 0.5579772591590881\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.7500, precision 0.7500, recall 0.3000, f1 0.4286\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1002 loss: 0.24318650364875793\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1003 loss: 0.21970798075199127\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1004 loss: 0.13080714643001556\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1005 loss: 0.22191506624221802\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1006 loss: 0.3436072766780853\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1007 loss: 0.5592760443687439\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1008 loss: 0.23698079586029053\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1009 loss: 0.3401775658130646\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1010 loss: 0.3879372477531433\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1011 loss: 0.3542705774307251\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1012 loss: 0.46930643916130066\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1013 loss: 0.28221073746681213\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1014 loss: 0.2667663097381592\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1015 loss: 0.2698572874069214\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1016 loss: 0.2972850501537323\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1017 loss: 0.38814055919647217\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1018 loss: 0.4302479326725006\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1019 loss: 0.26815956830978394\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1020 loss: 0.4047639071941376\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1021 loss: 0.48498937487602234\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1022 loss: 0.24375317990779877\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1023 loss: 0.2348688691854477\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1024 loss: 0.38079965114593506\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1025 loss: 0.18281659483909607\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1026 loss: 0.4193434715270996\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1027 loss: 0.2038108855485916\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1028 loss: 0.3416717052459717\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1029 loss: 0.3527403771877289\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1030 loss: 0.14298121631145477\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1031 loss: 0.49952182173728943\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1032 loss: 0.657442569732666\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1033 loss: 0.4599818289279938\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1034 loss: 0.24624969065189362\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1035 loss: 0.5797888040542603\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1036 loss: 0.11588750779628754\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1037 loss: 0.07694444805383682\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1038 loss: 0.816504955291748\n",
      "class 0: acc 0.7188, precision 0.7241, recall 0.9545, f1 0.8235\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1039 loss: 0.2640148103237152\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1040 loss: 0.23925429582595825\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1041 loss: 0.3891751170158386\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1042 loss: 0.4777669608592987\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1043 loss: 0.5005167126655579\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1044 loss: 0.3469659388065338\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1045 loss: 0.2973625063896179\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1046 loss: 0.2594119906425476\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1047 loss: 0.43106845021247864\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1048 loss: 0.30911630392074585\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1049 loss: 0.2523319125175476\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1050 loss: 0.36058345437049866\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1051 loss: 0.2838066816329956\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1052 loss: 0.4337471127510071\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1053 loss: 0.39375096559524536\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1054 loss: 0.3902072310447693\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1055 loss: 0.632007360458374\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1056 loss: 0.33167245984077454\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1057 loss: 0.2680007219314575\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1058 loss: 0.18974435329437256\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1059 loss: 0.28840386867523193\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1060 loss: 0.24071654677391052\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1061 loss: 0.47592970728874207\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1062 loss: 0.6086487174034119\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1063 loss: 0.5485562086105347\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1064 loss: 0.41057947278022766\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1065 loss: 0.29494497179985046\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1066 loss: 0.3539145290851593\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1067 loss: 0.16427844762802124\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1068 loss: 0.5057623982429504\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1069 loss: 0.29295673966407776\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1070 loss: 0.4345996081829071\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1071 loss: 0.5493406653404236\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1072 loss: 0.3231440782546997\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1073 loss: 0.22595582902431488\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 3 step: 1074 loss: 0.42509400844573975\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1075 loss: 0.41649264097213745\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1076 loss: 0.5561401844024658\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1077 loss: 0.4381828308105469\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1078 loss: 0.8621512651443481\n",
      "class 0: acc 0.6250, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 1: acc 0.7500, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1079 loss: 0.5249168872833252\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.7812, precision 0.6000, recall 0.3750, f1 0.4615\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1080 loss: 0.29262542724609375\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1081 loss: 0.32247161865234375\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 3 step: 1082 loss: 0.22416774928569794\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1083 loss: 0.5593456029891968\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1084 loss: 0.35089772939682007\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1085 loss: 0.4407285153865814\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1086 loss: 0.5367522239685059\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1087 loss: 0.2294987440109253\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1088 loss: 0.42568305134773254\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1089 loss: 0.4935799837112427\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1090 loss: 0.2255876660346985\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1091 loss: 0.3192073404788971\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1092 loss: 0.29564177989959717\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1093 loss: 0.4104142189025879\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1094 loss: 0.27099305391311646\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1095 loss: 0.348812997341156\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1096 loss: 0.19450733065605164\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1097 loss: 0.36418449878692627\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1098 loss: 0.42950737476348877\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1099 loss: 0.30187276005744934\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1100 loss: 0.35582101345062256\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1101 loss: 0.8731877207756042\n",
      "class 0: acc 0.6562, precision 0.6207, recall 1.0000, f1 0.7660\n",
      "class 1: acc 0.7812, precision 1.0000, recall 0.3000, f1 0.4615\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1102 loss: 0.5839973092079163\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1103 loss: 0.3953496515750885\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1104 loss: 0.28981178998947144\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1105 loss: 0.28146660327911377\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9375, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1106 loss: 0.3614799380302429\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1107 loss: 0.3764636218547821\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1108 loss: 0.38928112387657166\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1109 loss: 0.2978011965751648\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1110 loss: 0.21624413132667542\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1111 loss: 0.4415886104106903\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1112 loss: 0.5841723084449768\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1113 loss: 0.28594252467155457\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1114 loss: 0.3119022846221924\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1115 loss: 0.38007909059524536\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1116 loss: 0.6489921808242798\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1117 loss: 0.3859277367591858\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1118 loss: 0.43327605724334717\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1119 loss: 0.3267422616481781\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1120 loss: 0.4022711515426636\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1121 loss: 0.2863844335079193\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 3 step: 1122 loss: 0.6031025052070618\n",
      "class 0: acc 0.7500, precision 0.7778, recall 0.9130, f1 0.8400\n",
      "class 1: acc 0.8125, precision 0.6000, recall 0.4286, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1123 loss: 0.5447686910629272\n",
      "class 0: acc 0.7500, precision 0.7742, recall 0.9600, f1 0.8571\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1124 loss: 0.4734666049480438\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1125 loss: 0.237583726644516\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1126 loss: 0.24512985348701477\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1127 loss: 0.5153837203979492\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 3 step: 1128 loss: 0.32685500383377075\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1129 loss: 0.2874819040298462\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1130 loss: 0.2469359189271927\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1131 loss: 0.20793360471725464\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1132 loss: 0.29374876618385315\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 3 step: 1133 loss: 0.54302978515625\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1134 loss: 0.2897966206073761\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1135 loss: 0.3500960171222687\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1136 loss: 0.43722862005233765\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1137 loss: 0.8805069327354431\n",
      "class 0: acc 0.6875, precision 0.6774, recall 1.0000, f1 0.8077\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.1429, f1 0.2500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1138 loss: 0.4315185546875\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1139 loss: 0.19790193438529968\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1140 loss: 0.45060837268829346\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1141 loss: 0.35593053698539734\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1142 loss: 0.23053738474845886\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1143 loss: 0.5591221451759338\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1144 loss: 0.46037599444389343\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1145 loss: 0.4347185790538788\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1146 loss: 0.49918100237846375\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1147 loss: 0.2991730570793152\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1148 loss: 0.41315701603889465\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1149 loss: 0.40730515122413635\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1150 loss: 0.264516681432724\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1151 loss: 0.3947800397872925\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1152 loss: 0.37048715353012085\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1153 loss: 0.194083571434021\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1154 loss: 0.3283296525478363\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1155 loss: 0.4887966513633728\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1156 loss: 0.33913785219192505\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1157 loss: 0.3586239218711853\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1158 loss: 0.29382604360580444\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1159 loss: 0.313870370388031\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1160 loss: 0.5578560829162598\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1161 loss: 0.29650235176086426\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1162 loss: 0.649330735206604\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1163 loss: 0.29833438992500305\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1164 loss: 0.29574474692344666\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1165 loss: 0.5865283608436584\n",
      "class 0: acc 0.7500, precision 0.7931, recall 0.9200, f1 0.8519\n",
      "class 1: acc 0.7812, precision 0.3333, recall 0.1667, f1 0.2222\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1166 loss: 0.22656570374965668\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1167 loss: 0.5013493299484253\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1168 loss: 0.5591435432434082\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 3 step: 1169 loss: 0.34901660680770874\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1170 loss: 0.34341633319854736\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 3 step: 1171 loss: 0.20433247089385986\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1172 loss: 0.17431163787841797\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1173 loss: 0.48790237307548523\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1174 loss: 0.30171942710876465\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1175 loss: 0.4710474908351898\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1176 loss: 0.43848279118537903\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1177 loss: 0.5509512424468994\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1178 loss: 0.2563864290714264\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1179 loss: 0.4208371341228485\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1180 loss: 0.6077502369880676\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1181 loss: 0.30285364389419556\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1182 loss: 0.32990244030952454\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1183 loss: 0.41844481229782104\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1184 loss: 0.21770915389060974\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1185 loss: 0.4125096797943115\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1186 loss: 0.3744650185108185\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1187 loss: 0.5623136162757874\n",
      "class 0: acc 0.7500, precision 0.7931, recall 0.9200, f1 0.8519\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1188 loss: 0.31779542565345764\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1189 loss: 0.6767595410346985\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1190 loss: 0.32340192794799805\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1191 loss: 0.41162818670272827\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1192 loss: 0.22621381282806396\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1193 loss: 0.12338140606880188\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1194 loss: 0.7053555846214294\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1195 loss: 0.4232202172279358\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1196 loss: 0.4538629353046417\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1197 loss: 0.4657898247241974\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1198 loss: 0.38081440329551697\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1199 loss: 0.47894954681396484\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1200 loss: 0.31368163228034973\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1201 loss: 0.30182936787605286\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1202 loss: 0.23066478967666626\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1203 loss: 0.24687506258487701\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1204 loss: 0.18928217887878418\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1205 loss: 0.2863079607486725\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1206 loss: 0.3105385899543762\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1207 loss: 0.4185287058353424\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1208 loss: 0.4026719927787781\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1209 loss: 0.31065529584884644\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1210 loss: 0.25779998302459717\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1211 loss: 0.262442409992218\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1212 loss: 0.4265124201774597\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1213 loss: 0.5703932046890259\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1214 loss: 0.24179062247276306\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1215 loss: 0.3762999475002289\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1216 loss: 0.5113812685012817\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1217 loss: 0.521660327911377\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1218 loss: 0.26504868268966675\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1219 loss: 0.11231876164674759\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1220 loss: 0.2214655727148056\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1221 loss: 0.37151795625686646\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1222 loss: 0.31001564860343933\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1223 loss: 0.25016266107559204\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1224 loss: 0.10834389925003052\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1225 loss: 0.53946852684021\n",
      "class 0: acc 0.7188, precision 0.7778, recall 0.8750, f1 0.8235\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1226 loss: 0.4901474416255951\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1227 loss: 0.3277279734611511\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.9375, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1228 loss: 0.12412852793931961\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1229 loss: 0.5366319417953491\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1230 loss: 0.6933172345161438\n",
      "class 0: acc 0.7500, precision 0.7600, recall 0.9048, f1 0.8261\n",
      "class 1: acc 0.7500, precision 0.7143, recall 0.4545, f1 0.5556\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1231 loss: 0.2931581735610962\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1232 loss: 0.15879914164543152\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1233 loss: 0.40511247515678406\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1234 loss: 0.21215754747390747\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1235 loss: 0.3496597409248352\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1236 loss: 0.5738226175308228\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1237 loss: 0.2793322205543518\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1238 loss: 0.5776593089103699\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1239 loss: 0.257224440574646\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1240 loss: 0.4054435193538666\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1241 loss: 0.4283636510372162\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1242 loss: 0.28769323229789734\n",
      "class 0: acc 0.8750, precision 0.9643, recall 0.9000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1243 loss: 0.1835504174232483\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1244 loss: 0.4240404963493347\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1245 loss: 0.29125332832336426\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1246 loss: 0.34881117939949036\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1247 loss: 0.406953901052475\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1248 loss: 0.1507701873779297\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1249 loss: 0.4126337170600891\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 3 step: 1250 loss: 0.30610746145248413\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1 loss: 0.512565553188324\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 2 loss: 0.6406800150871277\n",
      "class 0: acc 0.7188, precision 0.7586, recall 0.9167, f1 0.8302\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 3 loss: 0.554580807685852\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 4 loss: 0.1772596687078476\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 5 loss: 0.2061585634946823\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 6 loss: 0.1734991818666458\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 7 loss: 0.28979992866516113\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 8 loss: 0.6005447506904602\n",
      "class 0: acc 0.8125, precision 0.7692, recall 1.0000, f1 0.8696\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 4 step: 9 loss: 0.39051756262779236\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 10 loss: 0.43815726041793823\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 11 loss: 0.5671194791793823\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 12 loss: 0.43312016129493713\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 13 loss: 0.4594038128852844\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 14 loss: 0.29973843693733215\n",
      "class 0: acc 0.8750, precision 0.9565, recall 0.8800, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.5556, recall 1.0000, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 15 loss: 0.2060120701789856\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 16 loss: 0.2957305312156677\n",
      "class 0: acc 0.8750, precision 0.9333, recall 0.9333, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 17 loss: 0.2594197988510132\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8966, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 18 loss: 0.3147309124469757\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 19 loss: 0.5645865797996521\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 20 loss: 0.4268297255039215\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 21 loss: 0.360482782125473\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 22 loss: 0.7179973721504211\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 23 loss: 0.2745780944824219\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 24 loss: 0.24734467267990112\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 25 loss: 0.16905604302883148\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 26 loss: 0.3661382794380188\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 27 loss: 0.5216558575630188\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 28 loss: 0.3923644423484802\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 29 loss: 0.41674575209617615\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 30 loss: 0.22579224407672882\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 31 loss: 0.40632280707359314\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 32 loss: 0.42503878474235535\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 33 loss: 0.20307089388370514\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 34 loss: 0.43319061398506165\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 35 loss: 0.46070367097854614\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 4 step: 36 loss: 0.35242584347724915\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 37 loss: 0.27356722950935364\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 38 loss: 0.22550256550312042\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 39 loss: 0.4671612083911896\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 40 loss: 0.26423129439353943\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 41 loss: 0.4459327459335327\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 42 loss: 0.514239490032196\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 43 loss: 0.5411859154701233\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 44 loss: 0.44820636510849\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 45 loss: 0.22287710011005402\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 46 loss: 0.40716850757598877\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 47 loss: 0.1779821366071701\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 48 loss: 0.29586106538772583\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 49 loss: 0.20013906061649323\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 50 loss: 0.226705402135849\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 51 loss: 0.22443245351314545\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 52 loss: 0.2718721628189087\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 53 loss: 0.43079739809036255\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 54 loss: 0.4507623612880707\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 55 loss: 0.2866694927215576\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 56 loss: 0.1557837873697281\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 57 loss: 0.08987650275230408\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 58 loss: 0.4996584355831146\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 59 loss: 0.3693537712097168\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 60 loss: 0.43939170241355896\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 61 loss: 0.39362451434135437\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 62 loss: 0.8336158394813538\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 63 loss: 0.4781778156757355\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 64 loss: 0.6451786160469055\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 65 loss: 0.26805412769317627\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 66 loss: 0.3968719244003296\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 67 loss: 0.7716996669769287\n",
      "class 0: acc 0.7188, precision 0.6786, recall 1.0000, f1 0.8085\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 68 loss: 0.7395456433296204\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 69 loss: 0.4623200595378876\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 70 loss: 0.374869167804718\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 71 loss: 0.532993495464325\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.4286, f1 0.4615\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 72 loss: 0.2726435959339142\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 73 loss: 0.3330546021461487\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8929, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 74 loss: 0.48915618658065796\n",
      "class 0: acc 0.8750, precision 0.9583, recall 0.8846, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 75 loss: 0.43346408009529114\n",
      "class 0: acc 0.8438, precision 0.9167, recall 0.8800, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.6250, recall 1.0000, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 76 loss: 0.4257594645023346\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 77 loss: 0.32404381036758423\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 78 loss: 0.19035857915878296\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 79 loss: 0.395061194896698\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 80 loss: 0.23849555850028992\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 81 loss: 0.6249760389328003\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "epoch: 4 step: 82 loss: 0.3330572247505188\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 83 loss: 0.3722440004348755\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 84 loss: 1.1541974544525146\n",
      "class 0: acc 0.6562, precision 0.6207, recall 1.0000, f1 0.7660\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 85 loss: 0.5265905857086182\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 86 loss: 0.32928702235221863\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 87 loss: 0.6044523119926453\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 88 loss: 0.3656064569950104\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 89 loss: 0.46611136198043823\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 90 loss: 0.22299398481845856\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 91 loss: 0.48975226283073425\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 92 loss: 0.40601015090942383\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 93 loss: 0.3721368908882141\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 94 loss: 0.3145599365234375\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 95 loss: 0.33797261118888855\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 96 loss: 0.3377144932746887\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 97 loss: 0.22054441273212433\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 98 loss: 0.2107265591621399\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 99 loss: 0.2992754280567169\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 100 loss: 0.2870534658432007\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 101 loss: 0.36061909794807434\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 4 step: 102 loss: 0.22071988880634308\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 103 loss: 0.49356454610824585\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.7812, precision 1.0000, recall 0.1250, f1 0.2222\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 104 loss: 0.4366062581539154\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 105 loss: 0.45310747623443604\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 106 loss: 0.4812251627445221\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 107 loss: 0.25867587327957153\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 108 loss: 0.2612387537956238\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 109 loss: 0.29724520444869995\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 110 loss: 0.3369154632091522\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 111 loss: 0.11126212775707245\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 112 loss: 0.29477423429489136\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 113 loss: 0.32019487023353577\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 114 loss: 0.6266250014305115\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 115 loss: 0.1963806301355362\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 116 loss: 0.37618064880371094\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 117 loss: 0.32316869497299194\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 118 loss: 0.3300723731517792\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 4 step: 119 loss: 0.246283158659935\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 120 loss: 0.5065516829490662\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 121 loss: 0.28254130482673645\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 122 loss: 0.5352662205696106\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 123 loss: 0.16079017519950867\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 124 loss: 0.3673912584781647\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 4 step: 125 loss: 0.37906455993652344\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 126 loss: 0.45830443501472473\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 127 loss: 0.38265731930732727\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 128 loss: 0.19865106046199799\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 129 loss: 0.13424429297447205\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 4 step: 130 loss: 0.3159386217594147\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 131 loss: 0.6311234831809998\n",
      "class 0: acc 0.7500, precision 0.7857, recall 0.9167, f1 0.8462\n",
      "class 1: acc 0.7812, precision 0.3333, recall 0.1667, f1 0.2222\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 132 loss: 0.46763819456100464\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 133 loss: 0.5217251181602478\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 134 loss: 0.16017454862594604\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 135 loss: 0.6595619320869446\n",
      "class 0: acc 0.7500, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 136 loss: 0.4057702124118805\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 137 loss: 0.1929132342338562\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 138 loss: 0.3220886290073395\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 139 loss: 0.45802760124206543\n",
      "class 0: acc 0.8125, precision 0.7692, recall 1.0000, f1 0.8696\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 140 loss: 0.16059087216854095\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 4 step: 141 loss: 0.2628227472305298\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 142 loss: 0.3118938207626343\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 143 loss: 0.5347476005554199\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 144 loss: 0.26455193758010864\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 145 loss: 0.6138042211532593\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 146 loss: 0.6121116876602173\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 147 loss: 0.36444854736328125\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 148 loss: 0.457245409488678\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 149 loss: 0.2062206119298935\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 150 loss: 0.3384059965610504\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 151 loss: 0.26386529207229614\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9677, f1 0.9836\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 152 loss: 0.46587762236595154\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 4 step: 153 loss: 0.5187916159629822\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 154 loss: 0.30690816044807434\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 155 loss: 0.6666887402534485\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 156 loss: 0.3218536674976349\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 157 loss: 0.21255142986774445\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 158 loss: 0.25848105549812317\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 159 loss: 0.20118872821331024\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9286, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 160 loss: 0.34622400999069214\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.1429, f1 0.2500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 161 loss: 0.40244060754776\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 4 step: 162 loss: 0.5484403371810913\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 163 loss: 0.2882893979549408\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 164 loss: 0.33843424916267395\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 165 loss: 0.446214884519577\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 166 loss: 0.35015738010406494\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 167 loss: 0.3664296269416809\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 168 loss: 0.4202924966812134\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 169 loss: 0.18767793476581573\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 170 loss: 0.2606167793273926\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 171 loss: 0.2558417320251465\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 172 loss: 0.2797829210758209\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 173 loss: 0.5391566753387451\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 174 loss: 0.36510783433914185\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 175 loss: 0.5149425268173218\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 176 loss: 0.5125701427459717\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 177 loss: 0.382998526096344\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 178 loss: 0.48939353227615356\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 179 loss: 0.27456483244895935\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 180 loss: 0.4182776212692261\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 181 loss: 0.7104128003120422\n",
      "class 0: acc 0.7188, precision 0.6897, recall 1.0000, f1 0.8163\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 182 loss: 0.4404733180999756\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 183 loss: 0.2925591766834259\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 184 loss: 0.38139015436172485\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 185 loss: 0.30409061908721924\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 186 loss: 0.5408902764320374\n",
      "class 0: acc 0.8125, precision 0.9259, recall 0.8621, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.2000, recall 0.5000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 187 loss: 0.30076390504837036\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 188 loss: 0.2800367474555969\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 189 loss: 0.3134114742279053\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 190 loss: 0.2534830570220947\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 191 loss: 0.304516464471817\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 192 loss: 0.4129360020160675\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 193 loss: 0.23243464529514313\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 194 loss: 0.2279558777809143\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 195 loss: 0.11465301364660263\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 4 step: 196 loss: 0.1078471913933754\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 197 loss: 0.5805845856666565\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 198 loss: 0.23667249083518982\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 199 loss: 0.6571910977363586\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 200 loss: 0.48305943608283997\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 201 loss: 0.21067304909229279\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 202 loss: 0.7154591083526611\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 203 loss: 0.4504045844078064\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 204 loss: 0.48806267976760864\n",
      "class 0: acc 0.8438, precision 0.8400, recall 0.9545, f1 0.8936\n",
      "class 1: acc 0.8750, precision 0.8571, recall 0.6667, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 205 loss: 0.46472620964050293\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 206 loss: 0.32034891843795776\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 207 loss: 0.30424901843070984\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 208 loss: 0.30608275532722473\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 209 loss: 0.38129329681396484\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9091, f1 0.8511\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 210 loss: 0.30144160985946655\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9259, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 211 loss: 0.40154922008514404\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 212 loss: 0.39058008790016174\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 213 loss: 0.31725504994392395\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 214 loss: 0.3548872470855713\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 215 loss: 0.31693515181541443\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 216 loss: 0.43657180666923523\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 217 loss: 0.33002355694770813\n",
      "class 0: acc 0.8750, precision 0.9333, recall 0.9333, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 218 loss: 0.1955108940601349\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 219 loss: 0.27181223034858704\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 220 loss: 0.7267020344734192\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 221 loss: 0.3653549551963806\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 222 loss: 0.4398871064186096\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 223 loss: 0.33825981616973877\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 224 loss: 0.27195432782173157\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 4 step: 225 loss: 0.7656014561653137\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 226 loss: 0.44731786847114563\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 227 loss: 0.5307613611221313\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 228 loss: 0.315171480178833\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 229 loss: 0.306143581867218\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 230 loss: 0.37897205352783203\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 231 loss: 0.5265588760375977\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 232 loss: 0.41535666584968567\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 4 step: 233 loss: 0.2296336591243744\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 234 loss: 0.25730204582214355\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 4 step: 235 loss: 0.22956348955631256\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 236 loss: 0.3256646990776062\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 237 loss: 0.30967041850090027\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 238 loss: 0.38304415345191956\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 239 loss: 0.4233029782772064\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8750, f1 0.9333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 240 loss: 0.44078633189201355\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 241 loss: 0.3907184898853302\n",
      "class 0: acc 0.8750, precision 0.8750, recall 0.9545, f1 0.9130\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.6667, f1 0.7059\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 242 loss: 0.3733398914337158\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 243 loss: 0.22189942002296448\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 244 loss: 0.6300551891326904\n",
      "class 0: acc 0.8125, precision 0.8400, recall 0.9130, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 245 loss: 0.24184589087963104\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 246 loss: 0.6291652917861938\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 247 loss: 0.29248982667922974\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 248 loss: 0.6040106415748596\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 249 loss: 0.4656902551651001\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 250 loss: 0.3273009955883026\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 251 loss: 0.3844797611236572\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 252 loss: 0.41284531354904175\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 4 step: 253 loss: 0.3975701928138733\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 254 loss: 0.3209918439388275\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 255 loss: 0.45886486768722534\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.8000, recall 0.4444, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 256 loss: 0.5201987028121948\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 257 loss: 0.4459095001220703\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 258 loss: 0.13219548761844635\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 259 loss: 0.3438073396682739\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 260 loss: 0.18031971156597137\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 261 loss: 0.15229202806949615\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 262 loss: 0.501671314239502\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 263 loss: 0.28934338688850403\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 264 loss: 0.15915654599666595\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 265 loss: 0.19679474830627441\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 266 loss: 0.32199355959892273\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 267 loss: 0.36043110489845276\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 268 loss: 0.3500986099243164\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 269 loss: 0.2814437747001648\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 270 loss: 0.6002020239830017\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 271 loss: 0.18808764219284058\n",
      "class 0: acc 0.9375, precision 0.9677, recall 0.9677, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 272 loss: 0.45870575308799744\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 273 loss: 0.30330243706703186\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 274 loss: 0.31721410155296326\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 275 loss: 0.16007503867149353\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 276 loss: 0.34850189089775085\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 277 loss: 0.34107762575149536\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 278 loss: 0.43994757533073425\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 279 loss: 0.19108156859874725\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 280 loss: 0.16332867741584778\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 281 loss: 0.5040778517723083\n",
      "class 0: acc 0.7812, precision 0.8519, recall 0.8846, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 282 loss: 0.25820526480674744\n",
      "class 0: acc 0.8750, precision 0.9643, recall 0.9000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 283 loss: 0.3469747304916382\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 284 loss: 0.20777073502540588\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 285 loss: 0.4351305365562439\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 286 loss: 0.1915770173072815\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 287 loss: 0.4517136514186859\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 4 step: 288 loss: 0.531377911567688\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 289 loss: 0.16680657863616943\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 290 loss: 0.37184032797813416\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 291 loss: 0.11018190532922745\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 292 loss: 0.3487028181552887\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 293 loss: 0.3349163830280304\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 294 loss: 0.4666233956813812\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 295 loss: 0.46366190910339355\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 296 loss: 0.30992671847343445\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 297 loss: 0.5756497383117676\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 298 loss: 0.4255049526691437\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 299 loss: 0.31066033244132996\n",
      "class 0: acc 0.9062, precision 0.9583, recall 0.9200, f1 0.9388\n",
      "class 1: acc 0.8750, precision 0.6250, recall 0.8333, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 300 loss: 0.351380854845047\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 301 loss: 0.3518606722354889\n",
      "class 0: acc 0.8438, precision 0.9231, recall 0.8889, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 302 loss: 0.3948577642440796\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 303 loss: 0.6723651885986328\n",
      "class 0: acc 0.7500, precision 0.7241, recall 1.0000, f1 0.8400\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 304 loss: 0.2331080436706543\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 305 loss: 0.27478957176208496\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 306 loss: 0.24114304780960083\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 307 loss: 0.48084789514541626\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 308 loss: 0.19326844811439514\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 309 loss: 0.31370094418525696\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 310 loss: 0.36829298734664917\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 311 loss: 0.35008153319358826\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 312 loss: 0.2981894016265869\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 313 loss: 0.2552437484264374\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 314 loss: 0.34473344683647156\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 315 loss: 0.2986864149570465\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 316 loss: 0.7081784605979919\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 317 loss: 0.2721858322620392\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 318 loss: 0.4097698926925659\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 319 loss: 0.09983330965042114\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 320 loss: 0.5687940120697021\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 321 loss: 0.3104592561721802\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 322 loss: 0.3222256004810333\n",
      "class 0: acc 0.8125, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 323 loss: 0.28795844316482544\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 324 loss: 0.37569916248321533\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 325 loss: 0.48079702258110046\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 326 loss: 0.49792781472206116\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 327 loss: 0.36056050658226013\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 328 loss: 0.21292580664157867\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 329 loss: 0.4076933264732361\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 330 loss: 0.21964150667190552\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 331 loss: 0.35721728205680847\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 332 loss: 0.38826116919517517\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 333 loss: 0.44903427362442017\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 334 loss: 0.5161625146865845\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 335 loss: 0.28550198674201965\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 336 loss: 0.4321860373020172\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 337 loss: 0.3457481265068054\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 338 loss: 0.12335255742073059\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 339 loss: 0.18894240260124207\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 340 loss: 0.4127257764339447\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 341 loss: 0.4881582260131836\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 342 loss: 0.3176015317440033\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 343 loss: 0.1966191679239273\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 344 loss: 0.1416071057319641\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 345 loss: 0.5763426423072815\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 346 loss: 0.30696970224380493\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 347 loss: 0.3656465709209442\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 348 loss: 0.33783918619155884\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 349 loss: 0.38407227396965027\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 350 loss: 0.2507018446922302\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 351 loss: 0.43247294425964355\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 352 loss: 0.6582984328269958\n",
      "class 0: acc 0.7188, precision 0.7407, recall 0.9091, f1 0.8163\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 353 loss: 0.19069625437259674\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 354 loss: 0.33378681540489197\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 355 loss: 0.41683629155158997\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 356 loss: 0.8229085206985474\n",
      "class 0: acc 0.6875, precision 0.7200, recall 0.8571, f1 0.7826\n",
      "class 1: acc 0.6875, precision 0.4286, recall 0.3333, f1 0.3750\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 357 loss: 0.4218834936618805\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 358 loss: 0.5583041906356812\n",
      "class 0: acc 0.7812, precision 0.8750, recall 0.8400, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.8000, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 359 loss: 0.4111355245113373\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 360 loss: 0.44484180212020874\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 361 loss: 0.4333434998989105\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 362 loss: 0.33390042185783386\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 363 loss: 0.43175724148750305\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 364 loss: 0.30767250061035156\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 365 loss: 0.39067819714546204\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 366 loss: 0.8081666231155396\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 367 loss: 0.288496732711792\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 368 loss: 0.30531296133995056\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 369 loss: 0.508056640625\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 370 loss: 0.4071885943412781\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 371 loss: 0.6048477292060852\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 372 loss: 0.6539992094039917\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 373 loss: 0.12246083468198776\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 374 loss: 0.31847426295280457\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 375 loss: 0.35830995440483093\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 376 loss: 0.32344430685043335\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 377 loss: 0.30727893114089966\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 378 loss: 0.35323566198349\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 379 loss: 0.36276066303253174\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 380 loss: 0.19638672471046448\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 381 loss: 0.44283849000930786\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 382 loss: 0.31951579451560974\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 383 loss: 0.15523961186408997\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9286, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 384 loss: 0.670233428478241\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 385 loss: 0.2416049689054489\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 386 loss: 0.22704899311065674\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 387 loss: 0.20850543677806854\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 388 loss: 0.5695070028305054\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.2000, recall 1.0000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 389 loss: 0.4275353252887726\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 390 loss: 0.1161036416888237\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 391 loss: 0.3990733325481415\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 4 step: 392 loss: 0.5488151907920837\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 393 loss: 0.5736070275306702\n",
      "class 0: acc 0.7812, precision 0.7812, recall 1.0000, f1 0.8772\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 394 loss: 0.2593548893928528\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 395 loss: 0.3480684161186218\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 396 loss: 0.3463347554206848\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 397 loss: 0.5660429000854492\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 398 loss: 0.49853581190109253\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 399 loss: 0.31096795201301575\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 400 loss: 0.5172377228736877\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 401 loss: 0.38930225372314453\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 402 loss: 0.5789227485656738\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 403 loss: 0.37717267870903015\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 404 loss: 0.35397782921791077\n",
      "class 0: acc 0.8438, precision 0.9231, recall 0.8889, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 405 loss: 0.26426100730895996\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 406 loss: 0.4748465120792389\n",
      "class 0: acc 0.8125, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 407 loss: 0.35387346148490906\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 408 loss: 0.24404792487621307\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 409 loss: 0.4511338174343109\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 410 loss: 0.3571294844150543\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 411 loss: 0.33696985244750977\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 412 loss: 0.3866051137447357\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 4 step: 413 loss: 0.5973072648048401\n",
      "class 0: acc 0.7188, precision 0.7241, recall 0.9545, f1 0.8235\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 414 loss: 0.3598833382129669\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 415 loss: 0.41147109866142273\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 416 loss: 0.38914206624031067\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 417 loss: 0.6382753252983093\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 418 loss: 0.6385322213172913\n",
      "class 0: acc 0.7188, precision 0.7097, recall 1.0000, f1 0.8302\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 419 loss: 0.3725844919681549\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 420 loss: 0.3489150404930115\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 421 loss: 0.20938105881214142\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 422 loss: 0.37126681208610535\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 423 loss: 0.16075770556926727\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 424 loss: 0.30167049169540405\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 425 loss: 0.23546700179576874\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 426 loss: 0.29929119348526\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 427 loss: 0.2582528591156006\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 428 loss: 0.13996228575706482\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9333, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 429 loss: 0.2763004004955292\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 430 loss: 0.5360574722290039\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.2000, recall 0.3333, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 431 loss: 0.37766003608703613\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 432 loss: 0.4246581494808197\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 433 loss: 0.29049238562583923\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 434 loss: 0.41814765334129333\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 435 loss: 0.2760312259197235\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 4 step: 436 loss: 0.16623330116271973\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 437 loss: 0.5453741550445557\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 438 loss: 0.7390106320381165\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 439 loss: 0.5487967133522034\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 440 loss: 0.19210121035575867\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 441 loss: 0.29940998554229736\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 442 loss: 0.4512591063976288\n",
      "class 0: acc 0.8125, precision 0.8000, recall 0.9524, f1 0.8696\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 443 loss: 0.4649837911128998\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 444 loss: 0.2775188386440277\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 445 loss: 0.2907713055610657\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9615, f1 0.9804\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 446 loss: 0.20676301419734955\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 447 loss: 0.24759705364704132\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 448 loss: 0.321082204580307\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 449 loss: 0.267852783203125\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 450 loss: 0.06121053919196129\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 451 loss: 0.614757776260376\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 452 loss: 0.29564040899276733\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 453 loss: 0.23351824283599854\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 454 loss: 0.5305635929107666\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 455 loss: 0.35214418172836304\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 456 loss: 0.1180037409067154\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 457 loss: 0.29732567071914673\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 458 loss: 0.5043196678161621\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 459 loss: 0.44398021697998047\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 460 loss: 0.40491268038749695\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 461 loss: 0.3679261803627014\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 462 loss: 0.4396093487739563\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 463 loss: 0.3570420444011688\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 464 loss: 0.27460548281669617\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 465 loss: 0.5686600804328918\n",
      "class 0: acc 0.7500, precision 0.8519, recall 0.8519, f1 0.8519\n",
      "class 1: acc 0.8438, precision 0.2000, recall 0.5000, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 466 loss: 0.5237217545509338\n",
      "class 0: acc 0.7188, precision 0.7586, recall 0.9167, f1 0.8302\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 467 loss: 0.4278668761253357\n",
      "class 0: acc 0.8750, precision 0.9643, recall 0.9000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 468 loss: 0.27128279209136963\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 469 loss: 0.24751384556293488\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 470 loss: 0.43605342507362366\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 471 loss: 0.1348097324371338\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 472 loss: 0.4274854063987732\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 473 loss: 0.14840954542160034\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 474 loss: 0.3546152710914612\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 475 loss: 0.3617732524871826\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 476 loss: 0.17414793372154236\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 477 loss: 0.29180651903152466\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 478 loss: 0.3444339334964752\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 479 loss: 0.35078784823417664\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 480 loss: 0.27743402123451233\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 481 loss: 0.3135830760002136\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 482 loss: 0.30534231662750244\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 483 loss: 0.25513023138046265\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 484 loss: 0.28930386900901794\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 485 loss: 0.1735137552022934\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 486 loss: 0.15525807440280914\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 487 loss: 0.38489094376564026\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 488 loss: 0.2947862446308136\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 489 loss: 0.16328100860118866\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 490 loss: 0.2443860024213791\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 491 loss: 0.2692970037460327\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 492 loss: 0.41116878390312195\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 493 loss: 0.45946457982063293\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 494 loss: 0.6044746041297913\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 495 loss: 0.1504841446876526\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 496 loss: 0.24788545072078705\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 497 loss: 0.3964422643184662\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 498 loss: 0.6267181634902954\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 499 loss: 0.5629903078079224\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 500 loss: 0.6661701798439026\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 501 loss: 0.33888357877731323\n",
      "class 0: acc 0.8750, precision 0.9643, recall 0.9000, f1 0.9310\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 502 loss: 0.158908873796463\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 503 loss: 0.3605511784553528\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 504 loss: 0.6038963198661804\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 505 loss: 0.2244495153427124\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 506 loss: 0.355327308177948\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 4 step: 507 loss: 0.3550080358982086\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 508 loss: 0.20906618237495422\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 509 loss: 0.2617091238498688\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 510 loss: 0.3143182098865509\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 511 loss: 0.2594049274921417\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 512 loss: 0.21326401829719543\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 513 loss: 0.3623373210430145\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 514 loss: 0.22168484330177307\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 515 loss: 0.32338809967041016\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 516 loss: 0.45913785696029663\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 517 loss: 0.27048686146736145\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 518 loss: 0.17963294684886932\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 519 loss: 0.47688406705856323\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 520 loss: 0.3506525754928589\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 521 loss: 0.5668804049491882\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 4 step: 522 loss: 0.34540703892707825\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 523 loss: 0.23366597294807434\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 524 loss: 0.5628697872161865\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 525 loss: 0.3574982285499573\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 526 loss: 0.22125352919101715\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 527 loss: 0.3406045436859131\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 528 loss: 0.3812987506389618\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 529 loss: 0.14147843420505524\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 530 loss: 0.3032069802284241\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 531 loss: 0.7807010412216187\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 532 loss: 0.342910498380661\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 533 loss: 0.3767351806163788\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 534 loss: 0.3515993654727936\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 535 loss: 0.42072880268096924\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 536 loss: 0.6753290295600891\n",
      "class 0: acc 0.7812, precision 0.8333, recall 0.8696, f1 0.8511\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.5714, f1 0.5333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 537 loss: 0.5404154658317566\n",
      "class 0: acc 0.8125, precision 0.8846, recall 0.8846, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 538 loss: 0.48535025119781494\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 539 loss: 0.346437007188797\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 4 step: 540 loss: 0.47053587436676025\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 541 loss: 0.4266531467437744\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 542 loss: 0.4563494920730591\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 543 loss: 0.42702850699424744\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 544 loss: 0.27905964851379395\n",
      "class 0: acc 0.9375, precision 0.9167, recall 1.0000, f1 0.9565\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 4 step: 545 loss: 0.6093493700027466\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 546 loss: 0.2841094136238098\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 547 loss: 0.40935853123664856\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 548 loss: 0.4593784213066101\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 549 loss: 0.5151569843292236\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 550 loss: 0.29358139634132385\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 551 loss: 0.21841542422771454\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 552 loss: 0.21205338835716248\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 553 loss: 0.3140934407711029\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 554 loss: 0.34996041655540466\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 555 loss: 0.27095240354537964\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 556 loss: 0.4510904848575592\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 557 loss: 0.19122567772865295\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 558 loss: 0.2617897689342499\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 559 loss: 0.47898274660110474\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 560 loss: 0.3385462760925293\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 561 loss: 0.6189680099487305\n",
      "class 0: acc 0.7500, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 562 loss: 0.07588505744934082\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 563 loss: 0.26817408204078674\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 564 loss: 0.44793128967285156\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 565 loss: 0.29216721653938293\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 566 loss: 0.36229416728019714\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 567 loss: 0.17705176770687103\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 568 loss: 0.28599852323532104\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 569 loss: 0.2856714427471161\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 570 loss: 0.5311444997787476\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 571 loss: 0.23299603164196014\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 572 loss: 0.5377616286277771\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 573 loss: 0.44933512806892395\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 574 loss: 0.2018825113773346\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 575 loss: 0.1965286135673523\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 576 loss: 0.4665106236934662\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 577 loss: 0.36711740493774414\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 578 loss: 0.5671470761299133\n",
      "class 0: acc 0.8438, precision 0.9231, recall 0.8889, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 579 loss: 0.39278826117515564\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 580 loss: 0.29721617698669434\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 581 loss: 0.5316503047943115\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 582 loss: 0.3533310294151306\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 583 loss: 0.3395226001739502\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 584 loss: 0.18768788874149323\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 585 loss: 0.28948673605918884\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 586 loss: 0.20224608480930328\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 587 loss: 0.43000856041908264\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 588 loss: 0.23593805730342865\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 589 loss: 0.5104919075965881\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 590 loss: 0.21904854476451874\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 591 loss: 0.3449987471103668\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 592 loss: 0.37115028500556946\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 593 loss: 0.2129666656255722\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 594 loss: 0.35865604877471924\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 595 loss: 0.6341596245765686\n",
      "class 0: acc 0.7188, precision 0.6897, recall 1.0000, f1 0.8163\n",
      "class 1: acc 0.7500, precision 1.0000, recall 0.2727, f1 0.4286\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 596 loss: 0.3100554645061493\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 597 loss: 0.16051089763641357\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 598 loss: 0.09920645505189896\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 599 loss: 0.6760715842247009\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 600 loss: 0.30333301424980164\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 601 loss: 0.3899345397949219\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 602 loss: 0.26732373237609863\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 603 loss: 0.2597823739051819\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 604 loss: 0.27494943141937256\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 605 loss: 0.4071803689002991\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 606 loss: 0.11041413247585297\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 607 loss: 0.48005396127700806\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.2000, recall 1.0000, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 608 loss: 0.29270610213279724\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 609 loss: 0.3664133548736572\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 610 loss: 0.2996477782726288\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 611 loss: 0.35895854234695435\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 612 loss: 0.5128517150878906\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 613 loss: 0.33963218331336975\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 614 loss: 0.4592607617378235\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 615 loss: 0.248436838388443\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 616 loss: 0.2662397623062134\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 617 loss: 0.302578866481781\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 618 loss: 0.2833292484283447\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 619 loss: 0.43187445402145386\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 620 loss: 0.9558906555175781\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 621 loss: 0.23206160962581635\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 622 loss: 0.45170074701309204\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 623 loss: 0.27685415744781494\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 624 loss: 0.28487110137939453\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 4 step: 625 loss: 0.2684732973575592\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 626 loss: 0.2639610171318054\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 627 loss: 0.2538839876651764\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 628 loss: 0.49626970291137695\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 629 loss: 0.18572595715522766\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 630 loss: 0.20754379034042358\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 631 loss: 0.4562680125236511\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 632 loss: 0.35566237568855286\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 633 loss: 0.3728153705596924\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 634 loss: 0.48449376225471497\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 635 loss: 0.22070159018039703\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 636 loss: 0.377265602350235\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 637 loss: 0.38740259408950806\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 638 loss: 0.15120989084243774\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 639 loss: 0.323149174451828\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 640 loss: 0.2625446915626526\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 641 loss: 0.3820389211177826\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 642 loss: 0.3688203990459442\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 643 loss: 0.27940553426742554\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 644 loss: 0.3752689063549042\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 645 loss: 0.5100898742675781\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 646 loss: 0.2581985294818878\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9375, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 647 loss: 0.5702908635139465\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 648 loss: 0.28914856910705566\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 649 loss: 0.21793916821479797\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 650 loss: 0.40454116463661194\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 651 loss: 0.475534051656723\n",
      "class 0: acc 0.8125, precision 0.7692, recall 1.0000, f1 0.8696\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 652 loss: 0.27556660771369934\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 653 loss: 0.45629727840423584\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 654 loss: 0.16213442385196686\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 655 loss: 0.2816367745399475\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 656 loss: 0.6177366971969604\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 657 loss: 0.2745323181152344\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 658 loss: 0.5844423770904541\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 659 loss: 0.36564186215400696\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 660 loss: 0.3836842477321625\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 661 loss: 0.570066511631012\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 662 loss: 0.23603135347366333\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 663 loss: 0.2092302292585373\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 664 loss: 0.5774602293968201\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 665 loss: 0.2555631399154663\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 666 loss: 0.3444218337535858\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 667 loss: 0.3885980546474457\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 668 loss: 0.33588480949401855\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 669 loss: 0.2499486804008484\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 670 loss: 0.24750399589538574\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 671 loss: 0.4938766658306122\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 672 loss: 0.5909877419471741\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 673 loss: 0.18342313170433044\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 674 loss: 0.4398159682750702\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 675 loss: 0.39903023838996887\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 676 loss: 0.4573119282722473\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 677 loss: 0.32359760999679565\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 678 loss: 0.2906346917152405\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 679 loss: 0.5774455666542053\n",
      "class 0: acc 0.7500, precision 0.7857, recall 0.9167, f1 0.8462\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 680 loss: 0.3995552361011505\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 681 loss: 0.3719080686569214\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 682 loss: 0.4577881097793579\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 683 loss: 0.24906353652477264\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 684 loss: 0.5020613074302673\n",
      "class 0: acc 0.8125, precision 0.7692, recall 1.0000, f1 0.8696\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 685 loss: 0.4073830544948578\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 686 loss: 0.3603380024433136\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 687 loss: 0.45400187373161316\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 688 loss: 0.39519962668418884\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 689 loss: 0.36919188499450684\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 690 loss: 0.266132652759552\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 691 loss: 0.28609222173690796\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 692 loss: 0.20197643339633942\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 693 loss: 0.2926749289035797\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 694 loss: 0.44015827775001526\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 695 loss: 0.28436097502708435\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 696 loss: 0.35809749364852905\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 697 loss: 0.1416095793247223\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 698 loss: 0.7087748646736145\n",
      "class 0: acc 0.7188, precision 0.7333, recall 0.9565, f1 0.8302\n",
      "class 1: acc 0.7500, precision 0.5000, recall 0.1250, f1 0.2000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 699 loss: 0.7643172144889832\n",
      "class 0: acc 0.7812, precision 0.7812, recall 1.0000, f1 0.8772\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 700 loss: 0.25942263007164\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 701 loss: 0.41961222887039185\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 702 loss: 0.3905899226665497\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 703 loss: 0.17680546641349792\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 704 loss: 0.394841730594635\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 705 loss: 0.4616940915584564\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 706 loss: 0.380669504404068\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 707 loss: 0.5716708898544312\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 708 loss: 0.5092103481292725\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 709 loss: 0.3420640528202057\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 710 loss: 0.3371943533420563\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 711 loss: 0.30490776896476746\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 712 loss: 0.3356725573539734\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 713 loss: 0.18872371315956116\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 714 loss: 0.24885646998882294\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 715 loss: 0.34005364775657654\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 716 loss: 0.2867264747619629\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 717 loss: 0.5848735570907593\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 718 loss: 0.25103622674942017\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 719 loss: 0.3703767955303192\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 720 loss: 0.5419601798057556\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 721 loss: 0.409604549407959\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 722 loss: 0.1381273865699768\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 723 loss: 0.22178669273853302\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 724 loss: 0.2426404356956482\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 725 loss: 0.44407519698143005\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 726 loss: 0.295536071062088\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 727 loss: 0.6067073941230774\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 728 loss: 0.506871223449707\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 729 loss: 0.38168880343437195\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 730 loss: 0.4016968309879303\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 731 loss: 0.39680999517440796\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 732 loss: 0.5003376007080078\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 733 loss: 0.4249327480792999\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 734 loss: 0.4218112528324127\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 735 loss: 0.5743573307991028\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 736 loss: 0.9334851503372192\n",
      "class 0: acc 0.7500, precision 0.7692, recall 0.9091, f1 0.8333\n",
      "class 1: acc 0.7188, precision 0.3333, recall 0.2857, f1 0.3077\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 737 loss: 0.3501911163330078\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 738 loss: 0.2364501953125\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 739 loss: 0.3894376754760742\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 740 loss: 0.3287423253059387\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 741 loss: 0.1813957691192627\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 742 loss: 0.30166321992874146\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 743 loss: 0.23831549286842346\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 744 loss: 0.4155857264995575\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 745 loss: 0.5807166695594788\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 746 loss: 0.15973520278930664\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 747 loss: 0.22031401097774506\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 748 loss: 0.5132278203964233\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9375, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 749 loss: 0.17367029190063477\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 750 loss: 0.36191147565841675\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 751 loss: 0.24344277381896973\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 752 loss: 0.2260417938232422\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 753 loss: 0.3075850009918213\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 754 loss: 0.39527627825737\n",
      "class 0: acc 0.9062, precision 0.9583, recall 0.9200, f1 0.9388\n",
      "class 1: acc 0.8750, precision 0.6250, recall 0.8333, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 755 loss: 0.23325613141059875\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 756 loss: 0.38189321756362915\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 757 loss: 0.20553359389305115\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 758 loss: 0.4476398825645447\n",
      "class 0: acc 0.8438, precision 0.9000, recall 0.9310, f1 0.9153\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 759 loss: 0.3632262349128723\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 760 loss: 0.18780235946178436\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 761 loss: 0.2405129075050354\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 762 loss: 0.22369371354579926\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 763 loss: 0.5808240175247192\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 764 loss: 0.388174831867218\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 765 loss: 0.41721028089523315\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 766 loss: 0.39180421829223633\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 767 loss: 0.49694985151290894\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 768 loss: 0.3170907199382782\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 769 loss: 0.2612423300743103\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 770 loss: 0.19017121195793152\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 771 loss: 0.3831396698951721\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 772 loss: 0.2604106068611145\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 773 loss: 0.41799455881118774\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 774 loss: 0.3239705264568329\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 775 loss: 0.2842244505882263\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 776 loss: 0.463537335395813\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 777 loss: 0.32269540429115295\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 778 loss: 0.3930649757385254\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 779 loss: 0.22119711339473724\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 780 loss: 0.4264625310897827\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 781 loss: 0.4348398447036743\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 782 loss: 0.5266112089157104\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 783 loss: 0.18689359724521637\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 784 loss: 0.47337332367897034\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 785 loss: 0.7522010803222656\n",
      "class 0: acc 0.7188, precision 0.7241, recall 0.9545, f1 0.8235\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 786 loss: 0.36156028509140015\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 787 loss: 0.3229527771472931\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 788 loss: 0.3399789333343506\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 789 loss: 0.346103698015213\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 790 loss: 0.42252862453460693\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 791 loss: 0.6742898225784302\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 792 loss: 0.37203463912010193\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 793 loss: 0.4238440692424774\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 794 loss: 0.23948952555656433\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 795 loss: 0.33214545249938965\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 796 loss: 0.3807540833950043\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 797 loss: 0.4636520743370056\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 798 loss: 0.19852110743522644\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 799 loss: 0.10548773407936096\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 800 loss: 0.7097676396369934\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 801 loss: 0.39560380578041077\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 802 loss: 0.2663063108921051\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 803 loss: 0.5654973387718201\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 804 loss: 0.5485444068908691\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 4 step: 805 loss: 0.2122393101453781\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 806 loss: 0.554128110408783\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 807 loss: 0.3544406294822693\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 808 loss: 0.2396048903465271\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8889, f1 0.9412\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "epoch: 4 step: 809 loss: 0.41741743683815\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 810 loss: 0.31623566150665283\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 811 loss: 0.2052280306816101\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 812 loss: 0.27931341528892517\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 813 loss: 0.3131430149078369\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 814 loss: 0.31859010457992554\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 815 loss: 0.1683257818222046\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 816 loss: 0.6409479975700378\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 817 loss: 0.16705414652824402\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 818 loss: 0.28125619888305664\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 819 loss: 0.5349534153938293\n",
      "class 0: acc 0.7812, precision 0.8889, recall 0.8571, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.2000, recall 0.5000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 820 loss: 0.6354473829269409\n",
      "class 0: acc 0.7188, precision 0.6800, recall 0.9444, f1 0.7907\n",
      "class 1: acc 0.8125, precision 0.7143, recall 0.5556, f1 0.6250\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 821 loss: 0.3353990912437439\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 822 loss: 0.5037651062011719\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 823 loss: 0.4519904553890228\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 824 loss: 0.09149179607629776\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 825 loss: 0.5015643239021301\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 826 loss: 0.17692159116268158\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 827 loss: 0.3772161602973938\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 828 loss: 0.5119288563728333\n",
      "class 0: acc 0.9375, precision 0.9167, recall 1.0000, f1 0.9565\n",
      "class 1: acc 0.8438, precision 0.6250, recall 0.7143, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 829 loss: 0.5042358040809631\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 830 loss: 0.9159306287765503\n",
      "class 0: acc 0.6562, precision 0.6452, recall 1.0000, f1 0.7843\n",
      "class 1: acc 0.7188, precision 1.0000, recall 0.1000, f1 0.1818\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 831 loss: 0.5213842988014221\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9091, f1 0.8696\n",
      "class 1: acc 0.8438, precision 0.7143, recall 0.6250, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 832 loss: 0.4668802320957184\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 833 loss: 0.3376109004020691\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 834 loss: 0.7983854413032532\n",
      "class 0: acc 0.7812, precision 0.8400, recall 0.8750, f1 0.8571\n",
      "class 1: acc 0.7812, precision 0.2000, recall 0.2500, f1 0.2222\n",
      "class 2: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "epoch: 4 step: 835 loss: 0.5901575088500977\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "epoch: 4 step: 836 loss: 0.3986065685749054\n",
      "class 0: acc 0.8750, precision 0.9583, recall 0.8846, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 837 loss: 0.1490650773048401\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9231, f1 0.9600\n",
      "class 1: acc 0.9688, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 838 loss: 0.48796889185905457\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 839 loss: 0.5488011837005615\n",
      "class 0: acc 0.7812, precision 0.9167, recall 0.8148, f1 0.8627\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "epoch: 4 step: 840 loss: 0.37483668327331543\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 841 loss: 0.44058936834335327\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 842 loss: 0.25913339853286743\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 843 loss: 0.485114187002182\n",
      "class 0: acc 0.7812, precision 0.8800, recall 0.8462, f1 0.8627\n",
      "class 1: acc 0.7812, precision 0.3333, recall 0.4000, f1 0.3636\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 844 loss: 0.38030004501342773\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 845 loss: 0.46009498834609985\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 846 loss: 0.44826388359069824\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 847 loss: 0.42482346296310425\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 848 loss: 0.4519254267215729\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 849 loss: 0.35524648427963257\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 850 loss: 0.29568761587142944\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 851 loss: 0.09964784979820251\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 852 loss: 0.40947970747947693\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 853 loss: 0.27086490392684937\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 854 loss: 0.3344690203666687\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 855 loss: 0.33186888694763184\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 856 loss: 0.22990573942661285\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 857 loss: 0.2984532117843628\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 858 loss: 0.33941420912742615\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 859 loss: 0.4122696816921234\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 860 loss: 0.37835580110549927\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 861 loss: 0.40264782309532166\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 862 loss: 0.39869868755340576\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 863 loss: 0.42032667994499207\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 864 loss: 0.4152865707874298\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 865 loss: 0.4826611876487732\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 866 loss: 0.2799125909805298\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 867 loss: 0.3341468274593353\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 868 loss: 0.4938007593154907\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 869 loss: 0.5668947696685791\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 870 loss: 0.44924136996269226\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 871 loss: 0.4153304994106293\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 872 loss: 0.4599725008010864\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 873 loss: 0.40696361660957336\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.8750, precision 0.6250, recall 0.8333, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 874 loss: 0.2053353190422058\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 875 loss: 0.42374229431152344\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 876 loss: 0.6045471429824829\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 877 loss: 0.20943011343479156\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 878 loss: 0.4824060797691345\n",
      "class 0: acc 0.8750, precision 0.8750, recall 0.9545, f1 0.9130\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.8571, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 879 loss: 0.45350074768066406\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 880 loss: 0.3138294219970703\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 881 loss: 0.3975093960762024\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 882 loss: 0.45667529106140137\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 883 loss: 0.409994512796402\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 884 loss: 0.6382752060890198\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 885 loss: 0.2473216950893402\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 886 loss: 0.720138669013977\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 887 loss: 0.3755481243133545\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 888 loss: 0.3566948175430298\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 889 loss: 0.829043984413147\n",
      "class 0: acc 0.7188, precision 0.7419, recall 0.9583, f1 0.8364\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 890 loss: 0.5386895537376404\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 891 loss: 0.40620148181915283\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 892 loss: 0.2621421217918396\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 893 loss: 0.28215792775154114\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 894 loss: 0.4022410809993744\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 895 loss: 0.5481247305870056\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 896 loss: 0.23993057012557983\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 897 loss: 0.37876784801483154\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 898 loss: 0.2733842730522156\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 899 loss: 0.5701537132263184\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 900 loss: 0.5529666543006897\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 901 loss: 0.21421831846237183\n",
      "class 0: acc 0.9688, precision 0.9583, recall 1.0000, f1 0.9787\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 902 loss: 0.1396830826997757\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 903 loss: 0.46277832984924316\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 904 loss: 0.3754967153072357\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 905 loss: 0.3386905789375305\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 906 loss: 0.48983174562454224\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 907 loss: 0.4525274634361267\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 908 loss: 0.5549705624580383\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 909 loss: 0.4570620357990265\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 910 loss: 0.1805751621723175\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 911 loss: 0.38837435841560364\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 912 loss: 0.2827858328819275\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 913 loss: 0.22725249826908112\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 914 loss: 0.17218531668186188\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 915 loss: 0.17242567241191864\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 916 loss: 0.22787664830684662\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 917 loss: 0.2747477889060974\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 918 loss: 0.6487892270088196\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 919 loss: 0.7127516269683838\n",
      "class 0: acc 0.6875, precision 0.7143, recall 0.9091, f1 0.8000\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 920 loss: 0.3657541275024414\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 921 loss: 0.3445945978164673\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 922 loss: 0.3238750398159027\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 923 loss: 0.4459850788116455\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 924 loss: 0.34173640608787537\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 925 loss: 0.3055521249771118\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 926 loss: 0.4265090525150299\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 927 loss: 0.4238683581352234\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 928 loss: 0.2863132655620575\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 929 loss: 0.3946950137615204\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 930 loss: 0.5214959979057312\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.8125, precision 0.4286, recall 0.6000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 931 loss: 0.5136740207672119\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.6000, recall 0.4286, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 932 loss: 0.2540067136287689\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 933 loss: 0.3912332355976105\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 934 loss: 0.35293498635292053\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 935 loss: 0.392093688249588\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 936 loss: 0.37819185853004456\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 937 loss: 0.45377272367477417\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 938 loss: 0.4563671052455902\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 939 loss: 0.4946190118789673\n",
      "class 0: acc 0.8750, precision 0.9600, recall 0.8889, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 940 loss: 0.22312989830970764\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 4 step: 941 loss: 0.3738669157028198\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 942 loss: 0.13255274295806885\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 4 step: 943 loss: 0.3316309452056885\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 944 loss: 0.26345935463905334\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 945 loss: 0.31926313042640686\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 946 loss: 0.49940216541290283\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 947 loss: 0.4540834426879883\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 948 loss: 0.7036215662956238\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 949 loss: 0.21262694895267487\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 950 loss: 0.5545971989631653\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 951 loss: 0.42381373047828674\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 952 loss: 0.2884405255317688\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 953 loss: 0.2289430946111679\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 954 loss: 0.6067957878112793\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 955 loss: 0.36836299300193787\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 956 loss: 0.330698162317276\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 957 loss: 0.2253553569316864\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 958 loss: 0.22687827050685883\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 959 loss: 0.37073057889938354\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 960 loss: 0.20403391122817993\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 961 loss: 0.3104396462440491\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 962 loss: 0.31454282999038696\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 963 loss: 0.35554587841033936\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 964 loss: 0.2975902855396271\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 965 loss: 0.3825724720954895\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 966 loss: 0.5486245155334473\n",
      "class 0: acc 0.7500, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 967 loss: 0.3830898404121399\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 968 loss: 0.25331932306289673\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 969 loss: 0.23797468841075897\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 970 loss: 0.27295005321502686\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 971 loss: 0.46715453267097473\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 972 loss: 0.2179965078830719\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 973 loss: 0.3105130195617676\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 974 loss: 0.3293747007846832\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 975 loss: 0.4620852768421173\n",
      "class 0: acc 0.7500, precision 0.7857, recall 0.9167, f1 0.8462\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 976 loss: 0.4316784739494324\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 977 loss: 0.28568387031555176\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 978 loss: 0.33462193608283997\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 979 loss: 0.28684619069099426\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 980 loss: 0.40307676792144775\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 981 loss: 0.6085948944091797\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 982 loss: 0.3717690408229828\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 983 loss: 0.3940768539905548\n",
      "class 0: acc 0.8438, precision 0.8750, recall 0.9130, f1 0.8936\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.8571, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 984 loss: 0.26715168356895447\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 985 loss: 0.32430678606033325\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 986 loss: 0.23549522459506989\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 987 loss: 0.49293845891952515\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 988 loss: 0.4606805741786957\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 989 loss: 0.7554877400398254\n",
      "class 0: acc 0.7812, precision 0.8065, recall 0.9615, f1 0.8772\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 990 loss: 0.22005876898765564\n",
      "class 0: acc 0.8750, precision 0.9643, recall 0.9000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 991 loss: 0.4583863317966461\n",
      "class 0: acc 0.9062, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.8750, recall 0.8750, f1 0.8750\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 992 loss: 0.33794811367988586\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 993 loss: 0.4200843870639801\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 994 loss: 0.24552683532238007\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 4 step: 995 loss: 0.3707619607448578\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 996 loss: 0.3039552569389343\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 997 loss: 0.3205083906650543\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 998 loss: 0.27501189708709717\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 999 loss: 0.30567315220832825\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1000 loss: 0.45742854475975037\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1001 loss: 0.44271838665008545\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1002 loss: 0.25078392028808594\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1003 loss: 0.20600616931915283\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1004 loss: 0.25929713249206543\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1005 loss: 0.2609221935272217\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 1006 loss: 0.2136494666337967\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1007 loss: 0.43118053674697876\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1008 loss: 0.6249179840087891\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1009 loss: 0.305867463350296\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1010 loss: 0.17517879605293274\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1011 loss: 0.24275481700897217\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1012 loss: 0.41896623373031616\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1013 loss: 0.4348231256008148\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1014 loss: 0.1406324952840805\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1015 loss: 0.1347745656967163\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1016 loss: 0.27625036239624023\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1017 loss: 0.2586573660373688\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1018 loss: 0.46149682998657227\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1019 loss: 0.37514528632164\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1020 loss: 0.5344370007514954\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1021 loss: 0.4327886998653412\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1022 loss: 0.2413281947374344\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1023 loss: 0.335226833820343\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1024 loss: 0.3427446782588959\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1025 loss: 0.4617917835712433\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1026 loss: 0.18433018028736115\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1027 loss: 0.6752978563308716\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.7812, precision 0.6667, recall 0.2500, f1 0.3636\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1028 loss: 0.3436346650123596\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1029 loss: 0.2613806426525116\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 4 step: 1030 loss: 0.2950966954231262\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1031 loss: 0.4646458923816681\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.8438, precision 0.7143, recall 0.6250, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1032 loss: 0.16593267023563385\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1033 loss: 0.3061703145503998\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1034 loss: 0.5680457949638367\n",
      "class 0: acc 0.7812, precision 0.8333, recall 0.8696, f1 0.8511\n",
      "class 1: acc 0.8750, precision 0.6250, recall 0.8333, f1 0.7143\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1035 loss: 0.6248271465301514\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.9375, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1036 loss: 0.8384302854537964\n",
      "class 0: acc 0.7500, precision 0.7917, recall 0.8636, f1 0.8261\n",
      "class 1: acc 0.7812, precision 0.3750, recall 0.6000, f1 0.4615\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1037 loss: 0.35861366987228394\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1038 loss: 0.6410759687423706\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1039 loss: 0.30689769983291626\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9688, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1040 loss: 0.4220007061958313\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1041 loss: 0.31054893136024475\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1042 loss: 0.5481744408607483\n",
      "class 0: acc 0.7500, precision 0.7241, recall 1.0000, f1 0.8400\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1043 loss: 0.4008874297142029\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1044 loss: 0.24278739094734192\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1045 loss: 0.519358217716217\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1046 loss: 0.3954832851886749\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1047 loss: 0.40861764550209045\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1048 loss: 0.4086017906665802\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1049 loss: 0.24569764733314514\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1050 loss: 0.4645771086215973\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1051 loss: 0.30689185857772827\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 4 step: 1052 loss: 0.38964083790779114\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1053 loss: 0.27008503675460815\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1054 loss: 0.4782344400882721\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.7000, f1 0.8235\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1055 loss: 0.4125443398952484\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1056 loss: 0.5784503817558289\n",
      "class 0: acc 0.7188, precision 0.7692, recall 0.8696, f1 0.8163\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1057 loss: 0.15747463703155518\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1058 loss: 0.3470013439655304\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1059 loss: 0.24318726360797882\n",
      "class 0: acc 0.9688, precision 0.9600, recall 1.0000, f1 0.9796\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1060 loss: 0.4507155418395996\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1061 loss: 0.5634757876396179\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1062 loss: 0.07162725180387497\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1063 loss: 0.27016735076904297\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1064 loss: 0.19037427008152008\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1065 loss: 0.32979387044906616\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1066 loss: 0.4494781196117401\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.2500, recall 0.2500, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1067 loss: 0.5758010149002075\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1068 loss: 0.4659572243690491\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1069 loss: 0.5310841798782349\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1070 loss: 0.24982209503650665\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1071 loss: 0.275453120470047\n",
      "class 0: acc 0.9375, precision 0.9677, recall 0.9677, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1072 loss: 0.6801690459251404\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1073 loss: 0.35078731179237366\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1074 loss: 0.3772607743740082\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1075 loss: 0.5098390579223633\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1076 loss: 0.2888668179512024\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1077 loss: 0.14369626343250275\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1078 loss: 0.3568609356880188\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1079 loss: 0.1988108903169632\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1080 loss: 0.24996264278888702\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1081 loss: 0.18180331587791443\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 4 step: 1082 loss: 0.1611277014017105\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1083 loss: 0.31970420479774475\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1084 loss: 0.37190744280815125\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1085 loss: 0.42902934551239014\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1086 loss: 0.5692789554595947\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9091, f1 0.8696\n",
      "class 1: acc 0.7812, precision 0.5714, recall 0.5000, f1 0.5333\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 1087 loss: 0.3861508369445801\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1088 loss: 0.25318893790245056\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1089 loss: 0.31855398416519165\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1090 loss: 0.5225480794906616\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1091 loss: 0.5546068549156189\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1092 loss: 0.5072832107543945\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1093 loss: 0.4322713017463684\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1094 loss: 0.346929132938385\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1095 loss: 0.2409532368183136\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1096 loss: 0.16648231446743011\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1097 loss: 0.3407342731952667\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1098 loss: 0.21278588473796844\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1099 loss: 0.3148242235183716\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1100 loss: 0.3649885356426239\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1101 loss: 0.41723766922950745\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1102 loss: 0.33030447363853455\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1103 loss: 0.364048033952713\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1104 loss: 0.044594306498765945\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1105 loss: 0.3123112618923187\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1106 loss: 0.3099488914012909\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1107 loss: 0.3093956708908081\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 4 step: 1108 loss: 0.5249895453453064\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1109 loss: 0.7620882391929626\n",
      "class 0: acc 0.7500, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1110 loss: 0.31938663125038147\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1111 loss: 0.2520124316215515\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1112 loss: 0.3612530827522278\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1113 loss: 0.263448029756546\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1114 loss: 0.31771305203437805\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1115 loss: 0.32293394207954407\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1116 loss: 0.6522907614707947\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1117 loss: 0.3204236924648285\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1118 loss: 0.5664333701133728\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1119 loss: 0.34885209798812866\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1120 loss: 0.5357381105422974\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1121 loss: 0.26831889152526855\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1122 loss: 0.48065242171287537\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1123 loss: 0.2838204503059387\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1124 loss: 0.17026366293430328\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1125 loss: 0.2875825762748718\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1126 loss: 0.3108792006969452\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1127 loss: 0.3692605495452881\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1128 loss: 0.25133559107780457\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1129 loss: 0.35001620650291443\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1130 loss: 0.25091493129730225\n",
      "class 0: acc 0.9375, precision 0.9200, recall 1.0000, f1 0.9583\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8750, f1 0.9333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1131 loss: 0.3035462200641632\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1132 loss: 0.4298509359359741\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1133 loss: 0.3114398717880249\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1134 loss: 0.3237902522087097\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1135 loss: 0.39736929535865784\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1136 loss: 0.30923086404800415\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1137 loss: 0.25002551078796387\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1138 loss: 0.2353634536266327\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1139 loss: 0.3067215383052826\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1140 loss: 0.32640254497528076\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1141 loss: 0.3435150682926178\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1142 loss: 0.41073551774024963\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1143 loss: 0.36442694067955017\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 1144 loss: 0.4757396876811981\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1145 loss: 0.15442226827144623\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1146 loss: 0.4169117212295532\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1147 loss: 0.6192180514335632\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1148 loss: 0.15269604325294495\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1149 loss: 0.3296218812465668\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1150 loss: 0.33860138058662415\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1151 loss: 0.37395426630973816\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1152 loss: 0.2753952443599701\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1153 loss: 0.1289520561695099\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1154 loss: 0.4657190442085266\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1155 loss: 0.21781043708324432\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1156 loss: 0.1856294572353363\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1157 loss: 0.3898566961288452\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1158 loss: 0.3403257131576538\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1159 loss: 0.31127238273620605\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1160 loss: 0.3280465006828308\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1161 loss: 0.40330031514167786\n",
      "class 0: acc 0.7812, precision 0.8462, recall 0.8800, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1162 loss: 0.4155692458152771\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1163 loss: 0.38574114441871643\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1164 loss: 0.15980826318264008\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1165 loss: 0.34282341599464417\n",
      "class 0: acc 0.8438, precision 0.9000, recall 0.9310, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1166 loss: 0.30740055441856384\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1167 loss: 0.21786190569400787\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1168 loss: 0.2422439306974411\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1169 loss: 0.3688630163669586\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1170 loss: 0.5533630847930908\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1171 loss: 0.42280644178390503\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1172 loss: 0.31934577226638794\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1173 loss: 0.35809391736984253\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1174 loss: 0.4630231559276581\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1175 loss: 0.41540956497192383\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1176 loss: 0.28935813903808594\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1177 loss: 0.4554801881313324\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1178 loss: 0.3815702199935913\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1179 loss: 0.3851642906665802\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1180 loss: 0.3005501627922058\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1181 loss: 0.1345890462398529\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 4 step: 1182 loss: 0.3601682782173157\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1183 loss: 0.3245452642440796\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1184 loss: 0.33365029096603394\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1185 loss: 0.4237571954727173\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1186 loss: 0.42994657158851624\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1187 loss: 0.21993102133274078\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1188 loss: 0.4515058696269989\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1189 loss: 0.4438595175743103\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1190 loss: 0.36560797691345215\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1191 loss: 0.4048985540866852\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1192 loss: 0.4473506212234497\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1193 loss: 0.6247173547744751\n",
      "class 0: acc 0.7812, precision 0.8519, recall 0.8846, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.2000, recall 0.3333, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1194 loss: 0.23581872880458832\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1195 loss: 0.19574704766273499\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1196 loss: 0.13546964526176453\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1197 loss: 0.3257441222667694\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1198 loss: 0.35526415705680847\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1199 loss: 0.24030637741088867\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1200 loss: 0.3242741525173187\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1201 loss: 0.49522262811660767\n",
      "class 0: acc 0.7812, precision 0.8065, recall 0.9615, f1 0.8772\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1202 loss: 0.2903304100036621\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1203 loss: 0.4811645448207855\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1204 loss: 0.2608804404735565\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1205 loss: 0.5816954970359802\n",
      "class 0: acc 0.7500, precision 0.8000, recall 0.9231, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1206 loss: 0.39620277285575867\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1207 loss: 0.29593825340270996\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1208 loss: 0.25772595405578613\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1209 loss: 0.32373180985450745\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1210 loss: 0.4060087203979492\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1211 loss: 0.6611195802688599\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1212 loss: 0.5295107364654541\n",
      "class 0: acc 0.6875, precision 0.7500, recall 0.8750, f1 0.8077\n",
      "class 1: acc 0.7500, precision 0.2500, recall 0.1667, f1 0.2000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1213 loss: 0.2936767339706421\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1214 loss: 0.2409154772758484\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1215 loss: 0.2727828919887543\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1216 loss: 0.3435448408126831\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1217 loss: 0.37189313769340515\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1218 loss: 0.5231905579566956\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1219 loss: 0.36011803150177\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1220 loss: 0.4893942177295685\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1221 loss: 0.41692784428596497\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1222 loss: 0.34205082058906555\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1223 loss: 0.22042015194892883\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1224 loss: 0.442696750164032\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 4 step: 1225 loss: 0.33896294236183167\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1226 loss: 0.3234837055206299\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1227 loss: 0.22679199278354645\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1228 loss: 0.356380820274353\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1229 loss: 0.23365572094917297\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1230 loss: 0.730670154094696\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "epoch: 4 step: 1231 loss: 0.4025477170944214\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 4 step: 1232 loss: 0.33636921644210815\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 4 step: 1233 loss: 0.5563833117485046\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1234 loss: 0.35268551111221313\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1235 loss: 0.5009300708770752\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1236 loss: 0.424593448638916\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1237 loss: 0.18806268274784088\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1238 loss: 0.32473576068878174\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1239 loss: 0.16280728578567505\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1240 loss: 0.1723562628030777\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1241 loss: 0.5283852219581604\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1242 loss: 0.24384362995624542\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1243 loss: 0.3455590307712555\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1244 loss: 0.24278026819229126\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1245 loss: 0.34312543272972107\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1246 loss: 0.24747832119464874\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1247 loss: 0.25451281666755676\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1248 loss: 0.24698998034000397\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1249 loss: 0.31644341349601746\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 4 step: 1250 loss: 0.34074217081069946\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1 loss: 0.3100632429122925\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 2 loss: 0.2079322338104248\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 3 loss: 0.38952410221099854\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 4 loss: 0.5867210030555725\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 5 loss: 0.2902984917163849\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 6 loss: 0.3833393156528473\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 7 loss: 0.15841761231422424\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 8 loss: 0.2751961648464203\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 9 loss: 0.6302891373634338\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 10 loss: 0.4408482611179352\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 11 loss: 0.20054839551448822\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 12 loss: 0.39863985776901245\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 13 loss: 0.3564034104347229\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 14 loss: 0.4513466954231262\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 15 loss: 0.5133175253868103\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 16 loss: 0.36706939339637756\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 17 loss: 0.37011662125587463\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 18 loss: 0.25994253158569336\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 19 loss: 0.37168827652931213\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 20 loss: 0.30456942319869995\n",
      "class 0: acc 0.9375, precision 0.9200, recall 1.0000, f1 0.9583\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 5 step: 21 loss: 0.28469184041023254\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 22 loss: 0.24151679873466492\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 23 loss: 0.0649038553237915\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 24 loss: 0.36287572979927063\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 25 loss: 0.336105614900589\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 26 loss: 0.7021531462669373\n",
      "class 0: acc 0.7812, precision 0.7407, recall 1.0000, f1 0.8511\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 27 loss: 0.45501118898391724\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 28 loss: 0.26958686113357544\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 29 loss: 0.6477308869361877\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 30 loss: 0.6620232462882996\n",
      "class 0: acc 0.7500, precision 0.7692, recall 0.9091, f1 0.8333\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 31 loss: 0.4129757285118103\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 32 loss: 0.33790960907936096\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 33 loss: 0.20391800999641418\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 34 loss: 0.3001648187637329\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 0.9375, precision 0.8750, recall 0.8750, f1 0.8750\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 35 loss: 0.4754613935947418\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 36 loss: 0.3156072497367859\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 37 loss: 0.4798533022403717\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 38 loss: 0.40843871235847473\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 39 loss: 0.12123727798461914\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 40 loss: 0.3712369203567505\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 41 loss: 0.23300206661224365\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 42 loss: 0.6678817272186279\n",
      "class 0: acc 0.7500, precision 0.7667, recall 0.9583, f1 0.8519\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.1429, f1 0.2222\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 43 loss: 0.31801795959472656\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 44 loss: 0.2972823977470398\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 45 loss: 0.3057768642902374\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 46 loss: 0.20267565548419952\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 47 loss: 0.49691253900527954\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 48 loss: 0.4727106988430023\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 49 loss: 0.46897271275520325\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 50 loss: 0.3102659583091736\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 51 loss: 0.15664918720722198\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 52 loss: 0.5455058813095093\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 53 loss: 0.267711341381073\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 54 loss: 0.4770047664642334\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 55 loss: 0.5039465427398682\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 56 loss: 0.31517690420150757\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 57 loss: 0.22140854597091675\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 58 loss: 0.552675187587738\n",
      "class 0: acc 0.8125, precision 0.9259, recall 0.8621, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.2000, recall 1.0000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 59 loss: 0.6524218916893005\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 60 loss: 0.4448007345199585\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 61 loss: 0.40818703174591064\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 62 loss: 0.3294000029563904\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 63 loss: 0.38617220520973206\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 64 loss: 0.41406556963920593\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 65 loss: 0.37613213062286377\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 66 loss: 0.5086371302604675\n",
      "class 0: acc 0.7500, precision 0.7667, recall 0.9583, f1 0.8519\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 67 loss: 0.17154885828495026\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 68 loss: 0.4734335243701935\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 69 loss: 0.557536780834198\n",
      "class 0: acc 0.7812, precision 0.8065, recall 0.9615, f1 0.8772\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 70 loss: 0.7190721035003662\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 71 loss: 0.47182708978652954\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 72 loss: 0.49664223194122314\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 73 loss: 0.4712187945842743\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 74 loss: 0.4779994785785675\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 75 loss: 0.4084867537021637\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 76 loss: 0.44217315316200256\n",
      "class 0: acc 0.7812, precision 0.8750, recall 0.8400, f1 0.8571\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 77 loss: 0.5125072598457336\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 78 loss: 0.6178495287895203\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 79 loss: 0.2914149761199951\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 80 loss: 0.31550201773643494\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 81 loss: 0.22694315016269684\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 82 loss: 0.1667892336845398\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 83 loss: 0.5136082172393799\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 84 loss: 0.43749943375587463\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 85 loss: 0.46646860241889954\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 86 loss: 0.1842217743396759\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 87 loss: 0.10864078998565674\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 88 loss: 0.21447275578975677\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 89 loss: 0.5639920830726624\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 90 loss: 0.5407041311264038\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 91 loss: 0.34422045946121216\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 92 loss: 0.2731676399707794\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 93 loss: 0.46805790066719055\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 94 loss: 0.26764070987701416\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 95 loss: 0.1896396428346634\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 96 loss: 0.3823305070400238\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 97 loss: 0.5278273820877075\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 98 loss: 0.21030884981155396\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 99 loss: 0.3239821195602417\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 100 loss: 0.20032325387001038\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 101 loss: 0.4104245603084564\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 102 loss: 0.6217532157897949\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 103 loss: 0.2999774217605591\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 104 loss: 0.3975093960762024\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 105 loss: 0.22962811589241028\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 106 loss: 0.20716562867164612\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 107 loss: 0.4219121038913727\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 108 loss: 0.22261486947536469\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 109 loss: 0.2594912350177765\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 110 loss: 0.3459230959415436\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 111 loss: 0.4774170219898224\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 112 loss: 0.1909971982240677\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 113 loss: 0.3223400115966797\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 114 loss: 0.5644926428794861\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 115 loss: 0.5011375546455383\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 116 loss: 0.163551926612854\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 117 loss: 0.23080824315547943\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 118 loss: 0.3959828019142151\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 119 loss: 0.34998735785484314\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 120 loss: 0.393714964389801\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 121 loss: 0.5090522766113281\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 122 loss: 0.408793181180954\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 123 loss: 0.28013285994529724\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 124 loss: 0.3820609748363495\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 125 loss: 0.2543618083000183\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 126 loss: 0.15903839468955994\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 127 loss: 0.5986286997795105\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 128 loss: 0.7158619165420532\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 129 loss: 0.4006478786468506\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 130 loss: 0.3892659842967987\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 131 loss: 0.5079174637794495\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 132 loss: 0.45355939865112305\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 133 loss: 0.1890501081943512\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9286, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 134 loss: 0.3481783866882324\n",
      "class 0: acc 0.8750, precision 0.9333, recall 0.9333, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 135 loss: 0.5349527597427368\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 136 loss: 0.3899974524974823\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 137 loss: 0.38453856110572815\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 138 loss: 0.4053177237510681\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 139 loss: 0.40941745042800903\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 140 loss: 0.13472922146320343\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 141 loss: 0.31212911009788513\n",
      "class 0: acc 0.8750, precision 0.9583, recall 0.8846, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 142 loss: 0.4769883453845978\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 143 loss: 0.5861208438873291\n",
      "class 0: acc 0.7500, precision 0.7241, recall 1.0000, f1 0.8400\n",
      "class 1: acc 0.7812, precision 0.6667, recall 0.2500, f1 0.3636\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 144 loss: 0.2933228611946106\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 145 loss: 0.33894824981689453\n",
      "class 0: acc 0.8438, precision 0.9286, recall 0.8966, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 146 loss: 0.21928589046001434\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 147 loss: 0.2837511897087097\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 148 loss: 0.43887725472450256\n",
      "class 0: acc 0.7812, precision 0.7812, recall 1.0000, f1 0.8772\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 149 loss: 0.12702696025371552\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 150 loss: 0.4060229957103729\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 151 loss: 0.3983553647994995\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 152 loss: 0.3124743103981018\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 153 loss: 0.3551819920539856\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 154 loss: 0.32566216588020325\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 155 loss: 0.2894994020462036\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 156 loss: 0.35792219638824463\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 157 loss: 0.35153141617774963\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 158 loss: 0.4082145690917969\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 159 loss: 0.1778818666934967\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 160 loss: 0.4748959243297577\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 161 loss: 0.07830936461687088\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 162 loss: 0.4616449475288391\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 163 loss: 0.18687906861305237\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 164 loss: 0.6447991132736206\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.7812, precision 0.3333, recall 0.4000, f1 0.3636\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 165 loss: 0.4717048406600952\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8125, precision 0.8000, recall 0.4444, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 166 loss: 0.12167946249246597\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 167 loss: 0.30218228697776794\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 168 loss: 0.25821754336357117\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 169 loss: 0.3091595470905304\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 170 loss: 0.3741280138492584\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 171 loss: 0.33719488978385925\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 172 loss: 0.2201392948627472\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 173 loss: 0.21800249814987183\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 174 loss: 0.32203778624534607\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 175 loss: 0.37383443117141724\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 176 loss: 0.3307712972164154\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 177 loss: 0.6040804982185364\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 178 loss: 0.4862023591995239\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 179 loss: 0.3235529661178589\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 180 loss: 0.21609823405742645\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 181 loss: 0.1805238425731659\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 182 loss: 0.15438717603683472\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 183 loss: 0.616401731967926\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 184 loss: 0.596680760383606\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 185 loss: 0.5082411170005798\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 186 loss: 0.3281957507133484\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 187 loss: 0.6265073418617249\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 188 loss: 0.5665509104728699\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 189 loss: 0.39870643615722656\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 190 loss: 0.43336036801338196\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 191 loss: 0.36070793867111206\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 192 loss: 0.24371573328971863\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 193 loss: 0.2607460916042328\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 194 loss: 0.5394889116287231\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 195 loss: 0.3579801619052887\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 196 loss: 0.31018081307411194\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 197 loss: 0.4215717017650604\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 198 loss: 0.2726527154445648\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 199 loss: 0.3820273280143738\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 200 loss: 0.17665591835975647\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 201 loss: 0.5589504837989807\n",
      "class 0: acc 0.7500, precision 0.7778, recall 0.9130, f1 0.8400\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 202 loss: 0.16838720440864563\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 203 loss: 0.2656823396682739\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 204 loss: 0.3550533950328827\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 205 loss: 0.41528335213661194\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 206 loss: 0.2710382044315338\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 207 loss: 0.260033518075943\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 208 loss: 0.49998602271080017\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 209 loss: 0.4024087190628052\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 210 loss: 0.25368767976760864\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 211 loss: 0.19519448280334473\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 212 loss: 0.26877474784851074\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 213 loss: 0.24357563257217407\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 214 loss: 0.2870052456855774\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 215 loss: 0.7123706936836243\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.2857, f1 0.3636\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 5 step: 216 loss: 0.2955878674983978\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 217 loss: 0.2823602259159088\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 218 loss: 0.33494848012924194\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 5 step: 219 loss: 0.18028415739536285\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9231, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 220 loss: 0.4591207802295685\n",
      "class 0: acc 0.8438, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.7000, f1 0.8235\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 221 loss: 0.3308100700378418\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 222 loss: 0.34719642996788025\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 223 loss: 0.4579419493675232\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 224 loss: 0.3104281723499298\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 225 loss: 0.39049872756004333\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 5 step: 226 loss: 0.2807672917842865\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 5 step: 227 loss: 0.41432204842567444\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 228 loss: 0.16987395286560059\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 229 loss: 0.22144199907779694\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 230 loss: 0.406869500875473\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 231 loss: 0.2636125087738037\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 232 loss: 0.32223036885261536\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 233 loss: 0.1987190544605255\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 234 loss: 0.22777196764945984\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 5 step: 235 loss: 0.43632200360298157\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 236 loss: 0.487072616815567\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 237 loss: 0.24476559460163116\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 238 loss: 0.17121990025043488\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 239 loss: 0.3247795104980469\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 5 step: 240 loss: 0.27771708369255066\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 241 loss: 0.5342745184898376\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 242 loss: 0.39598652720451355\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 243 loss: 0.3026399314403534\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 244 loss: 0.3167990446090698\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 245 loss: 0.1405576765537262\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 246 loss: 0.32313060760498047\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 247 loss: 0.41431543231010437\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 248 loss: 0.2943664491176605\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9286, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 249 loss: 0.4514063894748688\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 250 loss: 0.45295095443725586\n",
      "class 0: acc 0.8438, precision 0.8400, recall 0.9545, f1 0.8936\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 251 loss: 0.44236353039741516\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 252 loss: 0.309294730424881\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 253 loss: 0.3754281997680664\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 254 loss: 0.47330304980278015\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 255 loss: 0.31195178627967834\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 256 loss: 0.5167927145957947\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 257 loss: 0.48772338032722473\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 258 loss: 0.26267898082733154\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 259 loss: 0.4481065273284912\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 260 loss: 0.356899231672287\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 261 loss: 0.16318564116954803\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 262 loss: 0.15340381860733032\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 5 step: 263 loss: 0.30549848079681396\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 264 loss: 0.27120742201805115\n",
      "class 0: acc 0.9688, precision 0.9600, recall 1.0000, f1 0.9796\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 5 step: 265 loss: 0.5769175291061401\n",
      "class 0: acc 0.7188, precision 0.8148, recall 0.8462, f1 0.8302\n",
      "class 1: acc 0.7812, precision 0.2500, recall 0.2000, f1 0.2222\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 266 loss: 0.3079415559768677\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 267 loss: 0.32157567143440247\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 268 loss: 0.28071293234825134\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 269 loss: 0.4762286841869354\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 5 step: 270 loss: 0.2055101990699768\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 271 loss: 0.3041357100009918\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 272 loss: 0.3711472153663635\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 273 loss: 0.6223238706588745\n",
      "class 0: acc 0.7500, precision 0.7586, recall 0.9565, f1 0.8462\n",
      "class 1: acc 0.7812, precision 0.3333, recall 0.1667, f1 0.2222\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 274 loss: 0.19321279227733612\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 275 loss: 0.3212309181690216\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 276 loss: 0.5253707766532898\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 277 loss: 0.12162262946367264\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 278 loss: 0.5766267776489258\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 279 loss: 0.21409286558628082\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 280 loss: 0.1798352599143982\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 5 step: 281 loss: 0.15821069478988647\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 282 loss: 0.3708522319793701\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 283 loss: 0.5285220742225647\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 284 loss: 0.188805490732193\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 285 loss: 0.4191688299179077\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 286 loss: 0.2352699637413025\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 287 loss: 0.2896413505077362\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 288 loss: 0.3044978082180023\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 289 loss: 0.6384942531585693\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 290 loss: 0.16075138747692108\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 291 loss: 0.4335741400718689\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 292 loss: 0.308694452047348\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 293 loss: 0.3781292140483856\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 294 loss: 0.48232054710388184\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 295 loss: 0.2713913321495056\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 296 loss: 0.27140918374061584\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 297 loss: 0.3065984547138214\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 298 loss: 0.649398684501648\n",
      "class 0: acc 0.7188, precision 0.6923, recall 0.9474, f1 0.8000\n",
      "class 1: acc 0.7812, precision 0.8333, recall 0.4545, f1 0.5882\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 299 loss: 0.5990259051322937\n",
      "class 0: acc 0.7500, precision 0.7586, recall 0.9565, f1 0.8462\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 300 loss: 0.4355309307575226\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 301 loss: 0.26670217514038086\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 302 loss: 0.25700265169143677\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 303 loss: 0.3838048279285431\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 304 loss: 0.5871039032936096\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8125, precision 0.2500, recall 0.2500, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 305 loss: 0.5292311310768127\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 306 loss: 0.3198615610599518\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 307 loss: 0.38624683022499084\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 308 loss: 0.48718559741973877\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 309 loss: 0.29205960035324097\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 310 loss: 0.3457704186439514\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 311 loss: 0.5259078741073608\n",
      "class 0: acc 0.7812, precision 0.7308, recall 1.0000, f1 0.8444\n",
      "class 1: acc 0.7812, precision 1.0000, recall 0.4615, f1 0.6316\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 312 loss: 0.3914288282394409\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 313 loss: 0.37870126962661743\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 314 loss: 0.34131768345832825\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 315 loss: 0.4297609031200409\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 316 loss: 0.36288192868232727\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 317 loss: 0.3814285397529602\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 318 loss: 0.22805267572402954\n",
      "class 0: acc 0.9062, precision 0.9583, recall 0.9200, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.8571, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 319 loss: 0.4768086373806\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 320 loss: 0.5010110139846802\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 321 loss: 0.3153558671474457\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 322 loss: 0.10520511120557785\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 323 loss: 0.6318603157997131\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 324 loss: 0.2382378727197647\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 325 loss: 0.27615925669670105\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 326 loss: 0.4815889000892639\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 327 loss: 0.32222414016723633\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 328 loss: 0.11860182881355286\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 329 loss: 0.06432228535413742\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 330 loss: 0.1828891932964325\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 331 loss: 0.5821555852890015\n",
      "class 0: acc 0.8438, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7778, f1 0.8750\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 332 loss: 0.2938621938228607\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 333 loss: 0.4234071373939514\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 334 loss: 0.5197415947914124\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 335 loss: 0.16376952826976776\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 336 loss: 0.26958683133125305\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 337 loss: 0.15760648250579834\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 338 loss: 0.4585478603839874\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 339 loss: 0.17349795997142792\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 340 loss: 0.3889811038970947\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 341 loss: 0.22847138345241547\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 342 loss: 0.09814128279685974\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 343 loss: 0.21821562945842743\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 344 loss: 0.31987327337265015\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 345 loss: 0.37773144245147705\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 346 loss: 0.4179036617279053\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 347 loss: 0.24869781732559204\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 348 loss: 0.473367840051651\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 349 loss: 0.12211889773607254\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 350 loss: 0.5797366499900818\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 351 loss: 0.23435252904891968\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 352 loss: 0.303988516330719\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 353 loss: 0.3416372537612915\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 354 loss: 0.5817717909812927\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 355 loss: 0.5056598782539368\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 356 loss: 0.6837349534034729\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 357 loss: 0.31992197036743164\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 358 loss: 0.3009720742702484\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 359 loss: 0.2691457271575928\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 360 loss: 0.393198162317276\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 361 loss: 0.2680302560329437\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 5 step: 362 loss: 0.4547009766101837\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 363 loss: 0.19016174972057343\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 364 loss: 0.26848626136779785\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 365 loss: 0.8073161244392395\n",
      "class 0: acc 0.7500, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 366 loss: 0.5522369146347046\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 367 loss: 0.526691734790802\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 368 loss: 0.3944946825504303\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 369 loss: 0.28793832659721375\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 370 loss: 0.4248031973838806\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 371 loss: 0.12292040139436722\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 372 loss: 0.4606448709964752\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 373 loss: 0.33059462904930115\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 374 loss: 0.2699972689151764\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 375 loss: 0.3461475074291229\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 376 loss: 0.32699599862098694\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 377 loss: 0.32052743434906006\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 378 loss: 0.44963088631629944\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 379 loss: 0.2729681134223938\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 380 loss: 0.33939334750175476\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 381 loss: 0.26526740193367004\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 382 loss: 0.6892102956771851\n",
      "class 0: acc 0.7188, precision 0.7000, recall 1.0000, f1 0.8235\n",
      "class 1: acc 0.7812, precision 1.0000, recall 0.2222, f1 0.3636\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 383 loss: 0.4600909650325775\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 384 loss: 0.21545109152793884\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 385 loss: 0.23768523335456848\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 386 loss: 0.37128567695617676\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 387 loss: 0.27336567640304565\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 388 loss: 0.3990248143672943\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 389 loss: 0.37746554613113403\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 390 loss: 0.4047294557094574\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 391 loss: 0.21251578629016876\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 392 loss: 0.18167895078659058\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 393 loss: 0.38041314482688904\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 394 loss: 0.39730507135391235\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 395 loss: 0.28660139441490173\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 396 loss: 0.436347633600235\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 397 loss: 0.19716061651706696\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9286, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 398 loss: 0.21440470218658447\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 5 step: 399 loss: 0.310825377702713\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 400 loss: 0.5308191180229187\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 401 loss: 0.41497641801834106\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 402 loss: 0.13908931612968445\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 403 loss: 0.38125020265579224\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 404 loss: 0.42618152499198914\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 405 loss: 0.4671482741832733\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 406 loss: 0.2834376394748688\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 407 loss: 0.45408904552459717\n",
      "class 0: acc 0.8125, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 408 loss: 0.2595149874687195\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 5 step: 409 loss: 0.25482356548309326\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 410 loss: 0.21570758521556854\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 411 loss: 0.2526920735836029\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 412 loss: 0.27466535568237305\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 413 loss: 0.4628508687019348\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8125, precision 0.8000, recall 0.4444, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 414 loss: 0.2880937159061432\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 415 loss: 0.35469621419906616\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 416 loss: 0.32700079679489136\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 417 loss: 0.351464182138443\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 418 loss: 0.6153361797332764\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8125, precision 0.2000, recall 0.3333, f1 0.2500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 419 loss: 0.3745235204696655\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 420 loss: 0.45446309447288513\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 421 loss: 0.41534286737442017\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 422 loss: 0.21412606537342072\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 5 step: 423 loss: 0.32025569677352905\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 424 loss: 0.2468615174293518\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 425 loss: 0.25294721126556396\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 426 loss: 0.531416118144989\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 427 loss: 0.12169299274682999\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 428 loss: 0.23594984412193298\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 429 loss: 0.44271746277809143\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 430 loss: 0.5051171183586121\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 431 loss: 0.36573201417922974\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 432 loss: 0.28989937901496887\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 433 loss: 0.5640714764595032\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 434 loss: 0.3821709454059601\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 435 loss: 0.3341748118400574\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 436 loss: 0.21683037281036377\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 437 loss: 0.3135060667991638\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 438 loss: 0.4744967520236969\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 439 loss: 0.524448812007904\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 440 loss: 0.4286141097545624\n",
      "class 0: acc 0.8438, precision 0.9600, recall 0.8571, f1 0.9057\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8125, precision 0.2000, recall 0.3333, f1 0.2500\n",
      "epoch: 5 step: 441 loss: 0.40294378995895386\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 5 step: 442 loss: 0.600685179233551\n",
      "class 0: acc 0.7500, precision 0.8462, recall 0.8462, f1 0.8462\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 443 loss: 0.47383469343185425\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 5 step: 444 loss: 0.6087850332260132\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 445 loss: 0.4312629997730255\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 5 step: 446 loss: 0.3391972780227661\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 447 loss: 0.40765446424484253\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 5 step: 448 loss: 0.47185975313186646\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 449 loss: 0.5407218337059021\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 450 loss: 0.4332256615161896\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 451 loss: 0.2609196603298187\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 452 loss: 0.20299147069454193\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 453 loss: 0.42062652111053467\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 454 loss: 0.46772289276123047\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 455 loss: 0.26003023982048035\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 456 loss: 0.20640848577022552\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 457 loss: 0.22574040293693542\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 458 loss: 0.27383866906166077\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 459 loss: 0.3234387934207916\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 460 loss: 0.4533509612083435\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 461 loss: 0.5100895166397095\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 462 loss: 0.7140969038009644\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 463 loss: 0.42731180787086487\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 464 loss: 0.2414150983095169\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 465 loss: 0.5520515441894531\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 466 loss: 0.545465350151062\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 467 loss: 0.3181476294994354\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 468 loss: 0.2384042888879776\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 469 loss: 0.21669495105743408\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 470 loss: 0.44564327597618103\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 471 loss: 0.2182570993900299\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 472 loss: 0.4294499456882477\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 473 loss: 0.4312906265258789\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 474 loss: 0.2890743017196655\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 475 loss: 0.4301072955131531\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 476 loss: 0.3655959963798523\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 477 loss: 0.34026724100112915\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 478 loss: 0.3398827910423279\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 479 loss: 0.16535024344921112\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 480 loss: 0.48563462495803833\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 481 loss: 0.3118857443332672\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 482 loss: 0.26579707860946655\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 483 loss: 0.29578492045402527\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 484 loss: 0.2026636302471161\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 485 loss: 0.4653514325618744\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 486 loss: 0.2971995770931244\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 487 loss: 0.2844175100326538\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7778, f1 0.8750\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 488 loss: 0.4203600585460663\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 489 loss: 0.5995745658874512\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 490 loss: 0.5219286680221558\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 491 loss: 0.29392358660697937\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 492 loss: 0.469844788312912\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 493 loss: 0.26374492049217224\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9286, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 494 loss: 0.47335195541381836\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 495 loss: 0.27497532963752747\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 496 loss: 0.3979383111000061\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 497 loss: 0.2945106327533722\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 498 loss: 0.27704912424087524\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 499 loss: 0.5339846611022949\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 500 loss: 0.3556680679321289\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 501 loss: 0.7635096311569214\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8125, precision 0.6000, recall 0.4286, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 502 loss: 0.20031584799289703\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 503 loss: 0.29003721475601196\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 504 loss: 0.26226159930229187\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 505 loss: 0.31310510635375977\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 506 loss: 0.2527938187122345\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 507 loss: 0.2422010600566864\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 508 loss: 0.14810749888420105\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 509 loss: 0.6031299233436584\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 510 loss: 0.17673106491565704\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 511 loss: 0.31453827023506165\n",
      "class 0: acc 0.8438, precision 0.9231, recall 0.8889, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 512 loss: 0.18175408244132996\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 513 loss: 0.4445079267024994\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 514 loss: 0.27050700783729553\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 515 loss: 0.4948454797267914\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 516 loss: 0.3075371980667114\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 517 loss: 0.21313366293907166\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 518 loss: 0.22251002490520477\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 519 loss: 0.3987942934036255\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 520 loss: 0.2831243574619293\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 521 loss: 0.31196072697639465\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 522 loss: 0.22726377844810486\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 523 loss: 0.4626407027244568\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 524 loss: 0.2926041781902313\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 525 loss: 0.25899139046669006\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 526 loss: 0.5715042948722839\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 527 loss: 0.3564992845058441\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 528 loss: 0.44691479206085205\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 529 loss: 0.3283716142177582\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 530 loss: 0.5618411898612976\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 531 loss: 0.13838796317577362\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 532 loss: 0.5415247678756714\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 533 loss: 0.3964766561985016\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 534 loss: 0.3949643075466156\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 535 loss: 0.36625945568084717\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 536 loss: 0.3034277856349945\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 537 loss: 0.6027153730392456\n",
      "class 0: acc 0.8125, precision 0.7692, recall 1.0000, f1 0.8696\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 538 loss: 0.42360618710517883\n",
      "class 0: acc 0.7188, precision 0.7241, recall 0.9545, f1 0.8235\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 539 loss: 0.5386064052581787\n",
      "class 0: acc 0.8750, precision 0.9333, recall 0.9333, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 540 loss: 0.24864256381988525\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 541 loss: 0.6365125179290771\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 542 loss: 0.1468517929315567\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 543 loss: 0.2540437877178192\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 544 loss: 0.1513291299343109\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 545 loss: 0.2889939844608307\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 546 loss: 0.4513046443462372\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 547 loss: 0.29767706990242004\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 548 loss: 0.29380661249160767\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 549 loss: 0.1446993350982666\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 550 loss: 0.23919610679149628\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 551 loss: 0.4622859060764313\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 552 loss: 0.4813652038574219\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 553 loss: 0.33124056458473206\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 554 loss: 0.36755818128585815\n",
      "class 0: acc 0.7812, precision 0.7812, recall 1.0000, f1 0.8772\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 555 loss: 0.3648874759674072\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 556 loss: 0.6477914452552795\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 557 loss: 0.6566640734672546\n",
      "class 0: acc 0.7188, precision 0.7188, recall 1.0000, f1 0.8364\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 558 loss: 0.2406848669052124\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 559 loss: 0.41546475887298584\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 560 loss: 0.5420799255371094\n",
      "class 0: acc 0.7812, precision 0.8571, recall 0.8889, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 561 loss: 0.38457807898521423\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 562 loss: 0.44126954674720764\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.4286, recall 0.7500, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 563 loss: 0.34046119451522827\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 564 loss: 0.37689879536628723\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 565 loss: 0.6314225196838379\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8125, precision 0.4286, recall 0.6000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 566 loss: 0.3549322485923767\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 567 loss: 0.40549954771995544\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 568 loss: 0.1648457646369934\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 5 step: 569 loss: 0.22713683545589447\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 570 loss: 0.2573932707309723\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 571 loss: 0.48499375581741333\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 572 loss: 0.30765411257743835\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 573 loss: 0.31805554032325745\n",
      "class 0: acc 0.8438, precision 0.9286, recall 0.8966, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 574 loss: 0.11929626017808914\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 575 loss: 0.31306755542755127\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 576 loss: 0.34501779079437256\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 577 loss: 0.2714506983757019\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 578 loss: 0.4860227406024933\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 579 loss: 0.41449543833732605\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 580 loss: 0.3804575204849243\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 581 loss: 0.33824315667152405\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 582 loss: 0.6752007007598877\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 583 loss: 0.41340839862823486\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 584 loss: 0.33512628078460693\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 585 loss: 0.49778038263320923\n",
      "class 0: acc 0.7812, precision 0.8800, recall 0.8462, f1 0.8627\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 586 loss: 0.33652374148368835\n",
      "class 0: acc 0.9375, precision 0.9200, recall 1.0000, f1 0.9583\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "epoch: 5 step: 587 loss: 0.47392532229423523\n",
      "class 0: acc 0.8438, precision 0.8696, recall 0.9091, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 0.8750, precision 0.2000, recall 1.0000, f1 0.3333\n",
      "epoch: 5 step: 588 loss: 0.44699564576148987\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 589 loss: 0.508668065071106\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 5 step: 590 loss: 0.4167039096355438\n",
      "class 0: acc 0.7812, precision 0.9000, recall 0.7826, f1 0.8372\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.2000, recall 1.0000, f1 0.3333\n",
      "epoch: 5 step: 591 loss: 0.3988754153251648\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 592 loss: 0.4132439196109772\n",
      "class 0: acc 0.9062, precision 0.9130, recall 0.9545, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 593 loss: 0.2973772883415222\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 594 loss: 0.2950025498867035\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 595 loss: 0.2870100438594818\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 596 loss: 0.6243012547492981\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 597 loss: 0.3726540505886078\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 598 loss: 0.12003128230571747\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 599 loss: 0.5339727401733398\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 600 loss: 0.2954055070877075\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 601 loss: 0.28363481163978577\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 602 loss: 0.35994288325309753\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 603 loss: 0.4073945879936218\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 604 loss: 0.4002712368965149\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 605 loss: 0.27807918190956116\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 606 loss: 0.6001412272453308\n",
      "class 0: acc 0.7500, precision 0.7407, recall 0.9524, f1 0.8333\n",
      "class 1: acc 0.7812, precision 0.6000, recall 0.3750, f1 0.4615\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 607 loss: 0.4358930289745331\n",
      "class 0: acc 0.7500, precision 0.8000, recall 0.9231, f1 0.8571\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 608 loss: 0.2746565341949463\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 609 loss: 0.3493924140930176\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 610 loss: 0.3523316979408264\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 611 loss: 0.2557346522808075\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 612 loss: 0.42869696021080017\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 613 loss: 0.2364143431186676\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 614 loss: 0.22974732518196106\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 615 loss: 0.47383636236190796\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 616 loss: 0.27030882239341736\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 617 loss: 0.21497219800949097\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 618 loss: 0.32237550616264343\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 619 loss: 0.18602804839611053\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 620 loss: 0.28780582547187805\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 621 loss: 0.6093339323997498\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 622 loss: 0.669808566570282\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 623 loss: 0.5273184776306152\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 624 loss: 0.633256196975708\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 625 loss: 0.28687652945518494\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 626 loss: 0.39130374789237976\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 627 loss: 0.4913373291492462\n",
      "class 0: acc 0.7500, precision 0.7407, recall 0.9524, f1 0.8333\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 628 loss: 0.1985185444355011\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 629 loss: 0.4311010539531708\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 630 loss: 0.17820416390895844\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 631 loss: 0.2709019184112549\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 632 loss: 0.20516391098499298\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 633 loss: 0.16317875683307648\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 634 loss: 0.4878334701061249\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 635 loss: 0.5536130666732788\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 636 loss: 0.2538919746875763\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 637 loss: 0.27771684527397156\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 638 loss: 0.2542172372341156\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 639 loss: 0.5989575982093811\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 640 loss: 0.6942598819732666\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.2857, f1 0.3636\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 641 loss: 0.39630427956581116\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 642 loss: 0.2723006308078766\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 643 loss: 0.21779654920101166\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 644 loss: 0.19484907388687134\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 645 loss: 0.3231472074985504\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 646 loss: 0.3013884127140045\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 647 loss: 0.189954474568367\n",
      "class 0: acc 0.9688, precision 0.9600, recall 1.0000, f1 0.9796\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 648 loss: 0.22052687406539917\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 649 loss: 0.3218560516834259\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 650 loss: 0.3474412262439728\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 651 loss: 0.5649200081825256\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 652 loss: 0.20256257057189941\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 653 loss: 0.35860711336135864\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 654 loss: 0.21507877111434937\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 655 loss: 0.5703654885292053\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 656 loss: 0.3017770051956177\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 657 loss: 0.0976632609963417\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 658 loss: 0.29808175563812256\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 659 loss: 0.28830501437187195\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 660 loss: 0.64009690284729\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 661 loss: 0.2670614421367645\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 5 step: 662 loss: 0.31029409170150757\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 663 loss: 0.25361883640289307\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 664 loss: 0.48500555753707886\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 665 loss: 0.3991588056087494\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 666 loss: 0.42769861221313477\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 667 loss: 0.2868262827396393\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 668 loss: 0.4429677724838257\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.7500, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 669 loss: 0.5451521277427673\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 670 loss: 0.32859811186790466\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 671 loss: 0.16334211826324463\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 672 loss: 0.23876605927944183\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.9000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 673 loss: 0.4082166850566864\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 674 loss: 0.27691492438316345\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 675 loss: 0.2600520849227905\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 676 loss: 0.1909932941198349\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 677 loss: 0.1598016321659088\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 678 loss: 0.34257715940475464\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 679 loss: 0.2835460305213928\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 680 loss: 0.3903977572917938\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 681 loss: 0.597449779510498\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 682 loss: 0.1467810720205307\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 683 loss: 0.4332442283630371\n",
      "class 0: acc 0.7500, precision 0.7931, recall 0.9200, f1 0.8519\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 684 loss: 0.5258463621139526\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 685 loss: 0.330911248922348\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 686 loss: 0.18457722663879395\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 687 loss: 0.3350362777709961\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 5 step: 688 loss: 0.8321807980537415\n",
      "class 0: acc 0.6875, precision 0.6897, recall 0.9524, f1 0.8000\n",
      "class 1: acc 0.7500, precision 0.6667, recall 0.2222, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 689 loss: 0.2337939292192459\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 690 loss: 0.2139694094657898\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 691 loss: 0.21898725628852844\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 692 loss: 0.2654668688774109\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 693 loss: 0.37035977840423584\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 694 loss: 0.3710102140903473\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 695 loss: 0.2884311378002167\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 696 loss: 0.3738562762737274\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 697 loss: 0.2884247601032257\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 698 loss: 0.25236061215400696\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 699 loss: 0.3642923831939697\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 700 loss: 0.5837408900260925\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 701 loss: 0.5258931517601013\n",
      "class 0: acc 0.8125, precision 0.9231, recall 0.8571, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 702 loss: 0.26781097054481506\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 703 loss: 0.522610604763031\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 704 loss: 0.23608669638633728\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 705 loss: 0.1740393340587616\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 706 loss: 0.13936366140842438\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9688, f1 0.9841\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 707 loss: 0.31584906578063965\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 708 loss: 0.5079062581062317\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 709 loss: 0.39540359377861023\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 710 loss: 0.1783318817615509\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 711 loss: 0.25032293796539307\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 712 loss: 0.43233418464660645\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 713 loss: 0.30651116371154785\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 714 loss: 0.4176809787750244\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 715 loss: 0.32122117280960083\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 716 loss: 0.13230668008327484\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 717 loss: 0.45900917053222656\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 718 loss: 0.3723929524421692\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 719 loss: 0.3096785843372345\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 720 loss: 0.3571588397026062\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 721 loss: 0.4670120179653168\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 722 loss: 0.18215970695018768\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9286, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 723 loss: 0.33195823431015015\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 724 loss: 0.20105256140232086\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 725 loss: 0.23500531911849976\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 726 loss: 0.29302188754081726\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 727 loss: 0.13935688138008118\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 728 loss: 0.607011079788208\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 729 loss: 0.2511749863624573\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 730 loss: 0.2755672037601471\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 731 loss: 0.19493962824344635\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 732 loss: 0.16791284084320068\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 733 loss: 0.17540502548217773\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 734 loss: 0.43587401509284973\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 735 loss: 0.18080884218215942\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 736 loss: 0.21963952481746674\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 737 loss: 0.4158928096294403\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 738 loss: 0.4614749848842621\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 739 loss: 0.4626520276069641\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 740 loss: 0.2741486430168152\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 741 loss: 0.26012545824050903\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 742 loss: 0.2289191484451294\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 743 loss: 0.35058191418647766\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 744 loss: 0.2738751173019409\n",
      "class 0: acc 0.8750, precision 0.9630, recall 0.8966, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 745 loss: 0.2757926285266876\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 746 loss: 0.2047182023525238\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 747 loss: 0.31236982345581055\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 748 loss: 0.3313969373703003\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 749 loss: 0.42914748191833496\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 750 loss: 0.5672742128372192\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 751 loss: 0.4309402108192444\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 752 loss: 0.20687668025493622\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 753 loss: 0.4789501130580902\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 754 loss: 0.5758468508720398\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.5714, recall 0.6667, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 755 loss: 0.27279430627822876\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 756 loss: 0.18383939564228058\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 757 loss: 0.3088003993034363\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 758 loss: 0.4159850776195526\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 759 loss: 0.19721582531929016\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 760 loss: 0.3493194282054901\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 761 loss: 0.2848183512687683\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 762 loss: 0.5076020359992981\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 763 loss: 0.5200121998786926\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 764 loss: 0.3800966441631317\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 765 loss: 0.36025434732437134\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 766 loss: 0.5050081014633179\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 767 loss: 0.33406341075897217\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 768 loss: 0.3234817385673523\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 769 loss: 0.37645918130874634\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 770 loss: 0.37647297978401184\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 771 loss: 0.28511491417884827\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 772 loss: 0.4294865131378174\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 773 loss: 0.5355194807052612\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 774 loss: 0.30852845311164856\n",
      "class 0: acc 0.8750, precision 0.9333, recall 0.9333, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 775 loss: 0.4367281496524811\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 776 loss: 0.31971800327301025\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 777 loss: 0.33350226283073425\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 778 loss: 0.3896586000919342\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 779 loss: 0.3325635492801666\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 780 loss: 0.4303509593009949\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 781 loss: 0.5123841166496277\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 782 loss: 0.5778738856315613\n",
      "class 0: acc 0.7812, precision 0.8519, recall 0.8846, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 783 loss: 0.3746424615383148\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 784 loss: 0.3486788272857666\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 785 loss: 0.3738860785961151\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 786 loss: 0.21213364601135254\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 787 loss: 0.2867894172668457\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 788 loss: 0.4690341055393219\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 789 loss: 0.3051450550556183\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 790 loss: 0.4971647262573242\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 791 loss: 0.4095146358013153\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 792 loss: 0.4570807218551636\n",
      "class 0: acc 0.7812, precision 0.7407, recall 1.0000, f1 0.8511\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 793 loss: 0.2766991853713989\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 794 loss: 0.47472110390663147\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 795 loss: 0.3498886823654175\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 796 loss: 0.30662572383880615\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 797 loss: 0.24909819662570953\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 798 loss: 0.18401679396629333\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 799 loss: 0.1758236289024353\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 800 loss: 0.44084614515304565\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 801 loss: 0.34643104672431946\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 802 loss: 0.25299596786499023\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 803 loss: 0.2534383237361908\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 804 loss: 0.6275210976600647\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 805 loss: 0.18381336331367493\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 806 loss: 0.2831271290779114\n",
      "class 0: acc 0.9688, precision 0.9688, recall 1.0000, f1 0.9841\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 807 loss: 0.420915812253952\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 808 loss: 0.4217168390750885\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 809 loss: 0.23805764317512512\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 810 loss: 0.2748304605484009\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 811 loss: 0.35186225175857544\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 812 loss: 0.45947450399398804\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 813 loss: 0.21335282921791077\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 814 loss: 0.37834829092025757\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 815 loss: 0.30154871940612793\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 816 loss: 0.3206595182418823\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 817 loss: 0.2737753689289093\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 818 loss: 0.2380494922399521\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 819 loss: 0.5822018384933472\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 820 loss: 0.258073091506958\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 821 loss: 0.5301131010055542\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 822 loss: 0.4948329031467438\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 823 loss: 0.519352912902832\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 824 loss: 0.44399264454841614\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 825 loss: 0.37371399998664856\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 826 loss: 0.3810769021511078\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 827 loss: 0.43111786246299744\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 828 loss: 0.3104724884033203\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 829 loss: 0.274882435798645\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 830 loss: 0.2675168812274933\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 831 loss: 0.6108345985412598\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 832 loss: 0.3089804947376251\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 833 loss: 0.4283009469509125\n",
      "class 0: acc 0.8438, precision 0.8400, recall 0.9545, f1 0.8936\n",
      "class 1: acc 0.8438, precision 0.5714, recall 0.6667, f1 0.6154\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 834 loss: 0.39877769351005554\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 835 loss: 0.276894211769104\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 836 loss: 0.3062460720539093\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 837 loss: 0.5702677369117737\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 838 loss: 0.7697247862815857\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 839 loss: 0.3002338707447052\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 840 loss: 0.1704508662223816\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 841 loss: 0.38641244173049927\n",
      "class 0: acc 0.8438, precision 0.9310, recall 0.9000, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 842 loss: 0.17201010882854462\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.9000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 843 loss: 0.3349279463291168\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 844 loss: 0.3762395977973938\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 845 loss: 0.31127414107322693\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 846 loss: 0.14312291145324707\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 847 loss: 0.48272639513015747\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 848 loss: 0.2259185016155243\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 849 loss: 0.14190849661827087\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 850 loss: 0.367110937833786\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 851 loss: 0.39648351073265076\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 852 loss: 0.5379951596260071\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8125, precision 0.6000, recall 0.4286, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 853 loss: 0.47423526644706726\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 854 loss: 0.30132704973220825\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 855 loss: 0.28301945328712463\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 856 loss: 0.5284901857376099\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 857 loss: 0.31065210700035095\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 858 loss: 0.4479454755783081\n",
      "class 0: acc 0.7812, precision 0.8462, recall 0.8800, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 859 loss: 0.2661019563674927\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 860 loss: 0.2902486026287079\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 861 loss: 0.3613390326499939\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 862 loss: 0.32315975427627563\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 863 loss: 0.6828331351280212\n",
      "class 0: acc 0.7500, precision 0.7857, recall 0.9167, f1 0.8462\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 864 loss: 0.32285168766975403\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 865 loss: 0.4317662715911865\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 866 loss: 0.20209455490112305\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 867 loss: 0.14844384789466858\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 868 loss: 0.45314887166023254\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 869 loss: 0.47974222898483276\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 870 loss: 0.34922823309898376\n",
      "class 0: acc 0.8125, precision 0.8800, recall 0.8800, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.5714, recall 0.6667, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 871 loss: 0.19573958218097687\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.9032, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 872 loss: 0.16922952234745026\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 873 loss: 0.36464938521385193\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 874 loss: 0.4687896966934204\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 875 loss: 0.40883272886276245\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 876 loss: 0.34531015157699585\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 877 loss: 0.31349843740463257\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 878 loss: 0.328470915555954\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 879 loss: 0.4136362671852112\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 880 loss: 0.6700701713562012\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 881 loss: 0.1694837361574173\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 882 loss: 0.18886898458003998\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 883 loss: 0.8864116072654724\n",
      "class 0: acc 0.7188, precision 0.7000, recall 1.0000, f1 0.8235\n",
      "class 1: acc 0.7812, precision 1.0000, recall 0.2222, f1 0.3636\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 884 loss: 0.208715558052063\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 885 loss: 0.27188780903816223\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 886 loss: 0.553878903388977\n",
      "class 0: acc 0.7500, precision 0.7200, recall 0.9474, f1 0.8182\n",
      "class 1: acc 0.8125, precision 0.8571, recall 0.5455, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 887 loss: 0.3416193723678589\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 888 loss: 0.32403475046157837\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 889 loss: 0.29726505279541016\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 890 loss: 0.2687888443470001\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 891 loss: 0.44734108448028564\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 892 loss: 0.30952951312065125\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 893 loss: 0.27036112546920776\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 894 loss: 0.28318989276885986\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9231, f1 0.9600\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 5 step: 895 loss: 0.5747292041778564\n",
      "class 0: acc 0.8750, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.8750, recall 0.8750, f1 0.8750\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 896 loss: 0.47406771779060364\n",
      "class 0: acc 0.8438, precision 0.9231, recall 0.8889, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.2000, recall 0.5000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 5 step: 897 loss: 0.551156759262085\n",
      "class 0: acc 0.7812, precision 0.8077, recall 0.9130, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 898 loss: 0.4479665160179138\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 899 loss: 0.41067057847976685\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 5 step: 900 loss: 0.4271894097328186\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 901 loss: 0.33288541436195374\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 902 loss: 0.29544535279273987\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 903 loss: 0.3633199632167816\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 904 loss: 0.3063644468784332\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 905 loss: 0.25774508714675903\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 906 loss: 0.10845205932855606\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 907 loss: 0.26765307784080505\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 908 loss: 0.639909029006958\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 909 loss: 0.5162826180458069\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 910 loss: 0.15666422247886658\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 911 loss: 0.5875588655471802\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 912 loss: 0.499507337808609\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 5 step: 913 loss: 0.11286390572786331\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 914 loss: 0.2937183380126953\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 915 loss: 0.4532049596309662\n",
      "class 0: acc 0.8125, precision 0.8846, recall 0.8846, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 916 loss: 0.4368763566017151\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 917 loss: 0.41602402925491333\n",
      "class 0: acc 0.9062, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7778, f1 0.8750\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 5 step: 918 loss: 0.30009305477142334\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 5 step: 919 loss: 0.41538453102111816\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 920 loss: 0.4133361577987671\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 921 loss: 0.17645545303821564\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 922 loss: 0.2699394226074219\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 923 loss: 0.3480328321456909\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 924 loss: 0.2533184587955475\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 925 loss: 0.15183798968791962\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 926 loss: 0.26736751198768616\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 927 loss: 0.32219621539115906\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 928 loss: 0.5768733620643616\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 929 loss: 0.35899659991264343\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 930 loss: 0.3068297207355499\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 931 loss: 0.20816344022750854\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 932 loss: 0.30042505264282227\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 933 loss: 0.32860061526298523\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 934 loss: 0.8063121438026428\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 935 loss: 0.25111979246139526\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 936 loss: 0.20316411554813385\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 937 loss: 0.2627262771129608\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 938 loss: 0.1679254174232483\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 939 loss: 0.9101000428199768\n",
      "class 0: acc 0.6875, precision 0.7000, recall 0.9545, f1 0.8077\n",
      "class 1: acc 0.7188, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 940 loss: 0.44051772356033325\n",
      "class 0: acc 0.8125, precision 0.7692, recall 1.0000, f1 0.8696\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 941 loss: 0.23225069046020508\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 942 loss: 0.2978495657444\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 943 loss: 0.5582917332649231\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 944 loss: 0.38729551434516907\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 945 loss: 0.45607104897499084\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 946 loss: 0.337926983833313\n",
      "class 0: acc 0.9375, precision 0.9545, recall 0.9545, f1 0.9545\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.8889, f1 0.8421\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 947 loss: 0.3776845335960388\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 948 loss: 0.3394010066986084\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 949 loss: 0.1881946176290512\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 950 loss: 0.4076150059700012\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 951 loss: 0.4436791241168976\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 952 loss: 0.25601726770401\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 953 loss: 0.30693674087524414\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 954 loss: 0.31002116203308105\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 955 loss: 0.5314122438430786\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 956 loss: 0.5770313143730164\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 957 loss: 0.33938154578208923\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 958 loss: 0.3719489574432373\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 959 loss: 0.3609538674354553\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 960 loss: 0.6435819864273071\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 961 loss: 0.36752328276634216\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 962 loss: 0.46421581506729126\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 963 loss: 0.5498233437538147\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 964 loss: 0.30062320828437805\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 965 loss: 0.12930163741111755\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 966 loss: 0.14774662256240845\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 5 step: 967 loss: 0.3111165761947632\n",
      "class 0: acc 0.8750, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 968 loss: 0.3037866950035095\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 969 loss: 0.7205305099487305\n",
      "class 0: acc 0.6875, precision 0.7143, recall 0.9091, f1 0.8000\n",
      "class 1: acc 0.7500, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 970 loss: 0.269178569316864\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 971 loss: 0.36258381605148315\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 972 loss: 0.320556640625\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 973 loss: 0.3840734362602234\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 974 loss: 0.3021830916404724\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 975 loss: 0.12558801472187042\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9565, f1 0.9778\n",
      "class 1: acc 0.9688, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 976 loss: 0.2222662717103958\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 977 loss: 0.5037820339202881\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 978 loss: 0.6523157954216003\n",
      "class 0: acc 0.7500, precision 0.7200, recall 0.9474, f1 0.8182\n",
      "class 1: acc 0.8125, precision 0.7143, recall 0.5556, f1 0.6250\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 979 loss: 0.3275010287761688\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 980 loss: 0.27262529730796814\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 981 loss: 0.3526213467121124\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 982 loss: 0.18883247673511505\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 983 loss: 0.5886208415031433\n",
      "class 0: acc 0.7188, precision 0.8148, recall 0.8462, f1 0.8302\n",
      "class 1: acc 0.8750, precision 0.2000, recall 1.0000, f1 0.3333\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 984 loss: 0.32507988810539246\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 985 loss: 0.20528428256511688\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 986 loss: 0.3194422423839569\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 987 loss: 0.25226861238479614\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 988 loss: 0.5232566595077515\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 989 loss: 0.747248649597168\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 990 loss: 0.30565109848976135\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 991 loss: 0.5743238925933838\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 992 loss: 0.28875961899757385\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 993 loss: 0.33872339129447937\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 994 loss: 0.3572101593017578\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 995 loss: 0.2684555947780609\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 996 loss: 0.5448404550552368\n",
      "class 0: acc 0.8125, precision 0.7826, recall 0.9474, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.8889, recall 0.6667, f1 0.7619\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 997 loss: 0.5116538405418396\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 998 loss: 0.22840219736099243\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 999 loss: 0.3923853933811188\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1000 loss: 0.6006850004196167\n",
      "class 0: acc 0.7188, precision 0.7097, recall 1.0000, f1 0.8302\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1001 loss: 0.687373161315918\n",
      "class 0: acc 0.7812, precision 0.7407, recall 1.0000, f1 0.8511\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1002 loss: 0.25194495916366577\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1003 loss: 0.12329019606113434\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1004 loss: 0.3099864721298218\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1005 loss: 0.3278921842575073\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1006 loss: 0.4151036739349365\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1007 loss: 0.25778549909591675\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1008 loss: 0.26375120878219604\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1009 loss: 0.30178970098495483\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1010 loss: 0.41625967621803284\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1011 loss: 0.20762509107589722\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1012 loss: 0.13260473310947418\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1013 loss: 0.49607759714126587\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1014 loss: 0.30400118231773376\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1015 loss: 0.21211561560630798\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1016 loss: 0.8224903345108032\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1017 loss: 0.3594023287296295\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1018 loss: 0.4812256693840027\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1019 loss: 0.5172690153121948\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1020 loss: 0.5209051370620728\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1021 loss: 0.1506359875202179\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1022 loss: 0.2908409833908081\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1023 loss: 0.461972177028656\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1024 loss: 0.34515756368637085\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1025 loss: 0.4878823459148407\n",
      "class 0: acc 0.8125, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1026 loss: 0.43700382113456726\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1027 loss: 0.5644465684890747\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1028 loss: 0.275209903717041\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1029 loss: 0.4491926431655884\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1030 loss: 0.5555663108825684\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1031 loss: 0.39968574047088623\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1032 loss: 0.5258482694625854\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1033 loss: 0.26833391189575195\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 5 step: 1034 loss: 0.473442018032074\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1035 loss: 0.26561757922172546\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1036 loss: 0.22638922929763794\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1037 loss: 0.26050111651420593\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1038 loss: 0.24658481776714325\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1039 loss: 0.4306354224681854\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1040 loss: 0.13935890793800354\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1041 loss: 0.1657613217830658\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1042 loss: 0.19445277750492096\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1043 loss: 0.2591034173965454\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1044 loss: 0.3419438302516937\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1045 loss: 0.2962304353713989\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1046 loss: 0.3380920886993408\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1047 loss: 0.3953656256198883\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1048 loss: 0.2824913263320923\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1049 loss: 0.7745005488395691\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1050 loss: 0.32543161511421204\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1051 loss: 0.47882041335105896\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1052 loss: 0.5114026069641113\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1053 loss: 0.4758296310901642\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1054 loss: 0.50039142370224\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1055 loss: 0.6163972020149231\n",
      "class 0: acc 0.7500, precision 0.7931, recall 0.9200, f1 0.8519\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1056 loss: 0.16273629665374756\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1057 loss: 0.5165267586708069\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1058 loss: 0.5372709631919861\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1059 loss: 0.45806649327278137\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1060 loss: 0.642856776714325\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1061 loss: 0.44929495453834534\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1062 loss: 0.4809972643852234\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1063 loss: 0.5600472688674927\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1064 loss: 0.3739933669567108\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1065 loss: 0.43815934658050537\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1066 loss: 0.39157962799072266\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1067 loss: 0.312560498714447\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1068 loss: 0.395530641078949\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1069 loss: 0.2749940752983093\n",
      "class 0: acc 0.9688, precision 0.9688, recall 1.0000, f1 0.9841\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1070 loss: 0.34617677330970764\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1071 loss: 0.25632962584495544\n",
      "class 0: acc 0.9375, precision 0.9677, recall 0.9677, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1072 loss: 0.3023662567138672\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1073 loss: 0.28149470686912537\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1074 loss: 0.29035064578056335\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1075 loss: 0.3418748378753662\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1076 loss: 0.3229590952396393\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1077 loss: 0.3209902346134186\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1078 loss: 0.19493986666202545\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1079 loss: 0.11103262007236481\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1080 loss: 0.5300554037094116\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1081 loss: 0.20630401372909546\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1082 loss: 0.6435920000076294\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1083 loss: 0.3456297218799591\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1084 loss: 0.25684821605682373\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1085 loss: 0.4108406901359558\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1086 loss: 0.4477624297142029\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1087 loss: 0.389830619096756\n",
      "class 0: acc 0.8438, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7778, f1 0.8750\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1088 loss: 0.19377315044403076\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1089 loss: 0.35250455141067505\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1090 loss: 0.3150183856487274\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1091 loss: 0.12068770825862885\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1092 loss: 0.11433961242437363\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1093 loss: 0.4588797688484192\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1094 loss: 0.466585248708725\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1095 loss: 0.19181348383426666\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1096 loss: 0.13264347612857819\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1097 loss: 0.25855153799057007\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1098 loss: 0.14687597751617432\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1099 loss: 0.2693515419960022\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1100 loss: 0.13744327425956726\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1101 loss: 0.5931733250617981\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1102 loss: 0.2952704429626465\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1103 loss: 0.4607490003108978\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1104 loss: 0.24019888043403625\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1105 loss: 0.49709922075271606\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1106 loss: 0.5299726724624634\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1107 loss: 0.3480406105518341\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1108 loss: 0.3241616487503052\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1109 loss: 0.2234049290418625\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1110 loss: 0.325206458568573\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1111 loss: 0.7045732140541077\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1112 loss: 0.29273590445518494\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1113 loss: 0.3929513394832611\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1114 loss: 0.30028536915779114\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1115 loss: 0.5745826959609985\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1116 loss: 0.21984800696372986\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1117 loss: 0.4557691514492035\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1118 loss: 0.4640056788921356\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1119 loss: 0.23208729922771454\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 5 step: 1120 loss: 0.24635925889015198\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1121 loss: 0.3429155647754669\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1122 loss: 0.41708192229270935\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1123 loss: 0.21096482872962952\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1124 loss: 0.34894683957099915\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1125 loss: 0.22010987997055054\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1126 loss: 0.22861619293689728\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1127 loss: 0.18483546376228333\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1128 loss: 0.4770186245441437\n",
      "class 0: acc 0.7500, precision 0.7778, recall 0.9130, f1 0.8400\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1129 loss: 0.15088434517383575\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1130 loss: 0.28855228424072266\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1131 loss: 0.15105797350406647\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1132 loss: 0.4250345528125763\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1133 loss: 0.545477569103241\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1134 loss: 0.31867721676826477\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1135 loss: 0.4989425539970398\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1136 loss: 0.21041339635849\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1137 loss: 0.3202906847000122\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1138 loss: 0.2678816318511963\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1139 loss: 0.42070555686950684\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1140 loss: 0.18554376065731049\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1141 loss: 0.4434610605239868\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1142 loss: 0.4031425714492798\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1143 loss: 0.26332715153694153\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1144 loss: 0.34537172317504883\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1145 loss: 0.3350750207901001\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1146 loss: 0.33075234293937683\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1147 loss: 0.3653472363948822\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1148 loss: 0.7372620701789856\n",
      "class 0: acc 0.7188, precision 0.7500, recall 0.9130, f1 0.8235\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1149 loss: 0.22093753516674042\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1150 loss: 0.31658464670181274\n",
      "class 0: acc 0.8750, precision 0.9583, recall 0.8846, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1151 loss: 0.20821326971054077\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1152 loss: 0.49645867943763733\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1153 loss: 0.08202057331800461\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 5 step: 1154 loss: 0.2984746992588043\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1155 loss: 0.46547332406044006\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1156 loss: 0.6296113729476929\n",
      "class 0: acc 0.7188, precision 0.7037, recall 0.9500, f1 0.8085\n",
      "class 1: acc 0.7812, precision 0.7500, recall 0.3333, f1 0.4615\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 5 step: 1157 loss: 0.24694432318210602\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1158 loss: 0.4213317930698395\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1159 loss: 0.41229239106178284\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1160 loss: 0.2074623554944992\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1161 loss: 0.3314434885978699\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1162 loss: 0.23307664692401886\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1163 loss: 0.4103130102157593\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1164 loss: 0.3985271453857422\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1165 loss: 0.16453413665294647\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1166 loss: 0.24414250254631042\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1167 loss: 0.5838234424591064\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1168 loss: 0.403772234916687\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1169 loss: 0.5425649285316467\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1170 loss: 0.3081928491592407\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1171 loss: 0.09709128737449646\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1172 loss: 0.1472962498664856\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1173 loss: 0.27347108721733093\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1174 loss: 0.20309868454933167\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1175 loss: 0.4691944420337677\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1176 loss: 0.4607078731060028\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1177 loss: 0.5985846519470215\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1178 loss: 0.07290280610322952\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1179 loss: 0.19081994891166687\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1180 loss: 0.22538286447525024\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1181 loss: 0.47128722071647644\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1182 loss: 0.6958831548690796\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1183 loss: 0.623318612575531\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1184 loss: 0.3678940534591675\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1185 loss: 0.530804455280304\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1186 loss: 0.09425211697816849\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1187 loss: 0.583172082901001\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1188 loss: 0.34051451086997986\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1189 loss: 0.27763885259628296\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1190 loss: 0.2587306499481201\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1191 loss: 0.4126226603984833\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 5 step: 1192 loss: 0.34308385848999023\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 5 step: 1193 loss: 0.45658162236213684\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1194 loss: 0.34362536668777466\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 5 step: 1195 loss: 0.2641349732875824\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1196 loss: 0.16328203678131104\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1197 loss: 0.4281359016895294\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1198 loss: 0.35584089159965515\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1199 loss: 0.26696979999542236\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1200 loss: 0.4984234571456909\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1201 loss: 0.31848078966140747\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1202 loss: 0.232456773519516\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1203 loss: 0.5327140092849731\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1204 loss: 0.6465772986412048\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1205 loss: 0.47426846623420715\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1206 loss: 0.5983202457427979\n",
      "class 0: acc 0.7500, precision 0.7407, recall 0.9524, f1 0.8333\n",
      "class 1: acc 0.7812, precision 0.8000, recall 0.4000, f1 0.5333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1207 loss: 0.36436542868614197\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1208 loss: 0.18102878332138062\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1209 loss: 0.5603910088539124\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1210 loss: 0.19013091921806335\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1211 loss: 0.5058184862136841\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1212 loss: 0.37919580936431885\n",
      "class 0: acc 0.8438, precision 0.9630, recall 0.8667, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.2000, recall 0.5000, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1213 loss: 0.41837218403816223\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1214 loss: 0.3898414075374603\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1215 loss: 0.3518129289150238\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1216 loss: 0.4852466285228729\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1217 loss: 0.5723052620887756\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1218 loss: 0.3567954897880554\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1219 loss: 0.23143009841442108\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 5 step: 1220 loss: 0.3827744722366333\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1221 loss: 0.5417056083679199\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1222 loss: 0.5016633868217468\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1223 loss: 0.5832695960998535\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1224 loss: 0.5619738698005676\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1225 loss: 0.22427910566329956\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1226 loss: 0.5469518303871155\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1227 loss: 0.45118340849876404\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 5 step: 1228 loss: 0.4131491482257843\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1229 loss: 0.2853793501853943\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1230 loss: 0.4013703167438507\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1231 loss: 0.16069693863391876\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1232 loss: 0.20788589119911194\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1233 loss: 0.23640374839305878\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1234 loss: 0.3908970355987549\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1235 loss: 0.3468847870826721\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1236 loss: 0.32925349473953247\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1237 loss: 0.47387948632240295\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1238 loss: 0.3464348614215851\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1239 loss: 0.2031365931034088\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1240 loss: 0.23987716436386108\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1241 loss: 0.20611125230789185\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1242 loss: 0.8238914608955383\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1243 loss: 0.1310887187719345\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1244 loss: 0.2299622893333435\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1245 loss: 0.49371662735939026\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1246 loss: 0.42065098881721497\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1247 loss: 0.22129693627357483\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1248 loss: 0.26943257451057434\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1249 loss: 0.3361120820045471\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 5 step: 1250 loss: 0.5062670111656189\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1 loss: 0.28736627101898193\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 2 loss: 0.4332653284072876\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 3 loss: 0.5075830221176147\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 4 loss: 0.5563452839851379\n",
      "class 0: acc 0.8438, precision 0.7917, recall 1.0000, f1 0.8837\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "epoch: 6 step: 5 loss: 0.2585788369178772\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 6 loss: 0.3902595043182373\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 7 loss: 0.43380028009414673\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 8 loss: 0.34736159443855286\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 9 loss: 0.4624705910682678\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 10 loss: 0.42577484250068665\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 11 loss: 0.3291815221309662\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 12 loss: 0.24519798159599304\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 13 loss: 0.3580605387687683\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 14 loss: 0.28707900643348694\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 15 loss: 0.38021916151046753\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 16 loss: 0.17645445466041565\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 17 loss: 0.2158169001340866\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 18 loss: 0.33677762746810913\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 19 loss: 0.7357434630393982\n",
      "class 0: acc 0.7500, precision 0.7241, recall 1.0000, f1 0.8400\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 20 loss: 0.8328357338905334\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 21 loss: 0.1423623412847519\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 22 loss: 0.3295845687389374\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 23 loss: 0.34827297925949097\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 24 loss: 0.12801727652549744\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 25 loss: 0.26712390780448914\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 26 loss: 0.6024152040481567\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 27 loss: 0.33826181292533875\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 28 loss: 0.42648667097091675\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 29 loss: 0.20374278724193573\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 30 loss: 0.5006096959114075\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 31 loss: 0.10402011126279831\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 32 loss: 0.6237362623214722\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.2857, f1 0.3636\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 33 loss: 0.07381116598844528\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 34 loss: 0.3410031795501709\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 35 loss: 0.7958855032920837\n",
      "class 0: acc 0.7500, precision 0.7241, recall 1.0000, f1 0.8400\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 36 loss: 0.5652065277099609\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 37 loss: 0.1833219826221466\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 38 loss: 0.32332685589790344\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 39 loss: 0.3586024045944214\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 40 loss: 0.6061068773269653\n",
      "class 0: acc 0.7500, precision 0.7692, recall 0.9091, f1 0.8333\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 41 loss: 0.27540478110313416\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 42 loss: 0.23240235447883606\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 43 loss: 0.262660950422287\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 44 loss: 0.20703789591789246\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 45 loss: 0.22946122288703918\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 46 loss: 0.4728846549987793\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 6 step: 47 loss: 0.3353375196456909\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 48 loss: 0.3296601176261902\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 49 loss: 0.3409515619277954\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 50 loss: 0.20782384276390076\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 51 loss: 0.27981850504875183\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 52 loss: 0.15437670052051544\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 53 loss: 0.10069107264280319\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 54 loss: 0.27100691199302673\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 55 loss: 0.4991554319858551\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 56 loss: 0.28181079030036926\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 57 loss: 0.3404102027416229\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 58 loss: 0.4796522557735443\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 59 loss: 0.41952306032180786\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 60 loss: 0.16612137854099274\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 61 loss: 0.19470779597759247\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 62 loss: 0.5181211829185486\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 63 loss: 0.15037623047828674\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 64 loss: 0.18499203026294708\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 65 loss: 0.5651764273643494\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.7812, precision 1.0000, recall 0.2222, f1 0.3636\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 66 loss: 0.3607756197452545\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 67 loss: 0.46821534633636475\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 68 loss: 0.18651676177978516\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 69 loss: 0.3710622787475586\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 70 loss: 0.5898070931434631\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 71 loss: 0.2453051656484604\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 72 loss: 0.6275737881660461\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 73 loss: 0.32093045115470886\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 74 loss: 0.362732857465744\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 75 loss: 0.26229986548423767\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 76 loss: 0.14046725630760193\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 77 loss: 0.3172561526298523\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 78 loss: 0.2877822816371918\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 79 loss: 0.3195093274116516\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 80 loss: 0.4190366864204407\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 81 loss: 0.2924736440181732\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 82 loss: 0.3881358504295349\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 83 loss: 0.26347583532333374\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 84 loss: 0.2980559766292572\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 85 loss: 0.16469809412956238\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 86 loss: 0.29006123542785645\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 87 loss: 0.23595650494098663\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 88 loss: 0.19082702696323395\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 89 loss: 0.24631935358047485\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 90 loss: 0.3265667259693146\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 91 loss: 0.3157482445240021\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 92 loss: 0.12174531817436218\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 93 loss: 0.39817675948143005\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 94 loss: 0.19037878513336182\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 95 loss: 0.32564231753349304\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 96 loss: 0.4798524081707001\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 97 loss: 0.35616639256477356\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 98 loss: 0.29544487595558167\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 99 loss: 0.2676963210105896\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 100 loss: 0.16234144568443298\n",
      "class 0: acc 0.9688, precision 0.9583, recall 1.0000, f1 0.9787\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 101 loss: 0.1294207125902176\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 102 loss: 0.3903586268424988\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 103 loss: 0.25640666484832764\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 104 loss: 0.4087751507759094\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 105 loss: 0.30446869134902954\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 106 loss: 0.15541842579841614\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 107 loss: 0.35750463604927063\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 108 loss: 0.3957989811897278\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 109 loss: 0.2805972695350647\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 110 loss: 0.23903435468673706\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 111 loss: 0.5476016998291016\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 112 loss: 0.44861552119255066\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 113 loss: 0.21292273700237274\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 114 loss: 0.4885047674179077\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 115 loss: 0.33114516735076904\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 116 loss: 0.5102677345275879\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8750, f1 0.9333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 117 loss: 0.32731062173843384\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 118 loss: 0.3519241213798523\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 119 loss: 0.3735909163951874\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 120 loss: 0.44567444920539856\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 121 loss: 0.32077187299728394\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 122 loss: 0.19769036769866943\n",
      "class 0: acc 0.9375, precision 0.9200, recall 1.0000, f1 0.9583\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 123 loss: 0.5066145062446594\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 124 loss: 0.3092282712459564\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 125 loss: 0.2284916788339615\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 126 loss: 0.4498532712459564\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 127 loss: 0.48759210109710693\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 128 loss: 0.6354095339775085\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 129 loss: 0.6524229645729065\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 130 loss: 0.41384050250053406\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 131 loss: 0.40462201833724976\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 132 loss: 0.6968605518341064\n",
      "class 0: acc 0.7188, precision 0.7241, recall 0.9545, f1 0.8235\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 133 loss: 0.3188314437866211\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 134 loss: 0.22306425869464874\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 135 loss: 0.5841580033302307\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 136 loss: 0.27604761719703674\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 137 loss: 0.5755690336227417\n",
      "class 0: acc 0.8438, precision 0.9583, recall 0.8519, f1 0.9020\n",
      "class 1: acc 0.8125, precision 0.3750, recall 0.7500, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 138 loss: 0.30434757471084595\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 139 loss: 0.3880293667316437\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 140 loss: 0.6738177537918091\n",
      "class 0: acc 0.7500, precision 0.7692, recall 0.9091, f1 0.8333\n",
      "class 1: acc 0.7812, precision 0.6667, recall 0.4444, f1 0.5333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 141 loss: 0.13710495829582214\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 142 loss: 0.3505277931690216\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 143 loss: 0.496898353099823\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 144 loss: 0.41543033719062805\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 145 loss: 0.27672019600868225\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 146 loss: 0.35110679268836975\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 147 loss: 0.603248119354248\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 148 loss: 0.24364778399467468\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 149 loss: 0.24478498101234436\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 150 loss: 0.1360839605331421\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 151 loss: 0.8350775837898254\n",
      "class 0: acc 0.7188, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.4545, f1 0.6250\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 152 loss: 0.6320545673370361\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 153 loss: 0.4778582751750946\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 154 loss: 0.22515316307544708\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 155 loss: 0.4774448871612549\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 156 loss: 0.141872376203537\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9677, f1 0.9836\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 157 loss: 0.18498045206069946\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 158 loss: 0.21374286711215973\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 159 loss: 0.4736248552799225\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 160 loss: 0.5294547080993652\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.7812, precision 0.6000, recall 0.3750, f1 0.4615\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 161 loss: 0.5356518030166626\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 162 loss: 0.542095422744751\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 163 loss: 0.6034754514694214\n",
      "class 0: acc 0.7812, precision 0.8571, recall 0.8889, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 164 loss: 0.3778642416000366\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 165 loss: 0.27772167325019836\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.5714, recall 0.6667, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 166 loss: 0.26359695196151733\n",
      "class 0: acc 0.9688, precision 0.9583, recall 1.0000, f1 0.9787\n",
      "class 1: acc 0.9375, precision 0.8750, recall 0.8750, f1 0.8750\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 167 loss: 0.6685776710510254\n",
      "class 0: acc 0.7500, precision 0.7742, recall 0.9600, f1 0.8571\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 168 loss: 0.28400328755378723\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 169 loss: 0.4262121021747589\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 170 loss: 0.3166467845439911\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 171 loss: 0.28223663568496704\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 172 loss: 0.3139413595199585\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 173 loss: 0.3247969150543213\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 174 loss: 0.3653711676597595\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 175 loss: 0.3045045733451843\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 176 loss: 0.443670392036438\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 177 loss: 0.3807683289051056\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 178 loss: 0.39396220445632935\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 179 loss: 0.25241461396217346\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 180 loss: 0.21495601534843445\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 181 loss: 0.5239635109901428\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 182 loss: 0.3457077443599701\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 183 loss: 0.23902885615825653\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9615, f1 0.9804\n",
      "class 1: acc 0.9375, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 184 loss: 0.2557215392589569\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 185 loss: 0.23226779699325562\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 186 loss: 0.2828151285648346\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 187 loss: 0.26480981707572937\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 188 loss: 0.1768742948770523\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 189 loss: 0.5071607828140259\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 190 loss: 0.55506432056427\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 191 loss: 0.5006324648857117\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 192 loss: 0.1215672641992569\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 193 loss: 0.36852988600730896\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 194 loss: 0.10042117536067963\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 195 loss: 0.31590357422828674\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 196 loss: 0.4546695947647095\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 197 loss: 0.46646034717559814\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 198 loss: 0.3544609844684601\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 199 loss: 0.3683440387248993\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 200 loss: 0.30839794874191284\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 201 loss: 0.24136143922805786\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 202 loss: 0.35736048221588135\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 203 loss: 0.4297211170196533\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 204 loss: 0.475835919380188\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 205 loss: 0.3358890116214752\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 206 loss: 0.2875007390975952\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 207 loss: 0.28153225779533386\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 208 loss: 0.3927338421344757\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 209 loss: 0.41477170586586\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 210 loss: 0.6077001094818115\n",
      "class 0: acc 0.8750, precision 0.8750, recall 0.9545, f1 0.9130\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.8571, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 211 loss: 0.3121874928474426\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 212 loss: 0.6616631150245667\n",
      "class 0: acc 0.7812, precision 0.7692, recall 0.9524, f1 0.8511\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.4286, f1 0.4615\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 213 loss: 0.48197513818740845\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 214 loss: 0.4319046437740326\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 215 loss: 0.24976789951324463\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 216 loss: 0.4550319015979767\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 217 loss: 0.29524335265159607\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 218 loss: 0.2081027776002884\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 219 loss: 0.35934168100357056\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 220 loss: 0.25307151675224304\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 221 loss: 0.21662002801895142\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 222 loss: 0.26784053444862366\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 223 loss: 0.34795841574668884\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 224 loss: 0.3934926390647888\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 225 loss: 0.20706519484519958\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 226 loss: 0.38795745372772217\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 227 loss: 0.623973548412323\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 228 loss: 0.4795624911785126\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 229 loss: 0.28557538986206055\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 230 loss: 0.37857383489608765\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 231 loss: 0.12156231701374054\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 232 loss: 0.057893529534339905\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 233 loss: 0.40331417322158813\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 234 loss: 0.17876079678535461\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 235 loss: 0.2738576829433441\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 236 loss: 0.3536246418952942\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 237 loss: 0.18051618337631226\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 238 loss: 0.2865755259990692\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 239 loss: 0.39488324522972107\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 240 loss: 0.6227115988731384\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 241 loss: 0.2935408651828766\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 242 loss: 0.1666973978281021\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 243 loss: 0.28645825386047363\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 244 loss: 0.2249588668346405\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 245 loss: 0.4086310565471649\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 246 loss: 0.2812401056289673\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 247 loss: 0.27973422408103943\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 248 loss: 0.21355095505714417\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 249 loss: 0.3530212342739105\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 250 loss: 0.4812965393066406\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 251 loss: 0.41617411375045776\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 252 loss: 0.5209899544715881\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 253 loss: 0.2856381833553314\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 254 loss: 0.24710921943187714\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 255 loss: 0.1867973655462265\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 256 loss: 0.20356465876102448\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 257 loss: 0.12428606301546097\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 258 loss: 0.05022807791829109\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 259 loss: 0.28708240389823914\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 260 loss: 0.5173472166061401\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 261 loss: 0.40068724751472473\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 262 loss: 0.2105976790189743\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 263 loss: 0.30902284383773804\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 264 loss: 0.2434922754764557\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 265 loss: 0.3254827558994293\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 266 loss: 0.3496130108833313\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 267 loss: 0.17326830327510834\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 268 loss: 0.336300253868103\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 269 loss: 0.24215514957904816\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 270 loss: 0.42463529109954834\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 271 loss: 0.3871249854564667\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 272 loss: 0.23021812736988068\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 273 loss: 0.27258962392807007\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 274 loss: 0.20990805327892303\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 275 loss: 0.41056889295578003\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 276 loss: 0.3647174835205078\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 277 loss: 0.6982141137123108\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 278 loss: 0.4547286033630371\n",
      "class 0: acc 0.8438, precision 0.8400, recall 0.9545, f1 0.8936\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 279 loss: 0.4595116078853607\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 280 loss: 0.5189670920372009\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 281 loss: 0.46995308995246887\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 282 loss: 0.23939193785190582\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 283 loss: 0.15345408022403717\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 284 loss: 0.3808177411556244\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 285 loss: 0.5494212508201599\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 286 loss: 0.23635248839855194\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 287 loss: 0.2267734706401825\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 288 loss: 0.3542242646217346\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 289 loss: 0.16975072026252747\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9677, f1 0.9836\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 290 loss: 0.28355374932289124\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 291 loss: 0.2978842258453369\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 292 loss: 0.45133405923843384\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 293 loss: 0.4970933496952057\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 294 loss: 0.36476418375968933\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 295 loss: 0.7298362255096436\n",
      "class 0: acc 0.7500, precision 0.7419, recall 1.0000, f1 0.8519\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 296 loss: 0.23587006330490112\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 297 loss: 0.46697717905044556\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 298 loss: 0.28863033652305603\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 299 loss: 0.3280707597732544\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 300 loss: 0.2533223330974579\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9600, f1 0.9796\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 301 loss: 0.2264251559972763\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 302 loss: 0.17583170533180237\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 303 loss: 0.48095059394836426\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 304 loss: 0.4709274470806122\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 305 loss: 0.14525246620178223\n",
      "class 0: acc 0.9688, precision 0.9688, recall 1.0000, f1 0.9841\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 306 loss: 0.37666594982147217\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 307 loss: 0.5461717844009399\n",
      "class 0: acc 0.7500, precision 0.8148, recall 0.8800, f1 0.8462\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 308 loss: 0.06749889254570007\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 309 loss: 0.48321545124053955\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 310 loss: 0.3399113118648529\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 311 loss: 0.31444549560546875\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 312 loss: 0.348389595746994\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 313 loss: 0.6725817918777466\n",
      "class 0: acc 0.8438, precision 0.8182, recall 0.9474, f1 0.8780\n",
      "class 1: acc 0.8125, precision 0.7000, recall 0.7000, f1 0.7000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 314 loss: 0.3127450942993164\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 315 loss: 0.42586666345596313\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 316 loss: 0.43589648604393005\n",
      "class 0: acc 0.8750, precision 0.9630, recall 0.8966, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.2000, recall 0.5000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 317 loss: 0.24710088968276978\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 318 loss: 0.4199376702308655\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 319 loss: 0.3792596161365509\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 320 loss: 0.5441503524780273\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 321 loss: 0.4378916919231415\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 322 loss: 0.4878346025943756\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 323 loss: 0.3054230809211731\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 324 loss: 0.17889758944511414\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 325 loss: 0.2611595094203949\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 326 loss: 0.26025131344795227\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 327 loss: 0.4901736378669739\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 328 loss: 0.14292123913764954\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 329 loss: 0.13252055644989014\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 330 loss: 0.23042456805706024\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 331 loss: 0.2767421007156372\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 332 loss: 0.6437556743621826\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 333 loss: 0.248143270611763\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 334 loss: 0.23638422787189484\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 335 loss: 0.4944273829460144\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 336 loss: 0.6324736475944519\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 337 loss: 0.42132699489593506\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8125, precision 0.5714, recall 0.5714, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 338 loss: 0.43815699219703674\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 339 loss: 0.2084294706583023\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 340 loss: 0.16063494980335236\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 341 loss: 0.40860652923583984\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 342 loss: 0.2454415112733841\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 343 loss: 0.45067736506462097\n",
      "class 0: acc 0.7812, precision 0.7812, recall 1.0000, f1 0.8772\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 344 loss: 0.12461236119270325\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 345 loss: 0.35598140954971313\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 346 loss: 0.35776233673095703\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 347 loss: 0.23241038620471954\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 348 loss: 0.31480908393859863\n",
      "class 0: acc 0.8750, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 349 loss: 0.33585014939308167\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 350 loss: 0.24481987953186035\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 351 loss: 0.4386366903781891\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 352 loss: 0.16371573507785797\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 353 loss: 0.3594699501991272\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 354 loss: 0.22030068933963776\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 355 loss: 0.19019228219985962\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 356 loss: 0.38712090253829956\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 357 loss: 0.372285395860672\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 358 loss: 0.5208982229232788\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 359 loss: 0.34118837118148804\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 360 loss: 0.3697829842567444\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 361 loss: 0.7754508852958679\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 362 loss: 0.2101651430130005\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 363 loss: 0.31844353675842285\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 364 loss: 0.23882123827934265\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 365 loss: 0.3289180397987366\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 366 loss: 0.23118996620178223\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 367 loss: 0.6208846569061279\n",
      "class 0: acc 0.7812, precision 0.8077, recall 0.9130, f1 0.8571\n",
      "class 1: acc 0.7812, precision 0.6000, recall 0.3750, f1 0.4615\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 368 loss: 0.26656752824783325\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 369 loss: 0.27838847041130066\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 370 loss: 0.3315155804157257\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 371 loss: 0.2413276582956314\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9333, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 372 loss: 0.4257945120334625\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 373 loss: 0.5291727185249329\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 374 loss: 0.4812721312046051\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 375 loss: 0.4123077690601349\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 376 loss: 0.4333769381046295\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 377 loss: 0.49177783727645874\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 378 loss: 0.3069147765636444\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9091, f1 0.8696\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 379 loss: 0.6933184862136841\n",
      "class 0: acc 0.7188, precision 0.7407, recall 0.9091, f1 0.8163\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 380 loss: 0.27607160806655884\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 381 loss: 0.54511559009552\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 382 loss: 0.25922825932502747\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 383 loss: 0.5805885195732117\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 384 loss: 0.44238078594207764\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 385 loss: 0.4579223692417145\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 386 loss: 0.2956782281398773\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 387 loss: 0.4137741029262543\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 388 loss: 0.501515805721283\n",
      "class 0: acc 0.7812, precision 0.7692, recall 0.9524, f1 0.8511\n",
      "class 1: acc 0.8438, precision 0.8333, recall 0.5556, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 389 loss: 0.2988613247871399\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 390 loss: 0.3290713429450989\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 391 loss: 0.2659815549850464\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 392 loss: 0.4042161703109741\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 393 loss: 0.5434658527374268\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 394 loss: 0.21897192299365997\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 395 loss: 0.3658280372619629\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 396 loss: 0.26175224781036377\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 397 loss: 0.31983211636543274\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 6 step: 398 loss: 0.2664172053337097\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 399 loss: 0.2761985659599304\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 400 loss: 0.29658305644989014\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 401 loss: 0.2964971661567688\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 402 loss: 0.31633108854293823\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 403 loss: 0.43934908509254456\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 404 loss: 0.40231946110725403\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 405 loss: 0.5544796586036682\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 406 loss: 0.40492957830429077\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 407 loss: 0.23511585593223572\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 408 loss: 0.3636392652988434\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 409 loss: 0.27162206172943115\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 410 loss: 0.36910954117774963\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 411 loss: 0.3371712267398834\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 412 loss: 0.46961942315101624\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 413 loss: 0.31708627939224243\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 414 loss: 0.15348172187805176\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 415 loss: 0.2758634090423584\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 416 loss: 0.3435591459274292\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 417 loss: 0.4035991430282593\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 418 loss: 0.19822818040847778\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 419 loss: 0.3753393888473511\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 420 loss: 0.5950772762298584\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 421 loss: 0.09480994194746017\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 422 loss: 0.5852270126342773\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.2000, recall 1.0000, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 423 loss: 0.22454890608787537\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 424 loss: 0.21496371924877167\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 425 loss: 0.5157820582389832\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 426 loss: 0.33692505955696106\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 427 loss: 0.4152680039405823\n",
      "class 0: acc 0.8438, precision 0.9310, recall 0.9000, f1 0.9153\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 428 loss: 0.16134940087795258\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 429 loss: 0.24457955360412598\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 430 loss: 0.14672701060771942\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 431 loss: 0.48810499906539917\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 432 loss: 0.11292573809623718\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 433 loss: 0.2601594626903534\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 434 loss: 0.1705572009086609\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 435 loss: 0.28288504481315613\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 436 loss: 0.350202739238739\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 437 loss: 0.6013810038566589\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 438 loss: 0.6192814111709595\n",
      "class 0: acc 0.7188, precision 0.7333, recall 0.9565, f1 0.8302\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 439 loss: 0.2383788675069809\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 440 loss: 0.3570849299430847\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 441 loss: 0.36620184779167175\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 442 loss: 0.4710453748703003\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 443 loss: 0.513826310634613\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 444 loss: 0.26121091842651367\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 445 loss: 0.4306904077529907\n",
      "class 0: acc 0.8750, precision 0.9167, recall 0.9167, f1 0.9167\n",
      "class 1: acc 0.9062, precision 0.6250, recall 1.0000, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 446 loss: 0.26586511731147766\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 447 loss: 0.5828976631164551\n",
      "class 0: acc 0.7500, precision 0.7667, recall 0.9583, f1 0.8519\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 448 loss: 0.5285002589225769\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 449 loss: 0.46875131130218506\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 450 loss: 0.27816250920295715\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 451 loss: 0.3612508773803711\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 452 loss: 0.7681373357772827\n",
      "class 0: acc 0.7500, precision 0.7407, recall 0.9524, f1 0.8333\n",
      "class 1: acc 0.7812, precision 0.6000, recall 0.3750, f1 0.4615\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 453 loss: 0.2604120373725891\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 6 step: 454 loss: 0.41267696022987366\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 455 loss: 0.36999768018722534\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 456 loss: 0.3674795925617218\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 6 step: 457 loss: 0.3827899992465973\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 458 loss: 0.3176164925098419\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 459 loss: 0.4605942964553833\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 460 loss: 0.4138607978820801\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 461 loss: 0.37450090050697327\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 462 loss: 0.46005186438560486\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 463 loss: 0.37821337580680847\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 6 step: 464 loss: 0.2905845642089844\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 465 loss: 0.2901604473590851\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 466 loss: 0.4032267928123474\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 467 loss: 0.29260900616645813\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 468 loss: 0.481284499168396\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 469 loss: 0.31069445610046387\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 470 loss: 0.14506284892559052\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 471 loss: 0.23238512873649597\n",
      "class 0: acc 0.9062, precision 0.9583, recall 0.9200, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.8571, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 472 loss: 0.5696988701820374\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 473 loss: 0.6497882604598999\n",
      "class 0: acc 0.7812, precision 0.7407, recall 1.0000, f1 0.8511\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 474 loss: 0.32148826122283936\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 475 loss: 0.29876673221588135\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 476 loss: 0.3461097478866577\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 477 loss: 0.3764365315437317\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 478 loss: 0.26918235421180725\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 479 loss: 0.5611451864242554\n",
      "class 0: acc 0.7812, precision 0.8846, recall 0.8519, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.1667, recall 0.5000, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 480 loss: 0.4306110143661499\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 481 loss: 0.28528282046318054\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 482 loss: 0.482295423746109\n",
      "class 0: acc 0.7812, precision 0.8621, recall 0.8929, f1 0.8772\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 483 loss: 0.6387661695480347\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 484 loss: 0.22631634771823883\n",
      "class 0: acc 0.9375, precision 0.9677, recall 0.9677, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 485 loss: 0.3230428397655487\n",
      "class 0: acc 0.8125, precision 0.8800, recall 0.8800, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 6 step: 486 loss: 0.20911124348640442\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 487 loss: 0.2448142170906067\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 488 loss: 0.6181666254997253\n",
      "class 0: acc 0.7500, precision 0.7667, recall 0.9583, f1 0.8519\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 489 loss: 0.4450031518936157\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 490 loss: 0.14448349177837372\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 491 loss: 0.39711934328079224\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 492 loss: 0.33583128452301025\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 493 loss: 0.4110097587108612\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 494 loss: 0.27550962567329407\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 495 loss: 0.14096269011497498\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 496 loss: 0.31054195761680603\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 497 loss: 0.27105632424354553\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 498 loss: 0.3527873754501343\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 499 loss: 0.3402445316314697\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 500 loss: 0.28937143087387085\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 501 loss: 0.28559303283691406\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 502 loss: 0.4395018219947815\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 6 step: 503 loss: 0.40764695405960083\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 504 loss: 0.3244820833206177\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 505 loss: 0.45661455392837524\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 506 loss: 0.17244388163089752\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 507 loss: 0.5161221623420715\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 508 loss: 0.4344213604927063\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 509 loss: 0.3944949805736542\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.8438, precision 0.4286, recall 0.7500, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 510 loss: 0.2589152455329895\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 511 loss: 0.12966468930244446\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 512 loss: 0.3655244708061218\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 513 loss: 0.4975975751876831\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 514 loss: 0.23548954725265503\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 515 loss: 0.7244724035263062\n",
      "class 0: acc 0.7188, precision 0.7308, recall 0.9048, f1 0.8085\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 516 loss: 0.44227662682533264\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 6 step: 517 loss: 0.4836510121822357\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 518 loss: 0.429085910320282\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 519 loss: 0.5350480079650879\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 520 loss: 0.5477157831192017\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 521 loss: 0.2595178782939911\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9333, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 522 loss: 0.49738603830337524\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 523 loss: 0.30462971329689026\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 524 loss: 0.1802559643983841\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 525 loss: 0.26699087023735046\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 6 step: 526 loss: 0.34494102001190186\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 527 loss: 0.3235032558441162\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 528 loss: 0.2882354259490967\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 529 loss: 0.3506675958633423\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 530 loss: 0.324826717376709\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 531 loss: 0.2870442867279053\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 532 loss: 0.3070548474788666\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 533 loss: 0.32175448536872864\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 534 loss: 0.5382733941078186\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 535 loss: 0.6024268865585327\n",
      "class 0: acc 0.7812, precision 0.7692, recall 0.9524, f1 0.8511\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 536 loss: 0.5071779489517212\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 537 loss: 0.7415605187416077\n",
      "class 0: acc 0.7500, precision 0.8077, recall 0.8750, f1 0.8400\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.4286, f1 0.4615\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 538 loss: 0.5240831971168518\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 539 loss: 0.19501769542694092\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 540 loss: 0.23550480604171753\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 541 loss: 0.310359388589859\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 542 loss: 0.24286767840385437\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 543 loss: 0.39270517230033875\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 544 loss: 0.36142441630363464\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 545 loss: 0.32678958773612976\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 546 loss: 0.40818455815315247\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 547 loss: 0.2603539526462555\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 548 loss: 0.2680834233760834\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 549 loss: 0.7112185955047607\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 550 loss: 0.28524208068847656\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 551 loss: 0.2588990032672882\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 552 loss: 0.25913968682289124\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 553 loss: 0.339712917804718\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 554 loss: 0.2365456223487854\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9286, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 555 loss: 0.27132895588874817\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 556 loss: 0.32247185707092285\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 557 loss: 0.4763157069683075\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 558 loss: 0.14082062244415283\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 559 loss: 0.7101760506629944\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 560 loss: 0.26854807138442993\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 561 loss: 0.7308006882667542\n",
      "class 0: acc 0.6875, precision 0.6786, recall 0.9500, f1 0.7917\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 562 loss: 0.4815649390220642\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 563 loss: 0.5032163262367249\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 564 loss: 0.3760465681552887\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 565 loss: 0.5040906667709351\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 566 loss: 0.42033421993255615\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 567 loss: 0.32559826970100403\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 568 loss: 0.2801916003227234\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 569 loss: 0.3548295199871063\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.8571, recall 0.6667, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 570 loss: 0.6314195990562439\n",
      "class 0: acc 0.7812, precision 0.8571, recall 0.8889, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 571 loss: 0.3203652799129486\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 572 loss: 0.3694721758365631\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 6 step: 573 loss: 0.5557995438575745\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 6 step: 574 loss: 0.2656554877758026\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 575 loss: 0.3051314055919647\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 576 loss: 0.41197317838668823\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 577 loss: 0.5475242137908936\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 578 loss: 0.4242500066757202\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 579 loss: 0.2731774151325226\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 580 loss: 0.4483201503753662\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 581 loss: 0.23851798474788666\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 582 loss: 0.3264487087726593\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 583 loss: 0.43607693910598755\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 584 loss: 0.3903762698173523\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 585 loss: 0.5070214867591858\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 586 loss: 0.5162174701690674\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 587 loss: 0.39560115337371826\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 588 loss: 0.6621772646903992\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 589 loss: 0.2370339334011078\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 590 loss: 0.39622145891189575\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 591 loss: 0.23261147737503052\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 592 loss: 0.3343800902366638\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 593 loss: 0.22620780766010284\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 594 loss: 0.5324165225028992\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 595 loss: 0.2872070074081421\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 596 loss: 0.708075761795044\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 597 loss: 0.6690155863761902\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 598 loss: 0.3735998868942261\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 599 loss: 0.2581559121608734\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 600 loss: 0.31435689330101013\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 601 loss: 0.54232257604599\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 602 loss: 0.2846989929676056\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 603 loss: 0.23570993542671204\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 604 loss: 0.44401952624320984\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 605 loss: 0.1995476931333542\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 606 loss: 0.42245742678642273\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 607 loss: 0.5822721123695374\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 608 loss: 0.05908297002315521\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 609 loss: 0.46865028142929077\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 610 loss: 0.07603367418050766\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 611 loss: 0.30455631017684937\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 612 loss: 0.2892279326915741\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 613 loss: 0.10986396670341492\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 614 loss: 0.47405576705932617\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 615 loss: 0.4742042124271393\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 616 loss: 0.3902413845062256\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 617 loss: 0.3433750569820404\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 618 loss: 0.39048516750335693\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 619 loss: 0.3781058192253113\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 620 loss: 0.23309507966041565\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 621 loss: 0.24771173298358917\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 622 loss: 0.3179467022418976\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 623 loss: 0.31554707884788513\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 624 loss: 0.4529944360256195\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 625 loss: 0.2753143012523651\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 626 loss: 0.324565589427948\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 627 loss: 0.24354460835456848\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 628 loss: 0.40954411029815674\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 629 loss: 0.2804839015007019\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 630 loss: 0.6459124684333801\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 631 loss: 0.5582950115203857\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 632 loss: 0.42004072666168213\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 633 loss: 0.1826806664466858\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 634 loss: 0.440962016582489\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 635 loss: 0.3368770480155945\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 636 loss: 0.373251348733902\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 637 loss: 0.25770118832588196\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 638 loss: 0.37187492847442627\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 639 loss: 0.4030068814754486\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 640 loss: 0.4159567952156067\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 641 loss: 0.4495411813259125\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 642 loss: 0.472518652677536\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 643 loss: 0.29616135358810425\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 644 loss: 0.29420140385627747\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 645 loss: 0.18473340570926666\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 646 loss: 0.31227952241897583\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 647 loss: 0.3179798424243927\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 648 loss: 0.3369051218032837\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 649 loss: 0.20834414660930634\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 650 loss: 0.4779011607170105\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 651 loss: 0.2806588411331177\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 652 loss: 0.4650624990463257\n",
      "class 0: acc 0.7812, precision 0.8333, recall 0.9259, f1 0.8772\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 653 loss: 0.47284790873527527\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 654 loss: 0.3090440630912781\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 655 loss: 0.364825963973999\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 656 loss: 0.3174978494644165\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 657 loss: 0.5699356198310852\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 658 loss: 0.37647274136543274\n",
      "class 0: acc 0.7812, precision 0.8077, recall 0.9130, f1 0.8571\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 659 loss: 0.256102979183197\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 660 loss: 0.3666708767414093\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 661 loss: 0.31775322556495667\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 662 loss: 0.39384889602661133\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 663 loss: 0.2599027454853058\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 664 loss: 0.4668099284172058\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 665 loss: 0.30218201875686646\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 666 loss: 0.3226432204246521\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 667 loss: 0.2833898663520813\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 668 loss: 0.5239784121513367\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 669 loss: 0.3855276107788086\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 670 loss: 0.38863280415534973\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 671 loss: 0.3396696448326111\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 672 loss: 0.4637417793273926\n",
      "class 0: acc 0.8750, precision 0.9630, recall 0.8966, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 673 loss: 0.22789207100868225\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 674 loss: 0.28287890553474426\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 675 loss: 0.2875267267227173\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 676 loss: 0.3644515872001648\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 677 loss: 0.5372190475463867\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 678 loss: 0.3739355504512787\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 679 loss: 0.18434414267539978\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 680 loss: 0.7428522706031799\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 681 loss: 0.31028449535369873\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 682 loss: 0.27191829681396484\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 683 loss: 0.5418566465377808\n",
      "class 0: acc 0.7188, precision 0.7857, recall 0.8800, f1 0.8302\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 684 loss: 0.28709715604782104\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 685 loss: 0.46948543190956116\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 686 loss: 0.3413761854171753\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 687 loss: 0.568676769733429\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 688 loss: 0.7102038264274597\n",
      "class 0: acc 0.7500, precision 0.7407, recall 0.9524, f1 0.8333\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 689 loss: 0.3817470967769623\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 690 loss: 0.26843735575675964\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 691 loss: 0.5045881271362305\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 692 loss: 0.3550257384777069\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 693 loss: 0.759763777256012\n",
      "class 0: acc 0.7500, precision 0.8000, recall 0.8696, f1 0.8333\n",
      "class 1: acc 0.8438, precision 0.5714, recall 0.6667, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 694 loss: 0.4761713445186615\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 695 loss: 0.39416033029556274\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 696 loss: 0.28134849667549133\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 697 loss: 0.32950451970100403\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 698 loss: 0.4204965829849243\n",
      "class 0: acc 0.8750, precision 0.9600, recall 0.8889, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 699 loss: 0.515249490737915\n",
      "class 0: acc 0.7812, precision 0.7407, recall 1.0000, f1 0.8511\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 6 step: 700 loss: 0.5056110620498657\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 701 loss: 0.37741056084632874\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 702 loss: 0.3020191788673401\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 703 loss: 0.3683190643787384\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 704 loss: 0.5450993776321411\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 705 loss: 0.353127658367157\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 706 loss: 0.3705136775970459\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 707 loss: 0.11981600522994995\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 708 loss: 0.4376903772354126\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 709 loss: 0.4664836823940277\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 710 loss: 0.39639046788215637\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 711 loss: 0.3062041997909546\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 712 loss: 0.23978115618228912\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 713 loss: 0.2627202570438385\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 714 loss: 0.28593921661376953\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 715 loss: 0.5066434144973755\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 716 loss: 0.37302297353744507\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 717 loss: 0.5310304760932922\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 718 loss: 0.11840533465147018\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 719 loss: 0.38337260484695435\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 720 loss: 0.16413168609142303\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 721 loss: 0.44717952609062195\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 722 loss: 0.5080341696739197\n",
      "class 0: acc 0.7812, precision 0.8846, recall 0.8519, f1 0.8679\n",
      "class 1: acc 0.7812, precision 0.1667, recall 0.3333, f1 0.2222\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 723 loss: 0.2805415689945221\n",
      "class 0: acc 0.8438, precision 0.9600, recall 0.8571, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 724 loss: 0.3317590057849884\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 725 loss: 0.28917983174324036\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 726 loss: 0.4083157479763031\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 727 loss: 0.2922736406326294\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 728 loss: 0.3361567556858063\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 729 loss: 0.31252676248550415\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 730 loss: 0.3553973138332367\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 731 loss: 0.5298371911048889\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 732 loss: 0.2241211086511612\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 733 loss: 0.4969022572040558\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 734 loss: 0.4804978370666504\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8125, precision 0.8333, recall 0.5000, f1 0.6250\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 735 loss: 0.22744296491146088\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 736 loss: 0.2918277382850647\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 737 loss: 0.2857857346534729\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 738 loss: 0.4099072217941284\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 739 loss: 0.2828170955181122\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 740 loss: 0.23549160361289978\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 741 loss: 0.25973549485206604\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 742 loss: 0.2934803366661072\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 743 loss: 0.269645094871521\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 744 loss: 0.3299376368522644\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 745 loss: 0.35554826259613037\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 746 loss: 0.4754429757595062\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 747 loss: 0.3064919710159302\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 748 loss: 0.6607691645622253\n",
      "class 0: acc 0.7812, precision 0.8333, recall 0.9259, f1 0.8772\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 749 loss: 0.8703451752662659\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 750 loss: 0.36241891980171204\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 751 loss: 0.33905041217803955\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 752 loss: 0.27258190512657166\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 753 loss: 0.4340245723724365\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.8125, precision 0.2000, recall 0.3333, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 754 loss: 0.25463902950286865\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 755 loss: 0.3273802399635315\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 756 loss: 0.3892635405063629\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 757 loss: 0.2960438132286072\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 758 loss: 0.22215856611728668\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 759 loss: 0.2950960397720337\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 760 loss: 0.45831066370010376\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 761 loss: 0.3701908588409424\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 762 loss: 0.2680538296699524\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 763 loss: 0.29087576270103455\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 764 loss: 0.16198524832725525\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 765 loss: 0.2620868980884552\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 766 loss: 0.18510961532592773\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 767 loss: 0.2530549466609955\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 768 loss: 0.2679991126060486\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 769 loss: 0.5145092606544495\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 770 loss: 0.09477273374795914\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 771 loss: 0.29603293538093567\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 772 loss: 0.19656327366828918\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 773 loss: 0.4544282853603363\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 774 loss: 0.3284878134727478\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 775 loss: 0.35759302973747253\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 776 loss: 0.2922798991203308\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 777 loss: 0.6037413477897644\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 778 loss: 0.23489923775196075\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 779 loss: 0.31098672747612\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 780 loss: 0.24297432601451874\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 781 loss: 0.5043444633483887\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 782 loss: 0.37353265285491943\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 783 loss: 0.6091120839118958\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 784 loss: 0.5394107103347778\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 785 loss: 0.3031104505062103\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 786 loss: 0.40597495436668396\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 787 loss: 0.18756476044654846\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 788 loss: 0.22945204377174377\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 789 loss: 0.608842670917511\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 790 loss: 0.3977748453617096\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 791 loss: 0.3041238486766815\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 792 loss: 0.32549160718917847\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 793 loss: 0.49533310532569885\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 794 loss: 0.30869951844215393\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 795 loss: 0.27804693579673767\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 796 loss: 0.29876118898391724\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 797 loss: 0.399596631526947\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 798 loss: 0.22745805978775024\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 799 loss: 0.4072943329811096\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 800 loss: 0.16981644928455353\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 801 loss: 0.3002254068851471\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 802 loss: 0.3636830449104309\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 803 loss: 0.1538773626089096\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 804 loss: 0.5475800633430481\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8125, precision 0.8333, recall 0.5000, f1 0.6250\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 805 loss: 0.3532490134239197\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 806 loss: 0.5717335343360901\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 807 loss: 0.498993456363678\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 808 loss: 0.41342198848724365\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 809 loss: 0.43794089555740356\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 810 loss: 0.45176053047180176\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 811 loss: 0.17272759974002838\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9355, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 812 loss: 0.35185539722442627\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 813 loss: 0.2448405623435974\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 814 loss: 0.4583035409450531\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 815 loss: 0.5336841344833374\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 816 loss: 0.2912096381187439\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 817 loss: 0.4048440158367157\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 818 loss: 0.2896295487880707\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 819 loss: 0.3988199532032013\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 820 loss: 0.3561994433403015\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 821 loss: 0.4885734021663666\n",
      "class 0: acc 0.7500, precision 0.8462, recall 0.8462, f1 0.8462\n",
      "class 1: acc 0.7500, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 822 loss: 0.4310169219970703\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 823 loss: 0.30828770995140076\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 824 loss: 0.10569488257169724\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 825 loss: 0.22410742938518524\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 826 loss: 0.13043852150440216\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 827 loss: 0.2056606113910675\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 828 loss: 0.20605631172657013\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 829 loss: 0.5341192483901978\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 830 loss: 0.28697165846824646\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 831 loss: 0.3331802487373352\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 832 loss: 0.3473082184791565\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 833 loss: 0.29665347933769226\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 834 loss: 0.5603291988372803\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 835 loss: 0.44000890851020813\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 836 loss: 0.44382309913635254\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 837 loss: 0.2595966160297394\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 838 loss: 0.37365448474884033\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 839 loss: 0.22563858330249786\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 840 loss: 0.2333298772573471\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 841 loss: 0.21671649813652039\n",
      "class 0: acc 0.8750, precision 0.9630, recall 0.8966, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 842 loss: 0.36884835362434387\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 843 loss: 0.7720692157745361\n",
      "class 0: acc 0.7188, precision 0.7692, recall 0.8696, f1 0.8163\n",
      "class 1: acc 0.7188, precision 0.3333, recall 0.2857, f1 0.3077\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 844 loss: 0.22502261400222778\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 845 loss: 0.28960809111595154\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 846 loss: 0.1873280256986618\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 847 loss: 0.3494505286216736\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 848 loss: 0.4898778200149536\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 849 loss: 0.4155915677547455\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 850 loss: 0.3200133442878723\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 851 loss: 0.4574929475784302\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 852 loss: 0.35057926177978516\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 853 loss: 0.21708284318447113\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 854 loss: 0.4976082146167755\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 855 loss: 0.4193659722805023\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 856 loss: 0.367442786693573\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 857 loss: 0.5714235901832581\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 858 loss: 0.27410462498664856\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 6 step: 859 loss: 0.4572151303291321\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 860 loss: 0.30744582414627075\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 861 loss: 0.5555623769760132\n",
      "class 0: acc 0.7812, precision 0.8889, recall 0.8571, f1 0.8727\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 862 loss: 0.45700064301490784\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "epoch: 6 step: 863 loss: 0.24782375991344452\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 864 loss: 0.3163282871246338\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 865 loss: 0.32582125067710876\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 866 loss: 0.33920755982398987\n",
      "class 0: acc 0.8438, precision 0.9286, recall 0.8966, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 867 loss: 0.3149847984313965\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 868 loss: 0.1926548033952713\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 869 loss: 0.2545434832572937\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 870 loss: 0.25704535841941833\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 871 loss: 0.1670500487089157\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 872 loss: 0.33454883098602295\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 873 loss: 0.31871339678764343\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 874 loss: 0.36440110206604004\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 875 loss: 0.5425091981887817\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 876 loss: 0.16323837637901306\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 877 loss: 0.566847026348114\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 878 loss: 0.6597237586975098\n",
      "class 0: acc 0.8125, precision 0.7692, recall 1.0000, f1 0.8696\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5455, f1 0.7059\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 879 loss: 0.24430043995380402\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 880 loss: 0.35302114486694336\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 881 loss: 0.3448898494243622\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 882 loss: 0.5805498361587524\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 883 loss: 0.3640744090080261\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 884 loss: 0.5344642996788025\n",
      "class 0: acc 0.8125, precision 0.9200, recall 0.8519, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.4286, recall 0.7500, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 885 loss: 0.35299623012542725\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 886 loss: 0.1818782240152359\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 887 loss: 0.12975837290287018\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 888 loss: 0.14634893834590912\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 889 loss: 0.3754557967185974\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 890 loss: 0.5219942331314087\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 891 loss: 0.19257186353206635\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 892 loss: 0.2862139344215393\n",
      "class 0: acc 0.9062, precision 0.9583, recall 0.9200, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 893 loss: 0.6712144017219543\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 894 loss: 0.43369802832603455\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 895 loss: 0.3122328519821167\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 896 loss: 0.797453761100769\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.7812, precision 0.3333, recall 0.1667, f1 0.2222\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 897 loss: 0.7659094929695129\n",
      "class 0: acc 0.7500, precision 0.7778, recall 0.9130, f1 0.8400\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 898 loss: 0.31224384903907776\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 899 loss: 0.4814692735671997\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 900 loss: 0.24761317670345306\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 901 loss: 0.34013211727142334\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8750, f1 0.9333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 902 loss: 0.4204832911491394\n",
      "class 0: acc 0.7812, precision 0.8696, recall 0.8333, f1 0.8511\n",
      "class 1: acc 0.8438, precision 0.5556, recall 0.8333, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 903 loss: 0.5708546042442322\n",
      "class 0: acc 0.8438, precision 0.9583, recall 0.8519, f1 0.9020\n",
      "class 1: acc 0.8125, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 904 loss: 0.52415531873703\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 905 loss: 0.5012343525886536\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 906 loss: 0.6226354241371155\n",
      "class 0: acc 0.8125, precision 0.9130, recall 0.8400, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "epoch: 6 step: 907 loss: 0.5013030171394348\n",
      "class 0: acc 0.8438, precision 0.9200, recall 0.8846, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "epoch: 6 step: 908 loss: 0.28075969219207764\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 909 loss: 0.4044780433177948\n",
      "class 0: acc 0.8438, precision 0.9310, recall 0.9000, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 910 loss: 0.17341391742229462\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 911 loss: 0.21908438205718994\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 912 loss: 0.39803215861320496\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 913 loss: 0.24575203657150269\n",
      "class 0: acc 0.8750, precision 1.0000, recall 0.8710, f1 0.9310\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.2000, recall 1.0000, f1 0.3333\n",
      "epoch: 6 step: 914 loss: 0.5880086421966553\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 915 loss: 0.5189746618270874\n",
      "class 0: acc 0.9688, precision 0.9583, recall 1.0000, f1 0.9787\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.2857, f1 0.3636\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 916 loss: 0.4516071081161499\n",
      "class 0: acc 0.7812, precision 0.8462, recall 0.8800, f1 0.8627\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "epoch: 6 step: 917 loss: 0.45769357681274414\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 918 loss: 0.5749127268791199\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 919 loss: 0.18808399140834808\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 920 loss: 0.4155120551586151\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 921 loss: 0.5040853023529053\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 922 loss: 0.34853026270866394\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 923 loss: 0.400962769985199\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 924 loss: 0.3299497663974762\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 925 loss: 0.2593141198158264\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 926 loss: 0.18032681941986084\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 927 loss: 0.23651744425296783\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 928 loss: 0.33580678701400757\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 929 loss: 0.26119157671928406\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 930 loss: 0.38957974314689636\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 931 loss: 0.21978925168514252\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 932 loss: 0.34105613827705383\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 933 loss: 0.24336832761764526\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 934 loss: 0.31583890318870544\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 935 loss: 0.19280382990837097\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 936 loss: 0.4191107749938965\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 937 loss: 0.2969534397125244\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 938 loss: 0.18688781559467316\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 939 loss: 0.31177574396133423\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 940 loss: 0.26341336965560913\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 941 loss: 0.3003445863723755\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 942 loss: 0.22571250796318054\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 943 loss: 0.31818798184394836\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 944 loss: 0.4394298791885376\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 945 loss: 0.6370104551315308\n",
      "class 0: acc 0.7500, precision 0.7778, recall 0.9130, f1 0.8400\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 946 loss: 0.1190786361694336\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 947 loss: 0.516832709312439\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 948 loss: 0.39047449827194214\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8750, f1 0.9333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 949 loss: 0.3331601023674011\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 950 loss: 0.44906044006347656\n",
      "class 0: acc 0.7188, precision 0.7778, recall 0.8750, f1 0.8235\n",
      "class 1: acc 0.7812, precision 0.4000, recall 0.3333, f1 0.3636\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 951 loss: 0.37107744812965393\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 952 loss: 0.41572704911231995\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 953 loss: 0.2728327810764313\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 954 loss: 0.22577911615371704\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 955 loss: 0.6035853028297424\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 956 loss: 0.28841957449913025\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 957 loss: 0.3905003070831299\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 958 loss: 0.34633126854896545\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 959 loss: 0.4295397996902466\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 6 step: 960 loss: 0.3546445965766907\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 961 loss: 0.3479975163936615\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 962 loss: 0.5323494672775269\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 963 loss: 0.3688564896583557\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 964 loss: 0.1458842158317566\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 965 loss: 0.4586787521839142\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 966 loss: 0.37656599283218384\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 967 loss: 0.4960181415081024\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 968 loss: 0.3882821798324585\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 969 loss: 0.09355314821004868\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 970 loss: 0.4588299095630646\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 971 loss: 0.3789287209510803\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 972 loss: 0.2576155960559845\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 973 loss: 0.22690336406230927\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 974 loss: 0.4046339988708496\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 975 loss: 0.564907431602478\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 976 loss: 0.3131212294101715\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 977 loss: 0.3632146418094635\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 978 loss: 0.23068270087242126\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 979 loss: 0.3937949538230896\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 980 loss: 0.35915830731391907\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 981 loss: 0.38045454025268555\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 982 loss: 0.34774139523506165\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 983 loss: 0.46483927965164185\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 984 loss: 0.2631652355194092\n",
      "class 0: acc 0.9688, precision 0.9583, recall 1.0000, f1 0.9787\n",
      "class 1: acc 0.9688, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 985 loss: 0.3393927812576294\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 986 loss: 0.6101496815681458\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.7812, precision 0.4000, recall 0.3333, f1 0.3636\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 987 loss: 0.455615371465683\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 988 loss: 0.27190640568733215\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 989 loss: 0.5846887230873108\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 990 loss: 0.5744341015815735\n",
      "class 0: acc 0.7812, precision 0.8077, recall 0.9130, f1 0.8571\n",
      "class 1: acc 0.7500, precision 0.5000, recall 0.3750, f1 0.4286\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 991 loss: 0.5203617811203003\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 992 loss: 0.3489260673522949\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 993 loss: 0.23621419072151184\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 994 loss: 0.11734145134687424\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 995 loss: 0.29315951466560364\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 996 loss: 0.6955109238624573\n",
      "class 0: acc 0.7500, precision 0.7419, recall 1.0000, f1 0.8519\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 997 loss: 0.36762747168540955\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 998 loss: 0.2188117355108261\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 999 loss: 0.3202882409095764\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1000 loss: 0.2625182271003723\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1001 loss: 0.3741611838340759\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1002 loss: 0.43986278772354126\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1003 loss: 0.45039093494415283\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1004 loss: 0.393026202917099\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1005 loss: 0.6050922870635986\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1006 loss: 0.5406306982040405\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1007 loss: 0.4290533661842346\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1008 loss: 0.1909628063440323\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1009 loss: 0.4096193015575409\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1010 loss: 0.4380762279033661\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1011 loss: 0.23195944726467133\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1012 loss: 0.3228721022605896\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1013 loss: 0.33460021018981934\n",
      "class 0: acc 0.8750, precision 0.9583, recall 0.8846, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1014 loss: 0.32512834668159485\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1015 loss: 0.33096522092819214\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1016 loss: 0.3757695257663727\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1017 loss: 0.5234492421150208\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1018 loss: 0.5663629174232483\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1019 loss: 0.3398960530757904\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1020 loss: 0.3173847496509552\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1021 loss: 0.14355823397636414\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1022 loss: 0.6071979403495789\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 1023 loss: 0.11453448235988617\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1024 loss: 0.4571313261985779\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1025 loss: 0.31903597712516785\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1026 loss: 0.3471342623233795\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1027 loss: 0.08474863320589066\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1028 loss: 0.3843810260295868\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1029 loss: 0.25998789072036743\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1030 loss: 0.0667123943567276\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1031 loss: 0.2189682573080063\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1032 loss: 0.49970537424087524\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1033 loss: 0.22563479840755463\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1034 loss: 0.22552749514579773\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1035 loss: 0.4515403211116791\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1036 loss: 0.16657869517803192\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1037 loss: 0.7149364352226257\n",
      "class 0: acc 0.8125, precision 0.7826, recall 0.9474, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.7500, f1 0.7059\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1038 loss: 0.2678363621234894\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1039 loss: 0.2806822657585144\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1040 loss: 0.12855765223503113\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9565, f1 0.9778\n",
      "class 1: acc 0.9688, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1041 loss: 0.4111529290676117\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1042 loss: 0.23089678585529327\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1043 loss: 0.5273549556732178\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1044 loss: 0.3762631118297577\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 6 step: 1045 loss: 0.5031759142875671\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1046 loss: 0.3810841143131256\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1047 loss: 0.509456217288971\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1048 loss: 0.46487972140312195\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1049 loss: 0.36004042625427246\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9688, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1050 loss: 0.18370579183101654\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1051 loss: 0.4666580259799957\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1052 loss: 0.501940906047821\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1053 loss: 0.20519155263900757\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1054 loss: 0.2902779281139374\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1055 loss: 0.354419082403183\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1056 loss: 0.2489599883556366\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1057 loss: 0.16408249735832214\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1058 loss: 0.2510979175567627\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 6 step: 1059 loss: 0.32157784700393677\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1060 loss: 0.31291285157203674\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1061 loss: 0.23474808037281036\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1062 loss: 0.2711656987667084\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1063 loss: 0.3953753709793091\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1064 loss: 0.21726176142692566\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1065 loss: 0.457687646150589\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1066 loss: 0.32572823762893677\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1067 loss: 0.6529993414878845\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1068 loss: 0.3133259415626526\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1069 loss: 0.2668079137802124\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1070 loss: 0.2962082624435425\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1071 loss: 0.27326175570487976\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1072 loss: 0.334465354681015\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1073 loss: 0.43286511301994324\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1074 loss: 0.26829954981803894\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1075 loss: 0.5147152543067932\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1076 loss: 0.6530201435089111\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1077 loss: 0.41927793622016907\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1078 loss: 0.5543621182441711\n",
      "class 0: acc 0.7812, precision 0.7407, recall 1.0000, f1 0.8511\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1079 loss: 0.635399341583252\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.2857, f1 0.3636\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1080 loss: 0.6880592703819275\n",
      "class 0: acc 0.7500, precision 0.7692, recall 0.9091, f1 0.8333\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1081 loss: 0.3338325023651123\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1082 loss: 0.5359334349632263\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 1083 loss: 0.3666172921657562\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1084 loss: 0.4435926079750061\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1085 loss: 0.5327494740486145\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1086 loss: 0.1863565593957901\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1087 loss: 0.37175583839416504\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1088 loss: 0.4936027526855469\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1089 loss: 0.4797298312187195\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1090 loss: 0.1995934247970581\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1091 loss: 0.44012168049812317\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1092 loss: 0.4296117126941681\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1093 loss: 0.3821086287498474\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1094 loss: 0.5560804009437561\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1095 loss: 0.3531455099582672\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1096 loss: 0.20230184495449066\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1097 loss: 0.32907870411872864\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1098 loss: 0.24673783779144287\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1099 loss: 0.1973663866519928\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1100 loss: 0.32088711857795715\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1101 loss: 0.2709805369377136\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1102 loss: 0.6923640370368958\n",
      "class 0: acc 0.7500, precision 0.7778, recall 0.9130, f1 0.8400\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1103 loss: 0.3884129226207733\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1104 loss: 0.420987069606781\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1105 loss: 0.4218406677246094\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 1106 loss: 0.48625847697257996\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1107 loss: 0.21191202104091644\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1108 loss: 0.3778255879878998\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1109 loss: 0.38682472705841064\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1110 loss: 0.403816282749176\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1111 loss: 0.48963797092437744\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1112 loss: 0.3946072459220886\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 1113 loss: 0.15765166282653809\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1114 loss: 0.322335422039032\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1115 loss: 0.29832586646080017\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1116 loss: 0.38036414980888367\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 1117 loss: 0.4203031659126282\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1118 loss: 0.4162253439426422\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1119 loss: 0.2354736626148224\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1120 loss: 0.2615458071231842\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1121 loss: 0.3163772523403168\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1122 loss: 0.17799071967601776\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1123 loss: 0.4635297954082489\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1124 loss: 0.22264361381530762\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1125 loss: 0.3619627356529236\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1126 loss: 0.18767109513282776\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1127 loss: 0.18417634069919586\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1128 loss: 0.12707890570163727\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1129 loss: 0.4202388525009155\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1130 loss: 0.46265560388565063\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1131 loss: 0.3411639928817749\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1132 loss: 0.30898725986480713\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1133 loss: 0.6551705002784729\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1134 loss: 0.4237116575241089\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1135 loss: 0.7753732800483704\n",
      "class 0: acc 0.7812, precision 0.7692, recall 0.9524, f1 0.8511\n",
      "class 1: acc 0.7500, precision 0.6000, recall 0.3333, f1 0.4286\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1136 loss: 0.2535356283187866\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1137 loss: 0.2728974223136902\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1138 loss: 0.36265134811401367\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1139 loss: 0.17345015704631805\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1140 loss: 0.16608896851539612\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1141 loss: 0.3717151880264282\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1142 loss: 0.41460034251213074\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1143 loss: 0.2623332142829895\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1144 loss: 0.14549598097801208\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1145 loss: 0.17148807644844055\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9231, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1146 loss: 0.1346297711133957\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1147 loss: 0.19414082169532776\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9333, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1148 loss: 0.12446051836013794\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1149 loss: 0.1920095831155777\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1150 loss: 0.30163565278053284\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1151 loss: 0.44199997186660767\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 6 step: 1152 loss: 0.19546617567539215\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1153 loss: 0.1156107559800148\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 1154 loss: 0.567217230796814\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1155 loss: 0.32986980676651\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1156 loss: 0.47409915924072266\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1157 loss: 0.5707169771194458\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1158 loss: 0.3951875865459442\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1159 loss: 0.33998480439186096\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 1160 loss: 0.352521151304245\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1161 loss: 0.3083667755126953\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 1162 loss: 0.26571935415267944\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1163 loss: 0.768631100654602\n",
      "class 0: acc 0.7812, precision 0.7917, recall 0.9048, f1 0.8444\n",
      "class 1: acc 0.7812, precision 0.5714, recall 0.5000, f1 0.5333\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 6 step: 1164 loss: 0.41356533765792847\n",
      "class 0: acc 0.8438, precision 0.9630, recall 0.8667, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1165 loss: 0.3137964904308319\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1166 loss: 0.15129749476909637\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1167 loss: 0.43411093950271606\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8125, precision 0.2000, recall 0.3333, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1168 loss: 0.44247353076934814\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.9000, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1169 loss: 0.27798745036125183\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 1170 loss: 0.4641836881637573\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1171 loss: 0.6838718056678772\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1172 loss: 0.3314019739627838\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1173 loss: 0.18127140402793884\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 1174 loss: 0.5621781349182129\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 6 step: 1175 loss: 0.38385799527168274\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1176 loss: 0.20182116329669952\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1177 loss: 0.22130008041858673\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1178 loss: 0.2946600019931793\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1179 loss: 0.10012974590063095\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1180 loss: 0.43138813972473145\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1181 loss: 0.36936476826667786\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 6 step: 1182 loss: 0.1327214241027832\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1183 loss: 0.4022338390350342\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1184 loss: 0.463846892118454\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1185 loss: 0.6727554798126221\n",
      "class 0: acc 0.7188, precision 0.7333, recall 0.9565, f1 0.8302\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.1429, f1 0.2222\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1186 loss: 0.5219935178756714\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1187 loss: 0.14763374626636505\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1188 loss: 0.19527015089988708\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1189 loss: 0.2380664050579071\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1190 loss: 0.22165553271770477\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1191 loss: 0.28760868310928345\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 1192 loss: 0.32045456767082214\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1193 loss: 0.34578776359558105\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1194 loss: 0.548990786075592\n",
      "class 0: acc 0.7500, precision 0.8519, recall 0.8519, f1 0.8519\n",
      "class 1: acc 0.8438, precision 0.2000, recall 0.5000, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1195 loss: 0.42035678029060364\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1196 loss: 0.5217158198356628\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1197 loss: 0.3656466007232666\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1198 loss: 0.4529626965522766\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1199 loss: 0.36931321024894714\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1200 loss: 0.13985393941402435\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1201 loss: 0.3921683728694916\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 6 step: 1202 loss: 0.2846599817276001\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1203 loss: 0.48791635036468506\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1204 loss: 0.501612663269043\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1205 loss: 0.3444036841392517\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1206 loss: 0.3135291337966919\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9286, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 6 step: 1207 loss: 0.4052574038505554\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1208 loss: 0.37958455085754395\n",
      "class 0: acc 0.9688, precision 0.9600, recall 1.0000, f1 0.9796\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 6 step: 1209 loss: 0.3915252685546875\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1210 loss: 0.27797818183898926\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1211 loss: 0.4418960511684418\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1212 loss: 0.5006970763206482\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1213 loss: 0.537301778793335\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 6 step: 1214 loss: 0.1721661388874054\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1215 loss: 0.7161405682563782\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.7188, precision 0.6667, recall 0.2000, f1 0.3077\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1216 loss: 0.24491532146930695\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1217 loss: 0.2992209494113922\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 6 step: 1218 loss: 0.21050021052360535\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1219 loss: 0.2345535308122635\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1220 loss: 0.3358350098133087\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1221 loss: 0.32062408328056335\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1222 loss: 0.2995094656944275\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1223 loss: 0.5378142595291138\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1224 loss: 0.3016413748264313\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1225 loss: 0.47246554493904114\n",
      "class 0: acc 0.8125, precision 0.7692, recall 1.0000, f1 0.8696\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1226 loss: 0.2868858575820923\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1227 loss: 0.2434893697500229\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1228 loss: 0.2527902126312256\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1229 loss: 0.638197660446167\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1230 loss: 0.34299084544181824\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1231 loss: 0.31810855865478516\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1232 loss: 0.1944938600063324\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1233 loss: 0.5961437225341797\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8438, precision 0.8333, recall 0.5556, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1234 loss: 0.3141942024230957\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1235 loss: 0.42340123653411865\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1236 loss: 0.30188995599746704\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1237 loss: 0.3333905041217804\n",
      "class 0: acc 0.8750, precision 0.9583, recall 0.8846, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 6 step: 1238 loss: 0.4411887526512146\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1239 loss: 0.5498936772346497\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1240 loss: 0.3052137494087219\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1241 loss: 0.46237674355506897\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1242 loss: 0.25009965896606445\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1243 loss: 0.2254728227853775\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 1244 loss: 0.5362914800643921\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "epoch: 6 step: 1245 loss: 0.25178977847099304\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 6 step: 1246 loss: 0.2598167061805725\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1247 loss: 0.4446048438549042\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1248 loss: 0.34478893876075745\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1249 loss: 0.6250211000442505\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 6 step: 1250 loss: 0.3270418345928192\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1 loss: 0.09569811075925827\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 2 loss: 0.2278652936220169\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 3 loss: 0.47588294744491577\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 4 loss: 0.4239957332611084\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 7 step: 5 loss: 0.32926660776138306\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "epoch: 7 step: 6 loss: 0.35359442234039307\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 7 loss: 0.39038246870040894\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 8 loss: 0.3490138649940491\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 9 loss: 0.4951760172843933\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 7 step: 10 loss: 0.43049517273902893\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 11 loss: 0.22212174534797668\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 12 loss: 0.43547743558883667\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 13 loss: 0.4920433759689331\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 14 loss: 0.14889176189899445\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 15 loss: 0.5094258189201355\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 16 loss: 0.4550275504589081\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 17 loss: 0.4532596468925476\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.8750, precision 0.8571, recall 0.6667, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 18 loss: 0.5565708875656128\n",
      "class 0: acc 0.8125, precision 0.9231, recall 0.8571, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.1667, recall 0.5000, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 19 loss: 0.35874858498573303\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 20 loss: 0.5373462438583374\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.7812, precision 0.2000, recall 0.2500, f1 0.2222\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 21 loss: 0.38042113184928894\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 22 loss: 0.5295448899269104\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 23 loss: 0.5643234252929688\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 24 loss: 0.15172959864139557\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 25 loss: 0.14280572533607483\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 26 loss: 0.4530233144760132\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 27 loss: 0.20323443412780762\n",
      "class 0: acc 0.9375, precision 0.9677, recall 0.9677, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 28 loss: 0.3580869734287262\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "epoch: 7 step: 29 loss: 0.41594886779785156\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 30 loss: 0.42791908979415894\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 7 step: 31 loss: 0.26094621419906616\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 32 loss: 0.3234979212284088\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 33 loss: 0.5087116956710815\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 34 loss: 0.44899582862854004\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 35 loss: 0.5415620803833008\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 7 step: 36 loss: 0.2194777876138687\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 37 loss: 0.2259334772825241\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 38 loss: 0.19945219159126282\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 39 loss: 0.3003678321838379\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 40 loss: 0.18943113088607788\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9333, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 7 step: 41 loss: 0.31705397367477417\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 42 loss: 0.5070841908454895\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 43 loss: 0.42321449518203735\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 44 loss: 0.27762946486473083\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 45 loss: 0.20998424291610718\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 46 loss: 0.49778467416763306\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 47 loss: 0.40693235397338867\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 48 loss: 0.1020580530166626\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 49 loss: 0.4421323537826538\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 50 loss: 0.24146293103694916\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 51 loss: 0.511614203453064\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 52 loss: 0.3161369264125824\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 53 loss: 0.33428946137428284\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 54 loss: 0.3146054446697235\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 55 loss: 0.3981896936893463\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 56 loss: 0.7154179811477661\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 57 loss: 0.33739373087882996\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 58 loss: 0.2610194981098175\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 59 loss: 0.355679988861084\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "epoch: 7 step: 60 loss: 0.5149247050285339\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 61 loss: 0.2510640323162079\n",
      "class 0: acc 0.9375, precision 0.9565, recall 0.9565, f1 0.9565\n",
      "class 1: acc 0.9375, precision 0.8750, recall 0.8750, f1 0.8750\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 62 loss: 0.5422075390815735\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 63 loss: 0.26994889974594116\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 64 loss: 0.10814075171947479\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 65 loss: 0.21474415063858032\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 66 loss: 0.32981136441230774\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 67 loss: 0.1393842101097107\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 68 loss: 0.31751975417137146\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 69 loss: 0.2380935549736023\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 70 loss: 0.2897603213787079\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 71 loss: 0.6249802708625793\n",
      "class 0: acc 0.7500, precision 0.8182, recall 0.8182, f1 0.8182\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 7 step: 72 loss: 0.5469374060630798\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 73 loss: 0.16087596118450165\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 74 loss: 0.2949790954589844\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 75 loss: 0.29149937629699707\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 76 loss: 0.5055808424949646\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 7 step: 77 loss: 0.360336571931839\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 78 loss: 0.3081376552581787\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 79 loss: 0.2132284939289093\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 7 step: 80 loss: 0.4369240403175354\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 81 loss: 0.525288462638855\n",
      "class 0: acc 0.7812, precision 0.7692, recall 0.9524, f1 0.8511\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 82 loss: 0.6244992613792419\n",
      "class 0: acc 0.8125, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 7 step: 83 loss: 0.4199530780315399\n",
      "class 0: acc 0.8750, precision 0.9130, recall 0.9130, f1 0.9130\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 84 loss: 0.37017080187797546\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.9000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 85 loss: 0.2540915310382843\n",
      "class 0: acc 0.8750, precision 0.9630, recall 0.8966, f1 0.9286\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 86 loss: 0.37080085277557373\n",
      "class 0: acc 0.8438, precision 0.8696, recall 0.9091, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 7 step: 87 loss: 0.39046308398246765\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 88 loss: 0.4225427806377411\n",
      "class 0: acc 0.7812, precision 0.9091, recall 0.8000, f1 0.8511\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.2000, recall 1.0000, f1 0.3333\n",
      "epoch: 7 step: 89 loss: 0.25625401735305786\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 90 loss: 0.42648106813430786\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 7 step: 91 loss: 0.40642714500427246\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 92 loss: 0.39165738224983215\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 93 loss: 0.4744757115840912\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 94 loss: 0.34109926223754883\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 95 loss: 0.445659339427948\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 96 loss: 0.5153083205223083\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 97 loss: 0.460208535194397\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8125, precision 0.6000, recall 0.4286, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 98 loss: 0.12569287419319153\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 99 loss: 0.3588732182979584\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 100 loss: 0.2715778946876526\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 101 loss: 0.4571777582168579\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 102 loss: 0.4006233811378479\n",
      "class 0: acc 0.8438, precision 0.9000, recall 0.9310, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 103 loss: 0.3810942769050598\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 104 loss: 0.5516630411148071\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 105 loss: 0.49329596757888794\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 106 loss: 0.45473408699035645\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 107 loss: 0.42181241512298584\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 108 loss: 0.37983739376068115\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 109 loss: 0.6389135122299194\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.7812, precision 0.7500, recall 0.3333, f1 0.4615\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 110 loss: 0.1966344565153122\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 111 loss: 0.40551596879959106\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 112 loss: 0.4238627254962921\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 113 loss: 0.4540405571460724\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 114 loss: 0.44012629985809326\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 115 loss: 0.2607424259185791\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 116 loss: 0.3335111439228058\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 117 loss: 0.3372727632522583\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 118 loss: 0.4668863117694855\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 119 loss: 0.40672504901885986\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 120 loss: 0.2302216738462448\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 121 loss: 0.5702806711196899\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 122 loss: 0.2903957962989807\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 123 loss: 0.3149162828922272\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 124 loss: 0.06690278649330139\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 125 loss: 0.4205469787120819\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 126 loss: 0.35217681527137756\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 127 loss: 0.23815947771072388\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 128 loss: 0.40245321393013\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 129 loss: 0.40052735805511475\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 130 loss: 0.24836117029190063\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 131 loss: 0.23839597404003143\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 132 loss: 0.4688192307949066\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 133 loss: 0.488410621881485\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 134 loss: 0.500740647315979\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.4286, recall 0.7500, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 135 loss: 0.398407518863678\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 136 loss: 0.3076232075691223\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 137 loss: 0.3521490693092346\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 138 loss: 0.15174371004104614\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 139 loss: 0.5573233366012573\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 140 loss: 0.18593406677246094\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 141 loss: 0.3018317222595215\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 142 loss: 0.1813783496618271\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 143 loss: 0.3268979489803314\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 144 loss: 0.4049800634384155\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 145 loss: 0.2554236054420471\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 146 loss: 0.31916162371635437\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 147 loss: 0.662818431854248\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.1429, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 148 loss: 0.11862976849079132\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 149 loss: 0.181791290640831\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 150 loss: 0.39974743127822876\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 151 loss: 0.5832998752593994\n",
      "class 0: acc 0.6875, precision 0.7037, recall 0.9048, f1 0.7917\n",
      "class 1: acc 0.7188, precision 0.4000, recall 0.2500, f1 0.3077\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 152 loss: 0.7490991353988647\n",
      "class 0: acc 0.7500, precision 0.8519, recall 0.8519, f1 0.8519\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 153 loss: 0.33664456009864807\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 154 loss: 0.16943709552288055\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 155 loss: 0.3742285370826721\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 7 step: 156 loss: 0.19431428611278534\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 157 loss: 0.574410617351532\n",
      "class 0: acc 0.8438, precision 0.8750, recall 0.9130, f1 0.8936\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 158 loss: 0.2565724849700928\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 159 loss: 0.2728843688964844\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 160 loss: 0.5618104934692383\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 161 loss: 0.40849682688713074\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 162 loss: 0.5956214070320129\n",
      "class 0: acc 0.7812, precision 0.8800, recall 0.8462, f1 0.8627\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 7 step: 163 loss: 0.28926554322242737\n",
      "class 0: acc 0.8438, precision 0.9231, recall 0.8889, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "epoch: 7 step: 164 loss: 0.31629112362861633\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 165 loss: 0.3706691265106201\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 166 loss: 0.40707874298095703\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 167 loss: 0.2541716992855072\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 168 loss: 0.3679533004760742\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 169 loss: 0.33250516653060913\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 170 loss: 0.41468554735183716\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 171 loss: 0.20354129374027252\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 172 loss: 0.43434399366378784\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 173 loss: 0.39196816086769104\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 174 loss: 0.2204301655292511\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 175 loss: 0.4674834609031677\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 176 loss: 0.5445678234100342\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 177 loss: 0.36650779843330383\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 7 step: 178 loss: 0.43729862570762634\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 179 loss: 0.2882734537124634\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 180 loss: 0.23492130637168884\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 181 loss: 0.4204242527484894\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 182 loss: 0.5066830515861511\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 183 loss: 0.1296675056219101\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 184 loss: 0.31028372049331665\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 185 loss: 0.2750730812549591\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 186 loss: 0.2870636284351349\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 187 loss: 0.19771970808506012\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 188 loss: 0.5958411693572998\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 189 loss: 0.2581331133842468\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 190 loss: 0.28223180770874023\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 191 loss: 0.41667303442955017\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 192 loss: 0.1966586410999298\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 193 loss: 0.33599454164505005\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 194 loss: 0.544829785823822\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 195 loss: 0.4025053381919861\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 196 loss: 0.22687512636184692\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 197 loss: 0.4245009422302246\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 198 loss: 0.5482059121131897\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 199 loss: 0.4230624735355377\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 200 loss: 0.4027946889400482\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 201 loss: 0.6459612846374512\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 202 loss: 0.4462870955467224\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 203 loss: 0.1754278987646103\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 204 loss: 0.29175740480422974\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 205 loss: 0.39560019969940186\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 206 loss: 0.45637378096580505\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 207 loss: 0.5408037900924683\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 208 loss: 0.4936555027961731\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 209 loss: 0.40478548407554626\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 210 loss: 0.4678554832935333\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 211 loss: 0.26138293743133545\n",
      "class 0: acc 0.8750, precision 0.9167, recall 0.9167, f1 0.9167\n",
      "class 1: acc 0.9688, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 212 loss: 0.31931567192077637\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 213 loss: 0.3513593077659607\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 214 loss: 0.31797468662261963\n",
      "class 0: acc 0.8750, precision 0.9630, recall 0.8966, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 215 loss: 0.6121145486831665\n",
      "class 0: acc 0.7500, precision 0.7778, recall 0.9130, f1 0.8400\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 216 loss: 0.4108333885669708\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 217 loss: 0.4934329390525818\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 218 loss: 0.29307013750076294\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 219 loss: 0.34060660004615784\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 220 loss: 0.21038763225078583\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 221 loss: 0.2055828869342804\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 222 loss: 0.33073773980140686\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 223 loss: 0.488389790058136\n",
      "class 0: acc 0.7812, precision 0.7812, recall 1.0000, f1 0.8772\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 224 loss: 0.26530054211616516\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 225 loss: 0.387621134519577\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 226 loss: 0.1357429176568985\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 227 loss: 0.2745853364467621\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 228 loss: 0.08713364601135254\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 229 loss: 0.27759990096092224\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 230 loss: 0.3018827736377716\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 231 loss: 0.4510156512260437\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 232 loss: 0.14612020552158356\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 233 loss: 0.6930994391441345\n",
      "class 0: acc 0.7500, precision 0.7586, recall 0.9565, f1 0.8462\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 234 loss: 0.4612797498703003\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 235 loss: 0.20443958044052124\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 236 loss: 0.29653841257095337\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 237 loss: 0.2786630690097809\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 238 loss: 0.33241090178489685\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 239 loss: 0.2138732522726059\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 240 loss: 0.3452427387237549\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 241 loss: 0.4693085551261902\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 242 loss: 0.4344208240509033\n",
      "class 0: acc 0.8750, precision 0.9565, recall 0.8800, f1 0.9167\n",
      "class 1: acc 0.9688, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 243 loss: 0.4842911958694458\n",
      "class 0: acc 0.7812, precision 0.8400, recall 0.8750, f1 0.8571\n",
      "class 1: acc 0.8125, precision 0.6000, recall 0.4286, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 7 step: 244 loss: 0.46006086468696594\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 7 step: 245 loss: 0.2147083878517151\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 246 loss: 0.37386825680732727\n",
      "class 0: acc 0.8125, precision 0.9231, recall 0.8571, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 247 loss: 0.3309861421585083\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 7 step: 248 loss: 0.6508349776268005\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 249 loss: 0.33832013607025146\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 250 loss: 0.48066049814224243\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 251 loss: 0.4012613892555237\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 252 loss: 0.21854373812675476\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 253 loss: 0.20842483639717102\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 254 loss: 0.29154273867607117\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 255 loss: 0.38369083404541016\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 256 loss: 0.1852005571126938\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 7 step: 257 loss: 0.29271137714385986\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 7 step: 258 loss: 0.2232930213212967\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 259 loss: 0.2827061414718628\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 260 loss: 0.25445520877838135\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 261 loss: 0.17652752995491028\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9375, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 262 loss: 0.703789472579956\n",
      "class 0: acc 0.7188, precision 0.7143, recall 0.9524, f1 0.8163\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 263 loss: 0.428786963224411\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 264 loss: 0.4691217541694641\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 265 loss: 0.5349866151809692\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 266 loss: 0.5038135051727295\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 267 loss: 0.7595975995063782\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 268 loss: 0.35650432109832764\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 269 loss: 0.3256755769252777\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 7 step: 270 loss: 0.37995782494544983\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 271 loss: 0.2265603244304657\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 272 loss: 0.326793909072876\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 273 loss: 0.33025604486465454\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 274 loss: 0.14675433933734894\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 275 loss: 0.4001055359840393\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 276 loss: 0.6831262707710266\n",
      "class 0: acc 0.7812, precision 0.8077, recall 0.9130, f1 0.8571\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 277 loss: 0.2906375825405121\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 7 step: 278 loss: 0.21922942996025085\n",
      "class 0: acc 0.9688, precision 0.9565, recall 1.0000, f1 0.9778\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "epoch: 7 step: 279 loss: 0.3416360318660736\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 7 step: 280 loss: 0.17041034996509552\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 281 loss: 0.2770926058292389\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8889, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 7 step: 282 loss: 0.4367019832134247\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 7 step: 283 loss: 0.27692005038261414\n",
      "class 0: acc 0.8750, precision 0.9600, recall 0.8889, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "epoch: 7 step: 284 loss: 0.2965330481529236\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8929, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.2000, recall 1.0000, f1 0.3333\n",
      "epoch: 7 step: 285 loss: 0.3743877708911896\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 7 step: 286 loss: 0.34361732006073\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 287 loss: 0.5006213784217834\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 288 loss: 0.49191591143608093\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 7 step: 289 loss: 0.3567380905151367\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 290 loss: 0.1883106231689453\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 7 step: 291 loss: 0.6521108150482178\n",
      "class 0: acc 0.9062, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.8438, precision 0.6250, recall 0.7143, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 292 loss: 0.4555529057979584\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 293 loss: 0.29348739981651306\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 294 loss: 0.38753029704093933\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 295 loss: 0.6634632349014282\n",
      "class 0: acc 0.7188, precision 0.7143, recall 0.9524, f1 0.8163\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 296 loss: 0.18109001219272614\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 297 loss: 0.4779872000217438\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 298 loss: 0.23269037902355194\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8846, f1 0.9388\n",
      "class 1: acc 0.8750, precision 0.5556, recall 1.0000, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 299 loss: 0.3242662250995636\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 300 loss: 0.49217474460601807\n",
      "class 0: acc 0.7500, precision 0.8214, recall 0.8846, f1 0.8519\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 301 loss: 0.3911457657814026\n",
      "class 0: acc 0.9375, precision 0.9565, recall 0.9565, f1 0.9565\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 302 loss: 0.3104710876941681\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 303 loss: 0.34775063395500183\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 304 loss: 0.33354219794273376\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 305 loss: 0.26483842730522156\n",
      "class 0: acc 0.8750, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.3750, recall 1.0000, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 306 loss: 0.2979288101196289\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 307 loss: 0.1854918748140335\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 308 loss: 0.1430029273033142\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 309 loss: 0.4377508759498596\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 310 loss: 0.2948758006095886\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 311 loss: 0.13758635520935059\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9677, f1 0.9836\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 312 loss: 0.31259065866470337\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 313 loss: 0.4474225342273712\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 314 loss: 0.13370336592197418\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 315 loss: 0.3856983482837677\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 7 step: 316 loss: 0.2715396583080292\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 317 loss: 0.17049221694469452\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 318 loss: 0.8995382785797119\n",
      "class 0: acc 0.7500, precision 0.7241, recall 1.0000, f1 0.8400\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 319 loss: 0.6580660343170166\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 320 loss: 0.5138257741928101\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 321 loss: 0.4713735282421112\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 322 loss: 0.2540993392467499\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 323 loss: 0.08833244442939758\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 324 loss: 0.23489604890346527\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 325 loss: 0.3559010326862335\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 7 step: 326 loss: 0.21723687648773193\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9259, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 7 step: 327 loss: 0.3345566391944885\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 328 loss: 0.1511981040239334\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 329 loss: 0.30978453159332275\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 330 loss: 0.2368168979883194\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 331 loss: 0.2763786315917969\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 332 loss: 0.21029692888259888\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 333 loss: 0.2580482065677643\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 334 loss: 0.35998737812042236\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 335 loss: 0.3128611445426941\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 336 loss: 0.17557436227798462\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 337 loss: 0.07849394530057907\n",
      "class 0: acc 0.9688, precision 0.9583, recall 1.0000, f1 0.9787\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8889, f1 0.9412\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 338 loss: 0.31219980120658875\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 339 loss: 0.5526122450828552\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 340 loss: 0.37817466259002686\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 341 loss: 0.4392777681350708\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 342 loss: 0.19091343879699707\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "epoch: 7 step: 343 loss: 0.16445747017860413\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 344 loss: 0.3329816162586212\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 345 loss: 0.49942874908447266\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 346 loss: 0.28187018632888794\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 7 step: 347 loss: 0.29968181252479553\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 348 loss: 0.21536564826965332\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 349 loss: 0.12112019211053848\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 350 loss: 0.3415132462978363\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 351 loss: 0.3916284441947937\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 352 loss: 0.2278580218553543\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 353 loss: 0.5868700742721558\n",
      "class 0: acc 0.7812, precision 0.8800, recall 0.8462, f1 0.8627\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 354 loss: 0.284428209066391\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.7000, f1 0.8235\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 355 loss: 0.161753848195076\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 356 loss: 0.1804063320159912\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 357 loss: 0.3960704803466797\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 358 loss: 0.24940325319766998\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 359 loss: 0.28837281465530396\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 360 loss: 0.5170755982398987\n",
      "class 0: acc 0.8438, precision 0.7826, recall 1.0000, f1 0.8780\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.8182, f1 0.9000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 361 loss: 0.39722105860710144\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 362 loss: 0.20258529484272003\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 363 loss: 0.18871523439884186\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 364 loss: 0.4818938672542572\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 365 loss: 0.23289909958839417\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 366 loss: 0.2529136538505554\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 367 loss: 0.1330481767654419\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 368 loss: 0.44966235756874084\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 369 loss: 0.38066500425338745\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 370 loss: 0.3474808931350708\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 7 step: 371 loss: 0.15851609408855438\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 372 loss: 0.12379389256238937\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 373 loss: 0.14886587858200073\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 374 loss: 0.3892762362957001\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 375 loss: 0.6587478518486023\n",
      "class 0: acc 0.7188, precision 0.7407, recall 0.9091, f1 0.8163\n",
      "class 1: acc 0.7812, precision 0.4000, recall 0.3333, f1 0.3636\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 376 loss: 0.3767930567264557\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 377 loss: 0.23042874038219452\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 378 loss: 0.4641154110431671\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 379 loss: 0.31022027134895325\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 380 loss: 0.07645370811223984\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 381 loss: 0.11655836552381516\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 382 loss: 0.4394683241844177\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 383 loss: 0.7067246437072754\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 384 loss: 0.14196692407131195\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 385 loss: 0.27750134468078613\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 386 loss: 0.26452773809432983\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 387 loss: 0.3362860679626465\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 388 loss: 0.3825664818286896\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 389 loss: 0.48323750495910645\n",
      "class 0: acc 0.8438, precision 0.8696, recall 0.9091, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.7778, recall 0.7778, f1 0.7778\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 390 loss: 0.37097102403640747\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 391 loss: 0.31618553400039673\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 7 step: 392 loss: 0.2644577622413635\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 393 loss: 0.1201615259051323\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 394 loss: 0.40015602111816406\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 395 loss: 0.39085936546325684\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 396 loss: 0.2967309057712555\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 397 loss: 0.29197314381599426\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 398 loss: 0.654466986656189\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 399 loss: 0.23183725774288177\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 400 loss: 0.05806248262524605\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 401 loss: 0.07023599743843079\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 402 loss: 0.24531228840351105\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 403 loss: 0.21222321689128876\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 404 loss: 1.032524824142456\n",
      "class 0: acc 0.6250, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 405 loss: 0.2910017669200897\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 406 loss: 0.16498054563999176\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 407 loss: 0.7529866099357605\n",
      "class 0: acc 0.7500, precision 0.8000, recall 0.9231, f1 0.8571\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 408 loss: 0.47771909832954407\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 409 loss: 0.4830075800418854\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 410 loss: 0.4193294644355774\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 411 loss: 0.18852092325687408\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 412 loss: 0.4167611300945282\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 413 loss: 0.512733519077301\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 414 loss: 0.27521923184394836\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 415 loss: 0.4484495222568512\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 416 loss: 0.2807016372680664\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 417 loss: 0.2974306046962738\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 418 loss: 0.5107842087745667\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 419 loss: 0.21889042854309082\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 7 step: 420 loss: 0.3496645390987396\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 421 loss: 0.42201510071754456\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 422 loss: 0.4190853238105774\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 423 loss: 0.3875415027141571\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 424 loss: 0.3216651678085327\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 425 loss: 0.4699248969554901\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 426 loss: 0.39253634214401245\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 427 loss: 0.2044759839773178\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 428 loss: 0.33883535861968994\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 429 loss: 0.2747420072555542\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 430 loss: 0.3352939486503601\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 431 loss: 0.291683554649353\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 432 loss: 0.43835633993148804\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 433 loss: 0.1824190765619278\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 434 loss: 0.24928276240825653\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 435 loss: 0.42799046635627747\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 436 loss: 0.20113469660282135\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 437 loss: 0.6201725006103516\n",
      "class 0: acc 0.7500, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 438 loss: 0.39452287554740906\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 439 loss: 0.4006045162677765\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 440 loss: 0.5160990357398987\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 441 loss: 0.2841978669166565\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 7 step: 442 loss: 0.28805485367774963\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 443 loss: 0.7654008865356445\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 444 loss: 0.09640994668006897\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 445 loss: 0.1907014399766922\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 7 step: 446 loss: 0.4636642634868622\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 447 loss: 0.3581753075122833\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 448 loss: 0.47041621804237366\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 449 loss: 0.3723018765449524\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 450 loss: 0.3370259702205658\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 451 loss: 0.07907436043024063\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 452 loss: 0.6339941024780273\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 453 loss: 0.37559905648231506\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 454 loss: 0.1662832349538803\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 455 loss: 0.17000459134578705\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9333, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 456 loss: 0.39529669284820557\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 457 loss: 0.19704028964042664\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 458 loss: 0.45099934935569763\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 459 loss: 0.5257524847984314\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 460 loss: 0.371806800365448\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 461 loss: 0.21970227360725403\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 462 loss: 0.38526979088783264\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 463 loss: 0.354990690946579\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 7 step: 464 loss: 0.36715880036354065\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 7 step: 465 loss: 0.5404394865036011\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 466 loss: 0.37861764430999756\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 467 loss: 0.22641190886497498\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 468 loss: 0.33657702803611755\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 469 loss: 0.1889410763978958\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 470 loss: 0.3770348131656647\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 7 step: 471 loss: 0.2725364565849304\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 472 loss: 0.25592613220214844\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 473 loss: 0.49527278542518616\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 474 loss: 0.120407834649086\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 475 loss: 0.501603364944458\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.7500, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 476 loss: 0.2817644774913788\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8846, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 7 step: 477 loss: 0.4438072144985199\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 478 loss: 0.44377219676971436\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 479 loss: 0.3890798091888428\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 480 loss: 0.3906799554824829\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 481 loss: 0.5875683426856995\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 7 step: 482 loss: 0.2304181456565857\n",
      "class 0: acc 0.8438, precision 1.0000, recall 0.8276, f1 0.9057\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 483 loss: 0.15804201364517212\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 484 loss: 0.6231432557106018\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 485 loss: 0.37996238470077515\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 486 loss: 0.3831402063369751\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 487 loss: 0.41171982884407043\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 488 loss: 0.19421139359474182\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 489 loss: 0.3970845341682434\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 490 loss: 0.32700106501579285\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 491 loss: 0.33986228704452515\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 492 loss: 0.4303394556045532\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 493 loss: 0.39127328991889954\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 494 loss: 0.23906831443309784\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 495 loss: 0.3865649998188019\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 496 loss: 0.24251079559326172\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 497 loss: 0.16629470884799957\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 498 loss: 0.5664653778076172\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "epoch: 7 step: 499 loss: 0.1681242287158966\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 500 loss: 0.443747341632843\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 501 loss: 0.3234873414039612\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 502 loss: 0.16340109705924988\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9355, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 503 loss: 0.3088223338127136\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 504 loss: 0.4645739197731018\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 7 step: 505 loss: 0.18631671369075775\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 506 loss: 0.5778672695159912\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 507 loss: 0.4470386803150177\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 508 loss: 0.39240241050720215\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 509 loss: 0.46975788474082947\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 510 loss: 0.3616647720336914\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 511 loss: 0.3837100863456726\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 512 loss: 0.402743399143219\n",
      "class 0: acc 0.8438, precision 0.9091, recall 0.8696, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 7 step: 513 loss: 0.4473186433315277\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 514 loss: 0.30643290281295776\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 515 loss: 0.26996904611587524\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 516 loss: 0.4416680335998535\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 517 loss: 0.45084792375564575\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 518 loss: 0.2489919811487198\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 519 loss: 0.31688210368156433\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 520 loss: 0.14942200481891632\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 521 loss: 0.33183756470680237\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 522 loss: 0.2990071475505829\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 523 loss: 0.2855192720890045\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 524 loss: 0.5396729707717896\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 525 loss: 0.5755126476287842\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.7812, precision 0.3333, recall 0.1667, f1 0.2222\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 526 loss: 0.3007716238498688\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 527 loss: 0.4147531986236572\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 528 loss: 0.4828842878341675\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 529 loss: 0.6421934366226196\n",
      "class 0: acc 0.7500, precision 0.7778, recall 0.9130, f1 0.8400\n",
      "class 1: acc 0.7812, precision 0.2500, recall 0.2000, f1 0.2222\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 7 step: 530 loss: 0.5384383201599121\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 531 loss: 0.24679061770439148\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 7 step: 532 loss: 0.12072811275720596\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 533 loss: 0.11431407183408737\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 534 loss: 0.6317485570907593\n",
      "class 0: acc 0.7188, precision 0.7333, recall 0.9565, f1 0.8302\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 535 loss: 0.3462541997432709\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 536 loss: 0.6724401712417603\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 537 loss: 0.29058322310447693\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 538 loss: 0.2987390458583832\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 539 loss: 0.35765957832336426\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 540 loss: 0.32234838604927063\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 541 loss: 0.2975093424320221\n",
      "class 0: acc 0.9688, precision 0.9583, recall 1.0000, f1 0.9787\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 542 loss: 0.4713691771030426\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 543 loss: 0.5173392295837402\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 544 loss: 0.3899747133255005\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 545 loss: 0.36379939317703247\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 546 loss: 0.27811095118522644\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 547 loss: 0.21117261052131653\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 548 loss: 0.18350005149841309\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 549 loss: 0.2616005837917328\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 550 loss: 0.4671701192855835\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 551 loss: 0.5089997053146362\n",
      "class 0: acc 0.7812, precision 0.7692, recall 0.9524, f1 0.8511\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 7 step: 552 loss: 0.2383173406124115\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 553 loss: 0.39335381984710693\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 554 loss: 0.3592277765274048\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 555 loss: 0.7777346968650818\n",
      "class 0: acc 0.7500, precision 0.7667, recall 0.9583, f1 0.8519\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 556 loss: 0.19412994384765625\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 557 loss: 0.4367399215698242\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 558 loss: 0.47948309779167175\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 559 loss: 0.27204862236976624\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 560 loss: 0.1655925214290619\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 561 loss: 0.30993515253067017\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 562 loss: 0.4616212844848633\n",
      "class 0: acc 0.7812, precision 0.8519, recall 0.8846, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 563 loss: 0.26723769307136536\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 564 loss: 0.6813635230064392\n",
      "class 0: acc 0.7500, precision 0.7586, recall 0.9565, f1 0.8462\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 565 loss: 0.246281236410141\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 566 loss: 0.6496313810348511\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 567 loss: 0.6107238531112671\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 568 loss: 0.38145920634269714\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 569 loss: 0.4125121235847473\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 570 loss: 0.6046712398529053\n",
      "class 0: acc 0.6875, precision 0.6786, recall 0.9500, f1 0.7917\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 571 loss: 0.3567739427089691\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 572 loss: 0.4131934344768524\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 573 loss: 0.5114458799362183\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 574 loss: 0.45176956057548523\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 575 loss: 0.29062339663505554\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 576 loss: 0.3292006552219391\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 577 loss: 0.4385219216346741\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 578 loss: 0.47138574719429016\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 579 loss: 0.3710228204727173\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 580 loss: 0.39988312125205994\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 581 loss: 0.2985161244869232\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 582 loss: 0.32050013542175293\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 583 loss: 0.45178356766700745\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 584 loss: 0.32438772916793823\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 585 loss: 0.2289368361234665\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 586 loss: 0.5734759569168091\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 587 loss: 0.22616754472255707\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 588 loss: 0.38706058263778687\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 589 loss: 0.5749491453170776\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 590 loss: 0.32065349817276\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 591 loss: 0.2630155086517334\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 592 loss: 0.26518455147743225\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 593 loss: 0.2330971658229828\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 594 loss: 0.39014145731925964\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 595 loss: 0.37235915660858154\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 596 loss: 0.35313889384269714\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 597 loss: 0.26798588037490845\n",
      "class 0: acc 0.9375, precision 0.9167, recall 1.0000, f1 0.9565\n",
      "class 1: acc 0.9375, precision 0.8750, recall 0.8750, f1 0.8750\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 598 loss: 0.2852730453014374\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9600, f1 0.9796\n",
      "class 1: acc 0.9375, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 599 loss: 0.2538246512413025\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 7 step: 600 loss: 0.45968499779701233\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 601 loss: 0.3741597831249237\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 602 loss: 0.2565171718597412\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 603 loss: 0.203603133559227\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 604 loss: 0.1973126232624054\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 605 loss: 0.2102767825126648\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 606 loss: 0.47931283712387085\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 607 loss: 0.3628668189048767\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 608 loss: 0.35953980684280396\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 609 loss: 0.2249259352684021\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 610 loss: 0.3383350372314453\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 611 loss: 0.26522770524024963\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 612 loss: 0.26109275221824646\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 613 loss: 0.2911769151687622\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 614 loss: 0.2839471101760864\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8966, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "epoch: 7 step: 615 loss: 0.25629717111587524\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "epoch: 7 step: 616 loss: 0.39173051714897156\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 617 loss: 0.34834548830986023\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "epoch: 7 step: 618 loss: 0.40883857011795044\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 7 step: 619 loss: 0.5078101754188538\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "epoch: 7 step: 620 loss: 0.5642331838607788\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9091, f1 0.8696\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 7 step: 621 loss: 0.3912702798843384\n",
      "class 0: acc 0.8750, precision 0.9565, recall 0.8800, f1 0.9167\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8438, precision 0.3333, recall 0.6667, f1 0.4444\n",
      "epoch: 7 step: 622 loss: 0.4453086853027344\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 623 loss: 0.31803134083747864\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 624 loss: 0.23843398690223694\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 7 step: 625 loss: 0.4446370303630829\n",
      "class 0: acc 0.8438, precision 0.8400, recall 0.9545, f1 0.8936\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "epoch: 7 step: 626 loss: 0.3731411099433899\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.8438, precision 0.3750, recall 1.0000, f1 0.5455\n",
      "epoch: 7 step: 627 loss: 0.5685515999794006\n",
      "class 0: acc 0.7812, precision 0.9130, recall 0.8077, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.7812, precision 0.1429, recall 0.5000, f1 0.2222\n",
      "epoch: 7 step: 628 loss: 0.3831865191459656\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 629 loss: 0.31379255652427673\n",
      "class 0: acc 0.8125, precision 0.9200, recall 0.8519, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 630 loss: 0.3338911235332489\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 7 step: 631 loss: 0.4046685993671417\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 7 step: 632 loss: 0.32153889536857605\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 633 loss: 0.17933709919452667\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9333, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 634 loss: 0.24171999096870422\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 635 loss: 0.45666173100471497\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 636 loss: 0.27062949538230896\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 637 loss: 0.334611713886261\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 638 loss: 0.2857550084590912\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 639 loss: 0.42417624592781067\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 640 loss: 0.32463160157203674\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 641 loss: 0.26413699984550476\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 642 loss: 0.2688947319984436\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9355, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 643 loss: 0.3585282266139984\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 644 loss: 0.5781428217887878\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 645 loss: 0.42364078760147095\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 646 loss: 0.5866318941116333\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 647 loss: 0.5077813863754272\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 648 loss: 0.25637948513031006\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 649 loss: 0.13164064288139343\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 650 loss: 0.5240918397903442\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 651 loss: 0.6450731754302979\n",
      "class 0: acc 0.7500, precision 0.7931, recall 0.9200, f1 0.8519\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 652 loss: 0.36248981952667236\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 653 loss: 0.43979743123054504\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 654 loss: 0.48008963465690613\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 655 loss: 0.3031674027442932\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 656 loss: 0.5044882297515869\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 657 loss: 0.297619104385376\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 658 loss: 0.45751073956489563\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 659 loss: 0.19297653436660767\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 660 loss: 0.1963517814874649\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 661 loss: 0.4033045470714569\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 662 loss: 0.3321129083633423\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 663 loss: 0.41474300622940063\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 664 loss: 0.301771879196167\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 665 loss: 0.23595382273197174\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 666 loss: 0.6135827302932739\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 667 loss: 0.2447306513786316\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 668 loss: 0.4930810332298279\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 669 loss: 0.3360820710659027\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 670 loss: 0.3458646237850189\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 671 loss: 0.8044848442077637\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 672 loss: 0.3479617238044739\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 673 loss: 0.15490451455116272\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 674 loss: 0.4195541441440582\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 675 loss: 0.29529500007629395\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 676 loss: 0.22770929336547852\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 677 loss: 0.22411790490150452\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 678 loss: 0.3576940894126892\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 679 loss: 0.46709340810775757\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 680 loss: 0.40295475721359253\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 681 loss: 0.3954707086086273\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 682 loss: 0.18404389917850494\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.7000, f1 0.8235\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 683 loss: 0.2335999608039856\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 684 loss: 0.2560342848300934\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 685 loss: 0.4864899814128876\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 686 loss: 0.3821161687374115\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 687 loss: 0.1724240630865097\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 688 loss: 0.33803579211235046\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 689 loss: 0.330980122089386\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 690 loss: 0.5512470006942749\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 691 loss: 0.17414766550064087\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 692 loss: 0.5099902749061584\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 693 loss: 0.5637702345848083\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 694 loss: 0.37479764223098755\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 695 loss: 0.3767814040184021\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 696 loss: 0.2433650642633438\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 697 loss: 0.53203284740448\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 698 loss: 0.43209147453308105\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 699 loss: 0.28080329298973083\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 700 loss: 0.2895604372024536\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 701 loss: 0.4963470995426178\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 702 loss: 0.4077862501144409\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 703 loss: 0.23890073597431183\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 704 loss: 0.2223035991191864\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 705 loss: 0.15259017050266266\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 706 loss: 0.17055557668209076\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 707 loss: 0.30181530117988586\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 708 loss: 0.3012447655200958\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 709 loss: 0.3698822259902954\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 710 loss: 0.3731919825077057\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 711 loss: 0.38138848543167114\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 712 loss: 0.2565409243106842\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 713 loss: 0.4323875606060028\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 714 loss: 0.28947925567626953\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 715 loss: 0.3542490005493164\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 716 loss: 0.5255016684532166\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 717 loss: 0.3757597506046295\n",
      "class 0: acc 0.8438, precision 0.9286, recall 0.8966, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 718 loss: 0.21334458887577057\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 719 loss: 0.29263585805892944\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 720 loss: 0.26714298129081726\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 721 loss: 0.3553294837474823\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 722 loss: 0.35478493571281433\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 723 loss: 0.3548203110694885\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 724 loss: 0.46237725019454956\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 725 loss: 0.20227576792240143\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 726 loss: 0.23915526270866394\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 727 loss: 0.5769833922386169\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 728 loss: 0.1645556092262268\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 729 loss: 0.4384404420852661\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 730 loss: 0.17930902540683746\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 731 loss: 0.6028693318367004\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 732 loss: 0.4692302346229553\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 733 loss: 0.4330272972583771\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 734 loss: 0.4306580722332001\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 735 loss: 0.22859202325344086\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 736 loss: 0.2217763513326645\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 737 loss: 0.24208295345306396\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 738 loss: 0.4567861557006836\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 739 loss: 0.29357627034187317\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 740 loss: 0.33495861291885376\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 741 loss: 0.25619909167289734\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 742 loss: 0.6055608987808228\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 743 loss: 0.2364581823348999\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 744 loss: 0.2748156189918518\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 745 loss: 0.34603068232536316\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 746 loss: 0.4640887677669525\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 747 loss: 0.27942731976509094\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 748 loss: 0.4571031928062439\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 749 loss: 0.2604469954967499\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 750 loss: 0.3665649890899658\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 751 loss: 0.3678446114063263\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 752 loss: 0.4218635559082031\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 753 loss: 0.28214898705482483\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 754 loss: 0.32789361476898193\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 755 loss: 0.1972232609987259\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 756 loss: 0.2227180302143097\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 757 loss: 0.33306798338890076\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 758 loss: 0.220783993601799\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 759 loss: 0.2390705794095993\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 760 loss: 0.28806591033935547\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 761 loss: 0.28630638122558594\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 762 loss: 0.15354932844638824\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 763 loss: 0.4668300747871399\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 764 loss: 0.29549646377563477\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 765 loss: 0.8885367512702942\n",
      "class 0: acc 0.7188, precision 0.8000, recall 0.8333, f1 0.8163\n",
      "class 1: acc 0.7500, precision 0.4286, recall 0.4286, f1 0.4286\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 766 loss: 0.46166178584098816\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 767 loss: 0.23505949974060059\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 768 loss: 0.2147524356842041\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 769 loss: 0.15032099187374115\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 770 loss: 0.2864733338356018\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 771 loss: 0.1892499327659607\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 772 loss: 0.4069482386112213\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 773 loss: 0.2936459183692932\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 774 loss: 0.5160019397735596\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 775 loss: 0.20604170858860016\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 776 loss: 0.24727796018123627\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 777 loss: 0.6291687488555908\n",
      "class 0: acc 0.7500, precision 0.7241, recall 1.0000, f1 0.8400\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 778 loss: 0.2822107970714569\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 779 loss: 0.33537042140960693\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 780 loss: 0.32201656699180603\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 781 loss: 0.3346976637840271\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 782 loss: 0.4621719717979431\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 7 step: 783 loss: 0.22004683315753937\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 784 loss: 0.4638546407222748\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 7 step: 785 loss: 0.35245975852012634\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 786 loss: 0.22776849567890167\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 0.9688, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 787 loss: 0.41153356432914734\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 788 loss: 0.34222668409347534\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 789 loss: 0.4451345205307007\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 790 loss: 0.5063064098358154\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9375, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 791 loss: 0.37718465924263\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 792 loss: 0.2863108217716217\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 793 loss: 0.40804269909858704\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 794 loss: 0.27339988946914673\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 795 loss: 0.27319371700286865\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.8438, precision 0.8333, recall 0.5556, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 796 loss: 0.30182987451553345\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 797 loss: 0.4563174545764923\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 798 loss: 0.4031166732311249\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 799 loss: 0.14703121781349182\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 800 loss: 0.2896057367324829\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 801 loss: 0.46946442127227783\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 802 loss: 0.49329113960266113\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 803 loss: 0.4536293148994446\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 804 loss: 0.29187509417533875\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 805 loss: 0.1657198965549469\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 806 loss: 0.3279512822628021\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 807 loss: 0.4320901930332184\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 808 loss: 0.36315983533859253\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 809 loss: 0.2711030840873718\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 810 loss: 0.18543560802936554\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 811 loss: 0.4100852310657501\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 812 loss: 0.3521306812763214\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 813 loss: 0.2670397162437439\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 814 loss: 0.3636479079723358\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 815 loss: 0.48137322068214417\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 816 loss: 0.38831931352615356\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 817 loss: 0.4635045826435089\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 818 loss: 0.6832220554351807\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 819 loss: 0.36415424942970276\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 820 loss: 0.4119480550289154\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 821 loss: 0.3248525857925415\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 822 loss: 0.23640266060829163\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 823 loss: 0.46521076560020447\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 824 loss: 0.5745536088943481\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 7 step: 825 loss: 0.36565059423446655\n",
      "class 0: acc 0.9062, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.8750, recall 0.7778, f1 0.8235\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 826 loss: 0.3106464743614197\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 827 loss: 0.35810407996177673\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 828 loss: 0.4374058246612549\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 829 loss: 0.3981810510158539\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 830 loss: 0.2689899206161499\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 831 loss: 0.30656203627586365\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 832 loss: 0.2503032386302948\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 833 loss: 0.29893869161605835\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 834 loss: 0.2390984445810318\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 835 loss: 0.5846712589263916\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 836 loss: 0.41238221526145935\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 837 loss: 0.2202039361000061\n",
      "class 0: acc 0.8750, precision 0.9333, recall 0.9333, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 838 loss: 0.2665502727031708\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 839 loss: 0.44160062074661255\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 840 loss: 0.1458987146615982\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 841 loss: 0.3772949278354645\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 842 loss: 0.34062644839286804\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 843 loss: 0.22654402256011963\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 844 loss: 0.3227972090244293\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 845 loss: 0.2698657512664795\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 846 loss: 0.20976369082927704\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 847 loss: 0.4828927218914032\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 848 loss: 0.3910389840602875\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 849 loss: 0.5219318866729736\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 850 loss: 0.1935017853975296\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 851 loss: 0.2623342275619507\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 852 loss: 0.1351350098848343\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 853 loss: 0.2660549283027649\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 854 loss: 0.23132619261741638\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 855 loss: 0.35161346197128296\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 856 loss: 0.4593868553638458\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 857 loss: 0.40106943249702454\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 858 loss: 0.2146073877811432\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 859 loss: 0.2931663990020752\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 860 loss: 0.3496357798576355\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 861 loss: 0.5404190421104431\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 862 loss: 0.5380509495735168\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 863 loss: 0.46580758690834045\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 864 loss: 0.2022343873977661\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 865 loss: 0.2717752754688263\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 866 loss: 0.3805294632911682\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 867 loss: 0.14224138855934143\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 868 loss: 0.5614195466041565\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 869 loss: 0.37608104944229126\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 870 loss: 0.7124229073524475\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 871 loss: 0.3504527807235718\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 872 loss: 0.4902031719684601\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 873 loss: 0.22152923047542572\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 874 loss: 0.330946683883667\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 875 loss: 0.4300577938556671\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 876 loss: 0.6670231819152832\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 877 loss: 0.3852011263370514\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 878 loss: 0.3392829895019531\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 879 loss: 0.4245506823062897\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 880 loss: 0.2905048131942749\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 7 step: 881 loss: 0.20419439673423767\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 882 loss: 0.2202465534210205\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 883 loss: 0.2218281328678131\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 884 loss: 0.23680059611797333\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 885 loss: 0.2995999753475189\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 886 loss: 0.5477986335754395\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 887 loss: 0.4960654377937317\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 888 loss: 0.28561481833457947\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 889 loss: 0.3150536119937897\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 890 loss: 0.3227037787437439\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 891 loss: 0.2806764841079712\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 892 loss: 0.4358474612236023\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 7 step: 893 loss: 0.0473315604031086\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 894 loss: 0.5757434368133545\n",
      "class 0: acc 0.8125, precision 0.8800, recall 0.8800, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.4286, recall 0.7500, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 895 loss: 0.3336922228336334\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 7 step: 896 loss: 0.43766799569129944\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 897 loss: 0.2799816131591797\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 898 loss: 0.39559614658355713\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 899 loss: 0.15315431356430054\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 900 loss: 0.3088553845882416\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 901 loss: 0.3100103735923767\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 902 loss: 0.18913811445236206\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 903 loss: 0.22050337493419647\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 904 loss: 0.8270397186279297\n",
      "class 0: acc 0.7188, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 905 loss: 0.5127583742141724\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 906 loss: 0.23766851425170898\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 907 loss: 0.4587976932525635\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 908 loss: 0.12974610924720764\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 909 loss: 0.20620441436767578\n",
      "class 0: acc 0.9688, precision 0.9688, recall 1.0000, f1 0.9841\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 910 loss: 0.43902117013931274\n",
      "class 0: acc 0.8438, precision 0.8750, recall 0.9130, f1 0.8936\n",
      "class 1: acc 0.8438, precision 0.7143, recall 0.6250, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 911 loss: 0.33366289734840393\n",
      "class 0: acc 0.9688, precision 0.9600, recall 1.0000, f1 0.9796\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 912 loss: 0.22783294320106506\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 913 loss: 0.5166986584663391\n",
      "class 0: acc 0.7500, precision 0.7931, recall 0.9200, f1 0.8519\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 914 loss: 0.233873650431633\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 915 loss: 0.43633806705474854\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 916 loss: 0.16201524436473846\n",
      "class 0: acc 0.9375, precision 0.9677, recall 0.9677, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 917 loss: 0.4246741235256195\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 918 loss: 0.6329807043075562\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 919 loss: 0.16571182012557983\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 920 loss: 0.4133695960044861\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 921 loss: 0.41960424184799194\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 922 loss: 0.7197695374488831\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 923 loss: 0.2750947177410126\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 924 loss: 0.4976581335067749\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 925 loss: 0.38155442476272583\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 926 loss: 0.22046628594398499\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 927 loss: 0.22614336013793945\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 928 loss: 0.1563080996274948\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 929 loss: 0.22704234719276428\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 930 loss: 0.42709195613861084\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 931 loss: 0.2998882234096527\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 932 loss: 0.1695219725370407\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 933 loss: 0.2380835860967636\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 934 loss: 0.3907659351825714\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 935 loss: 0.3271375894546509\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 936 loss: 0.4527881145477295\n",
      "class 0: acc 0.8750, precision 0.9615, recall 0.8929, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 937 loss: 0.6817455291748047\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 938 loss: 0.37758496403694153\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 939 loss: 0.284756064414978\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 940 loss: 0.18605001270771027\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 941 loss: 0.4674866199493408\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 942 loss: 0.1435435563325882\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 943 loss: 0.41604724526405334\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 944 loss: 0.3507731258869171\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 945 loss: 0.5567048788070679\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 946 loss: 0.5424066185951233\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 947 loss: 0.5256050825119019\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 948 loss: 0.35319849848747253\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 949 loss: 0.222137451171875\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 950 loss: 0.19469135999679565\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 951 loss: 0.25816768407821655\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 952 loss: 0.37623435258865356\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 953 loss: 0.2779003083705902\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 954 loss: 0.17609594762325287\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 955 loss: 0.25474587082862854\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 956 loss: 0.5394121408462524\n",
      "class 0: acc 0.7188, precision 0.7241, recall 0.9545, f1 0.8235\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 957 loss: 0.2757546007633209\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 958 loss: 0.2744239270687103\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 959 loss: 0.16943730413913727\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 960 loss: 0.5260429978370667\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 961 loss: 0.42117825150489807\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 962 loss: 0.2194191962480545\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 963 loss: 0.267887681722641\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 964 loss: 0.17862623929977417\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 965 loss: 0.28769421577453613\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 966 loss: 0.5697945952415466\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 967 loss: 0.5527613162994385\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 968 loss: 0.1710914820432663\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 969 loss: 0.2781302332878113\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9286, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 970 loss: 0.2593226432800293\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 971 loss: 0.4130869507789612\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 972 loss: 0.6830487847328186\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.7812, precision 0.1667, recall 0.3333, f1 0.2222\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 973 loss: 0.14367012679576874\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 974 loss: 0.2697064280509949\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 975 loss: 0.5468857288360596\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 976 loss: 0.3522702157497406\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 977 loss: 0.3838883340358734\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 978 loss: 0.44674813747406006\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 979 loss: 0.3058331608772278\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 980 loss: 0.2951275110244751\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 981 loss: 0.20573875308036804\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 982 loss: 0.2933535873889923\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 983 loss: 0.44172006845474243\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 984 loss: 0.29630112648010254\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 985 loss: 0.6244127154350281\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 986 loss: 0.29286035895347595\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 987 loss: 0.2684895396232605\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 988 loss: 0.2790645956993103\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 989 loss: 0.33016490936279297\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 990 loss: 0.37226882576942444\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 991 loss: 0.31179285049438477\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 992 loss: 0.2079349160194397\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 993 loss: 0.2787785232067108\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 994 loss: 0.37032169103622437\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 995 loss: 0.2793571650981903\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 996 loss: 0.3834075927734375\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 997 loss: 0.7451780438423157\n",
      "class 0: acc 0.7188, precision 0.7419, recall 0.9583, f1 0.8364\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 998 loss: 0.587147057056427\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 999 loss: 0.22643974423408508\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1000 loss: 0.4952806234359741\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1001 loss: 0.3485974371433258\n",
      "class 0: acc 0.9375, precision 0.9200, recall 1.0000, f1 0.9583\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1002 loss: 0.7464939951896667\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1003 loss: 0.3436288833618164\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1004 loss: 0.2645658552646637\n",
      "class 0: acc 0.9688, precision 0.9583, recall 1.0000, f1 0.9787\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1005 loss: 0.27427664399147034\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1006 loss: 0.5128621459007263\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1007 loss: 0.2462182492017746\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1008 loss: 0.5168826580047607\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1009 loss: 0.32098203897476196\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1010 loss: 0.2880170941352844\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1011 loss: 0.3395494222640991\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1012 loss: 0.41105782985687256\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1013 loss: 0.2868621051311493\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1014 loss: 0.20281539857387543\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1015 loss: 0.34019795060157776\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1016 loss: 0.34982889890670776\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1017 loss: 0.36768725514411926\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 7 step: 1018 loss: 0.24275724589824677\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1019 loss: 0.3350711166858673\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1020 loss: 0.22707006335258484\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 7 step: 1021 loss: 0.4722587466239929\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1022 loss: 0.32919570803642273\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1023 loss: 0.2886866331100464\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1024 loss: 0.5557188391685486\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1025 loss: 0.5226085186004639\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1026 loss: 0.3445495367050171\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1027 loss: 0.20616312325000763\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1028 loss: 0.3246079981327057\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1029 loss: 0.22742541134357452\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1030 loss: 0.419678270816803\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1031 loss: 0.35728445649147034\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1032 loss: 0.34157833456993103\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1033 loss: 0.6220014691352844\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1034 loss: 0.23706568777561188\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1035 loss: 0.6164408922195435\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1036 loss: 0.32333019375801086\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1037 loss: 0.29054689407348633\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1038 loss: 0.39585548639297485\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.6000, recall 0.4286, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1039 loss: 0.38389915227890015\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1040 loss: 0.16509483754634857\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1041 loss: 0.20414918661117554\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1042 loss: 0.3619568645954132\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1043 loss: 0.335296094417572\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1044 loss: 0.4772726595401764\n",
      "class 0: acc 0.7812, precision 0.8065, recall 0.9615, f1 0.8772\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1045 loss: 0.3841187655925751\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1046 loss: 0.21169552206993103\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1047 loss: 0.22297963500022888\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1048 loss: 0.13432680070400238\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1049 loss: 0.49987417459487915\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1050 loss: 0.25539034605026245\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1051 loss: 0.15313850343227386\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1052 loss: 0.8601022362709045\n",
      "class 0: acc 0.7188, precision 0.7000, recall 1.0000, f1 0.8235\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1053 loss: 0.49278953671455383\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1054 loss: 0.452533483505249\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1055 loss: 0.3401739001274109\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1056 loss: 0.4174962639808655\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1057 loss: 0.4628138542175293\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1058 loss: 0.3804645538330078\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1059 loss: 0.20308846235275269\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1060 loss: 0.3970341682434082\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 7 step: 1061 loss: 0.3819977343082428\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1062 loss: 0.19341853260993958\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1063 loss: 0.44373610615730286\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1064 loss: 0.3278813064098358\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1065 loss: 0.33288800716400146\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1066 loss: 0.6492777466773987\n",
      "class 0: acc 0.6875, precision 0.6875, recall 1.0000, f1 0.8148\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1067 loss: 0.37573307752609253\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1068 loss: 0.4913521111011505\n",
      "class 0: acc 0.7812, precision 0.7308, recall 1.0000, f1 0.8444\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1069 loss: 0.17425549030303955\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1070 loss: 0.4389612376689911\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1071 loss: 0.36542072892189026\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1072 loss: 0.4696882367134094\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1073 loss: 0.540203869342804\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1074 loss: 0.28052806854248047\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1075 loss: 0.4998078942298889\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1076 loss: 0.3392558991909027\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 7 step: 1077 loss: 0.4196406304836273\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1078 loss: 0.31641820073127747\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1079 loss: 0.2735807001590729\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1080 loss: 0.154619500041008\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1081 loss: 0.3523179292678833\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1082 loss: 0.42498937249183655\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1083 loss: 0.26840218901634216\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1084 loss: 0.40980491042137146\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1085 loss: 0.5332171320915222\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1086 loss: 0.35066476464271545\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1087 loss: 0.28976404666900635\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 1088 loss: 0.3819732367992401\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1089 loss: 0.3983047902584076\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1090 loss: 0.2999305725097656\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1091 loss: 0.2567559480667114\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1092 loss: 0.14101889729499817\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1093 loss: 0.198530912399292\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1094 loss: 0.5835708975791931\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1095 loss: 0.2827444076538086\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1096 loss: 0.47914019227027893\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1097 loss: 0.25926706194877625\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1098 loss: 0.4181710481643677\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1099 loss: 0.4379819631576538\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1100 loss: 0.14591529965400696\n",
      "class 0: acc 0.9688, precision 0.9688, recall 1.0000, f1 0.9841\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1101 loss: 0.35941800475120544\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1102 loss: 0.4440127909183502\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1103 loss: 0.4025559723377228\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1104 loss: 0.2751096785068512\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1105 loss: 0.26894041895866394\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1106 loss: 0.4211214780807495\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1107 loss: 0.2764354646205902\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1108 loss: 0.1254616230726242\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1109 loss: 0.477385014295578\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1110 loss: 0.7070150375366211\n",
      "class 0: acc 0.7812, precision 0.8571, recall 0.8889, f1 0.8727\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1111 loss: 0.37339138984680176\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1112 loss: 0.15172415971755981\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 1113 loss: 0.30279988050460815\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1114 loss: 0.24449893832206726\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1115 loss: 0.24682535231113434\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1116 loss: 0.32726144790649414\n",
      "class 0: acc 0.8750, precision 0.9655, recall 0.9032, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1117 loss: 0.33059459924697876\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1118 loss: 0.19638216495513916\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1119 loss: 0.3883870840072632\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1120 loss: 0.3926299810409546\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1121 loss: 0.2706720232963562\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1122 loss: 0.30605417490005493\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1123 loss: 0.43494316935539246\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1124 loss: 0.1866237074136734\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1125 loss: 0.2594214081764221\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1126 loss: 0.39170658588409424\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1127 loss: 0.3005487322807312\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1128 loss: 0.25713109970092773\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1129 loss: 0.26701802015304565\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1130 loss: 0.5141692161560059\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1131 loss: 0.5923975706100464\n",
      "class 0: acc 0.7812, precision 0.7407, recall 1.0000, f1 0.8511\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1132 loss: 0.6020268797874451\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1133 loss: 0.2338632047176361\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1134 loss: 0.23851141333580017\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1135 loss: 0.3925180733203888\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1136 loss: 0.3478989601135254\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1137 loss: 0.34084731340408325\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1138 loss: 0.2545062303543091\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1139 loss: 0.4957824647426605\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8438, precision 0.5714, recall 0.6667, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1140 loss: 0.3481302261352539\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1141 loss: 0.4649452567100525\n",
      "class 0: acc 0.8125, precision 0.9091, recall 0.8333, f1 0.8696\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.7143, f1 0.5882\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1142 loss: 0.28179654479026794\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9355, f1 0.9667\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1143 loss: 0.5413854718208313\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1144 loss: 0.4093339443206787\n",
      "class 0: acc 0.9375, precision 0.9200, recall 1.0000, f1 0.9583\n",
      "class 1: acc 0.9688, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1145 loss: 0.5629324316978455\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1146 loss: 0.30150118470191956\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1147 loss: 0.2335330694913864\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1148 loss: 0.24428397417068481\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1149 loss: 0.44908058643341064\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1150 loss: 0.34481266140937805\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1151 loss: 0.17530985176563263\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1152 loss: 0.6070984601974487\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1153 loss: 0.24132481217384338\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1154 loss: 0.42567870020866394\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1155 loss: 0.2805120348930359\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1156 loss: 0.2883259952068329\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1157 loss: 0.6891722679138184\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1158 loss: 0.2340967357158661\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1159 loss: 0.467016339302063\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1160 loss: 0.22568579018115997\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1161 loss: 0.40861979126930237\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1162 loss: 0.665783703327179\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1163 loss: 0.40709033608436584\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1164 loss: 0.38299691677093506\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1165 loss: 0.42040765285491943\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1166 loss: 0.44978684186935425\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1167 loss: 0.19452790915966034\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1168 loss: 0.2127266377210617\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1169 loss: 0.4689403474330902\n",
      "class 0: acc 0.8438, precision 0.9310, recall 0.9000, f1 0.9153\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1170 loss: 0.5670537948608398\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1171 loss: 0.19925081729888916\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1172 loss: 0.4546210467815399\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1173 loss: 0.18541225790977478\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1174 loss: 0.3948782682418823\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1175 loss: 0.2689872682094574\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 1176 loss: 0.3870532512664795\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1177 loss: 0.6615980267524719\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1178 loss: 0.19225585460662842\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 1179 loss: 0.5034620761871338\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1180 loss: 0.39177367091178894\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1181 loss: 0.168949693441391\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1182 loss: 0.24163517355918884\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 7 step: 1183 loss: 0.37062889337539673\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1184 loss: 0.22250914573669434\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1185 loss: 0.37132760882377625\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1186 loss: 0.37166181206703186\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1187 loss: 0.3061908483505249\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1188 loss: 0.5018042325973511\n",
      "class 0: acc 0.8125, precision 0.8400, recall 0.9130, f1 0.8750\n",
      "class 1: acc 0.7812, precision 0.5714, recall 0.5000, f1 0.5333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1189 loss: 0.1939646601676941\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 7 step: 1190 loss: 0.246279776096344\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1191 loss: 0.24386385083198547\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1192 loss: 0.323603093624115\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1193 loss: 0.3336678445339203\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1194 loss: 0.48465025424957275\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1195 loss: 0.6971683502197266\n",
      "class 0: acc 0.6875, precision 0.7037, recall 0.9048, f1 0.7917\n",
      "class 1: acc 0.7500, precision 0.6000, recall 0.3333, f1 0.4286\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1196 loss: 0.5197077989578247\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1197 loss: 0.35191965103149414\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1198 loss: 0.32899871468544006\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1199 loss: 0.7831637263298035\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.7812, precision 0.3333, recall 0.1667, f1 0.2222\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1200 loss: 0.3150101602077484\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1201 loss: 0.2301114946603775\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1202 loss: 0.46581315994262695\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1203 loss: 0.2891453802585602\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 7 step: 1204 loss: 0.2495737373828888\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1205 loss: 0.33687344193458557\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1206 loss: 0.2588213086128235\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 7 step: 1207 loss: 0.390241414308548\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1208 loss: 0.32750168442726135\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 7 step: 1209 loss: 0.2909480929374695\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 7 step: 1210 loss: 0.10800489783287048\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1211 loss: 0.21018441021442413\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1212 loss: 0.5199357271194458\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1213 loss: 0.31609806418418884\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 1214 loss: 0.27491018176078796\n",
      "class 0: acc 0.9062, precision 0.9565, recall 0.9167, f1 0.9362\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 7 step: 1215 loss: 0.5289127230644226\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1216 loss: 0.6007857918739319\n",
      "class 0: acc 0.7500, precision 0.7857, recall 0.9167, f1 0.8462\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 7 step: 1217 loss: 0.48561426997184753\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1218 loss: 0.4584181010723114\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1219 loss: 0.23436850309371948\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1220 loss: 0.33083388209342957\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1221 loss: 0.41671884059906006\n",
      "class 0: acc 0.8750, precision 0.9333, recall 0.9333, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1222 loss: 0.33340850472450256\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1223 loss: 0.18432080745697021\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1224 loss: 0.25884848833084106\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1225 loss: 0.31026849150657654\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1226 loss: 0.4136483371257782\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1227 loss: 0.4027256667613983\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1228 loss: 0.241446390748024\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1229 loss: 0.33940011262893677\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1230 loss: 0.31664136052131653\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1231 loss: 0.5123234391212463\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1232 loss: 0.5028828382492065\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1233 loss: 0.3720189332962036\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 1234 loss: 0.4672888517379761\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1235 loss: 0.3105296790599823\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 7 step: 1236 loss: 0.32736748456954956\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1237 loss: 0.19970418512821198\n",
      "class 0: acc 0.9375, precision 0.9677, recall 0.9677, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1238 loss: 0.4482872188091278\n",
      "class 0: acc 0.8125, precision 0.8400, recall 0.9130, f1 0.8750\n",
      "class 1: acc 0.8438, precision 0.7143, recall 0.6250, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1239 loss: 0.10091354697942734\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9677, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1240 loss: 0.34455907344818115\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1241 loss: 0.16772988438606262\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1242 loss: 0.2281343638896942\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1243 loss: 0.2557009160518646\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1244 loss: 0.3177628815174103\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1245 loss: 0.12226717174053192\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1246 loss: 0.13999171555042267\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9688, f1 0.9841\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1247 loss: 0.37619879841804504\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1248 loss: 0.1781940758228302\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1249 loss: 0.6643497943878174\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 7 step: 1250 loss: 0.5124555230140686\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1 loss: 0.19170154631137848\n",
      "class 0: acc 0.9375, precision 0.9167, recall 1.0000, f1 0.9565\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8889, f1 0.9412\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 2 loss: 0.24987590312957764\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 3 loss: 0.5547387599945068\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 4 loss: 0.5839099287986755\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 5 loss: 0.5624253749847412\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 6 loss: 0.6793675422668457\n",
      "class 0: acc 0.7188, precision 0.7241, recall 0.9545, f1 0.8235\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.1429, f1 0.2222\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 7 loss: 0.436495304107666\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 8 loss: 0.5874181985855103\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 9 loss: 0.3075594902038574\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 10 loss: 0.7367038130760193\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 11 loss: 0.31976690888404846\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 12 loss: 0.5661187171936035\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 13 loss: 0.25282979011535645\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 14 loss: 0.2737377882003784\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 15 loss: 0.47918397188186646\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 16 loss: 0.30758118629455566\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 17 loss: 0.46956658363342285\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8125, precision 1.0000, recall 0.1429, f1 0.2500\n",
      "epoch: 8 step: 18 loss: 0.3191368281841278\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 19 loss: 0.32720476388931274\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 20 loss: 0.31191760301589966\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 21 loss: 0.4191787838935852\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 22 loss: 0.16463303565979004\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 23 loss: 0.5163075923919678\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 8 step: 24 loss: 0.1621876209974289\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 25 loss: 0.38188907504081726\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 26 loss: 0.32472899556159973\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 27 loss: 0.5395010113716125\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 28 loss: 0.289535254240036\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 29 loss: 0.5747225284576416\n",
      "class 0: acc 0.7500, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 30 loss: 0.44942688941955566\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 31 loss: 0.21009387075901031\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 32 loss: 0.2092684656381607\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 33 loss: 0.4498438239097595\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 34 loss: 0.21613624691963196\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 35 loss: 0.42502471804618835\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 36 loss: 0.5646809339523315\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.2500, recall 0.2500, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 37 loss: 0.6421687602996826\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 38 loss: 0.3898657262325287\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 39 loss: 0.37874069809913635\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 40 loss: 0.3203912675380707\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 41 loss: 0.489965558052063\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 42 loss: 0.4075246751308441\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 43 loss: 0.42873021960258484\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 44 loss: 0.2315661460161209\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 45 loss: 0.5535465478897095\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 46 loss: 0.21297307312488556\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 47 loss: 0.32137271761894226\n",
      "class 0: acc 0.8438, precision 0.8400, recall 0.9545, f1 0.8936\n",
      "class 1: acc 0.8438, precision 0.8571, recall 0.6000, f1 0.7059\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 48 loss: 0.15447482466697693\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 49 loss: 0.22736598551273346\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 50 loss: 0.4064646363258362\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.7812, precision 0.4000, recall 0.3333, f1 0.3636\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 51 loss: 0.3465191125869751\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 52 loss: 0.31085482239723206\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 53 loss: 0.23097045719623566\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 54 loss: 0.5639483332633972\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 55 loss: 0.4343258738517761\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 56 loss: 0.3140638768672943\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 57 loss: 0.2937609553337097\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 58 loss: 0.38058584928512573\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 59 loss: 0.29339084029197693\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 60 loss: 0.5095839500427246\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 61 loss: 0.42947861552238464\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 62 loss: 0.402098685503006\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 63 loss: 0.4260018467903137\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 64 loss: 0.44295328855514526\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 8 step: 65 loss: 0.19605576992034912\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 66 loss: 0.3094691336154938\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 67 loss: 0.6093810796737671\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 68 loss: 0.1944616585969925\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 69 loss: 0.342115581035614\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 70 loss: 0.15188486874103546\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 71 loss: 0.1526188999414444\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 72 loss: 0.524712085723877\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 73 loss: 0.2357185333967209\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 74 loss: 0.43161314725875854\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 75 loss: 0.290584921836853\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 76 loss: 0.15840676426887512\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 77 loss: 0.25182628631591797\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 78 loss: 0.3374985456466675\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 79 loss: 0.27742621302604675\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 80 loss: 0.43126288056373596\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 81 loss: 0.27900177240371704\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 82 loss: 0.30999556183815\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 83 loss: 0.3577342927455902\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 84 loss: 0.3677135705947876\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 85 loss: 0.28036803007125854\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 86 loss: 0.30815690755844116\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 87 loss: 0.3528805375099182\n",
      "class 0: acc 0.8750, precision 0.9333, recall 0.9333, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 88 loss: 0.11699528992176056\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 89 loss: 0.26198622584342957\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 90 loss: 0.3331890404224396\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 91 loss: 0.5450380444526672\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 92 loss: 0.15003417432308197\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 93 loss: 0.41660743951797485\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 94 loss: 0.5786018371582031\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 95 loss: 0.17269161343574524\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 96 loss: 0.23414650559425354\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 97 loss: 0.26893189549446106\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 98 loss: 0.4053102135658264\n",
      "class 0: acc 0.7500, precision 0.7586, recall 0.9565, f1 0.8462\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 99 loss: 0.24568645656108856\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 100 loss: 0.1851957142353058\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 101 loss: 0.4411497712135315\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 102 loss: 0.5389550924301147\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 103 loss: 0.2789632976055145\n",
      "class 0: acc 0.9062, precision 0.9667, recall 0.9355, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 104 loss: 0.3850664496421814\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 105 loss: 0.24165016412734985\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 106 loss: 0.5116915106773376\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 107 loss: 0.1629580408334732\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 108 loss: 0.5999453067779541\n",
      "class 0: acc 0.7500, precision 0.8077, recall 0.8750, f1 0.8400\n",
      "class 1: acc 0.7812, precision 0.4000, recall 0.3333, f1 0.3636\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 109 loss: 0.27624425292015076\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 110 loss: 0.47118711471557617\n",
      "class 0: acc 0.8438, precision 0.8333, recall 0.9524, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.8750, recall 0.7778, f1 0.8235\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 111 loss: 0.2183629274368286\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 112 loss: 0.35949626564979553\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 113 loss: 0.3024895191192627\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 114 loss: 0.35178613662719727\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 115 loss: 0.26563528180122375\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 116 loss: 0.37195584177970886\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 117 loss: 0.22611109912395477\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 8 step: 118 loss: 0.3860325217247009\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 119 loss: 0.2722824513912201\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 120 loss: 0.43570011854171753\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 121 loss: 0.5208231210708618\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 122 loss: 0.38801366090774536\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 123 loss: 0.19934344291687012\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 124 loss: 0.2533204257488251\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 125 loss: 0.23142163455486298\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 126 loss: 0.3601439297199249\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 127 loss: 0.42694091796875\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "epoch: 8 step: 128 loss: 0.3660842180252075\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 129 loss: 0.4559885561466217\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 130 loss: 0.22797682881355286\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 131 loss: 0.33550241589546204\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 132 loss: 0.1428043693304062\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 133 loss: 0.46660441160202026\n",
      "class 0: acc 0.8438, precision 0.9524, recall 0.8333, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.8571, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 8 step: 134 loss: 0.42416441440582275\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 135 loss: 0.30399850010871887\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 136 loss: 0.3409358263015747\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 137 loss: 0.242459237575531\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9615, f1 0.9804\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 8 step: 138 loss: 0.37501731514930725\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 139 loss: 0.23981228470802307\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 140 loss: 0.31356891989707947\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 141 loss: 0.4468364417552948\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 142 loss: 0.29864397644996643\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 143 loss: 0.4032515287399292\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 144 loss: 0.4510841369628906\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "epoch: 8 step: 145 loss: 0.5718706846237183\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 146 loss: 0.30581575632095337\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 147 loss: 0.15301117300987244\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9333, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 148 loss: 0.4821220636367798\n",
      "class 0: acc 0.8125, precision 0.8400, recall 0.9130, f1 0.8750\n",
      "class 1: acc 0.7812, precision 0.6000, recall 0.3750, f1 0.4615\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 149 loss: 0.35313642024993896\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 150 loss: 0.43736591935157776\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 151 loss: 0.2985106408596039\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 152 loss: 0.2660145163536072\n",
      "class 0: acc 0.8750, precision 0.9583, recall 0.8846, f1 0.9200\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 153 loss: 0.4015086889266968\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 154 loss: 0.24690166115760803\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 155 loss: 0.0930604413151741\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 156 loss: 0.22328022122383118\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 157 loss: 0.3102935254573822\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 158 loss: 0.5270410180091858\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 159 loss: 0.5582444667816162\n",
      "class 0: acc 0.8438, precision 0.8333, recall 0.9524, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.6667, f1 0.7059\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 160 loss: 0.264503538608551\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 161 loss: 0.17476074397563934\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9615, f1 0.9804\n",
      "class 1: acc 0.9375, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 162 loss: 0.27488142251968384\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 163 loss: 0.4299459159374237\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 164 loss: 0.3755894601345062\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 165 loss: 0.40882718563079834\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 166 loss: 0.3435947895050049\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 167 loss: 0.25641509890556335\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 168 loss: 0.18883147835731506\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 8 step: 169 loss: 0.2805866599082947\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 170 loss: 0.25936850905418396\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 171 loss: 0.11870285868644714\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 172 loss: 0.24312952160835266\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 173 loss: 0.1059432327747345\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 174 loss: 0.3845632076263428\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 175 loss: 0.2752477824687958\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 176 loss: 0.22563669085502625\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 177 loss: 0.5840616822242737\n",
      "class 0: acc 0.7500, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 178 loss: 0.28146255016326904\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 179 loss: 0.25086456537246704\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 180 loss: 0.3419298231601715\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 181 loss: 0.39800354838371277\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 182 loss: 0.3586026430130005\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 183 loss: 0.6008911728858948\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "epoch: 8 step: 184 loss: 0.31437182426452637\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 185 loss: 0.3856736123561859\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 186 loss: 0.20241843163967133\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 187 loss: 0.39580607414245605\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 188 loss: 0.3366057276725769\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 189 loss: 0.162307009100914\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 190 loss: 0.30193373560905457\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 8 step: 191 loss: 0.6946030855178833\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9091, f1 0.8511\n",
      "class 1: acc 0.7812, precision 0.5714, recall 0.5000, f1 0.5333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 192 loss: 0.21221309900283813\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 8 step: 193 loss: 0.1871570646762848\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 194 loss: 0.38305017352104187\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 195 loss: 0.29163452982902527\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 196 loss: 0.31342247128486633\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 197 loss: 0.22533488273620605\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 198 loss: 0.30992043018341064\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 199 loss: 0.18686285614967346\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 200 loss: 0.25623151659965515\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 201 loss: 0.39023780822753906\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 202 loss: 0.1594516932964325\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 203 loss: 0.3727727234363556\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 204 loss: 0.16212411224842072\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 205 loss: 0.23853912949562073\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 206 loss: 0.36796221137046814\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 207 loss: 0.30194833874702454\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 208 loss: 0.3729957044124603\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 209 loss: 0.196569561958313\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 210 loss: 0.3371790945529938\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 211 loss: 0.290010929107666\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 212 loss: 0.4352377653121948\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 213 loss: 0.5241726040840149\n",
      "class 0: acc 0.7812, precision 0.8065, recall 0.9615, f1 0.8772\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 214 loss: 0.21684101223945618\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 215 loss: 0.26355472207069397\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 216 loss: 0.35619866847991943\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 217 loss: 0.33823657035827637\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 218 loss: 0.4217594265937805\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 219 loss: 0.3667675852775574\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 220 loss: 0.44131988286972046\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 221 loss: 0.5897716283798218\n",
      "class 0: acc 0.7812, precision 0.7407, recall 1.0000, f1 0.8511\n",
      "class 1: acc 0.8125, precision 0.8000, recall 0.4444, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 222 loss: 0.5021464824676514\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 223 loss: 0.4988116919994354\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "epoch: 8 step: 224 loss: 0.2786208689212799\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 225 loss: 0.30751025676727295\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 226 loss: 0.5802243947982788\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 227 loss: 0.2614904046058655\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 8 step: 228 loss: 0.23340792953968048\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 229 loss: 0.502415657043457\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8125, precision 0.8333, recall 0.5000, f1 0.6250\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 230 loss: 0.3370225429534912\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "epoch: 8 step: 231 loss: 0.34275344014167786\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 232 loss: 0.16595080494880676\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 233 loss: 0.6613970994949341\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 234 loss: 0.23890715837478638\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 235 loss: 0.42530763149261475\n",
      "class 0: acc 0.7812, precision 0.9167, recall 0.8148, f1 0.8627\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 8 step: 236 loss: 0.20605646073818207\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 237 loss: 0.16287045180797577\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 238 loss: 0.4023617208003998\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 239 loss: 0.2737075388431549\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 240 loss: 0.3455934524536133\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 241 loss: 0.38271790742874146\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 242 loss: 0.13606375455856323\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 243 loss: 0.21227261424064636\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 244 loss: 0.13058887422084808\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 245 loss: 0.4402022957801819\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 246 loss: 0.1252516508102417\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 247 loss: 0.10581561923027039\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 248 loss: 0.4510834515094757\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 249 loss: 0.45209628343582153\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 250 loss: 0.41174179315567017\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 251 loss: 0.2714187800884247\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 252 loss: 0.21854376792907715\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 253 loss: 0.12711873650550842\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 254 loss: 0.25366348028182983\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 255 loss: 0.3644745945930481\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 256 loss: 0.370652973651886\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 257 loss: 0.40667232871055603\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 258 loss: 0.3317692279815674\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 259 loss: 0.1870567351579666\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 260 loss: 0.23308280110359192\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 261 loss: 0.5068948268890381\n",
      "class 0: acc 0.7188, precision 0.7308, recall 0.9048, f1 0.8085\n",
      "class 1: acc 0.7812, precision 0.6667, recall 0.4444, f1 0.5333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 262 loss: 0.22009281814098358\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 263 loss: 0.2440757006406784\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 264 loss: 0.14039726555347443\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 265 loss: 0.20161664485931396\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 266 loss: 0.19052843749523163\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 267 loss: 0.19492967426776886\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 268 loss: 0.339825302362442\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 269 loss: 0.35008829832077026\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 270 loss: 0.5563526749610901\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 271 loss: 0.4066307842731476\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 272 loss: 0.43173614144325256\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 273 loss: 0.21026252210140228\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 274 loss: 0.2487286925315857\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 275 loss: 0.43627601861953735\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 276 loss: 0.39454030990600586\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 277 loss: 0.28643089532852173\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 278 loss: 0.33666539192199707\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 279 loss: 0.29617470502853394\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 280 loss: 0.4783165156841278\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 281 loss: 0.20105953514575958\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 282 loss: 0.2818911671638489\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 283 loss: 0.4356324076652527\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 284 loss: 0.4004742205142975\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 285 loss: 0.3616136610507965\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 286 loss: 0.34564414620399475\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 287 loss: 0.21601007878780365\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 288 loss: 0.5685679912567139\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "epoch: 8 step: 289 loss: 0.4302576184272766\n",
      "class 0: acc 0.8125, precision 0.8846, recall 0.8846, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 8 step: 290 loss: 0.27536410093307495\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 291 loss: 0.2854081392288208\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "epoch: 8 step: 292 loss: 0.5239944458007812\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 293 loss: 0.31908664107322693\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 294 loss: 0.5351189970970154\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 295 loss: 0.26909828186035156\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 296 loss: 0.5768471360206604\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 297 loss: 0.25068894028663635\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 298 loss: 0.45444607734680176\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 299 loss: 0.26670199632644653\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 300 loss: 0.20550522208213806\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 301 loss: 0.22729022800922394\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 302 loss: 0.555708646774292\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 303 loss: 0.41855862736701965\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 304 loss: 0.6257888078689575\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 305 loss: 0.6795772910118103\n",
      "class 0: acc 0.7812, precision 0.8077, recall 0.9130, f1 0.8571\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 306 loss: 0.45811185240745544\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 307 loss: 0.4685969948768616\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 308 loss: 0.5454868674278259\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.7812, precision 0.6667, recall 0.2500, f1 0.3636\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 309 loss: 0.42801332473754883\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 310 loss: 0.2685726583003998\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 311 loss: 0.35267508029937744\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 312 loss: 0.2973509728908539\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 8 step: 313 loss: 0.24561722576618195\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 314 loss: 0.46169373393058777\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 315 loss: 0.28906387090682983\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 316 loss: 0.15852272510528564\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 317 loss: 0.28140097856521606\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9231, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 318 loss: 0.24134337902069092\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 319 loss: 0.23393887281417847\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 8 step: 320 loss: 0.17233210802078247\n",
      "class 0: acc 0.8750, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 321 loss: 0.3737826347351074\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 322 loss: 0.25438302755355835\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9333, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 323 loss: 0.18806423246860504\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 324 loss: 0.2472226321697235\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 325 loss: 0.4202599823474884\n",
      "class 0: acc 0.8750, precision 0.8750, recall 0.9545, f1 0.9130\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 326 loss: 0.18343663215637207\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 8 step: 327 loss: 0.3563123643398285\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 328 loss: 0.4874974191188812\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 329 loss: 0.47544798254966736\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 330 loss: 0.27118921279907227\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 331 loss: 0.29423415660858154\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 8 step: 332 loss: 0.43627047538757324\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 333 loss: 0.283987820148468\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 334 loss: 0.4162091612815857\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 335 loss: 0.09144726395606995\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 336 loss: 0.27426302433013916\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 337 loss: 0.2620631456375122\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 338 loss: 0.13891448080539703\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 339 loss: 0.31972450017929077\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 340 loss: 0.31664109230041504\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 341 loss: 0.33906590938568115\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 342 loss: 0.405195415019989\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 343 loss: 0.37060675024986267\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 344 loss: 0.16372160613536835\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 345 loss: 0.16612984240055084\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 346 loss: 0.34595826268196106\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 347 loss: 0.4195539355278015\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 348 loss: 0.2577507793903351\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 349 loss: 0.2274032086133957\n",
      "class 0: acc 0.9375, precision 0.9130, recall 1.0000, f1 0.9545\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.8182, f1 0.9000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 350 loss: 0.5843143463134766\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 351 loss: 0.22645127773284912\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 352 loss: 0.4500315189361572\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 353 loss: 0.3089321255683899\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 354 loss: 0.47550323605537415\n",
      "class 0: acc 0.8438, precision 0.9000, recall 0.9310, f1 0.9153\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 355 loss: 0.15918156504631042\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 356 loss: 0.587087869644165\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 357 loss: 0.29747799038887024\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 358 loss: 0.4517301619052887\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 359 loss: 0.3760737180709839\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 360 loss: 0.19607463479042053\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 361 loss: 0.22697752714157104\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 362 loss: 0.1777695119380951\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 363 loss: 0.39360910654067993\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 364 loss: 0.24799418449401855\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 365 loss: 0.27939772605895996\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 366 loss: 0.38741597533226013\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 367 loss: 0.17528043687343597\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 368 loss: 0.3027287721633911\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 369 loss: 0.36546215415000916\n",
      "class 0: acc 0.8438, precision 0.9000, recall 0.9310, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 370 loss: 0.3751322329044342\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 371 loss: 0.2897995710372925\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 372 loss: 0.4453171193599701\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 373 loss: 0.2851957082748413\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 374 loss: 0.29908111691474915\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 375 loss: 0.14375363290309906\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 376 loss: 0.42733636498451233\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 377 loss: 0.15403056144714355\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 378 loss: 0.47972506284713745\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 379 loss: 0.36186352372169495\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 380 loss: 0.35140836238861084\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 381 loss: 0.14405612647533417\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 382 loss: 0.1484939008951187\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 383 loss: 0.2811211049556732\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 384 loss: 0.40639829635620117\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 385 loss: 0.33479639887809753\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 386 loss: 0.3357049226760864\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 387 loss: 0.29821521043777466\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 388 loss: 0.29383131861686707\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 389 loss: 0.3975554406642914\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 390 loss: 0.3733675479888916\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 391 loss: 0.2278163880109787\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 392 loss: 0.6600058078765869\n",
      "class 0: acc 0.7188, precision 0.7000, recall 1.0000, f1 0.8235\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.7500, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 393 loss: 0.4559808075428009\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 394 loss: 0.3503929078578949\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 395 loss: 0.2959703803062439\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 396 loss: 0.4101884663105011\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 397 loss: 0.46227186918258667\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 398 loss: 0.19107955694198608\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 399 loss: 0.600908637046814\n",
      "class 0: acc 0.7188, precision 0.7778, recall 0.8750, f1 0.8235\n",
      "class 1: acc 0.7500, precision 0.4000, recall 0.2857, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 400 loss: 0.4086153209209442\n",
      "class 0: acc 0.9062, precision 0.9130, recall 0.9545, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 401 loss: 0.2927132546901703\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 402 loss: 0.616399347782135\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 403 loss: 0.2732852101325989\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 404 loss: 0.23817501962184906\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 405 loss: 0.35966530442237854\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 406 loss: 0.39066773653030396\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 407 loss: 0.7513344287872314\n",
      "class 0: acc 0.7812, precision 0.8077, recall 0.9130, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 408 loss: 0.4041813611984253\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 409 loss: 0.2854507565498352\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 410 loss: 0.35466986894607544\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 411 loss: 0.23737330734729767\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 412 loss: 0.2797991633415222\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 413 loss: 0.449319064617157\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 414 loss: 0.35667523741722107\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 415 loss: 0.38461804389953613\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 416 loss: 0.5400206446647644\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 417 loss: 0.23377178609371185\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 418 loss: 0.46776533126831055\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.8000, recall 0.4444, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 419 loss: 0.7533796429634094\n",
      "class 0: acc 0.7500, precision 0.7586, recall 0.9565, f1 0.8462\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 420 loss: 0.3835841119289398\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 421 loss: 0.37302279472351074\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 422 loss: 0.30473852157592773\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 423 loss: 0.5377257466316223\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 424 loss: 0.40111243724823\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 425 loss: 0.39636245369911194\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 426 loss: 0.21267347037792206\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 427 loss: 0.3242707848548889\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 428 loss: 0.35975381731987\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 429 loss: 0.25112032890319824\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 430 loss: 0.33176389336586\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 431 loss: 0.3228272795677185\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 432 loss: 0.34078076481819153\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 433 loss: 0.289838582277298\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 434 loss: 0.4595414996147156\n",
      "class 0: acc 0.7812, precision 0.7812, recall 1.0000, f1 0.8772\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 435 loss: 0.14845505356788635\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 436 loss: 0.3371436893939972\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 437 loss: 0.3012126684188843\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 438 loss: 0.355634480714798\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 439 loss: 0.216787651181221\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 440 loss: 0.5759260058403015\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 441 loss: 0.3739188015460968\n",
      "class 0: acc 0.8438, precision 0.8750, recall 0.9130, f1 0.8936\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 8 step: 442 loss: 0.6058618426322937\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 443 loss: 0.30419233441352844\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 444 loss: 0.5184844732284546\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 445 loss: 0.4318612217903137\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 446 loss: 0.5205929279327393\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 447 loss: 0.4611179232597351\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 448 loss: 0.31469306349754333\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 449 loss: 0.3837997317314148\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 450 loss: 0.33247116208076477\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 451 loss: 0.2301366627216339\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 452 loss: 0.2094433456659317\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 453 loss: 0.514432430267334\n",
      "class 0: acc 0.8438, precision 0.9000, recall 0.9310, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 454 loss: 0.38970842957496643\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 455 loss: 0.5243929624557495\n",
      "class 0: acc 0.7500, precision 0.7419, recall 1.0000, f1 0.8519\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 456 loss: 0.4129965305328369\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 457 loss: 0.2908289134502411\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 458 loss: 0.3013838827610016\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 459 loss: 0.23515062034130096\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 460 loss: 0.45401713252067566\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 461 loss: 0.4316471517086029\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 462 loss: 0.6429404616355896\n",
      "class 0: acc 0.7188, precision 0.7241, recall 0.9545, f1 0.8235\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 463 loss: 0.28353944420814514\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 464 loss: 0.4028093218803406\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 465 loss: 0.6207809448242188\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 466 loss: 0.6716101169586182\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 467 loss: 0.46664363145828247\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 468 loss: 0.4463692307472229\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 469 loss: 0.23264065384864807\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 470 loss: 0.4222447872161865\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 471 loss: 0.42164137959480286\n",
      "class 0: acc 0.9062, precision 0.9130, recall 0.9545, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.7778, recall 0.7778, f1 0.7778\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 472 loss: 0.31552278995513916\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 473 loss: 0.294040709733963\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 474 loss: 0.6916247606277466\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 475 loss: 0.3532569706439972\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 476 loss: 0.40480637550354004\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 477 loss: 0.5296117663383484\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 478 loss: 0.308208703994751\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 479 loss: 0.343997061252594\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 480 loss: 0.29568877816200256\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 481 loss: 0.3909778296947479\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 482 loss: 0.47187167406082153\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 483 loss: 0.4037819504737854\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 484 loss: 0.33579960465431213\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 485 loss: 0.3571345806121826\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 486 loss: 0.24241578578948975\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 487 loss: 0.28094205260276794\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.7000, f1 0.8235\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 488 loss: 0.37293004989624023\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 489 loss: 0.31464341282844543\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 490 loss: 0.1861123889684677\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 491 loss: 0.5695488452911377\n",
      "class 0: acc 0.7812, precision 0.8462, recall 0.8800, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 492 loss: 0.2721354067325592\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 493 loss: 0.49040913581848145\n",
      "class 0: acc 0.8125, precision 0.9200, recall 0.8519, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.2857, recall 0.6667, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 494 loss: 0.43291065096855164\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 495 loss: 0.35074567794799805\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 496 loss: 0.19531354308128357\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 497 loss: 0.405790239572525\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 498 loss: 0.21874134242534637\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 499 loss: 0.42355963587760925\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 500 loss: 0.19286486506462097\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 501 loss: 0.4094879925251007\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 502 loss: 0.23384974896907806\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 503 loss: 0.33445101976394653\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 504 loss: 0.2706442177295685\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 505 loss: 0.3897501230239868\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 506 loss: 0.6898896098136902\n",
      "class 0: acc 0.7500, precision 0.7586, recall 0.9565, f1 0.8462\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 507 loss: 0.3997073769569397\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 508 loss: 0.2988522946834564\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 509 loss: 0.49758079648017883\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 510 loss: 0.29817402362823486\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 511 loss: 0.11894133687019348\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 512 loss: 0.34468182921409607\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 513 loss: 0.3277139663696289\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 514 loss: 0.21404126286506653\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 515 loss: 0.4597868323326111\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 516 loss: 0.30102187395095825\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 517 loss: 0.40867680311203003\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 518 loss: 0.5733624696731567\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.7812, precision 0.3333, recall 0.1667, f1 0.2222\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 519 loss: 0.16737014055252075\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 520 loss: 0.5613371729850769\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 521 loss: 0.43658918142318726\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 522 loss: 0.16529147326946259\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 523 loss: 0.296418160200119\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9286, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 524 loss: 0.32817068696022034\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 525 loss: 0.26279252767562866\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 526 loss: 0.20536983013153076\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 527 loss: 0.8493865728378296\n",
      "class 0: acc 0.6250, precision 0.6957, recall 0.7619, f1 0.7273\n",
      "class 1: acc 0.5938, precision 0.2222, recall 0.2500, f1 0.2353\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 528 loss: 0.2905980348587036\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 529 loss: 0.5176190733909607\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 530 loss: 0.31510013341903687\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 531 loss: 0.28669703006744385\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 532 loss: 0.28715893626213074\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 533 loss: 0.3927481174468994\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 534 loss: 0.43614625930786133\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 535 loss: 0.27555233240127563\n",
      "class 0: acc 0.8438, precision 0.9310, recall 0.9000, f1 0.9153\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 536 loss: 0.38591068983078003\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 537 loss: 0.24373003840446472\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 538 loss: 0.1981625109910965\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 539 loss: 0.2715523838996887\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 540 loss: 0.4499007761478424\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 541 loss: 0.37489745020866394\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 542 loss: 0.4781419634819031\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 543 loss: 0.3867555856704712\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 544 loss: 0.22789379954338074\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 545 loss: 0.2541312575340271\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 546 loss: 0.22474059462547302\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 547 loss: 0.18185819685459137\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 548 loss: 0.1853560358285904\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 549 loss: 0.09986624121665955\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 550 loss: 0.37042441964149475\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 551 loss: 0.08649417012929916\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 552 loss: 0.39010491967201233\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 553 loss: 0.519942045211792\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 554 loss: 0.221006840467453\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 555 loss: 0.10465386509895325\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 556 loss: 0.26971542835235596\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 557 loss: 0.275113970041275\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 558 loss: 0.212972953915596\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 559 loss: 0.22155824303627014\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 560 loss: 0.28185614943504333\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 561 loss: 0.30331680178642273\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 562 loss: 0.28765207529067993\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 563 loss: 0.45001089572906494\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 564 loss: 0.23465664684772491\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 565 loss: 0.37017422914505005\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 566 loss: 0.2823810577392578\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 567 loss: 0.1786479949951172\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 568 loss: 0.28968244791030884\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 569 loss: 0.22728833556175232\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 570 loss: 0.23421815037727356\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 571 loss: 0.4124923348426819\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 572 loss: 0.2726233899593353\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 573 loss: 0.3592507839202881\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 574 loss: 0.4456973373889923\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 575 loss: 0.7077429294586182\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 576 loss: 0.24612845480442047\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 577 loss: 0.6254492402076721\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 578 loss: 0.3209574222564697\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 579 loss: 0.3481837213039398\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 580 loss: 0.25601863861083984\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 581 loss: 0.22972433269023895\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 582 loss: 0.7220169901847839\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 583 loss: 0.3193376064300537\n",
      "class 0: acc 0.9375, precision 0.9167, recall 1.0000, f1 0.9565\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "epoch: 8 step: 584 loss: 0.15589860081672668\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 585 loss: 0.3782309889793396\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 586 loss: 0.19705304503440857\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 587 loss: 0.4222191274166107\n",
      "class 0: acc 0.8438, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.8571, recall 0.6000, f1 0.7059\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 588 loss: 0.3429935574531555\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 589 loss: 0.2812034487724304\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 590 loss: 0.3004649877548218\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 591 loss: 0.1935090720653534\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 592 loss: 0.36798790097236633\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 593 loss: 0.35189685225486755\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 594 loss: 0.3115447163581848\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 595 loss: 0.4173383116722107\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 596 loss: 0.1962851583957672\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 597 loss: 0.26722070574760437\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 598 loss: 0.23300525546073914\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 599 loss: 0.2709304094314575\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 600 loss: 0.2791028618812561\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 601 loss: 0.29810401797294617\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 602 loss: 0.11796614527702332\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 603 loss: 0.765917181968689\n",
      "class 0: acc 0.7500, precision 0.7692, recall 0.9091, f1 0.8333\n",
      "class 1: acc 0.7812, precision 0.4000, recall 0.3333, f1 0.3636\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 8 step: 604 loss: 0.31020766496658325\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 605 loss: 0.13685156404972076\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 606 loss: 0.265805721282959\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 607 loss: 0.25969022512435913\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 608 loss: 0.45906442403793335\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 609 loss: 0.5248407125473022\n",
      "class 0: acc 0.7500, precision 0.7407, recall 0.9524, f1 0.8333\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 610 loss: 0.2311827838420868\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 611 loss: 0.23982742428779602\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 612 loss: 0.21650105714797974\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 613 loss: 0.5169653296470642\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 614 loss: 0.29066312313079834\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 615 loss: 0.14798086881637573\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 616 loss: 0.26320382952690125\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 617 loss: 0.375618577003479\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 618 loss: 0.2570878863334656\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 619 loss: 0.5812965035438538\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 620 loss: 0.34589970111846924\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 621 loss: 0.3281215727329254\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 622 loss: 0.5546818375587463\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 623 loss: 0.6185232400894165\n",
      "class 0: acc 0.7188, precision 0.7333, recall 0.9565, f1 0.8302\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 624 loss: 0.41581735014915466\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 625 loss: 0.2744752764701843\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8929, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 626 loss: 0.2880704402923584\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 627 loss: 0.409781813621521\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "epoch: 8 step: 628 loss: 0.2658717632293701\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 629 loss: 0.3067944347858429\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 630 loss: 0.46593573689460754\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9091, f1 0.8511\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 631 loss: 0.7290905714035034\n",
      "class 0: acc 0.7188, precision 0.6897, recall 1.0000, f1 0.8163\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.7500, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 632 loss: 0.18599888682365417\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 633 loss: 0.4172917306423187\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 634 loss: 0.314104288816452\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 635 loss: 0.17093408107757568\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 636 loss: 0.1394645869731903\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "epoch: 8 step: 637 loss: 0.4691113531589508\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "epoch: 8 step: 638 loss: 0.1649831235408783\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 639 loss: 0.38412779569625854\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 640 loss: 0.32732799649238586\n",
      "class 0: acc 0.9062, precision 0.9583, recall 0.9200, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 641 loss: 0.3395199179649353\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "epoch: 8 step: 642 loss: 0.3952374756336212\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "epoch: 8 step: 643 loss: 0.21102608740329742\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "epoch: 8 step: 644 loss: 0.23699451982975006\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 645 loss: 0.2811269164085388\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 646 loss: 0.37822413444519043\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "epoch: 8 step: 647 loss: 0.24867945909500122\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 8 step: 648 loss: 0.5875999331474304\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 649 loss: 0.28476792573928833\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 650 loss: 0.36955735087394714\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 8 step: 651 loss: 0.5345731973648071\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 652 loss: 0.32183390855789185\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9259, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "epoch: 8 step: 653 loss: 0.2519676387310028\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 654 loss: 0.22045780718326569\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 655 loss: 0.4700276255607605\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 8 step: 656 loss: 0.23820437490940094\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 657 loss: 0.47712841629981995\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 658 loss: 0.12732841074466705\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 659 loss: 0.5306757688522339\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 660 loss: 0.21514016389846802\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 661 loss: 0.41312626004219055\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 662 loss: 0.1571483463048935\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 663 loss: 0.6265753507614136\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 664 loss: 0.2798614799976349\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 665 loss: 0.2323984056711197\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 666 loss: 0.231678768992424\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 667 loss: 0.40807998180389404\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 668 loss: 0.2604442238807678\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 669 loss: 0.11557306349277496\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 670 loss: 0.4321647584438324\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 671 loss: 0.612903356552124\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 672 loss: 0.28306588530540466\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 673 loss: 0.46939969062805176\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 674 loss: 0.21744242310523987\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 675 loss: 0.35902220010757446\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 676 loss: 0.1593698263168335\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 677 loss: 0.21836397051811218\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 678 loss: 0.6200998425483704\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 679 loss: 0.3324221968650818\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 680 loss: 0.3000134527683258\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 681 loss: 0.302874892950058\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "epoch: 8 step: 682 loss: 0.25234949588775635\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 683 loss: 0.3584160804748535\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 684 loss: 0.5014018416404724\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8125, precision 0.2500, recall 0.2500, f1 0.2500\n",
      "epoch: 8 step: 685 loss: 0.30568310618400574\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 686 loss: 0.4427354633808136\n",
      "class 0: acc 0.7812, precision 0.8889, recall 0.8571, f1 0.8727\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 687 loss: 0.26041048765182495\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "epoch: 8 step: 688 loss: 0.41338667273521423\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 689 loss: 0.5486010313034058\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "epoch: 8 step: 690 loss: 0.18703368306159973\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 691 loss: 0.3103717565536499\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 692 loss: 0.47118157148361206\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 693 loss: 0.1907665729522705\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 694 loss: 0.1685275137424469\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 695 loss: 0.3009680211544037\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 696 loss: 0.3656262457370758\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 697 loss: 0.605792224407196\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 698 loss: 0.492930144071579\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 699 loss: 0.3073241114616394\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 700 loss: 0.20587727427482605\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 701 loss: 0.22787398099899292\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 702 loss: 0.1654539555311203\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 703 loss: 0.5292364954948425\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 704 loss: 0.3113950192928314\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 705 loss: 0.3253513276576996\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 706 loss: 0.18087676167488098\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 707 loss: 0.3702343702316284\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 708 loss: 0.1828933209180832\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 709 loss: 0.23774836957454681\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 710 loss: 0.4856054484844208\n",
      "class 0: acc 0.7812, precision 0.7407, recall 1.0000, f1 0.8511\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 711 loss: 0.35468024015426636\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 712 loss: 0.3565889298915863\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 713 loss: 0.19789403676986694\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 714 loss: 0.2635556161403656\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 715 loss: 0.37058424949645996\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 716 loss: 0.3187706470489502\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 717 loss: 0.3635600209236145\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 718 loss: 0.2454845905303955\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 719 loss: 0.3849095404148102\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 720 loss: 0.355072021484375\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 721 loss: 0.5285388827323914\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 722 loss: 0.3154488205909729\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 723 loss: 0.437359482049942\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 724 loss: 0.45877817273139954\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 725 loss: 0.2866230309009552\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 726 loss: 0.5617659687995911\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 727 loss: 0.14305751025676727\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 728 loss: 0.39217010140419006\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 729 loss: 0.18222643435001373\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 730 loss: 0.39951297640800476\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 731 loss: 0.4117441773414612\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 732 loss: 0.28292402625083923\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 733 loss: 0.26633819937705994\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 734 loss: 0.2770358622074127\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 735 loss: 0.11093588918447495\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 736 loss: 0.28646349906921387\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 737 loss: 0.351195752620697\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 738 loss: 0.2610728144645691\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 739 loss: 0.3762873113155365\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 740 loss: 0.40801405906677246\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 741 loss: 0.1829318106174469\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 742 loss: 0.2385382205247879\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 743 loss: 0.4934791028499603\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 744 loss: 0.25123700499534607\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 745 loss: 0.4910702407360077\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 746 loss: 0.0703282505273819\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 747 loss: 0.4540488123893738\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 748 loss: 0.3096228241920471\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 749 loss: 0.4085368812084198\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 750 loss: 0.239300936460495\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 751 loss: 0.20599989593029022\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 752 loss: 0.36309507489204407\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 753 loss: 0.5230306386947632\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 754 loss: 0.30574166774749756\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 755 loss: 0.22712890803813934\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 756 loss: 0.6764753460884094\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 757 loss: 0.3684512674808502\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 758 loss: 0.24324122071266174\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 759 loss: 0.45772042870521545\n",
      "class 0: acc 0.7812, precision 0.8333, recall 0.9259, f1 0.8772\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 760 loss: 0.36326366662979126\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 761 loss: 0.35567936301231384\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 762 loss: 0.17766901850700378\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 763 loss: 0.29060420393943787\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 764 loss: 0.18091589212417603\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 765 loss: 0.27080366015434265\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9600, f1 0.9796\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "epoch: 8 step: 766 loss: 0.2687099874019623\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 767 loss: 0.29591888189315796\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 768 loss: 0.2598491311073303\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 769 loss: 0.4376235008239746\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 770 loss: 0.15924741327762604\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 771 loss: 0.24297143518924713\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 772 loss: 0.19736549258232117\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 773 loss: 0.12026238441467285\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 774 loss: 0.06441541016101837\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 775 loss: 0.3931310474872589\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 776 loss: 0.34204044938087463\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 777 loss: 0.7021050453186035\n",
      "class 0: acc 0.8438, precision 0.8333, recall 0.9524, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.8571, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 778 loss: 0.41625553369522095\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 779 loss: 0.3454115688800812\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 780 loss: 0.25635385513305664\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 781 loss: 0.3079627752304077\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 8 step: 782 loss: 0.2988462448120117\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 783 loss: 0.5846611857414246\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 784 loss: 0.2658206522464752\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 785 loss: 0.3396121859550476\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 786 loss: 0.35755234956741333\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 787 loss: 0.19785980880260468\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 788 loss: 0.29954949021339417\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 789 loss: 0.36115893721580505\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 8 step: 790 loss: 0.44503891468048096\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 791 loss: 0.7777872681617737\n",
      "class 0: acc 0.7500, precision 0.7308, recall 0.9500, f1 0.8261\n",
      "class 1: acc 0.7812, precision 0.6000, recall 0.3750, f1 0.4615\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 8 step: 792 loss: 0.30444371700286865\n",
      "class 0: acc 0.9062, precision 0.9583, recall 0.9200, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "epoch: 8 step: 793 loss: 0.25608164072036743\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 794 loss: 0.38061195611953735\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 795 loss: 0.31729915738105774\n",
      "class 0: acc 0.8750, precision 0.9615, recall 0.8929, f1 0.9259\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 8 step: 796 loss: 0.5486205816268921\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.7812, precision 0.6667, recall 0.2500, f1 0.3636\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 797 loss: 0.23545126616954803\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 798 loss: 0.2653501033782959\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 799 loss: 0.5275007486343384\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 800 loss: 0.3373558819293976\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 801 loss: 0.3745248317718506\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 802 loss: 0.25217151641845703\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 803 loss: 0.3886023163795471\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 804 loss: 0.4284316897392273\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 805 loss: 0.5072939395904541\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 806 loss: 0.5142412781715393\n",
      "class 0: acc 0.8125, precision 0.8696, recall 0.8696, f1 0.8696\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "epoch: 8 step: 807 loss: 0.22736386954784393\n",
      "class 0: acc 0.9688, precision 0.9600, recall 1.0000, f1 0.9796\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 808 loss: 0.44333481788635254\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 809 loss: 0.6888326406478882\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 810 loss: 0.2908422648906708\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 811 loss: 0.2631654441356659\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 812 loss: 0.36398863792419434\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 813 loss: 0.653742790222168\n",
      "class 0: acc 0.8438, precision 0.7826, recall 1.0000, f1 0.8780\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 8 step: 814 loss: 0.2998577952384949\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 815 loss: 0.083273746073246\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 816 loss: 0.30925053358078003\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 817 loss: 0.2713479995727539\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 818 loss: 0.2695021331310272\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 819 loss: 0.21489481627941132\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 820 loss: 0.34253746271133423\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 821 loss: 0.32712864875793457\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 822 loss: 0.5313047766685486\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 823 loss: 0.37334126234054565\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 824 loss: 0.5050674676895142\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 825 loss: 0.1607397496700287\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 826 loss: 0.37668538093566895\n",
      "class 0: acc 0.8750, precision 0.9167, recall 0.9167, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.6250, recall 0.8333, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 827 loss: 0.29609885811805725\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 828 loss: 0.4145795404911041\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "epoch: 8 step: 829 loss: 0.47694098949432373\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 8 step: 830 loss: 0.16407205164432526\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "epoch: 8 step: 831 loss: 0.2972366511821747\n",
      "class 0: acc 0.8750, precision 0.9655, recall 0.9032, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 832 loss: 0.48952925205230713\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 833 loss: 0.21171872317790985\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 834 loss: 0.4484621286392212\n",
      "class 0: acc 0.9062, precision 0.9130, recall 0.9545, f1 0.9333\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 8 step: 835 loss: 0.5443845391273499\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 836 loss: 0.2612886130809784\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 837 loss: 0.2271229326725006\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 838 loss: 0.3435935974121094\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 839 loss: 0.3093193471431732\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 840 loss: 0.1393958330154419\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 841 loss: 0.484521746635437\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 842 loss: 0.1664630025625229\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 8 step: 843 loss: 0.4048202335834503\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 844 loss: 0.47593340277671814\n",
      "class 0: acc 0.7812, precision 0.8889, recall 0.8571, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.2000, recall 0.5000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 845 loss: 0.2563478350639343\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 846 loss: 0.6240569949150085\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 847 loss: 0.34987393021583557\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 848 loss: 0.3498614430427551\n",
      "class 0: acc 0.9062, precision 0.9545, recall 0.9130, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "epoch: 8 step: 849 loss: 0.2890615463256836\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 850 loss: 0.08139283210039139\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 851 loss: 0.28302812576293945\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 852 loss: 0.41285470128059387\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 853 loss: 0.4446456730365753\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 854 loss: 0.38018590211868286\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 855 loss: 0.3274702727794647\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 856 loss: 0.23256778717041016\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 857 loss: 0.5423233509063721\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 858 loss: 0.5523750185966492\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 859 loss: 0.25888511538505554\n",
      "class 0: acc 0.8750, precision 0.9615, recall 0.8929, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 860 loss: 0.19204768538475037\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 861 loss: 0.37428197264671326\n",
      "class 0: acc 0.8750, precision 0.8261, recall 1.0000, f1 0.9048\n",
      "class 1: acc 0.9062, precision 0.8889, recall 0.8000, f1 0.8421\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 862 loss: 0.10494700074195862\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 863 loss: 0.26951223611831665\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.9375, precision 0.8750, recall 0.8750, f1 0.8750\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 864 loss: 0.31640225648880005\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 865 loss: 0.3688342869281769\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 866 loss: 0.07945755869150162\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 867 loss: 0.21855874359607697\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 868 loss: 0.19063399732112885\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 869 loss: 0.434198796749115\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 870 loss: 0.3420908749103546\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 871 loss: 0.490515798330307\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 872 loss: 0.2911408841609955\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 873 loss: 0.41340869665145874\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 874 loss: 0.47947412729263306\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 875 loss: 0.36241814494132996\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 876 loss: 0.4877883791923523\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 877 loss: 0.31088125705718994\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 878 loss: 0.5225940346717834\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 879 loss: 0.47620558738708496\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 880 loss: 0.46844568848609924\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 881 loss: 0.29116374254226685\n",
      "class 0: acc 0.8438, precision 0.9200, recall 0.8846, f1 0.9020\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 8 step: 882 loss: 0.20942778885364532\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 883 loss: 0.26954221725463867\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "epoch: 8 step: 884 loss: 0.7721110582351685\n",
      "class 0: acc 0.7812, precision 0.7692, recall 0.9524, f1 0.8511\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 885 loss: 0.43836715817451477\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 886 loss: 0.17058078944683075\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 887 loss: 0.27198275923728943\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 888 loss: 0.2826484143733978\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 889 loss: 0.22524812817573547\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9286, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 890 loss: 0.2485893964767456\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 891 loss: 0.3988732695579529\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 892 loss: 0.2713843584060669\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 893 loss: 0.4554976224899292\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 894 loss: 0.431986540555954\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 895 loss: 0.21320046484470367\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 896 loss: 0.1764679104089737\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 897 loss: 0.35555872321128845\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 898 loss: 0.15077298879623413\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 899 loss: 0.621406078338623\n",
      "class 0: acc 0.7500, precision 0.8214, recall 0.8846, f1 0.8519\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 900 loss: 0.15379326045513153\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 901 loss: 0.41633301973342896\n",
      "class 0: acc 0.8125, precision 0.8846, recall 0.8846, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "epoch: 8 step: 902 loss: 0.3449176251888275\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 8 step: 903 loss: 0.2184300571680069\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 904 loss: 0.3386577367782593\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 905 loss: 0.37343600392341614\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 906 loss: 0.45419636368751526\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 907 loss: 0.3480575382709503\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 908 loss: 0.24532736837863922\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 909 loss: 0.24413305521011353\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 910 loss: 0.34783264994621277\n",
      "class 0: acc 0.8438, precision 0.9231, recall 0.8889, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 8 step: 911 loss: 0.2591197192668915\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 912 loss: 0.6021813154220581\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 913 loss: 0.12884938716888428\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 914 loss: 0.2163926213979721\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 915 loss: 0.47054627537727356\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 916 loss: 0.386913001537323\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 917 loss: 0.3453858494758606\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 918 loss: 0.1973600536584854\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 919 loss: 0.5895538926124573\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 920 loss: 0.21387681365013123\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 921 loss: 0.17432650923728943\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 922 loss: 0.07061979174613953\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 923 loss: 0.4898684620857239\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 924 loss: 0.2776646614074707\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 925 loss: 0.2204548567533493\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 926 loss: 0.6467674970626831\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 927 loss: 0.2876071631908417\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 928 loss: 0.3538464903831482\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 929 loss: 0.316278874874115\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 930 loss: 0.27433663606643677\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 931 loss: 0.2570924460887909\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 932 loss: 0.4589397609233856\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 933 loss: 0.2257930189371109\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 934 loss: 0.23988211154937744\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 935 loss: 0.535550594329834\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 936 loss: 0.3056882619857788\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 937 loss: 0.23703086376190186\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 938 loss: 0.29381096363067627\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 939 loss: 0.12980176508426666\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 940 loss: 0.2281024307012558\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 941 loss: 0.5000119209289551\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 942 loss: 0.42764008045196533\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 943 loss: 0.4596618413925171\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 944 loss: 0.5263128280639648\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 945 loss: 0.25719931721687317\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 946 loss: 0.33928564190864563\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 0.9375, precision 0.8750, recall 0.8750, f1 0.8750\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 947 loss: 0.36939650774002075\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 948 loss: 0.7089506983757019\n",
      "class 0: acc 0.7188, precision 0.7778, recall 0.8750, f1 0.8235\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 949 loss: 0.6254958510398865\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 950 loss: 0.15808431804180145\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 951 loss: 0.3083387017250061\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 952 loss: 0.24209201335906982\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 953 loss: 0.320512592792511\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 954 loss: 0.37972530722618103\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 955 loss: 0.3233943283557892\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 956 loss: 0.42822152376174927\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 957 loss: 0.26989462971687317\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 958 loss: 0.35288289189338684\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 959 loss: 0.433157742023468\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 960 loss: 0.3913462162017822\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 961 loss: 0.22859850525856018\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 962 loss: 0.2485085427761078\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 963 loss: 0.45122262835502625\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 964 loss: 0.3797871470451355\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 965 loss: 0.369078665971756\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 966 loss: 0.21653497219085693\n",
      "class 0: acc 0.9375, precision 0.9677, recall 0.9677, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 967 loss: 0.42368578910827637\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 968 loss: 0.5710235834121704\n",
      "class 0: acc 0.8125, precision 0.7692, recall 1.0000, f1 0.8696\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 969 loss: 0.2978249490261078\n",
      "class 0: acc 0.8438, precision 0.9286, recall 0.8966, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 970 loss: 0.41238507628440857\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 971 loss: 0.43958359956741333\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 972 loss: 0.76502525806427\n",
      "class 0: acc 0.8438, precision 0.8261, recall 0.9500, f1 0.8837\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.8571, f1 0.7500\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 973 loss: 0.26084253191947937\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 974 loss: 0.37329670786857605\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 975 loss: 0.24535270035266876\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 976 loss: 0.3576553761959076\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 8 step: 977 loss: 0.34825271368026733\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 8 step: 978 loss: 0.1828206479549408\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 8 step: 979 loss: 0.1641288697719574\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9615, f1 0.9804\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 980 loss: 0.3798953890800476\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 981 loss: 0.3274776339530945\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 982 loss: 0.44471976161003113\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 983 loss: 0.35595452785491943\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 984 loss: 0.4785113036632538\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 985 loss: 0.2708880603313446\n",
      "class 0: acc 0.8438, precision 0.9000, recall 0.9310, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 986 loss: 0.21701818704605103\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 987 loss: 0.3286719024181366\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 988 loss: 0.26207977533340454\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 989 loss: 0.1899041384458542\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 990 loss: 0.17421762645244598\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 991 loss: 0.19560426473617554\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 992 loss: 0.16485477983951569\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 993 loss: 0.31911930441856384\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 994 loss: 0.30455830693244934\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 995 loss: 0.4647963047027588\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 996 loss: 0.4007234275341034\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 997 loss: 0.2923170328140259\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 998 loss: 0.2778531312942505\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 999 loss: 0.46612292528152466\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.7812, precision 0.8000, recall 0.4000, f1 0.5333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1000 loss: 0.2640535235404968\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1001 loss: 0.3963671922683716\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1002 loss: 0.3901708722114563\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1003 loss: 0.4828142523765564\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1004 loss: 0.6884403824806213\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1005 loss: 0.3546587824821472\n",
      "class 0: acc 0.8125, precision 0.9167, recall 0.8462, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.3750, recall 1.0000, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1006 loss: 0.09702431410551071\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1007 loss: 0.30007171630859375\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1008 loss: 0.29050740599632263\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1009 loss: 0.1587735265493393\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1010 loss: 0.573943018913269\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1011 loss: 0.4422944486141205\n",
      "class 0: acc 0.8125, precision 0.7692, recall 1.0000, f1 0.8696\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1012 loss: 0.5345125794410706\n",
      "class 0: acc 0.7812, precision 0.8462, recall 0.8800, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1013 loss: 0.3854082226753235\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1014 loss: 0.31205472350120544\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1015 loss: 0.40545910596847534\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.8571, recall 0.6667, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1016 loss: 0.30178529024124146\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1017 loss: 0.29019442200660706\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1018 loss: 0.2916598320007324\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 1019 loss: 0.4607159495353699\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 8 step: 1020 loss: 0.5431723594665527\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1021 loss: 0.46916690468788147\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 8 step: 1022 loss: 0.218491330742836\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1023 loss: 0.6599401235580444\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1024 loss: 0.4368302822113037\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1025 loss: 0.4656161963939667\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1026 loss: 0.4785294234752655\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1027 loss: 0.28210675716400146\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1028 loss: 0.42779746651649475\n",
      "class 0: acc 0.8125, precision 0.8966, recall 0.8966, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1029 loss: 0.3196316063404083\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1030 loss: 0.1010744720697403\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1031 loss: 0.272686630487442\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1032 loss: 0.4061541259288788\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1033 loss: 0.5193126797676086\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1034 loss: 0.26827386021614075\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1035 loss: 0.284506618976593\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1036 loss: 0.39770376682281494\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1037 loss: 0.14098237454891205\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1038 loss: 0.5686015486717224\n",
      "class 0: acc 0.7812, precision 0.8065, recall 0.9615, f1 0.8772\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1039 loss: 0.16654489934444427\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1040 loss: 0.3010469079017639\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 1041 loss: 0.3607921600341797\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1042 loss: 0.3484642207622528\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1043 loss: 0.34818267822265625\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1044 loss: 0.4579482972621918\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1045 loss: 0.38033151626586914\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1046 loss: 0.4267304539680481\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 1047 loss: 0.19615952670574188\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1048 loss: 0.44339630007743835\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1049 loss: 0.455824077129364\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1050 loss: 0.2349977195262909\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1051 loss: 0.3790297508239746\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 8 step: 1052 loss: 0.42686226963996887\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 1053 loss: 0.4387719929218292\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 1054 loss: 0.2665034830570221\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1055 loss: 0.26835885643959045\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7778, f1 0.8750\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1056 loss: 0.3076663911342621\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 8 step: 1057 loss: 0.11810030043125153\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1058 loss: 0.5891468524932861\n",
      "class 0: acc 0.7812, precision 0.8462, recall 0.8800, f1 0.8627\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "epoch: 8 step: 1059 loss: 0.3722047507762909\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1060 loss: 0.39805617928504944\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 8 step: 1061 loss: 0.38812193274497986\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "epoch: 8 step: 1062 loss: 0.21745793521404266\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 8 step: 1063 loss: 0.29320549964904785\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1064 loss: 0.3013242185115814\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1065 loss: 0.326111763715744\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 8 step: 1066 loss: 0.21230953931808472\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 1067 loss: 0.43457236886024475\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1068 loss: 0.3734464943408966\n",
      "class 0: acc 0.8438, precision 0.9286, recall 0.8966, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1069 loss: 0.4002225399017334\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1070 loss: 0.40804386138916016\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1071 loss: 0.3347945213317871\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1072 loss: 0.6468713283538818\n",
      "class 0: acc 0.6875, precision 0.6875, recall 1.0000, f1 0.8148\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1073 loss: 0.21185854077339172\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1074 loss: 0.15729054808616638\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1075 loss: 0.2948402166366577\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1076 loss: 0.35262733697891235\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "epoch: 8 step: 1077 loss: 0.22661423683166504\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1078 loss: 0.38519400358200073\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 1079 loss: 0.3512972593307495\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1080 loss: 0.6958284974098206\n",
      "class 0: acc 0.7812, precision 0.8261, recall 0.8636, f1 0.8444\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "epoch: 8 step: 1081 loss: 0.4928460717201233\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1082 loss: 0.7218775749206543\n",
      "class 0: acc 0.7812, precision 0.8333, recall 0.8696, f1 0.8511\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "epoch: 8 step: 1083 loss: 0.24354811012744904\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1084 loss: 0.40225833654403687\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1085 loss: 0.40139007568359375\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 8 step: 1086 loss: 0.3683567941188812\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1087 loss: 0.38829365372657776\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 8 step: 1088 loss: 0.3952258825302124\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 8 step: 1089 loss: 0.3039039373397827\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 1090 loss: 0.25822997093200684\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1091 loss: 0.419197678565979\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1092 loss: 0.37580007314682007\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1093 loss: 0.44120413064956665\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "epoch: 8 step: 1094 loss: 0.4401962459087372\n",
      "class 0: acc 0.8125, precision 0.8000, recall 0.9524, f1 0.8696\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 1095 loss: 0.48691830039024353\n",
      "class 0: acc 0.8438, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.8333, recall 0.5556, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 1096 loss: 0.2628294825553894\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1097 loss: 0.31839829683303833\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1098 loss: 0.39679381251335144\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1099 loss: 0.2693643867969513\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1100 loss: 0.20201027393341064\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1101 loss: 0.4504556953907013\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1102 loss: 0.5119297504425049\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1103 loss: 0.4271382689476013\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1104 loss: 0.2823665142059326\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1105 loss: 0.6194148063659668\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1106 loss: 0.33011114597320557\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1107 loss: 0.3041934072971344\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1108 loss: 0.2558134198188782\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1109 loss: 0.7420192360877991\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1110 loss: 0.57278972864151\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1111 loss: 0.6418745517730713\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1112 loss: 0.26550909876823425\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1113 loss: 0.23899275064468384\n",
      "class 0: acc 0.8438, precision 0.9643, recall 0.8710, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1114 loss: 0.3368254005908966\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 1115 loss: 0.44615283608436584\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1116 loss: 0.17484252154827118\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 1117 loss: 0.21586941182613373\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1118 loss: 0.47570669651031494\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 1119 loss: 0.2744067907333374\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1120 loss: 0.13896270096302032\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1121 loss: 0.12397858500480652\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1122 loss: 0.3492370843887329\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.7000, f1 0.8235\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1123 loss: 0.6011013984680176\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1124 loss: 0.3735005259513855\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1125 loss: 0.4094915986061096\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1126 loss: 0.2538661062717438\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1127 loss: 0.20480550825595856\n",
      "class 0: acc 0.9375, precision 0.9677, recall 0.9677, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1128 loss: 0.17692413926124573\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1129 loss: 0.375760018825531\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1130 loss: 0.3046501576900482\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 1131 loss: 0.3083152770996094\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1132 loss: 0.8051559925079346\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1133 loss: 0.24248866736888885\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1134 loss: 0.4755719304084778\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1135 loss: 0.2453380823135376\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1136 loss: 0.3118111491203308\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1137 loss: 0.4370425045490265\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 1138 loss: 0.2750410735607147\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1139 loss: 0.3286360204219818\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1140 loss: 0.16747961938381195\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1141 loss: 0.29762423038482666\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1142 loss: 0.18261992931365967\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1143 loss: 0.43559521436691284\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1144 loss: 0.3486742079257965\n",
      "class 0: acc 0.8750, precision 0.9630, recall 0.8966, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.2000, recall 0.5000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1145 loss: 0.4265610873699188\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1146 loss: 0.40640532970428467\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 0.8750, precision 0.6250, recall 0.8333, f1 0.7143\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1147 loss: 0.15846364200115204\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 1148 loss: 0.44227680563926697\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1149 loss: 0.20848046243190765\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1150 loss: 0.49086305499076843\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1151 loss: 0.41310715675354004\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 8 step: 1152 loss: 0.31884580850601196\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 8 step: 1153 loss: 0.3552340567111969\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 8 step: 1154 loss: 0.5655991435050964\n",
      "class 0: acc 0.8438, precision 0.8750, recall 0.9130, f1 0.8936\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1155 loss: 0.11441359668970108\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1156 loss: 0.14935259521007538\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 8 step: 1157 loss: 0.25812792778015137\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1158 loss: 0.14487804472446442\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1159 loss: 0.6371660828590393\n",
      "class 0: acc 0.7500, precision 0.7692, recall 0.9091, f1 0.8333\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 8 step: 1160 loss: 0.4064747393131256\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1161 loss: 0.5752050876617432\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1162 loss: 0.5443403124809265\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1163 loss: 0.3797903060913086\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1164 loss: 0.5454196333885193\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1165 loss: 0.21999455988407135\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9677, f1 0.9836\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1166 loss: 0.3280802071094513\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1167 loss: 0.5210422277450562\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1168 loss: 0.2940441966056824\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1169 loss: 0.23435157537460327\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1170 loss: 0.6132528185844421\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1171 loss: 0.5127256512641907\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1172 loss: 0.23556487262248993\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1173 loss: 0.459445983171463\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1174 loss: 0.1830177903175354\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1175 loss: 0.5029218792915344\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1176 loss: 0.2263670116662979\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1177 loss: 0.15206614136695862\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1178 loss: 0.36735251545906067\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1179 loss: 0.47660762071609497\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1180 loss: 0.3722415864467621\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 1181 loss: 0.38819700479507446\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1182 loss: 0.6506972908973694\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1183 loss: 0.12523673474788666\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1184 loss: 0.3761163055896759\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1185 loss: 0.5245974063873291\n",
      "class 0: acc 0.8438, precision 0.8636, recall 0.9048, f1 0.8837\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "epoch: 8 step: 1186 loss: 0.33640846610069275\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 8 step: 1187 loss: 0.33585935831069946\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 8 step: 1188 loss: 0.3190065026283264\n",
      "class 0: acc 0.9375, precision 0.9565, recall 0.9565, f1 0.9565\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "epoch: 8 step: 1189 loss: 0.3083036541938782\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1190 loss: 0.34808439016342163\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1191 loss: 0.4781307876110077\n",
      "class 0: acc 0.7812, precision 0.8500, recall 0.8095, f1 0.8293\n",
      "class 1: acc 0.7188, precision 0.6000, recall 0.5455, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1192 loss: 0.3404345214366913\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1193 loss: 0.30909502506256104\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1194 loss: 0.37714993953704834\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1195 loss: 0.334364116191864\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1196 loss: 0.3048485517501831\n",
      "class 0: acc 0.8750, precision 0.9333, recall 0.9333, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1197 loss: 0.13974922895431519\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 8 step: 1198 loss: 0.4136981666088104\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1199 loss: 0.41982051730155945\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1200 loss: 0.14833872020244598\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1201 loss: 0.4378962814807892\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 1202 loss: 0.30404216051101685\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1203 loss: 0.30271580815315247\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1204 loss: 0.20846016705036163\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1205 loss: 0.40484005212783813\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1206 loss: 0.6527406573295593\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1207 loss: 0.20670947432518005\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1208 loss: 0.47708860039711\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1209 loss: 0.7459316849708557\n",
      "class 0: acc 0.7188, precision 0.7143, recall 0.9524, f1 0.8163\n",
      "class 1: acc 0.7812, precision 0.7500, recall 0.3333, f1 0.4615\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1210 loss: 0.10791303962469101\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1211 loss: 0.1597791463136673\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9333, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1212 loss: 0.4117317795753479\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1213 loss: 0.46012818813323975\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1214 loss: 0.1931227147579193\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1215 loss: 0.3150651156902313\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1216 loss: 0.32601580023765564\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1217 loss: 0.12328632920980453\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1218 loss: 0.34374114871025085\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 1219 loss: 0.36037957668304443\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1220 loss: 0.9656591415405273\n",
      "class 0: acc 0.7812, precision 0.7308, recall 1.0000, f1 0.8444\n",
      "class 1: acc 0.7500, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1221 loss: 0.1496954709291458\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1222 loss: 0.6693020462989807\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.7812, precision 0.2500, recall 0.2000, f1 0.2222\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 8 step: 1223 loss: 0.38429996371269226\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1224 loss: 0.3441394567489624\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1225 loss: 0.36298465728759766\n",
      "class 0: acc 0.8750, precision 0.8750, recall 0.9545, f1 0.9130\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 8 step: 1226 loss: 0.44991952180862427\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 8 step: 1227 loss: 0.23741765320301056\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1228 loss: 0.2760940492153168\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1229 loss: 0.6604644656181335\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1230 loss: 0.3493863344192505\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1231 loss: 0.5412641167640686\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "epoch: 8 step: 1232 loss: 0.33638495206832886\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1233 loss: 0.25310036540031433\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9333, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1234 loss: 0.3453584611415863\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1235 loss: 0.24626541137695312\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1236 loss: 0.23374725878238678\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1237 loss: 0.1154673844575882\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1238 loss: 0.29304277896881104\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1239 loss: 0.1080772802233696\n",
      "class 0: acc 0.9688, precision 0.9688, recall 1.0000, f1 0.9841\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1240 loss: 0.2483430951833725\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1241 loss: 0.18736590445041656\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1242 loss: 0.644254207611084\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1243 loss: 0.4643876254558563\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1244 loss: 0.20828747749328613\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1245 loss: 0.2769416868686676\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1246 loss: 0.4111268222332001\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1247 loss: 0.2424609363079071\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1248 loss: 0.22361230850219727\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1249 loss: 0.3981907069683075\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 8 step: 1250 loss: 0.3710488975048065\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1 loss: 0.26837727427482605\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 2 loss: 0.22093579173088074\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 3 loss: 0.29564231634140015\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 4 loss: 0.21765105426311493\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 5 loss: 0.2595426142215729\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 6 loss: 0.5690822005271912\n",
      "class 0: acc 0.7812, precision 0.8065, recall 0.9615, f1 0.8772\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 7 loss: 0.42440587282180786\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 8 loss: 0.5497986674308777\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 9 loss: 0.3746160566806793\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 10 loss: 0.229816734790802\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 11 loss: 0.41813939809799194\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 12 loss: 0.3983745574951172\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 13 loss: 0.4363335967063904\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 14 loss: 0.2559491991996765\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 15 loss: 0.3445306718349457\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 16 loss: 0.31088125705718994\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 17 loss: 0.5870504379272461\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 18 loss: 0.2200963795185089\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 19 loss: 0.30957940220832825\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 20 loss: 0.21113604307174683\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 21 loss: 0.35350948572158813\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 22 loss: 0.24199289083480835\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 23 loss: 0.32672035694122314\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 24 loss: 0.3433493971824646\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 25 loss: 0.1835387796163559\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 26 loss: 0.4454948604106903\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 27 loss: 0.2517542839050293\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 28 loss: 0.40736842155456543\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 29 loss: 0.4422410726547241\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 30 loss: 0.20932455360889435\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 31 loss: 0.24618899822235107\n",
      "class 0: acc 0.9688, precision 0.9600, recall 1.0000, f1 0.9796\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 9 step: 32 loss: 0.29908519983291626\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 33 loss: 0.24071675539016724\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 34 loss: 0.565430760383606\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 35 loss: 0.4494330883026123\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 36 loss: 0.3139692544937134\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 37 loss: 0.3573162853717804\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "epoch: 9 step: 38 loss: 0.28252291679382324\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 39 loss: 0.3689645230770111\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 40 loss: 0.5275325179100037\n",
      "class 0: acc 0.7500, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 9 step: 41 loss: 0.442013144493103\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 42 loss: 0.2848717272281647\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 43 loss: 0.41181060671806335\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 44 loss: 0.24461829662322998\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 45 loss: 0.3232194483280182\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 46 loss: 0.25136691331863403\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 47 loss: 0.33249977231025696\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 48 loss: 0.3260762393474579\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 49 loss: 0.45875969529151917\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 50 loss: 0.4863448143005371\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 51 loss: 0.4815208613872528\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 52 loss: 0.7005212903022766\n",
      "class 0: acc 0.7812, precision 0.7692, recall 0.9524, f1 0.8511\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 53 loss: 0.2074868381023407\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 54 loss: 0.1668703258037567\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 55 loss: 0.348580539226532\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 56 loss: 0.2701171636581421\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 57 loss: 0.3271807134151459\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 58 loss: 0.30948972702026367\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 59 loss: 0.7936761975288391\n",
      "class 0: acc 0.7188, precision 0.7333, recall 0.9565, f1 0.8302\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 60 loss: 0.3195311427116394\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 61 loss: 0.42618176341056824\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 62 loss: 0.5508562922477722\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 63 loss: 0.20889241993427277\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 64 loss: 0.46226203441619873\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 65 loss: 0.29615315794944763\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 66 loss: 0.33468231558799744\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 67 loss: 0.3344586193561554\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 68 loss: 0.3817172944545746\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 69 loss: 0.3466740846633911\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 70 loss: 0.47878706455230713\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 71 loss: 0.27691900730133057\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 72 loss: 0.6489691734313965\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 73 loss: 0.7422640323638916\n",
      "class 0: acc 0.7188, precision 0.7000, recall 1.0000, f1 0.8235\n",
      "class 1: acc 0.7812, precision 1.0000, recall 0.2222, f1 0.3636\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 74 loss: 0.6907370686531067\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 75 loss: 0.44665026664733887\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 76 loss: 0.34432604908943176\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 77 loss: 0.3572998046875\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 78 loss: 0.3067568838596344\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 79 loss: 0.39500242471694946\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 80 loss: 0.36177322268486023\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 81 loss: 0.3234966993331909\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 82 loss: 0.19820237159729004\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 83 loss: 0.44228383898735046\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 84 loss: 0.28264012932777405\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 85 loss: 0.5488596558570862\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 86 loss: 0.4438638389110565\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 87 loss: 0.6440918445587158\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 88 loss: 0.40411555767059326\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 89 loss: 0.5559238195419312\n",
      "class 0: acc 0.7500, precision 0.7586, recall 0.9565, f1 0.8462\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 90 loss: 0.2166944146156311\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 91 loss: 0.292045533657074\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 92 loss: 0.24113893508911133\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 93 loss: 0.21851377189159393\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 94 loss: 0.45311278104782104\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 95 loss: 0.46859920024871826\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 96 loss: 0.28814801573753357\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 9 step: 97 loss: 0.44716590642929077\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 98 loss: 0.2037564069032669\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 99 loss: 0.18843457102775574\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 100 loss: 0.1478244513273239\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 101 loss: 0.2611246705055237\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 102 loss: 0.3624732792377472\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 103 loss: 0.25887295603752136\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 104 loss: 0.4543028473854065\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 105 loss: 0.5115328431129456\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 106 loss: 0.2856806218624115\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 107 loss: 0.23696425557136536\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 108 loss: 0.2893887758255005\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 109 loss: 0.27134189009666443\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 110 loss: 0.3487061858177185\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 9 step: 111 loss: 0.47653308510780334\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 112 loss: 0.20180611312389374\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 113 loss: 0.5341894030570984\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 114 loss: 0.43210339546203613\n",
      "class 0: acc 0.7812, precision 0.7812, recall 1.0000, f1 0.8772\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 115 loss: 0.3090443015098572\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 116 loss: 0.4981350600719452\n",
      "class 0: acc 0.8125, precision 0.9583, recall 0.8214, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.4286, recall 1.0000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 117 loss: 0.25732263922691345\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 118 loss: 0.4719308614730835\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 119 loss: 0.2328667789697647\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 120 loss: 0.29016539454460144\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 9 step: 121 loss: 0.2588566243648529\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 122 loss: 0.5624120831489563\n",
      "class 0: acc 0.8125, precision 0.9200, recall 0.8519, f1 0.8846\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 123 loss: 0.4866105914115906\n",
      "class 0: acc 0.7500, precision 0.7931, recall 0.9200, f1 0.8519\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 124 loss: 0.9110512137413025\n",
      "class 0: acc 0.7188, precision 0.7241, recall 0.9545, f1 0.8235\n",
      "class 1: acc 0.7812, precision 0.3333, recall 0.1667, f1 0.2222\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 125 loss: 0.41767123341560364\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "epoch: 9 step: 126 loss: 0.2760027050971985\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 127 loss: 0.4776216149330139\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 128 loss: 0.4031670391559601\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 129 loss: 0.39159658551216125\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "epoch: 9 step: 130 loss: 0.5222706198692322\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 131 loss: 0.6026676893234253\n",
      "class 0: acc 0.8125, precision 0.8800, recall 0.8800, f1 0.8800\n",
      "class 1: acc 0.7500, precision 0.1667, recall 0.2500, f1 0.2000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 132 loss: 0.48120516538619995\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 133 loss: 0.34274765849113464\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 134 loss: 0.5928289294242859\n",
      "class 0: acc 0.8438, precision 0.8400, recall 0.9545, f1 0.8936\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 135 loss: 0.2794104814529419\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 136 loss: 0.3382027745246887\n",
      "class 0: acc 0.9062, precision 0.9545, recall 0.9130, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.8889, f1 0.8421\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 137 loss: 0.2367967814207077\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 138 loss: 0.16219858825206757\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 139 loss: 0.3896009624004364\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 140 loss: 0.5597273707389832\n",
      "class 0: acc 0.8125, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 141 loss: 0.42061200737953186\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 142 loss: 0.2676871716976166\n",
      "class 0: acc 0.8750, precision 0.9630, recall 0.8966, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 143 loss: 0.23343521356582642\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 144 loss: 0.1660013496875763\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 145 loss: 0.5600290894508362\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.6000, recall 0.4286, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 146 loss: 0.5283073782920837\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 147 loss: 0.09691686183214188\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 148 loss: 0.1349092721939087\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 149 loss: 0.4804723560810089\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 150 loss: 0.2708700895309448\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 151 loss: 0.3019459545612335\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 152 loss: 0.23128144443035126\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 153 loss: 0.28885743021965027\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 154 loss: 0.4399973154067993\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 155 loss: 0.14302916824817657\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 156 loss: 0.3990336060523987\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 157 loss: 0.22778210043907166\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 158 loss: 0.4059780538082123\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 159 loss: 0.20823335647583008\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 160 loss: 0.6283724904060364\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "epoch: 9 step: 161 loss: 0.31745094060897827\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 162 loss: 0.12177754938602448\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 163 loss: 0.20958080887794495\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 164 loss: 0.2844187915325165\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 165 loss: 0.5013979077339172\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 166 loss: 0.42609626054763794\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 9 step: 167 loss: 0.2596483528614044\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 168 loss: 0.45015212893486023\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 169 loss: 0.5050950646400452\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 170 loss: 0.178190216422081\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 171 loss: 0.2895510494709015\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 172 loss: 0.48711687326431274\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 173 loss: 0.4234009385108948\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 174 loss: 0.535257875919342\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "epoch: 9 step: 175 loss: 0.3160897493362427\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 176 loss: 0.38376325368881226\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 177 loss: 0.38518890738487244\n",
      "class 0: acc 0.7812, precision 0.8065, recall 0.9615, f1 0.8772\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 178 loss: 0.0819692388176918\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 179 loss: 0.5714957118034363\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8125, precision 0.6000, recall 0.4286, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 180 loss: 0.18407592177391052\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 181 loss: 0.4779409170150757\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 182 loss: 0.19157953560352325\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 183 loss: 0.25210702419281006\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 184 loss: 0.36312422156333923\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 9 step: 185 loss: 0.2587374150753021\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 9 step: 186 loss: 0.4766438901424408\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9091, f1 0.8696\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 9 step: 187 loss: 0.24690814316272736\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 188 loss: 0.16980531811714172\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 9 step: 189 loss: 0.2757473587989807\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 190 loss: 0.45710131525993347\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 191 loss: 0.3703874945640564\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 192 loss: 0.5548039674758911\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "epoch: 9 step: 193 loss: 0.29958051443099976\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 194 loss: 0.23989476263523102\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "epoch: 9 step: 195 loss: 0.3078732192516327\n",
      "class 0: acc 0.8438, precision 0.9130, recall 0.8750, f1 0.8936\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 196 loss: 0.6964688301086426\n",
      "class 0: acc 0.7500, precision 0.7407, recall 0.9524, f1 0.8333\n",
      "class 1: acc 0.7812, precision 0.8000, recall 0.4000, f1 0.5333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 197 loss: 0.24720193445682526\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 198 loss: 0.4497905671596527\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 199 loss: 0.3822649419307709\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 200 loss: 0.4826202094554901\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 9 step: 201 loss: 0.3205084502696991\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 202 loss: 0.4266924560070038\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 9 step: 203 loss: 0.5396134853363037\n",
      "class 0: acc 0.7812, precision 0.9565, recall 0.7857, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 204 loss: 0.26368290185928345\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 205 loss: 0.3598615825176239\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 9 step: 206 loss: 0.39307689666748047\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 207 loss: 0.29640090465545654\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 208 loss: 0.2950940430164337\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 209 loss: 0.6167289614677429\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.8438, precision 0.8333, recall 0.5556, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 210 loss: 0.14530274271965027\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 211 loss: 0.2477942854166031\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 212 loss: 0.4623170495033264\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 213 loss: 0.6399156451225281\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 214 loss: 0.6737060546875\n",
      "class 0: acc 0.7812, precision 0.7407, recall 1.0000, f1 0.8511\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 215 loss: 0.2742878496646881\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 216 loss: 0.24393481016159058\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 217 loss: 0.3525315523147583\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 218 loss: 0.34007757902145386\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 219 loss: 0.38914358615875244\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 220 loss: 0.3300913870334625\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 221 loss: 0.24218951165676117\n",
      "class 0: acc 0.8750, precision 0.9333, recall 0.9333, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 222 loss: 0.39615684747695923\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 223 loss: 0.2230341136455536\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 224 loss: 0.352243572473526\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 225 loss: 0.30059218406677246\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 226 loss: 0.3762025535106659\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 227 loss: 0.32637709379196167\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 228 loss: 0.24416297674179077\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 229 loss: 0.28614580631256104\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 230 loss: 0.4052886366844177\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 231 loss: 0.3255600035190582\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 232 loss: 0.2343914657831192\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 233 loss: 0.6680634021759033\n",
      "class 0: acc 0.7188, precision 0.7097, recall 1.0000, f1 0.8302\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 234 loss: 0.2910384237766266\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 235 loss: 0.17198042571544647\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 236 loss: 0.3443601727485657\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 237 loss: 0.5377828478813171\n",
      "class 0: acc 0.8438, precision 0.8636, recall 0.9048, f1 0.8837\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 9 step: 238 loss: 0.27026548981666565\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 239 loss: 0.4788237512111664\n",
      "class 0: acc 0.8438, precision 0.9200, recall 0.8846, f1 0.9020\n",
      "class 1: acc 0.7812, precision 0.2857, recall 0.5000, f1 0.3636\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 240 loss: 0.3802119195461273\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 241 loss: 0.4092961847782135\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 9 step: 242 loss: 0.2813250720500946\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 243 loss: 0.444204181432724\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 244 loss: 0.23793837428092957\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 245 loss: 0.35127174854278564\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 246 loss: 0.4280027151107788\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 247 loss: 0.33876895904541016\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 248 loss: 0.3133891522884369\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 249 loss: 0.2485119253396988\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 250 loss: 0.4235161244869232\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 251 loss: 0.4652957618236542\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 9 step: 252 loss: 0.510881781578064\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 253 loss: 0.2931210398674011\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 254 loss: 0.17041730880737305\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 255 loss: 0.3926085829734802\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 256 loss: 0.13332845270633698\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9615, f1 0.9804\n",
      "class 1: acc 0.9688, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 257 loss: 0.1101633608341217\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 258 loss: 0.41708481311798096\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 9 step: 259 loss: 0.35239964723587036\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 260 loss: 0.4360201358795166\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 261 loss: 0.13122297823429108\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 262 loss: 0.20668469369411469\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 263 loss: 0.19954413175582886\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 264 loss: 0.44992026686668396\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 265 loss: 0.450443834066391\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 266 loss: 0.09995890408754349\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 267 loss: 0.330001562833786\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 268 loss: 0.18308860063552856\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 269 loss: 0.47322878241539\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 270 loss: 0.44099798798561096\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 271 loss: 0.32601529359817505\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 272 loss: 0.15732721984386444\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 273 loss: 0.5122091770172119\n",
      "class 0: acc 0.8125, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 274 loss: 0.24540218710899353\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 275 loss: 0.3072538673877716\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 276 loss: 0.28847765922546387\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 277 loss: 0.46929535269737244\n",
      "class 0: acc 0.8125, precision 0.8000, recall 0.9524, f1 0.8696\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 278 loss: 0.3905811011791229\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 279 loss: 0.29919227957725525\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 280 loss: 0.19070199131965637\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 281 loss: 0.05834858864545822\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 282 loss: 0.484355628490448\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 283 loss: 0.6792022585868835\n",
      "class 0: acc 0.8125, precision 0.8095, recall 0.8947, f1 0.8500\n",
      "class 1: acc 0.7812, precision 0.8571, recall 0.5000, f1 0.6316\n",
      "class 2: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "epoch: 9 step: 284 loss: 0.45790380239486694\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 9 step: 285 loss: 0.42601919174194336\n",
      "class 0: acc 0.8438, precision 0.9048, recall 0.8636, f1 0.8837\n",
      "class 1: acc 0.8438, precision 0.7000, recall 0.7778, f1 0.7368\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 286 loss: 0.33407366275787354\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 287 loss: 0.33829814195632935\n",
      "class 0: acc 0.9062, precision 0.9130, recall 0.9545, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 288 loss: 0.4468308091163635\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 289 loss: 0.1699504852294922\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 290 loss: 0.30933457612991333\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 291 loss: 0.15552890300750732\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 292 loss: 0.2562023401260376\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 293 loss: 0.269876629114151\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 9 step: 294 loss: 0.16215237975120544\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 295 loss: 0.2504458725452423\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 296 loss: 0.2905426025390625\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 297 loss: 0.12067434191703796\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 298 loss: 0.22021763026714325\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 299 loss: 0.3867865800857544\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 300 loss: 0.10628259927034378\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 301 loss: 0.5534990429878235\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 302 loss: 0.239191472530365\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 303 loss: 0.1563325971364975\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 304 loss: 0.2894555926322937\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 305 loss: 0.25223031640052795\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 306 loss: 0.22198903560638428\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 307 loss: 0.5209343433380127\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 308 loss: 0.2813984751701355\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 309 loss: 0.16565489768981934\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 310 loss: 0.24912317097187042\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 311 loss: 0.2791791260242462\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 312 loss: 0.32120245695114136\n",
      "class 0: acc 0.8750, precision 0.9615, recall 0.8929, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "epoch: 9 step: 313 loss: 0.36519694328308105\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 314 loss: 0.4583166837692261\n",
      "class 0: acc 0.8125, precision 0.8000, recall 0.9524, f1 0.8696\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 9 step: 315 loss: 0.25032973289489746\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 316 loss: 0.4156661033630371\n",
      "class 0: acc 0.8438, precision 0.9286, recall 0.8966, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 317 loss: 0.4493809640407562\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 318 loss: 0.2957767844200134\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 319 loss: 0.5500692129135132\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 320 loss: 0.14907945692539215\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 321 loss: 0.3326329290866852\n",
      "class 0: acc 0.8438, precision 0.9310, recall 0.9000, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 322 loss: 0.3755955696105957\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 323 loss: 0.27958405017852783\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 324 loss: 0.08585898578166962\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 325 loss: 0.5007938742637634\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 326 loss: 0.36522746086120605\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 327 loss: 0.3787989020347595\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 328 loss: 0.3225368559360504\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 329 loss: 0.3086340129375458\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 330 loss: 0.24492700397968292\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 331 loss: 0.34767988324165344\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 332 loss: 0.2791118621826172\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 333 loss: 0.7685373425483704\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 334 loss: 0.4928296208381653\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 335 loss: 0.3675623834133148\n",
      "class 0: acc 0.8125, precision 0.9200, recall 0.8519, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.4286, recall 0.6000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 336 loss: 0.4845290184020996\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 337 loss: 0.43333151936531067\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 338 loss: 0.5566185712814331\n",
      "class 0: acc 0.7500, precision 0.7917, recall 0.8636, f1 0.8261\n",
      "class 1: acc 0.8125, precision 0.6250, recall 0.6250, f1 0.6250\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 339 loss: 0.3397590219974518\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 340 loss: 0.35872963070869446\n",
      "class 0: acc 0.8750, precision 0.9630, recall 0.8966, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 341 loss: 0.3718838691711426\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 342 loss: 0.38801395893096924\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 343 loss: 0.1413394659757614\n",
      "class 0: acc 0.9375, precision 0.9677, recall 0.9677, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 344 loss: 0.1947857141494751\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 345 loss: 0.23671400547027588\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 346 loss: 0.314706414937973\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 347 loss: 0.15159377455711365\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 348 loss: 0.6435194611549377\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 349 loss: 0.5202251672744751\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 350 loss: 0.3659101128578186\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 351 loss: 0.45885831117630005\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 352 loss: 0.24046479165554047\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 353 loss: 0.288947194814682\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 354 loss: 0.23314662277698517\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 355 loss: 0.36981481313705444\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 356 loss: 0.6099938750267029\n",
      "class 0: acc 0.7500, precision 0.7586, recall 0.9565, f1 0.8462\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 357 loss: 0.2969168424606323\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 358 loss: 0.3166597783565521\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 359 loss: 0.2440081685781479\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 360 loss: 0.46270883083343506\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 361 loss: 0.46414023637771606\n",
      "class 0: acc 0.7812, precision 0.8800, recall 0.8462, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.2000, recall 0.3333, f1 0.2500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 9 step: 362 loss: 0.41535696387290955\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 363 loss: 0.3511136472225189\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 364 loss: 0.38919734954833984\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 365 loss: 0.23229441046714783\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 366 loss: 0.8395983576774597\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.7812, precision 1.0000, recall 0.1250, f1 0.2222\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 367 loss: 0.20905162394046783\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 368 loss: 0.3828102946281433\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 369 loss: 0.1329314112663269\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 370 loss: 0.22134700417518616\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 371 loss: 0.37858057022094727\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 372 loss: 0.6202647089958191\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 373 loss: 0.3321772515773773\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 374 loss: 0.2253735214471817\n",
      "class 0: acc 0.9688, precision 0.9600, recall 1.0000, f1 0.9796\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 375 loss: 0.3489672541618347\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 376 loss: 0.47528985142707825\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 377 loss: 0.7000144124031067\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 378 loss: 0.19849400222301483\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 379 loss: 0.313700795173645\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 380 loss: 0.23574551939964294\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 381 loss: 0.1433599293231964\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 382 loss: 0.38489726185798645\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 383 loss: 0.2553267776966095\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 384 loss: 0.18558527529239655\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 385 loss: 0.1940220594406128\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 386 loss: 0.4497234523296356\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 387 loss: 0.45839840173721313\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 388 loss: 0.2922179400920868\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.9000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 389 loss: 0.5394158959388733\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 390 loss: 0.31908687949180603\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 391 loss: 0.09150879830121994\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 392 loss: 0.2909183204174042\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 393 loss: 0.6284414529800415\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 9 step: 394 loss: 0.740304708480835\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 395 loss: 0.3105996549129486\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 396 loss: 0.32501208782196045\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 397 loss: 0.38465264439582825\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 398 loss: 0.2221996784210205\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 399 loss: 0.1301169991493225\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 400 loss: 0.13206583261489868\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 401 loss: 0.285754919052124\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 402 loss: 0.1423254758119583\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 403 loss: 0.33075764775276184\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 404 loss: 0.12382513284683228\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 405 loss: 0.3436344861984253\n",
      "class 0: acc 0.8438, precision 0.9167, recall 0.8800, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.6250, recall 0.7143, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 406 loss: 0.17028015851974487\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 407 loss: 0.46032044291496277\n",
      "class 0: acc 0.7812, precision 0.8519, recall 0.8846, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.2000, recall 0.5000, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 408 loss: 0.3674456477165222\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 409 loss: 0.19562551379203796\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 410 loss: 0.21792709827423096\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 411 loss: 0.25774434208869934\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 412 loss: 0.37798234820365906\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 413 loss: 0.5719395279884338\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 414 loss: 0.47874242067337036\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8125, precision 0.2500, recall 0.2500, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 415 loss: 0.4086916148662567\n",
      "class 0: acc 0.9062, precision 0.9583, recall 0.9200, f1 0.9388\n",
      "class 1: acc 0.8750, precision 0.6250, recall 0.8333, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 416 loss: 0.4461483955383301\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 417 loss: 0.2232344001531601\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 418 loss: 0.28799647092819214\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 419 loss: 0.37102943658828735\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 420 loss: 0.42807766795158386\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 421 loss: 0.3030102252960205\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 422 loss: 0.3229420483112335\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 423 loss: 0.30157095193862915\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 424 loss: 0.39377039670944214\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 425 loss: 0.2447052299976349\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 426 loss: 0.3049040138721466\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 427 loss: 0.23490473628044128\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 428 loss: 0.3778093755245209\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 429 loss: 0.13709594309329987\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 430 loss: 0.36023956537246704\n",
      "class 0: acc 0.8438, precision 0.8750, recall 0.9130, f1 0.8936\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 431 loss: 0.49459758400917053\n",
      "class 0: acc 0.8125, precision 0.8846, recall 0.8846, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 432 loss: 0.5472856760025024\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 433 loss: 0.3008001744747162\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 434 loss: 0.3382665812969208\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 435 loss: 0.29302892088890076\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 436 loss: 0.3167477250099182\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 437 loss: 0.18636733293533325\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 438 loss: 0.4150586724281311\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 439 loss: 0.16785305738449097\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 440 loss: 0.3724307715892792\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 441 loss: 0.40839919447898865\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 442 loss: 0.5304612517356873\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 443 loss: 0.40126490592956543\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 444 loss: 0.33669745922088623\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 445 loss: 0.6106787323951721\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 446 loss: 0.41741350293159485\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 9 step: 447 loss: 0.2619926929473877\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 448 loss: 0.2000960409641266\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 449 loss: 0.19482342898845673\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 450 loss: 0.1912291795015335\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 451 loss: 0.2278710901737213\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 452 loss: 0.3916158378124237\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 453 loss: 0.2705790102481842\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 454 loss: 0.34965580701828003\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 455 loss: 0.3586708605289459\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 456 loss: 0.2832852602005005\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 457 loss: 0.22395479679107666\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 458 loss: 0.3862000107765198\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 459 loss: 0.11275225877761841\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 460 loss: 0.3389819860458374\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 461 loss: 0.49919456243515015\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 462 loss: 0.32943853735923767\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 463 loss: 0.54204922914505\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 464 loss: 0.15071816742420197\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 465 loss: 0.03868268057703972\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 466 loss: 0.43688857555389404\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 467 loss: 0.5944324731826782\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 468 loss: 0.2065514773130417\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 469 loss: 0.17997035384178162\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 470 loss: 0.2893871068954468\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 471 loss: 0.2027837485074997\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8800, f1 0.9362\n",
      "class 1: acc 0.9062, precision 0.7000, recall 1.0000, f1 0.8235\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 472 loss: 0.4219498634338379\n",
      "class 0: acc 0.7812, precision 0.8077, recall 0.9130, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 473 loss: 0.19172552227973938\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 474 loss: 0.29552361369132996\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 475 loss: 0.3219600021839142\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 476 loss: 0.24696306884288788\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 477 loss: 0.12034767866134644\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 478 loss: 0.14922496676445007\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 479 loss: 0.33717119693756104\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 480 loss: 0.35116487741470337\n",
      "class 0: acc 0.9062, precision 0.9583, recall 0.9200, f1 0.9388\n",
      "class 1: acc 0.8750, precision 0.6250, recall 0.8333, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 481 loss: 0.21265704929828644\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 482 loss: 0.3675922751426697\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 483 loss: 0.4647113084793091\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 484 loss: 0.09293663501739502\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 485 loss: 0.6221916079521179\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 486 loss: 0.14783456921577454\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 487 loss: 0.14742769300937653\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 488 loss: 0.2985438108444214\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 489 loss: 0.4185015559196472\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 490 loss: 0.1669687032699585\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 491 loss: 0.3704456388950348\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 492 loss: 0.18448564410209656\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 493 loss: 0.4040006399154663\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 9 step: 494 loss: 0.5316498875617981\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 495 loss: 0.37454894185066223\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 496 loss: 0.45840921998023987\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 497 loss: 0.19964830577373505\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 498 loss: 0.3478713035583496\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 499 loss: 0.2935977578163147\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 500 loss: 0.4050367772579193\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 501 loss: 0.25333428382873535\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 502 loss: 0.4184741675853729\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 503 loss: 0.37813377380371094\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 504 loss: 0.3922027051448822\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 505 loss: 0.3570516109466553\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 506 loss: 0.42340272665023804\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 507 loss: 0.33086296916007996\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 508 loss: 0.21337728202342987\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 509 loss: 0.27662792801856995\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 510 loss: 0.17940622568130493\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 511 loss: 0.340485543012619\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 512 loss: 0.6476787328720093\n",
      "class 0: acc 0.7500, precision 0.7586, recall 0.9565, f1 0.8462\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 513 loss: 0.3376363515853882\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 514 loss: 0.1658511906862259\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 515 loss: 0.1321525126695633\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 516 loss: 0.22180894017219543\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 517 loss: 0.45144036412239075\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 518 loss: 0.17557446658611298\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 519 loss: 0.9029837846755981\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.7812, precision 0.3333, recall 0.1667, f1 0.2222\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 520 loss: 0.2135215401649475\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 521 loss: 0.4583166539669037\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 522 loss: 0.3148777186870575\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 523 loss: 0.27959805727005005\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 524 loss: 0.4367343783378601\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 525 loss: 0.33392006158828735\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 526 loss: 0.3494724631309509\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 527 loss: 0.3642069697380066\n",
      "class 0: acc 0.8750, precision 0.9600, recall 0.8889, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 528 loss: 0.309103786945343\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 529 loss: 0.5307074785232544\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 530 loss: 0.24655167758464813\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 531 loss: 0.3435535728931427\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 532 loss: 0.25854480266571045\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 533 loss: 0.5156529545783997\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 534 loss: 0.13174846768379211\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 535 loss: 0.5938252806663513\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 536 loss: 0.18058563768863678\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 537 loss: 0.3532215654850006\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 538 loss: 0.3495083451271057\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 539 loss: 0.49702754616737366\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 540 loss: 0.2399701625108719\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 541 loss: 0.4653884172439575\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 542 loss: 0.1910863220691681\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 543 loss: 0.3875316381454468\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 544 loss: 0.18517567217350006\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 545 loss: 0.13670790195465088\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 546 loss: 0.3946932852268219\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 547 loss: 0.4964703321456909\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 548 loss: 0.7510936856269836\n",
      "class 0: acc 0.7812, precision 0.8261, recall 0.8636, f1 0.8444\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.5714, f1 0.5333\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 549 loss: 0.45762190222740173\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 9 step: 550 loss: 0.40280500054359436\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 551 loss: 0.1946149468421936\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 552 loss: 0.3165968656539917\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 553 loss: 0.5233864784240723\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 554 loss: 0.41065576672554016\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 9 step: 555 loss: 0.2824613153934479\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 556 loss: 0.42840445041656494\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 557 loss: 0.2499072104692459\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 558 loss: 0.31272485852241516\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "epoch: 9 step: 559 loss: 0.5283822417259216\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 560 loss: 0.236470028758049\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 561 loss: 0.4020901024341583\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 562 loss: 0.2415301352739334\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 563 loss: 0.5055666565895081\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 564 loss: 0.3093970715999603\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 565 loss: 0.20096048712730408\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 566 loss: 0.3670894503593445\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 567 loss: 0.31132906675338745\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 568 loss: 0.43744587898254395\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 569 loss: 0.2379271537065506\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 570 loss: 0.3990963101387024\n",
      "class 0: acc 0.8438, precision 0.9565, recall 0.8462, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 571 loss: 0.44601598381996155\n",
      "class 0: acc 0.8125, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 9 step: 572 loss: 0.27857959270477295\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 573 loss: 0.33201444149017334\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 574 loss: 0.3489099442958832\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 9 step: 575 loss: 0.3911544382572174\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 576 loss: 0.31342798471450806\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 577 loss: 0.3114743232727051\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 578 loss: 0.21380290389060974\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 579 loss: 0.16423839330673218\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 580 loss: 0.8376985788345337\n",
      "class 0: acc 0.7500, precision 0.7407, recall 0.9524, f1 0.8333\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8125, precision 1.0000, recall 0.1429, f1 0.2500\n",
      "epoch: 9 step: 581 loss: 0.4763016700744629\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 582 loss: 0.47038331627845764\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.8333, recall 0.5556, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 583 loss: 0.8771469593048096\n",
      "class 0: acc 0.7188, precision 0.7586, recall 0.9167, f1 0.8302\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 584 loss: 0.34686774015426636\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 585 loss: 0.520341157913208\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 586 loss: 0.32353588938713074\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 587 loss: 0.3264046013355255\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 588 loss: 0.6866299510002136\n",
      "class 0: acc 0.7188, precision 0.7586, recall 0.9167, f1 0.8302\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 589 loss: 0.27270573377609253\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9688, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 590 loss: 0.46743518114089966\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 591 loss: 0.39978334307670593\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 9 step: 592 loss: 0.20041081309318542\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 593 loss: 0.375729501247406\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 594 loss: 0.1542832851409912\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 595 loss: 0.38015925884246826\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 596 loss: 0.14700081944465637\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 597 loss: 0.305187851190567\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 598 loss: 0.4711866080760956\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 599 loss: 0.4262581467628479\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 600 loss: 0.3814312815666199\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 601 loss: 0.501731276512146\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 602 loss: 0.5034515261650085\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 603 loss: 0.12550759315490723\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 604 loss: 0.28737762570381165\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 605 loss: 0.3032863140106201\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 606 loss: 0.2970298230648041\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 607 loss: 0.2862953543663025\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 608 loss: 0.32393118739128113\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 609 loss: 0.1852850615978241\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 610 loss: 0.6072266697883606\n",
      "class 0: acc 0.7188, precision 0.7407, recall 0.9091, f1 0.8163\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 611 loss: 0.24300000071525574\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 612 loss: 0.5011861324310303\n",
      "class 0: acc 0.8438, precision 0.9091, recall 0.8696, f1 0.8889\n",
      "class 1: acc 0.7188, precision 0.3000, recall 0.6000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 613 loss: 0.20123018324375153\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 614 loss: 0.372488796710968\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 615 loss: 0.3985951244831085\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 616 loss: 0.379197895526886\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 9 step: 617 loss: 0.33222049474716187\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 618 loss: 0.3786226212978363\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 9 step: 619 loss: 0.6405302882194519\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8125, precision 0.8000, recall 0.4444, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 620 loss: 0.24887733161449432\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 621 loss: 0.4047984778881073\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 9 step: 622 loss: 0.4447995722293854\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.8438, precision 0.5714, recall 0.6667, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 623 loss: 0.416226863861084\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 624 loss: 0.3489813804626465\n",
      "class 0: acc 0.8750, precision 0.9600, recall 0.8889, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "epoch: 9 step: 625 loss: 0.3287150263786316\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 626 loss: 0.6175597906112671\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 627 loss: 0.293741375207901\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 628 loss: 0.4362354874610901\n",
      "class 0: acc 0.8438, precision 0.8750, recall 0.9130, f1 0.8936\n",
      "class 1: acc 0.8125, precision 0.5714, recall 0.5714, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 629 loss: 0.269930362701416\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 630 loss: 0.3178003430366516\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 9 step: 631 loss: 0.30892494320869446\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 632 loss: 0.2610154449939728\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 633 loss: 0.5024440288543701\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 634 loss: 0.3165789544582367\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 635 loss: 0.285970002412796\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 636 loss: 0.29591697454452515\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 637 loss: 0.28760483860969543\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 638 loss: 0.30107617378234863\n",
      "class 0: acc 0.9375, precision 0.9167, recall 1.0000, f1 0.9565\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 639 loss: 0.2844812870025635\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 640 loss: 0.4521038830280304\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 641 loss: 0.2605958878993988\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 642 loss: 0.13489817082881927\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 643 loss: 0.1686658263206482\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 644 loss: 0.4091087281703949\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 645 loss: 0.3430303931236267\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 646 loss: 0.3704086244106293\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 647 loss: 0.2860942482948303\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 9 step: 648 loss: 0.38942116498947144\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 649 loss: 0.4361799359321594\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 650 loss: 0.5072367787361145\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 651 loss: 0.19142085313796997\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 652 loss: 0.23657961189746857\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 653 loss: 0.34335047006607056\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 654 loss: 0.20274761319160461\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 655 loss: 0.15801140666007996\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 656 loss: 0.556053638458252\n",
      "class 0: acc 0.8750, precision 0.9167, recall 0.9167, f1 0.9167\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 657 loss: 0.1322159320116043\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 658 loss: 0.4847680926322937\n",
      "class 0: acc 0.8438, precision 0.9565, recall 0.8462, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 659 loss: 0.33933067321777344\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 660 loss: 0.4184163510799408\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 661 loss: 0.4704572856426239\n",
      "class 0: acc 0.8438, precision 0.9231, recall 0.8889, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 662 loss: 0.3651143014431\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 663 loss: 0.2895241975784302\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 664 loss: 0.48329848051071167\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 665 loss: 0.34521886706352234\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 666 loss: 0.3340173065662384\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 667 loss: 0.4458978474140167\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 668 loss: 0.6307834982872009\n",
      "class 0: acc 0.8438, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 669 loss: 0.39861413836479187\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 670 loss: 0.572883129119873\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 671 loss: 0.42212697863578796\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 672 loss: 0.36553215980529785\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 673 loss: 0.5488326549530029\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 674 loss: 0.4718248248100281\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9600, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 675 loss: 0.30274325609207153\n",
      "class 0: acc 0.8750, precision 0.9655, recall 0.9032, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 676 loss: 0.47530120611190796\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.7812, precision 0.7500, recall 0.3333, f1 0.4615\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 677 loss: 0.33654293417930603\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 678 loss: 0.29436206817626953\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 679 loss: 0.2596818208694458\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 9 step: 680 loss: 0.24442508816719055\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 681 loss: 0.291106253862381\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 682 loss: 0.2540743052959442\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 683 loss: 0.21105293929576874\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 684 loss: 0.5167826414108276\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 685 loss: 0.4039847254753113\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 686 loss: 0.1227923259139061\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 687 loss: 0.3940083384513855\n",
      "class 0: acc 0.9375, precision 0.9200, recall 1.0000, f1 0.9583\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 688 loss: 0.26068201661109924\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 689 loss: 0.20968180894851685\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 690 loss: 0.16657565534114838\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 691 loss: 0.5935004949569702\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 692 loss: 0.29676058888435364\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 693 loss: 0.3563864529132843\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 694 loss: 0.4100402295589447\n",
      "class 0: acc 0.8750, precision 1.0000, recall 0.8462, f1 0.9167\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "epoch: 9 step: 695 loss: 0.3782695233821869\n",
      "class 0: acc 0.7812, precision 0.8000, recall 0.9091, f1 0.8511\n",
      "class 1: acc 0.8438, precision 0.7143, recall 0.6250, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 696 loss: 0.2767542898654938\n",
      "class 0: acc 0.8750, precision 0.9583, recall 0.8846, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.6250, recall 0.8333, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 697 loss: 0.3800704777240753\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 698 loss: 0.2871626913547516\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 699 loss: 0.20876851677894592\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 700 loss: 0.3929893374443054\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 701 loss: 0.39814677834510803\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 702 loss: 0.633948028087616\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 703 loss: 0.3666439652442932\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 704 loss: 0.2605103552341461\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 705 loss: 0.32928022742271423\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 706 loss: 0.21974310278892517\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 707 loss: 0.2792883813381195\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 708 loss: 0.2564275562763214\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 709 loss: 0.5690687894821167\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 710 loss: 0.48091188073158264\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 711 loss: 0.3849419355392456\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 712 loss: 0.3851972818374634\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 713 loss: 0.6027464866638184\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 714 loss: 0.2941741347312927\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 715 loss: 0.4247759282588959\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 716 loss: 0.3268028199672699\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 717 loss: 0.4596605896949768\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 718 loss: 0.31037771701812744\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 719 loss: 0.4333318769931793\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 720 loss: 0.16950181126594543\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 721 loss: 0.3899727165699005\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 722 loss: 0.5032145380973816\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 723 loss: 0.2317674160003662\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 724 loss: 0.34995314478874207\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 725 loss: 0.26989346742630005\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 726 loss: 0.36669760942459106\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 727 loss: 0.2894707918167114\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 728 loss: 0.3832160234451294\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 729 loss: 0.22948762774467468\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 730 loss: 0.34851256012916565\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 731 loss: 0.271610289812088\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 732 loss: 0.3793885111808777\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 733 loss: 0.18032708764076233\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 734 loss: 0.33858639001846313\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 735 loss: 0.25389280915260315\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 736 loss: 0.8657124638557434\n",
      "class 0: acc 0.7500, precision 0.7419, recall 1.0000, f1 0.8519\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 737 loss: 0.3944951891899109\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 738 loss: 0.26361384987831116\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 739 loss: 0.1911812126636505\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 740 loss: 0.3317605257034302\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 741 loss: 0.25166383385658264\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 742 loss: 0.3666081428527832\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 743 loss: 0.4168846607208252\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 744 loss: 0.20475304126739502\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 745 loss: 0.4017108082771301\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 746 loss: 0.492303729057312\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 747 loss: 0.41471782326698303\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 748 loss: 0.6072139143943787\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 749 loss: 0.2625994384288788\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 750 loss: 0.4466991126537323\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "epoch: 9 step: 751 loss: 0.3832314908504486\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 752 loss: 0.36398762464523315\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 753 loss: 0.32184067368507385\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 754 loss: 0.2969922721385956\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 9 step: 755 loss: 0.2573806643486023\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 756 loss: 0.2634711265563965\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 757 loss: 0.6920136213302612\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 758 loss: 0.2632392346858978\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 759 loss: 0.30739641189575195\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 760 loss: 0.32026755809783936\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 761 loss: 0.207628533244133\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 762 loss: 0.3334210216999054\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 763 loss: 0.5930026173591614\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 764 loss: 0.1326141655445099\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 765 loss: 0.4286048412322998\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 766 loss: 0.27973487973213196\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 767 loss: 0.48151934146881104\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 768 loss: 0.3563673794269562\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 769 loss: 0.4099506735801697\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 770 loss: 0.40209534764289856\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 771 loss: 0.49512872099876404\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.8000, recall 0.4444, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 772 loss: 0.697672963142395\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.1429, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 773 loss: 0.33345329761505127\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 774 loss: 0.28697073459625244\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 775 loss: 0.5977044105529785\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 776 loss: 0.2526569366455078\n",
      "class 0: acc 0.9688, precision 0.9688, recall 1.0000, f1 0.9841\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 777 loss: 0.5076220631599426\n",
      "class 0: acc 0.8438, precision 0.8696, recall 0.9091, f1 0.8889\n",
      "class 1: acc 0.9375, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 778 loss: 0.36451297998428345\n",
      "class 0: acc 0.8750, precision 0.9615, recall 0.8929, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 779 loss: 0.42716267704963684\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 780 loss: 0.43458449840545654\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 781 loss: 0.1857149600982666\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 782 loss: 0.3779391050338745\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 783 loss: 0.15673620998859406\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 784 loss: 0.2231471836566925\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 785 loss: 0.3093276619911194\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 786 loss: 0.5133992433547974\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 787 loss: 0.42029911279678345\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 788 loss: 0.40548011660575867\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 789 loss: 0.3807942867279053\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 790 loss: 0.15159475803375244\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 791 loss: 0.22582551836967468\n",
      "class 0: acc 0.9062, precision 0.9667, recall 0.9355, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 792 loss: 0.46831631660461426\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 793 loss: 0.5251070261001587\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 794 loss: 0.23272573947906494\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 795 loss: 0.3920365571975708\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 796 loss: 0.4779253304004669\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 797 loss: 0.5576531291007996\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "epoch: 9 step: 798 loss: 0.3718700408935547\n",
      "class 0: acc 0.8750, precision 0.9643, recall 0.9000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 799 loss: 0.4131891131401062\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 800 loss: 0.3173387944698334\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 801 loss: 0.3043511211872101\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 802 loss: 0.29709163308143616\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 803 loss: 0.40157052874565125\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "epoch: 9 step: 804 loss: 0.18596196174621582\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 805 loss: 0.34590718150138855\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 806 loss: 0.2230200320482254\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 807 loss: 0.5346898436546326\n",
      "class 0: acc 0.7500, precision 0.7778, recall 0.9130, f1 0.8400\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 808 loss: 0.37553948163986206\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 809 loss: 0.3200726807117462\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 810 loss: 0.2482706755399704\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 9 step: 811 loss: 0.2207830548286438\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 812 loss: 0.4753195643424988\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "epoch: 9 step: 813 loss: 0.18564246594905853\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 814 loss: 0.12722165882587433\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 815 loss: 0.31812095642089844\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 816 loss: 0.33523887395858765\n",
      "class 0: acc 0.8125, precision 0.9259, recall 0.8621, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 817 loss: 0.8285599946975708\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 9 step: 818 loss: 0.1645403802394867\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 819 loss: 0.38087159395217896\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 820 loss: 0.3012937009334564\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 821 loss: 0.3938218057155609\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 822 loss: 0.4155450761318207\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 823 loss: 0.9643976092338562\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "epoch: 9 step: 824 loss: 0.1723385602235794\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 825 loss: 0.609251081943512\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 826 loss: 0.271697461605072\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 827 loss: 0.40848448872566223\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 828 loss: 0.23198236525058746\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 829 loss: 0.3231245279312134\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 830 loss: 0.19568373262882233\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 831 loss: 0.1968088001012802\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 832 loss: 0.18847692012786865\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9286, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 833 loss: 0.41602927446365356\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 834 loss: 0.5966410040855408\n",
      "class 0: acc 0.8125, precision 0.8000, recall 0.9524, f1 0.8696\n",
      "class 1: acc 0.8750, precision 0.8571, recall 0.6667, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 835 loss: 0.24262236058712006\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 836 loss: 0.269105464220047\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 837 loss: 0.38653677701950073\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 838 loss: 0.33301421999931335\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 839 loss: 0.2636607885360718\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 840 loss: 0.25937721133232117\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 841 loss: 0.30688053369522095\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 842 loss: 0.40130868554115295\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 843 loss: 0.21414817869663239\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 844 loss: 0.09281760454177856\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 845 loss: 0.5116767287254333\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 846 loss: 0.6587849855422974\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 847 loss: 0.2662840187549591\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 848 loss: 0.21990042924880981\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 849 loss: 0.20154303312301636\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 850 loss: 0.4896213114261627\n",
      "class 0: acc 0.8125, precision 0.7692, recall 1.0000, f1 0.8696\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 851 loss: 0.38943183422088623\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 852 loss: 0.2525692284107208\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 853 loss: 0.22777925431728363\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 9 step: 854 loss: 0.491545706987381\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 855 loss: 0.22068753838539124\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 856 loss: 0.4404842257499695\n",
      "class 0: acc 0.8125, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 857 loss: 0.2539728879928589\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 858 loss: 0.17333944141864777\n",
      "class 0: acc 0.9688, precision 0.9600, recall 1.0000, f1 0.9796\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 859 loss: 0.27917778491973877\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8929, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 860 loss: 0.21052727103233337\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 861 loss: 0.5520927906036377\n",
      "class 0: acc 0.8125, precision 0.8400, recall 0.9130, f1 0.8750\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 862 loss: 0.49441996216773987\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 863 loss: 0.3876175582408905\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 9 step: 864 loss: 0.3748931586742401\n",
      "class 0: acc 0.8438, precision 0.9000, recall 0.9310, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 865 loss: 0.36810046434402466\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 866 loss: 0.3362818956375122\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 867 loss: 0.4523076117038727\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 868 loss: 0.21595776081085205\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 869 loss: 0.41522344946861267\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 870 loss: 0.281525582075119\n",
      "class 0: acc 0.9375, precision 0.9565, recall 0.9565, f1 0.9565\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 871 loss: 0.4627290368080139\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 872 loss: 0.43943682312965393\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 873 loss: 0.4335145056247711\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 874 loss: 0.2921796143054962\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 875 loss: 0.12319081276655197\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 876 loss: 0.4148533344268799\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 9 step: 877 loss: 0.5307380557060242\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 878 loss: 0.34372633695602417\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 879 loss: 0.19455799460411072\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 880 loss: 0.3958098590373993\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 9 step: 881 loss: 0.3100813031196594\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 882 loss: 0.35134196281433105\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 883 loss: 0.1795203983783722\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 9 step: 884 loss: 0.36711063981056213\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 885 loss: 0.33241528272628784\n",
      "class 0: acc 0.8750, precision 0.8696, recall 0.9524, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.8750, recall 0.7778, f1 0.8235\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 886 loss: 0.2879423201084137\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "epoch: 9 step: 887 loss: 0.4074711501598358\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 888 loss: 0.23930853605270386\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8966, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 889 loss: 0.2523643970489502\n",
      "class 0: acc 0.9688, precision 0.9583, recall 1.0000, f1 0.9787\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 890 loss: 0.38635680079460144\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 891 loss: 0.3543846011161804\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 892 loss: 0.24905890226364136\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 893 loss: 0.5716149806976318\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "epoch: 9 step: 894 loss: 0.3599613904953003\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 895 loss: 0.14205743372440338\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 896 loss: 0.15988323092460632\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 897 loss: 0.23879964649677277\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 898 loss: 0.203401118516922\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 899 loss: 0.13634443283081055\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 900 loss: 0.48348286747932434\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 901 loss: 0.5593095421791077\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 902 loss: 0.424202561378479\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 903 loss: 0.40597406029701233\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 904 loss: 0.18424110114574432\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 905 loss: 0.3311518430709839\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 906 loss: 0.3449706733226776\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 907 loss: 0.34988564252853394\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 908 loss: 0.8084882497787476\n",
      "class 0: acc 0.7500, precision 0.8077, recall 0.8750, f1 0.8400\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 909 loss: 0.15041373670101166\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 910 loss: 0.3288829028606415\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 911 loss: 0.3237929344177246\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 912 loss: 0.26830121874809265\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 913 loss: 0.20058146119117737\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 914 loss: 0.272832453250885\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 915 loss: 0.13186179101467133\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 916 loss: 0.25113043189048767\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 917 loss: 0.3401659429073334\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 918 loss: 0.40308812260627747\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 919 loss: 0.3350338041782379\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 920 loss: 0.13464832305908203\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 921 loss: 0.4323689341545105\n",
      "class 0: acc 0.8125, precision 0.8125, recall 1.0000, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 922 loss: 0.35754042863845825\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 923 loss: 0.3456154763698578\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 924 loss: 0.5408084392547607\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 925 loss: 0.2905067205429077\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 926 loss: 0.33369526267051697\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 927 loss: 0.5805960893630981\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 928 loss: 0.3246782720088959\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 929 loss: 0.12675338983535767\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 930 loss: 0.6426680088043213\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "epoch: 9 step: 931 loss: 0.39729538559913635\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8929, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 932 loss: 0.16310423612594604\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "epoch: 9 step: 933 loss: 0.15543821454048157\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 934 loss: 0.2915040850639343\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 935 loss: 0.37398791313171387\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 936 loss: 0.31393203139305115\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 937 loss: 0.4129692316055298\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 938 loss: 0.42415496706962585\n",
      "class 0: acc 0.7500, precision 0.7667, recall 0.9583, f1 0.8519\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 939 loss: 0.3251725733280182\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 940 loss: 0.18942265212535858\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 941 loss: 0.362692266702652\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 942 loss: 0.2953558564186096\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 943 loss: 0.13334274291992188\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 944 loss: 0.302377313375473\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 945 loss: 0.5937925577163696\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 946 loss: 0.47574087977409363\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 947 loss: 0.28292980790138245\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 948 loss: 0.4496113657951355\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 949 loss: 0.6353722214698792\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 950 loss: 0.36580216884613037\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 951 loss: 0.41552188992500305\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 952 loss: 0.3362027704715729\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 953 loss: 0.3481139540672302\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "epoch: 9 step: 954 loss: 0.256878137588501\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 955 loss: 0.520217776298523\n",
      "class 0: acc 0.8438, precision 0.8261, recall 0.9500, f1 0.8837\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 956 loss: 0.41791754961013794\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 957 loss: 0.39453548192977905\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 958 loss: 0.22666744887828827\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 959 loss: 0.33877032995224\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 960 loss: 0.17690980434417725\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 961 loss: 0.392656534910202\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 962 loss: 0.3342493772506714\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 963 loss: 0.24208030104637146\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9355, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 964 loss: 0.21553757786750793\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 965 loss: 0.333854079246521\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 966 loss: 0.43347588181495667\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 967 loss: 0.4684937000274658\n",
      "class 0: acc 0.9062, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 9 step: 968 loss: 0.2871704697608948\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 969 loss: 0.333510160446167\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 970 loss: 0.3663686513900757\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 971 loss: 0.40085455775260925\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 972 loss: 0.2187868058681488\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 973 loss: 0.18335752189159393\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 974 loss: 0.3819981813430786\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 975 loss: 0.3755781054496765\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 976 loss: 0.3215474784374237\n",
      "class 0: acc 0.8438, precision 0.9286, recall 0.8966, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 977 loss: 0.5197687745094299\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 978 loss: 0.2893487215042114\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9565, f1 0.9778\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "epoch: 9 step: 979 loss: 0.2692909240722656\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 980 loss: 0.495211124420166\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 9 step: 981 loss: 0.3141178786754608\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 982 loss: 0.4016832411289215\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 9 step: 983 loss: 0.5329486131668091\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 9 step: 984 loss: 0.39170220494270325\n",
      "class 0: acc 0.8438, precision 0.9130, recall 0.8750, f1 0.8936\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 985 loss: 0.4684455990791321\n",
      "class 0: acc 0.8438, precision 0.9167, recall 0.8800, f1 0.8980\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "epoch: 9 step: 986 loss: 0.5418766140937805\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 987 loss: 0.3080254793167114\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 988 loss: 0.39349499344825745\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 989 loss: 0.2702067792415619\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "epoch: 9 step: 990 loss: 0.4535285234451294\n",
      "class 0: acc 0.7812, precision 0.8800, recall 0.8462, f1 0.8627\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 991 loss: 0.28179308772087097\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 992 loss: 0.4235580265522003\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 993 loss: 0.4254952073097229\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 994 loss: 0.3194073736667633\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 995 loss: 0.18591643869876862\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 996 loss: 0.5551506876945496\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 997 loss: 0.12694987654685974\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 998 loss: 0.5304893255233765\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 999 loss: 0.5461475849151611\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1000 loss: 0.16846488416194916\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1001 loss: 0.2019628882408142\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 1002 loss: 0.18376149237155914\n",
      "class 0: acc 0.9375, precision 0.9677, recall 0.9677, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1003 loss: 0.3264940679073334\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1004 loss: 0.3648856282234192\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1005 loss: 0.7326544523239136\n",
      "class 0: acc 0.7812, precision 0.7407, recall 1.0000, f1 0.8511\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1006 loss: 0.2439139485359192\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 1007 loss: 0.47446390986442566\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1008 loss: 0.11778666079044342\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1009 loss: 0.41280487179756165\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1010 loss: 0.45296794176101685\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1011 loss: 0.2987077236175537\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1012 loss: 0.27048176527023315\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1013 loss: 0.526639997959137\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "epoch: 9 step: 1014 loss: 0.3693067729473114\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "epoch: 9 step: 1015 loss: 0.4635177552700043\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1016 loss: 0.4444124102592468\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 1017 loss: 0.3564656674861908\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 1018 loss: 0.3002835214138031\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9565, f1 0.9778\n",
      "class 1: acc 0.9688, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 9 step: 1019 loss: 0.30269625782966614\n",
      "class 0: acc 0.9688, precision 0.9600, recall 1.0000, f1 0.9796\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "epoch: 9 step: 1020 loss: 0.20490717887878418\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1021 loss: 0.3537856936454773\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 1022 loss: 0.351492702960968\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1023 loss: 0.28571656346321106\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 9 step: 1024 loss: 0.47184357047080994\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1025 loss: 0.38842442631721497\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1026 loss: 0.21784618496894836\n",
      "class 0: acc 0.9688, precision 0.9565, recall 1.0000, f1 0.9778\n",
      "class 1: acc 0.9375, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1027 loss: 0.19933094084262848\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1028 loss: 0.09823133051395416\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1029 loss: 0.2918896973133087\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1030 loss: 0.34398505091667175\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1031 loss: 0.1753585934638977\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1032 loss: 0.28765472769737244\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1033 loss: 0.3761814832687378\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1034 loss: 0.44672784209251404\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1035 loss: 0.5474503040313721\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1036 loss: 0.14872942864894867\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1037 loss: 0.490324467420578\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1038 loss: 0.6591455340385437\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1039 loss: 0.20249322056770325\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1040 loss: 0.22902995347976685\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1041 loss: 0.13672217726707458\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1042 loss: 0.2922247350215912\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1043 loss: 0.2557474970817566\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1044 loss: 0.22165587544441223\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1045 loss: 0.36491841077804565\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1046 loss: 0.2905949652194977\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1047 loss: 0.3211199641227722\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1048 loss: 0.4497309923171997\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1049 loss: 0.3286186158657074\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1050 loss: 0.3029182255268097\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1051 loss: 0.4818676710128784\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1052 loss: 0.2839089334011078\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1053 loss: 0.3320394456386566\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1054 loss: 0.29294082522392273\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 9 step: 1055 loss: 0.5577414035797119\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1056 loss: 0.37285369634628296\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1057 loss: 0.27029550075531006\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9375, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1058 loss: 0.3783130645751953\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1059 loss: 0.47741395235061646\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1060 loss: 0.31238290667533875\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1061 loss: 0.3059022128582001\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1062 loss: 0.25433439016342163\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1063 loss: 0.3548816740512848\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1064 loss: 0.6903191804885864\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1065 loss: 0.2904127538204193\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1066 loss: 0.49146512150764465\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1067 loss: 0.30946019291877747\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1068 loss: 0.5663821697235107\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 1069 loss: 0.6245563626289368\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1070 loss: 0.42593517899513245\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1071 loss: 0.209907665848732\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1072 loss: 0.5559452772140503\n",
      "class 0: acc 0.8438, precision 0.9565, recall 0.8462, f1 0.8980\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 9 step: 1073 loss: 0.23990505933761597\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1074 loss: 0.37564176321029663\n",
      "class 0: acc 0.8750, precision 1.0000, recall 0.8400, f1 0.9130\n",
      "class 1: acc 0.9062, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1075 loss: 0.2816270589828491\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 1076 loss: 0.2297469824552536\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 1077 loss: 0.49338069558143616\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 9 step: 1078 loss: 0.16187764704227448\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 1079 loss: 0.17018628120422363\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1080 loss: 0.5597717761993408\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1081 loss: 0.32244551181793213\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1082 loss: 0.16070452332496643\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 1083 loss: 0.3142277002334595\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1084 loss: 0.13614314794540405\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1085 loss: 0.4249306321144104\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1086 loss: 0.34810781478881836\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1087 loss: 0.18283285200595856\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 9 step: 1088 loss: 0.5448874831199646\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1089 loss: 0.25416243076324463\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1090 loss: 0.4411196708679199\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1091 loss: 0.4305185079574585\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1092 loss: 0.2628660798072815\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 1093 loss: 0.3161216080188751\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1094 loss: 0.16510730981826782\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1095 loss: 0.3008168041706085\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1096 loss: 0.5174578428268433\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1097 loss: 0.48375484347343445\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "epoch: 9 step: 1098 loss: 0.14803658425807953\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 1099 loss: 0.4051726758480072\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1100 loss: 0.15772922337055206\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1101 loss: 0.3437589704990387\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1102 loss: 0.14619818329811096\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1103 loss: 0.14438095688819885\n",
      "class 0: acc 0.9375, precision 0.9677, recall 0.9677, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1104 loss: 0.3284173905849457\n",
      "class 0: acc 0.8438, precision 0.9167, recall 0.8800, f1 0.8980\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.2000, recall 1.0000, f1 0.3333\n",
      "epoch: 9 step: 1105 loss: 0.11551588028669357\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 1106 loss: 0.2144235521554947\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1107 loss: 0.29533958435058594\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1108 loss: 0.1791801154613495\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 1109 loss: 0.3116390109062195\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1110 loss: 0.09104466438293457\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 1111 loss: 0.5396135449409485\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 1112 loss: 0.5293716192245483\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1113 loss: 0.251924991607666\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1114 loss: 0.3069179356098175\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1115 loss: 0.44969019293785095\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1116 loss: 0.4177667498588562\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1117 loss: 0.2792164087295532\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 1118 loss: 0.13740596175193787\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9615, f1 0.9804\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1119 loss: 0.25053852796554565\n",
      "class 0: acc 0.8750, precision 0.9583, recall 0.8846, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1120 loss: 0.4240952432155609\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1121 loss: 0.44434893131256104\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1122 loss: 0.21623726189136505\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1123 loss: 0.18816141784191132\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1124 loss: 0.37476539611816406\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 1125 loss: 0.5419536232948303\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1126 loss: 0.4099620580673218\n",
      "class 0: acc 0.9375, precision 0.9167, recall 1.0000, f1 0.9565\n",
      "class 1: acc 0.9375, precision 0.8750, recall 0.8750, f1 0.8750\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1127 loss: 0.7877512574195862\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1128 loss: 0.28974220156669617\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1129 loss: 0.21818475425243378\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1130 loss: 0.06122557073831558\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1131 loss: 0.19036155939102173\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1132 loss: 0.29628488421440125\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1133 loss: 0.5798157453536987\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1134 loss: 0.4259852468967438\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1135 loss: 0.34323954582214355\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 1136 loss: 0.16859744489192963\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1137 loss: 0.5995249152183533\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1138 loss: 0.37742745876312256\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1139 loss: 0.385846883058548\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1140 loss: 0.331020712852478\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 1141 loss: 0.3115848898887634\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1142 loss: 0.18777212500572205\n",
      "class 0: acc 0.9688, precision 0.9600, recall 1.0000, f1 0.9796\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1143 loss: 0.30509883165359497\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 1144 loss: 0.2855175733566284\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1145 loss: 0.4112931787967682\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1146 loss: 0.6006845235824585\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1147 loss: 0.780178964138031\n",
      "class 0: acc 0.7500, precision 0.7333, recall 1.0000, f1 0.8462\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1148 loss: 0.39039361476898193\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1149 loss: 0.25362807512283325\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1150 loss: 0.44149911403656006\n",
      "class 0: acc 0.8125, precision 0.8800, recall 0.8800, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1151 loss: 0.21966925263404846\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1152 loss: 0.34497758746147156\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1153 loss: 0.2569233477115631\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1154 loss: 0.24558007717132568\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1155 loss: 0.1693347543478012\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1156 loss: 0.2861648201942444\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1157 loss: 0.5540404915809631\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1158 loss: 0.0952417179942131\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 1159 loss: 0.5710810422897339\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "epoch: 9 step: 1160 loss: 0.239986389875412\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1161 loss: 0.3521435558795929\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1162 loss: 0.37238985300064087\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1163 loss: 0.16520437598228455\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1164 loss: 0.29957321286201477\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 1165 loss: 0.33551403880119324\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1166 loss: 0.3198111653327942\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 9 step: 1167 loss: 0.23487134277820587\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1168 loss: 0.38239315152168274\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1169 loss: 0.15792633593082428\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1170 loss: 0.0680127814412117\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1171 loss: 0.35055866837501526\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1172 loss: 0.1594473272562027\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1173 loss: 0.3898947238922119\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1174 loss: 0.27898114919662476\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1175 loss: 0.36268350481987\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1176 loss: 0.4904448091983795\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 1177 loss: 0.3831249475479126\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1178 loss: 0.31533530354499817\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1179 loss: 0.3619900643825531\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 1180 loss: 0.1930641531944275\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 1181 loss: 0.40298929810523987\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1182 loss: 0.24226273596286774\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1183 loss: 0.27797845005989075\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1184 loss: 0.2862909436225891\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1185 loss: 0.2514464855194092\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1186 loss: 0.3710026741027832\n",
      "class 0: acc 0.8438, precision 0.9615, recall 0.8621, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "epoch: 9 step: 1187 loss: 0.5494353175163269\n",
      "class 0: acc 0.8750, precision 0.9167, recall 0.9167, f1 0.9167\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 9 step: 1188 loss: 0.4546111226081848\n",
      "class 0: acc 0.8750, precision 0.9583, recall 0.8846, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1189 loss: 0.3171558082103729\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1190 loss: 0.27469074726104736\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1191 loss: 0.4310787320137024\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 1192 loss: 0.0634407252073288\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1193 loss: 0.43503645062446594\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1194 loss: 0.3315376043319702\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1195 loss: 0.23457671701908112\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1196 loss: 0.3549824059009552\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1197 loss: 0.3928401470184326\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1198 loss: 0.4920322895050049\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1199 loss: 0.5261180400848389\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1200 loss: 0.29214322566986084\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1201 loss: 0.2686591148376465\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1202 loss: 0.4303566813468933\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1203 loss: 0.3711423873901367\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1204 loss: 0.1482408046722412\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1205 loss: 0.19503137469291687\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1206 loss: 0.13648897409439087\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1207 loss: 0.22400140762329102\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1208 loss: 0.4234267771244049\n",
      "class 0: acc 0.8438, precision 0.9583, recall 0.8519, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.3750, recall 1.0000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1209 loss: 0.450580358505249\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1210 loss: 0.2756192088127136\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1211 loss: 0.37456148862838745\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1212 loss: 0.39920851588249207\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 9 step: 1213 loss: 0.33680835366249084\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1214 loss: 0.2798774242401123\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1215 loss: 0.3024827837944031\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 9 step: 1216 loss: 0.43209490180015564\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1217 loss: 0.45443961024284363\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1218 loss: 0.5980681777000427\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1219 loss: 0.8226490020751953\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1220 loss: 0.6285149455070496\n",
      "class 0: acc 0.8125, precision 0.8929, recall 0.8929, f1 0.8929\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1221 loss: 0.3778396248817444\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1222 loss: 0.29012930393218994\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1223 loss: 0.41148698329925537\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1224 loss: 0.31741440296173096\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8800, f1 0.9362\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "epoch: 9 step: 1225 loss: 0.35016828775405884\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 1226 loss: 0.3422786593437195\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 9 step: 1227 loss: 0.36454305052757263\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1228 loss: 0.4025614857673645\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1229 loss: 0.5782766342163086\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1230 loss: 0.19387587904930115\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1231 loss: 0.488914430141449\n",
      "class 0: acc 0.8750, precision 0.9167, recall 0.9167, f1 0.9167\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1232 loss: 0.4872892498970032\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1233 loss: 0.4996849298477173\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1234 loss: 0.44841688871383667\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 1235 loss: 0.3360278904438019\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1236 loss: 0.42360156774520874\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1237 loss: 0.5119404196739197\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1238 loss: 0.41501423716545105\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1239 loss: 0.22417685389518738\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1240 loss: 0.3896923363208771\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1241 loss: 0.20534588396549225\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 9 step: 1242 loss: 0.46557897329330444\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1243 loss: 0.20413191616535187\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 9 step: 1244 loss: 0.4465641379356384\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1245 loss: 0.15671613812446594\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1246 loss: 0.0733024850487709\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1247 loss: 0.39339402318000793\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1248 loss: 0.3381272554397583\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1249 loss: 0.5251327157020569\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 9 step: 1250 loss: 0.20962701737880707\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1 loss: 0.30077460408210754\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 2 loss: 0.11681649088859558\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 3 loss: 0.30505678057670593\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 4 loss: 0.47376003861427307\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 5 loss: 0.6318475604057312\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 6 loss: 0.10367541760206223\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 7 loss: 0.17938794195652008\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 8 loss: 0.3896394968032837\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 9 loss: 0.40950363874435425\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 10 loss: 0.33139294385910034\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 11 loss: 0.24761153757572174\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 12 loss: 0.1703980267047882\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 13 loss: 0.2491254061460495\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 14 loss: 0.4309225380420685\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 15 loss: 0.5433827638626099\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 16 loss: 0.0934973731637001\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 17 loss: 0.3343690037727356\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 18 loss: 0.2151212841272354\n",
      "class 0: acc 0.9062, precision 0.9583, recall 0.9200, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 19 loss: 0.29196879267692566\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 20 loss: 0.3964962065219879\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 21 loss: 0.45501962304115295\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 22 loss: 0.33518674969673157\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 23 loss: 0.30599841475486755\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 24 loss: 0.3560727536678314\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 25 loss: 0.47026437520980835\n",
      "class 0: acc 0.7812, precision 0.9615, recall 0.8065, f1 0.8772\n",
      "class 1: acc 0.7812, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 26 loss: 0.29174524545669556\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 27 loss: 0.45703935623168945\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 28 loss: 0.3609425127506256\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 29 loss: 0.2011418491601944\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 30 loss: 0.24200348556041718\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9615, f1 0.9804\n",
      "class 1: acc 0.9375, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 31 loss: 0.34189048409461975\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.7000, f1 0.8235\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 32 loss: 0.272952139377594\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 33 loss: 0.30925917625427246\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 34 loss: 0.2674182057380676\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 35 loss: 0.26876306533813477\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 36 loss: 0.08256764709949493\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 37 loss: 0.43939515948295593\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 38 loss: 0.3461737334728241\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 39 loss: 0.16555403172969818\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 40 loss: 0.3894958198070526\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 41 loss: 0.1257510632276535\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 42 loss: 0.173553004860878\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 43 loss: 0.31970706582069397\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 44 loss: 0.2547093629837036\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 45 loss: 0.47026312351226807\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 46 loss: 0.22927503287792206\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 47 loss: 0.27003660798072815\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 48 loss: 0.33632445335388184\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 49 loss: 0.616701602935791\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 50 loss: 0.41059303283691406\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 51 loss: 0.2873374819755554\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 52 loss: 0.3508581221103668\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 53 loss: 0.5105975866317749\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 54 loss: 0.27114856243133545\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 55 loss: 0.3625321388244629\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 56 loss: 0.568701982498169\n",
      "class 0: acc 0.7188, precision 0.7667, recall 0.9200, f1 0.8364\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 57 loss: 0.2585899531841278\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 58 loss: 0.5161962509155273\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 59 loss: 0.4270554184913635\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 60 loss: 0.4383324682712555\n",
      "class 0: acc 0.9375, precision 0.9200, recall 1.0000, f1 0.9583\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 61 loss: 0.23221713304519653\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9259, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 62 loss: 0.3414164185523987\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 63 loss: 0.20011498034000397\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 64 loss: 0.24436655640602112\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 65 loss: 0.22331012785434723\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 66 loss: 0.13482075929641724\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 67 loss: 0.26998260617256165\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 68 loss: 0.09346675127744675\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 69 loss: 0.4657469689846039\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 70 loss: 0.26051682233810425\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 71 loss: 0.6521682143211365\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.3750, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 72 loss: 0.4034443497657776\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 73 loss: 0.28944820165634155\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 74 loss: 0.4211278557777405\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "epoch: 10 step: 75 loss: 0.5361312627792358\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 76 loss: 0.3978528082370758\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "epoch: 10 step: 77 loss: 0.2792081832885742\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 78 loss: 0.08283694833517075\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 79 loss: 0.23398132622241974\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 80 loss: 0.49356701970100403\n",
      "class 0: acc 0.8750, precision 0.9130, recall 0.9130, f1 0.9130\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 10 step: 81 loss: 0.14415305852890015\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 82 loss: 0.4154168665409088\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 83 loss: 0.41475164890289307\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 84 loss: 0.16329620778560638\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 85 loss: 0.2280529886484146\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8750, f1 0.9333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 86 loss: 0.4548507332801819\n",
      "class 0: acc 0.8438, precision 0.9200, recall 0.8846, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 10 step: 87 loss: 0.38604843616485596\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 88 loss: 0.2916572093963623\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 89 loss: 0.24133235216140747\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 90 loss: 0.2988765239715576\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 91 loss: 0.31457653641700745\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 92 loss: 0.17516295611858368\n",
      "class 0: acc 0.9375, precision 0.9200, recall 1.0000, f1 0.9583\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7778, f1 0.8750\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 93 loss: 0.41716352105140686\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 94 loss: 0.37596726417541504\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 95 loss: 0.2423824667930603\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 96 loss: 0.4728802442550659\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 97 loss: 0.19116036593914032\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 98 loss: 0.44782063364982605\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 99 loss: 0.6453366279602051\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.7812, precision 0.6667, recall 0.2500, f1 0.3636\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 100 loss: 0.4350816309452057\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 101 loss: 0.23856137692928314\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 102 loss: 0.24541747570037842\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 10 step: 103 loss: 0.20543517172336578\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "epoch: 10 step: 104 loss: 0.14948102831840515\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 105 loss: 0.2806984782218933\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 106 loss: 0.13920272886753082\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 107 loss: 0.5271593928337097\n",
      "class 0: acc 0.8438, precision 0.9200, recall 0.8846, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "epoch: 10 step: 108 loss: 0.31648948788642883\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 109 loss: 0.32558760046958923\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 10 step: 110 loss: 0.3380343019962311\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 111 loss: 0.29394078254699707\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 112 loss: 0.2959293723106384\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 113 loss: 0.4110255241394043\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 114 loss: 0.0832415521144867\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 115 loss: 0.1717672497034073\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 116 loss: 0.6721183657646179\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 117 loss: 0.24395954608917236\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 118 loss: 0.2238193154335022\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 119 loss: 0.4316538870334625\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.1667, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 120 loss: 0.15721267461776733\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 121 loss: 0.29611915349960327\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 122 loss: 0.6514335870742798\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 123 loss: 0.251479834318161\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 124 loss: 0.2093510925769806\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 125 loss: 0.43861615657806396\n",
      "class 0: acc 0.8125, precision 0.8800, recall 0.8800, f1 0.8800\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 126 loss: 0.16671110689640045\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 127 loss: 0.3268051743507385\n",
      "class 0: acc 0.8750, precision 0.9565, recall 0.8800, f1 0.9167\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 10 step: 128 loss: 0.29354414343833923\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 129 loss: 0.3902464807033539\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 130 loss: 0.22831177711486816\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 10 step: 131 loss: 0.42036089301109314\n",
      "class 0: acc 0.8438, precision 0.9615, recall 0.8621, f1 0.9091\n",
      "class 1: acc 0.8125, precision 0.1667, recall 0.5000, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 132 loss: 0.22171589732170105\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 133 loss: 0.2810323238372803\n",
      "class 0: acc 0.8750, precision 0.8750, recall 0.9545, f1 0.9130\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7778, f1 0.8750\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 134 loss: 0.610887885093689\n",
      "class 0: acc 0.7500, precision 0.7667, recall 0.9583, f1 0.8519\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.1429, f1 0.2222\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 135 loss: 0.5591884255409241\n",
      "class 0: acc 0.8125, precision 0.8800, recall 0.8800, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 136 loss: 0.44026556611061096\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 137 loss: 0.4828858971595764\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 138 loss: 0.20058435201644897\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 139 loss: 0.28357499837875366\n",
      "class 0: acc 0.8750, precision 0.9615, recall 0.8929, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 140 loss: 0.31358954310417175\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 141 loss: 0.34364771842956543\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 10 step: 142 loss: 0.5896586179733276\n",
      "class 0: acc 0.7500, precision 0.8400, recall 0.8400, f1 0.8400\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 143 loss: 0.2557874917984009\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 144 loss: 0.21000796556472778\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 145 loss: 0.2840477228164673\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 146 loss: 0.34744030237197876\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 147 loss: 0.3183600902557373\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 148 loss: 0.27149516344070435\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 149 loss: 0.6534798741340637\n",
      "class 0: acc 0.7188, precision 0.7241, recall 0.9545, f1 0.8235\n",
      "class 1: acc 0.7500, precision 0.6667, recall 0.2222, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 150 loss: 0.3428204655647278\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "epoch: 10 step: 151 loss: 0.49463537335395813\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 152 loss: 0.21551455557346344\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 153 loss: 0.6014868021011353\n",
      "class 0: acc 0.7812, precision 0.8400, recall 0.8750, f1 0.8571\n",
      "class 1: acc 0.7812, precision 0.4286, recall 0.5000, f1 0.4615\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 154 loss: 0.39339131116867065\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 155 loss: 0.17754992842674255\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 156 loss: 0.22332046926021576\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 157 loss: 0.37898173928260803\n",
      "class 0: acc 0.9062, precision 0.9545, recall 0.9130, f1 0.9333\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.7500, f1 0.7059\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 158 loss: 0.4806668162345886\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 159 loss: 0.2720818817615509\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 160 loss: 0.2874034643173218\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 161 loss: 0.31755489110946655\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 162 loss: 0.6134131550788879\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 163 loss: 0.2653237283229828\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 164 loss: 0.25903746485710144\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 165 loss: 0.2130843997001648\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 166 loss: 0.24729011952877045\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 167 loss: 0.44409775733947754\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 168 loss: 0.3079048991203308\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 169 loss: 0.2825418710708618\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 170 loss: 0.12479840219020844\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 171 loss: 0.37982606887817383\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 172 loss: 0.3990192115306854\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 173 loss: 0.2888256311416626\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 174 loss: 0.20735612511634827\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 175 loss: 0.16269320249557495\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 176 loss: 0.32660216093063354\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 177 loss: 0.5926752686500549\n",
      "class 0: acc 0.8125, precision 0.7692, recall 1.0000, f1 0.8696\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 178 loss: 0.2996072769165039\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 179 loss: 0.29319411516189575\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 180 loss: 0.37471330165863037\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 181 loss: 0.2736572027206421\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 182 loss: 0.40394648909568787\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 183 loss: 0.5109348893165588\n",
      "class 0: acc 0.8125, precision 0.8400, recall 0.9130, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 184 loss: 0.21314288675785065\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 185 loss: 0.4248199164867401\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 186 loss: 0.46328163146972656\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 187 loss: 0.29710474610328674\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 188 loss: 0.2848507761955261\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 189 loss: 0.3172336220741272\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 190 loss: 0.2060466706752777\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 191 loss: 0.2725891172885895\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 192 loss: 0.23510602116584778\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 193 loss: 0.3839740455150604\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 194 loss: 0.19897794723510742\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 195 loss: 0.18035556375980377\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 196 loss: 0.22708162665367126\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 197 loss: 0.47768083214759827\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 198 loss: 0.4934673309326172\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 199 loss: 0.5018535852432251\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 200 loss: 0.30823197960853577\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 201 loss: 0.34861236810684204\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 202 loss: 0.2056785225868225\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 203 loss: 0.43001019954681396\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 204 loss: 0.29286402463912964\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 205 loss: 0.22200724482536316\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 206 loss: 0.28049325942993164\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 207 loss: 0.36492666602134705\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 208 loss: 0.2522546648979187\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 209 loss: 0.2177000790834427\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 210 loss: 0.2824625074863434\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 211 loss: 0.33757564425468445\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 212 loss: 0.2601608633995056\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 213 loss: 0.24444493651390076\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 214 loss: 0.3834173083305359\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 215 loss: 0.2471754401922226\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 216 loss: 0.22512295842170715\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 217 loss: 0.3704150319099426\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 218 loss: 0.2247893214225769\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 219 loss: 0.17083492875099182\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 220 loss: 0.6612364649772644\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 221 loss: 0.19636860489845276\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 222 loss: 0.32385218143463135\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 223 loss: 0.14611497521400452\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 224 loss: 0.43008002638816833\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 225 loss: 0.30626380443573\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 226 loss: 0.36357009410858154\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 227 loss: 0.29927438497543335\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 228 loss: 0.7424517869949341\n",
      "class 0: acc 0.6250, precision 0.6154, recall 0.8889, f1 0.7273\n",
      "class 1: acc 0.7812, precision 0.6667, recall 0.4444, f1 0.5333\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 229 loss: 0.5995663404464722\n",
      "class 0: acc 0.8125, precision 0.7600, recall 1.0000, f1 0.8636\n",
      "class 1: acc 0.8125, precision 0.8571, recall 0.5455, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 230 loss: 0.5204132795333862\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "epoch: 10 step: 231 loss: 0.26244914531707764\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 232 loss: 0.4703831970691681\n",
      "class 0: acc 0.8438, precision 0.8710, recall 0.9643, f1 0.9153\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 233 loss: 0.38904473185539246\n",
      "class 0: acc 0.8750, precision 0.9167, recall 0.9167, f1 0.9167\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 234 loss: 0.4913228154182434\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 235 loss: 0.3754192292690277\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "epoch: 10 step: 236 loss: 0.6065424680709839\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.7500, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 237 loss: 0.5803031325340271\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 238 loss: 0.2335878312587738\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 239 loss: 0.35647690296173096\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 240 loss: 0.6192684769630432\n",
      "class 0: acc 0.6875, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "epoch: 10 step: 241 loss: 0.3984089493751526\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 242 loss: 0.3268544375896454\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 243 loss: 0.4296301603317261\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 244 loss: 0.3975414037704468\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 245 loss: 0.25402939319610596\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 246 loss: 0.17201533913612366\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 247 loss: 0.36604323983192444\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 248 loss: 0.530401349067688\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 249 loss: 0.39380359649658203\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 250 loss: 0.18251235783100128\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 251 loss: 0.31414076685905457\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 252 loss: 0.5706435441970825\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 253 loss: 0.38646361231803894\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 254 loss: 0.13329091668128967\n",
      "class 0: acc 0.9688, precision 0.9600, recall 1.0000, f1 0.9796\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8750, f1 0.9333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 255 loss: 0.48596879839897156\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 256 loss: 0.2926293611526489\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 257 loss: 0.3438241183757782\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 258 loss: 0.31600749492645264\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 259 loss: 0.2738838195800781\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 260 loss: 0.33374568819999695\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 261 loss: 0.3583099842071533\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 262 loss: 0.23580050468444824\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 263 loss: 0.21739605069160461\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 264 loss: 0.5195391774177551\n",
      "class 0: acc 0.7188, precision 0.7778, recall 0.8750, f1 0.8235\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 265 loss: 0.33232733607292175\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 266 loss: 0.3036537170410156\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 267 loss: 0.3051166534423828\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 268 loss: 0.33514413237571716\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 269 loss: 0.4894615709781647\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 270 loss: 0.3736737072467804\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 271 loss: 0.3650416135787964\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 272 loss: 0.7044948935508728\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 273 loss: 0.19692625105381012\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 274 loss: 0.4828242361545563\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 275 loss: 0.14249998331069946\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 276 loss: 0.41362157464027405\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 277 loss: 0.2194262444972992\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 278 loss: 0.1886364370584488\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 279 loss: 0.47518375515937805\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 280 loss: 0.23373183608055115\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 281 loss: 0.2751488983631134\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 282 loss: 0.31786543130874634\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 283 loss: 0.26950275897979736\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 284 loss: 0.27888596057891846\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 285 loss: 0.3250916600227356\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 10 step: 286 loss: 0.4233780801296234\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 287 loss: 0.61183100938797\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 288 loss: 0.34797602891921997\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 289 loss: 0.15647991001605988\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 290 loss: 0.37819135189056396\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 291 loss: 0.3232627809047699\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 292 loss: 0.3529333174228668\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 293 loss: 0.3002207577228546\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 294 loss: 0.5861847400665283\n",
      "class 0: acc 0.8125, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 295 loss: 0.4308200180530548\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 296 loss: 0.3164091408252716\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 297 loss: 0.3236539661884308\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 298 loss: 0.3294484615325928\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 299 loss: 0.27665576338768005\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 300 loss: 0.1456558108329773\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9688, f1 0.9841\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 301 loss: 0.35055577754974365\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 302 loss: 0.22174178063869476\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 303 loss: 0.3437052369117737\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 304 loss: 0.33647507429122925\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "epoch: 10 step: 305 loss: 0.5492144227027893\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 306 loss: 0.21454019844532013\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 307 loss: 0.40001749992370605\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 308 loss: 0.3032280206680298\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 309 loss: 0.17313766479492188\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 310 loss: 0.31470733880996704\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "epoch: 10 step: 311 loss: 0.17876778542995453\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 312 loss: 0.24247093498706818\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9286, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 313 loss: 0.3668135106563568\n",
      "class 0: acc 0.8438, precision 0.9286, recall 0.8966, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 314 loss: 0.45132705569267273\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 315 loss: 0.3578757047653198\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 316 loss: 0.5084291100502014\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6250, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 317 loss: 0.3989757001399994\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 318 loss: 0.6655259728431702\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 319 loss: 0.24221539497375488\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 320 loss: 0.3924947679042816\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 321 loss: 0.24555380642414093\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 322 loss: 0.24164721369743347\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 323 loss: 0.1290174424648285\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 324 loss: 0.21021294593811035\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 325 loss: 0.3402848541736603\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 326 loss: 0.06356377899646759\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 327 loss: 0.25938570499420166\n",
      "class 0: acc 0.8438, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8438, precision 0.1667, recall 1.0000, f1 0.2857\n",
      "epoch: 10 step: 328 loss: 0.8141219615936279\n",
      "class 0: acc 0.8125, precision 0.7917, recall 0.9500, f1 0.8636\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 329 loss: 0.4300731420516968\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 330 loss: 0.2949458360671997\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 331 loss: 0.24835537374019623\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 332 loss: 0.4156495928764343\n",
      "class 0: acc 0.8750, precision 1.0000, recall 0.8400, f1 0.9130\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.8125, precision 0.1429, recall 1.0000, f1 0.2500\n",
      "epoch: 10 step: 333 loss: 0.7507197260856628\n",
      "class 0: acc 0.7188, precision 0.7917, recall 0.8261, f1 0.8085\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 334 loss: 0.16397260129451752\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "epoch: 10 step: 335 loss: 0.6374228596687317\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "epoch: 10 step: 336 loss: 0.5271618366241455\n",
      "class 0: acc 0.8125, precision 0.9167, recall 0.8462, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.4000, recall 0.4000, f1 0.4000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 337 loss: 0.11636413633823395\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 338 loss: 0.24480631947517395\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 339 loss: 0.3655451536178589\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.7143, recall 0.6250, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 340 loss: 0.3749181032180786\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 341 loss: 0.5171937942504883\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "epoch: 10 step: 342 loss: 0.5151036977767944\n",
      "class 0: acc 0.7812, precision 0.8400, recall 0.8750, f1 0.8571\n",
      "class 1: acc 0.7812, precision 0.5714, recall 0.5000, f1 0.5333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 343 loss: 0.32954928278923035\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 344 loss: 0.18646183609962463\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9355, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 345 loss: 0.3834064304828644\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "epoch: 10 step: 346 loss: 0.14821338653564453\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 347 loss: 0.46983960270881653\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 348 loss: 0.324379026889801\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 349 loss: 0.17250964045524597\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 350 loss: 0.5082927346229553\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 351 loss: 0.27084875106811523\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 352 loss: 0.25613388419151306\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 353 loss: 0.13846881687641144\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 354 loss: 0.32336556911468506\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 355 loss: 0.2831008732318878\n",
      "class 0: acc 0.9375, precision 0.9200, recall 1.0000, f1 0.9583\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 356 loss: 0.3176899254322052\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 357 loss: 0.38164156675338745\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 358 loss: 0.26744943857192993\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 359 loss: 0.1998496651649475\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 360 loss: 0.1637609452009201\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 361 loss: 0.47271543741226196\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 362 loss: 0.27853965759277344\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 363 loss: 0.31235191226005554\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 364 loss: 0.5000407695770264\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8438, precision 0.5714, recall 0.6667, f1 0.6154\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 365 loss: 0.18792831897735596\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 366 loss: 0.472760409116745\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 367 loss: 0.42280763387680054\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 368 loss: 0.3572746217250824\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 369 loss: 0.4631967842578888\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 370 loss: 0.24943625926971436\n",
      "class 0: acc 0.8750, precision 0.9333, recall 0.9333, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 371 loss: 0.4290248453617096\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 372 loss: 0.534519612789154\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 373 loss: 0.2398936003446579\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 374 loss: 0.4499112665653229\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 375 loss: 0.7667204141616821\n",
      "class 0: acc 0.7500, precision 0.7586, recall 0.9565, f1 0.8462\n",
      "class 1: acc 0.7500, precision 1.0000, recall 0.1111, f1 0.2000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 376 loss: 0.5797986388206482\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 377 loss: 0.4275936782360077\n",
      "class 0: acc 0.9062, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.8571, recall 0.6667, f1 0.7500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 378 loss: 0.2841133177280426\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 379 loss: 0.4525899589061737\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 380 loss: 0.5676600337028503\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 381 loss: 0.40815839171409607\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 382 loss: 0.4138247072696686\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 383 loss: 0.4518781900405884\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 384 loss: 0.32233595848083496\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 385 loss: 0.3612755537033081\n",
      "class 0: acc 0.8438, precision 0.9500, recall 0.8261, f1 0.8837\n",
      "class 1: acc 0.9062, precision 0.7778, recall 0.8750, f1 0.8235\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 10 step: 386 loss: 0.3464273512363434\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 387 loss: 0.4769357144832611\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 388 loss: 0.2123987227678299\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 389 loss: 0.35258784890174866\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 390 loss: 0.32850053906440735\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 391 loss: 0.5546069145202637\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 392 loss: 0.2765149772167206\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 393 loss: 0.2676393985748291\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 394 loss: 0.3989960849285126\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 395 loss: 0.14054270088672638\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 396 loss: 0.358673095703125\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 397 loss: 0.14385555684566498\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 398 loss: 0.128311425447464\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 399 loss: 0.5324386954307556\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 400 loss: 0.37310361862182617\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 401 loss: 0.2640642523765564\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 402 loss: 0.2626866102218628\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 403 loss: 0.345108300447464\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 404 loss: 0.18375007808208466\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 405 loss: 0.40680992603302\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 406 loss: 0.25119948387145996\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 407 loss: 0.22494927048683167\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 408 loss: 0.43208327889442444\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 409 loss: 0.1382908672094345\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 410 loss: 0.36741799116134644\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8750, f1 0.9333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 411 loss: 0.23610717058181763\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 412 loss: 0.5514625310897827\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 413 loss: 0.0972992405295372\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 414 loss: 0.14511549472808838\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 415 loss: 0.11501854658126831\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 416 loss: 0.24738086760044098\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 417 loss: 0.45812660455703735\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 418 loss: 0.40755757689476013\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.4444, f1 0.6154\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 419 loss: 0.45633769035339355\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 420 loss: 0.1722911298274994\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 421 loss: 0.5835906863212585\n",
      "class 0: acc 0.7500, precision 0.7778, recall 0.9130, f1 0.8400\n",
      "class 1: acc 0.7812, precision 0.2000, recall 0.2500, f1 0.2222\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 422 loss: 0.25445911288261414\n",
      "class 0: acc 0.9688, precision 0.9583, recall 1.0000, f1 0.9787\n",
      "class 1: acc 0.9375, precision 0.8750, recall 0.8750, f1 0.8750\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 423 loss: 0.4513283967971802\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 424 loss: 0.233503520488739\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 425 loss: 0.5184630155563354\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 426 loss: 0.4544694721698761\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 427 loss: 0.6425663828849792\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 428 loss: 0.4231506586074829\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 429 loss: 0.28205880522727966\n",
      "class 0: acc 0.9062, precision 0.9667, recall 0.9355, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 430 loss: 0.4203169643878937\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 431 loss: 0.27752816677093506\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 432 loss: 0.4792136251926422\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 433 loss: 0.43985939025878906\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 434 loss: 0.4727013409137726\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 435 loss: 0.28676316142082214\n",
      "class 0: acc 0.8750, precision 0.9130, recall 0.9130, f1 0.9130\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 436 loss: 0.29245805740356445\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 437 loss: 0.515388011932373\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 438 loss: 0.5125400424003601\n",
      "class 0: acc 0.8750, precision 0.9167, recall 0.9167, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 439 loss: 0.48888251185417175\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8889, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.4286, recall 1.0000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 440 loss: 0.2912346124649048\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 441 loss: 0.4256041646003723\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 442 loss: 0.5245679616928101\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 443 loss: 0.46616101264953613\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 444 loss: 0.269626647233963\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 445 loss: 0.41159704327583313\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 446 loss: 0.14372320473194122\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 447 loss: 0.45952653884887695\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 448 loss: 0.21268005669116974\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 449 loss: 0.21584227681159973\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 450 loss: 0.43554890155792236\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 451 loss: 0.38532817363739014\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 452 loss: 0.1778930425643921\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 453 loss: 0.3481813669204712\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 454 loss: 0.12337145954370499\n",
      "class 0: acc 0.9688, precision 0.9688, recall 1.0000, f1 0.9841\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 455 loss: 0.495274156332016\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 456 loss: 0.3681393265724182\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 457 loss: 0.49687841534614563\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 458 loss: 0.4355831742286682\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 459 loss: 0.4308198392391205\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 460 loss: 0.537386417388916\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 461 loss: 0.5306165218353271\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 10 step: 462 loss: 0.18324978649616241\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 463 loss: 0.3689816892147064\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 464 loss: 0.17653237283229828\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 465 loss: 0.3941563069820404\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 466 loss: 0.272485613822937\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 467 loss: 0.20036451518535614\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 468 loss: 0.26817113161087036\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 469 loss: 0.4860226809978485\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 470 loss: 0.397193044424057\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 471 loss: 0.14853540062904358\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9333, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 472 loss: 0.24068643152713776\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 473 loss: 0.46483275294303894\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 474 loss: 0.23495790362358093\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 475 loss: 0.3237955570220947\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 476 loss: 0.22471140325069427\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 477 loss: 0.25637540221214294\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 478 loss: 0.18082420527935028\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 479 loss: 0.2585858106613159\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 480 loss: 0.28761744499206543\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 481 loss: 0.273550808429718\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 482 loss: 0.2231908142566681\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 483 loss: 0.3627723753452301\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 484 loss: 0.5274167060852051\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 485 loss: 0.13690133392810822\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 486 loss: 0.19879892468452454\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 487 loss: 0.24478758871555328\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 488 loss: 0.269544392824173\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 489 loss: 0.19047850370407104\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 490 loss: 0.41760408878326416\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 491 loss: 0.28244706988334656\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 492 loss: 0.25086939334869385\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 493 loss: 0.43188348412513733\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 494 loss: 0.18357118964195251\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9259, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 495 loss: 0.28922516107559204\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 496 loss: 0.2782316505908966\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 497 loss: 0.2082097828388214\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 498 loss: 0.23030725121498108\n",
      "class 0: acc 0.9688, precision 0.9583, recall 1.0000, f1 0.9787\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8750, f1 0.9333\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 499 loss: 0.4920021593570709\n",
      "class 0: acc 0.7812, precision 0.7200, recall 1.0000, f1 0.8372\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.7000, f1 0.8235\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 500 loss: 0.5015378594398499\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.4286, f1 0.4615\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 501 loss: 0.2968021333217621\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 502 loss: 0.17823347449302673\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 503 loss: 0.42981380224227905\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 504 loss: 0.40147364139556885\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 505 loss: 0.433295875787735\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 506 loss: 0.516655683517456\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 507 loss: 0.13455192744731903\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 508 loss: 0.39164113998413086\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 509 loss: 0.15366414189338684\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 510 loss: 0.3215322196483612\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 10 step: 511 loss: 0.3248690068721771\n",
      "class 0: acc 0.9375, precision 0.9167, recall 1.0000, f1 0.9565\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 10 step: 512 loss: 0.39329811930656433\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 513 loss: 0.6495009660720825\n",
      "class 0: acc 0.7500, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8125, precision 0.2500, recall 0.2500, f1 0.2500\n",
      "epoch: 10 step: 514 loss: 0.5269555449485779\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 515 loss: 0.18874596059322357\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 516 loss: 0.3573552966117859\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 517 loss: 0.45675140619277954\n",
      "class 0: acc 0.8438, precision 0.9000, recall 0.9310, f1 0.9153\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 518 loss: 0.3710457980632782\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 519 loss: 0.316905677318573\n",
      "class 0: acc 0.8438, precision 0.9600, recall 0.8571, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 520 loss: 0.2179696410894394\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 521 loss: 0.1458711177110672\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 522 loss: 0.4116339683532715\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 523 loss: 0.3229270577430725\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 524 loss: 0.3808000683784485\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 525 loss: 0.45052599906921387\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 526 loss: 0.10333722829818726\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 527 loss: 0.38645339012145996\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 528 loss: 0.3970305025577545\n",
      "class 0: acc 0.8750, precision 0.8750, recall 0.9545, f1 0.9130\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8750, f1 0.9333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 529 loss: 0.43382522463798523\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 530 loss: 0.24462099373340607\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 531 loss: 0.19868074357509613\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 532 loss: 0.32736966013908386\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 533 loss: 0.2737416625022888\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 534 loss: 0.21412742137908936\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 535 loss: 0.39915934205055237\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 536 loss: 0.22416937351226807\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 537 loss: 0.23621533811092377\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 538 loss: 0.3623029589653015\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 10 step: 539 loss: 0.4936339855194092\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 540 loss: 0.3166730999946594\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 541 loss: 0.46538037061691284\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 542 loss: 0.45719072222709656\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 543 loss: 0.7007763981819153\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.1429, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 544 loss: 0.16491807997226715\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 545 loss: 0.43502241373062134\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 546 loss: 0.4179788827896118\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 547 loss: 0.34038710594177246\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 548 loss: 0.22962109744548798\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 549 loss: 0.5412454009056091\n",
      "class 0: acc 0.8438, precision 0.8400, recall 0.9545, f1 0.8936\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.4286, f1 0.4615\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 550 loss: 0.46950477361679077\n",
      "class 0: acc 0.8438, precision 0.8333, recall 0.9524, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 551 loss: 0.14364513754844666\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 552 loss: 0.44527745246887207\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 553 loss: 0.26820629835128784\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "epoch: 10 step: 554 loss: 0.42865094542503357\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 555 loss: 0.40914180874824524\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 556 loss: 0.5033646821975708\n",
      "class 0: acc 0.8125, precision 0.8846, recall 0.8846, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 557 loss: 0.1657034009695053\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 558 loss: 0.6031807065010071\n",
      "class 0: acc 0.7500, precision 0.8148, recall 0.8800, f1 0.8462\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 559 loss: 0.5834373235702515\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 560 loss: 0.4013930857181549\n",
      "class 0: acc 0.8750, precision 0.9583, recall 0.8846, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 561 loss: 0.23941263556480408\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "epoch: 10 step: 562 loss: 0.3321966826915741\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 563 loss: 0.3626682162284851\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 564 loss: 0.38731083273887634\n",
      "class 0: acc 0.8750, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 565 loss: 0.13372406363487244\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 566 loss: 0.2844105362892151\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 567 loss: 0.519028902053833\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 568 loss: 0.36584556102752686\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 569 loss: 0.3125755786895752\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 570 loss: 0.6494253873825073\n",
      "class 0: acc 0.7812, precision 0.8519, recall 0.8846, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 10 step: 571 loss: 0.33667463064193726\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 572 loss: 0.3253796398639679\n",
      "class 0: acc 0.8750, precision 0.9615, recall 0.8929, f1 0.9259\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 573 loss: 0.30711838603019714\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 10 step: 574 loss: 0.2281571626663208\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8929, f1 0.9434\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "epoch: 10 step: 575 loss: 0.5387274026870728\n",
      "class 0: acc 0.7812, precision 0.8636, recall 0.8261, f1 0.8444\n",
      "class 1: acc 0.8438, precision 0.6250, recall 0.7143, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 10 step: 576 loss: 0.17100860178470612\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 577 loss: 0.36990585923194885\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 578 loss: 0.36239975690841675\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 579 loss: 0.33203113079071045\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 580 loss: 0.20790094137191772\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 581 loss: 0.39672717452049255\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 582 loss: 0.49450427293777466\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 10 step: 583 loss: 0.4823872745037079\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "epoch: 10 step: 584 loss: 0.3340575397014618\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 585 loss: 0.29511138796806335\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 586 loss: 0.25323057174682617\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 587 loss: 0.3262527287006378\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 588 loss: 0.38982874155044556\n",
      "class 0: acc 0.9375, precision 0.9200, recall 1.0000, f1 0.9583\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 589 loss: 0.42359408736228943\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 590 loss: 0.18311446905136108\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 591 loss: 0.36333534121513367\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 592 loss: 0.3493216931819916\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 593 loss: 0.4638400077819824\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 594 loss: 0.3280884325504303\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 595 loss: 0.44098883867263794\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.7500, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 596 loss: 0.41381219029426575\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 597 loss: 0.623116672039032\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 598 loss: 0.3516189754009247\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 599 loss: 0.26834768056869507\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 600 loss: 0.33878016471862793\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 601 loss: 0.2554043233394623\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 602 loss: 0.1541193276643753\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 603 loss: 0.5080864429473877\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 604 loss: 0.33375751972198486\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 605 loss: 0.5327276587486267\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 606 loss: 0.2731330096721649\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 607 loss: 0.4647686779499054\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "epoch: 10 step: 608 loss: 0.39944377541542053\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 10 step: 609 loss: 0.3415507674217224\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 610 loss: 0.3730746805667877\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 611 loss: 0.3734634518623352\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 612 loss: 0.33590659499168396\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 613 loss: 0.325975626707077\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 614 loss: 0.3578718900680542\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 615 loss: 0.17580443620681763\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9333, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 616 loss: 0.23409350216388702\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 617 loss: 0.47107991576194763\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 618 loss: 0.5026748776435852\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 619 loss: 0.257865309715271\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 620 loss: 0.41472041606903076\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 10 step: 621 loss: 0.37473466992378235\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 622 loss: 0.37208911776542664\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 623 loss: 0.33647221326828003\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 624 loss: 0.2814100980758667\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 625 loss: 0.2675597369670868\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 10 step: 626 loss: 0.37171459197998047\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 627 loss: 0.20821824669837952\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 628 loss: 0.4214624762535095\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 629 loss: 0.2858477234840393\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 630 loss: 0.2203102558851242\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 631 loss: 0.16396187245845795\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 632 loss: 0.3793286681175232\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 633 loss: 0.09391197562217712\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 634 loss: 0.18037058413028717\n",
      "class 0: acc 0.9375, precision 0.9200, recall 1.0000, f1 0.9583\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8750, f1 0.9333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 635 loss: 0.18288038671016693\n",
      "class 0: acc 0.9688, precision 0.9615, recall 1.0000, f1 0.9804\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 636 loss: 0.4118933081626892\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 637 loss: 0.3153406083583832\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 638 loss: 0.2953132688999176\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 639 loss: 0.5430238842964172\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 640 loss: 0.48424533009529114\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 641 loss: 0.4694809913635254\n",
      "class 0: acc 0.8438, precision 0.8400, recall 0.9545, f1 0.8936\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 642 loss: 0.17344583570957184\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 643 loss: 0.3240194022655487\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 644 loss: 0.4547034204006195\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 645 loss: 0.2985318601131439\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 646 loss: 0.299072802066803\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 647 loss: 0.18842452764511108\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 648 loss: 0.3350112736225128\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 649 loss: 0.29443469643592834\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 650 loss: 0.5826322436332703\n",
      "class 0: acc 0.8125, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 651 loss: 0.2438795566558838\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9677, f1 0.9836\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 652 loss: 0.6370647549629211\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.2857, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 653 loss: 0.5246351957321167\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 654 loss: 0.1542152762413025\n",
      "class 0: acc 0.9688, precision 0.9600, recall 1.0000, f1 0.9796\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 655 loss: 0.28963717818260193\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 656 loss: 0.15375742316246033\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 657 loss: 0.5523149967193604\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 658 loss: 0.2435034215450287\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 659 loss: 0.30091655254364014\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 660 loss: 0.18352988362312317\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 661 loss: 0.35858583450317383\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 662 loss: 0.5300496816635132\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.7812, precision 0.6000, recall 0.3750, f1 0.4615\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 663 loss: 0.5037352442741394\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 664 loss: 0.32674407958984375\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 665 loss: 0.27413490414619446\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 666 loss: 0.08291803300380707\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 667 loss: 0.44527000188827515\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 668 loss: 0.2300652116537094\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 669 loss: 0.37833377718925476\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 670 loss: 0.11499612778425217\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 671 loss: 0.44777828454971313\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 672 loss: 0.7344253063201904\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 10 step: 673 loss: 0.2767334580421448\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 674 loss: 0.3155473470687866\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 675 loss: 0.34127840399742126\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 676 loss: 0.21123751997947693\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 677 loss: 0.2794797420501709\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 678 loss: 0.5590211153030396\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9091, f1 0.8696\n",
      "class 1: acc 0.7812, precision 0.6250, recall 0.5556, f1 0.5882\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 679 loss: 0.18841321766376495\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 680 loss: 0.39370474219322205\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 681 loss: 0.26473891735076904\n",
      "class 0: acc 0.8750, precision 0.9167, recall 0.9167, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 682 loss: 0.5495330095291138\n",
      "class 0: acc 0.8438, precision 0.8400, recall 0.9545, f1 0.8936\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 683 loss: 0.23829692602157593\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 684 loss: 0.3526879847049713\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 685 loss: 0.4120965898036957\n",
      "class 0: acc 0.8750, precision 0.8400, recall 1.0000, f1 0.9130\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 686 loss: 0.27228254079818726\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 687 loss: 0.3021104335784912\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 688 loss: 0.6448001265525818\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.7812, precision 0.6000, recall 0.3750, f1 0.4615\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 689 loss: 0.4146588444709778\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 690 loss: 0.4498268961906433\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 691 loss: 0.23724861443042755\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 692 loss: 0.36951500177383423\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 693 loss: 0.2156447023153305\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 694 loss: 0.2993827760219574\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 695 loss: 0.21740791201591492\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 696 loss: 0.39170312881469727\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 697 loss: 0.38566258549690247\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 698 loss: 0.3917238116264343\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 699 loss: 0.6046077609062195\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 700 loss: 0.43124520778656006\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 701 loss: 0.2593711018562317\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 702 loss: 0.22553353011608124\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 703 loss: 0.2930811047554016\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 704 loss: 0.32824501395225525\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 705 loss: 0.2538239061832428\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 706 loss: 0.36980757117271423\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 707 loss: 0.318328320980072\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 708 loss: 0.3272116780281067\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 709 loss: 0.4176866412162781\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 710 loss: 0.2586127817630768\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 711 loss: 0.5791253447532654\n",
      "class 0: acc 0.8438, precision 0.8077, recall 1.0000, f1 0.8936\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 712 loss: 0.18542709946632385\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 713 loss: 0.3840803802013397\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 714 loss: 0.3806765079498291\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 715 loss: 0.274952232837677\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 716 loss: 0.5289034843444824\n",
      "class 0: acc 0.7812, precision 0.8077, recall 0.9130, f1 0.8571\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 717 loss: 0.5835376381874084\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 718 loss: 0.6556098461151123\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "epoch: 10 step: 719 loss: 0.11579950153827667\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 720 loss: 0.4563310444355011\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 721 loss: 0.3724663257598877\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 722 loss: 0.24676603078842163\n",
      "class 0: acc 0.9375, precision 0.9677, recall 0.9677, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 723 loss: 0.2347297966480255\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 724 loss: 0.2946418225765228\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 725 loss: 0.311931848526001\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 10 step: 726 loss: 0.5577998757362366\n",
      "class 0: acc 0.7812, precision 0.8519, recall 0.8846, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.2000, recall 1.0000, f1 0.3333\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 727 loss: 0.38575053215026855\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 10 step: 728 loss: 0.49457719922065735\n",
      "class 0: acc 0.8125, precision 0.9200, recall 0.8519, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "epoch: 10 step: 729 loss: 0.4275358319282532\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 730 loss: 0.5691109895706177\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 731 loss: 0.25148531794548035\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 732 loss: 0.26215672492980957\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 733 loss: 0.264338880777359\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 734 loss: 0.36133110523223877\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "epoch: 10 step: 735 loss: 0.2514536678791046\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 736 loss: 0.44107335805892944\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 737 loss: 0.496721476316452\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 738 loss: 0.282626748085022\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 739 loss: 0.4437122941017151\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 740 loss: 0.25464755296707153\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 741 loss: 0.4022473394870758\n",
      "class 0: acc 0.8125, precision 0.8387, recall 0.9630, f1 0.8966\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 742 loss: 0.3210757076740265\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 743 loss: 0.1357703059911728\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 744 loss: 0.23667733371257782\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 745 loss: 0.3405817747116089\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 746 loss: 0.17401835322380066\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 747 loss: 0.4758903384208679\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.7143, recall 0.6250, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 748 loss: 0.4663921296596527\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 749 loss: 0.5120600461959839\n",
      "class 0: acc 0.7188, precision 0.7586, recall 0.9167, f1 0.8302\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 750 loss: 0.22346948087215424\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.9375, precision 0.8750, recall 0.8750, f1 0.8750\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 751 loss: 0.6518765091896057\n",
      "class 0: acc 0.7188, precision 0.7500, recall 0.9130, f1 0.8235\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.2857, f1 0.3636\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 752 loss: 0.20817184448242188\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 753 loss: 0.3718837797641754\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 754 loss: 0.2950904369354248\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 755 loss: 0.2468273639678955\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 756 loss: 0.49595174193382263\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 757 loss: 0.4755326509475708\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.8750, precision 0.6250, recall 0.8333, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 758 loss: 0.16354531049728394\n",
      "class 0: acc 0.9375, precision 0.9375, recall 1.0000, f1 0.9677\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 759 loss: 0.6659496426582336\n",
      "class 0: acc 0.9062, precision 0.8696, recall 1.0000, f1 0.9302\n",
      "class 1: acc 0.9062, precision 0.8571, recall 0.7500, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "epoch: 10 step: 760 loss: 0.3732791841030121\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 10 step: 761 loss: 0.2425418347120285\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 762 loss: 0.2088877111673355\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 763 loss: 0.246597558259964\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 764 loss: 0.22967275977134705\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.9032, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 10 step: 765 loss: 0.5601244568824768\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.1429, f1 0.2500\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 766 loss: 0.08170588314533234\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 767 loss: 0.2523469924926758\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 768 loss: 0.5163723230361938\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.9062, precision 0.8333, recall 0.7143, f1 0.7692\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 769 loss: 0.4426584839820862\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 770 loss: 0.25570711493492126\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 771 loss: 0.48097285628318787\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.8438, precision 0.8000, recall 0.5000, f1 0.6154\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 772 loss: 0.6618891954421997\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 773 loss: 0.4747063219547272\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "epoch: 10 step: 774 loss: 0.5784420371055603\n",
      "class 0: acc 0.8438, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.8333, recall 0.5556, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 775 loss: 0.22663278877735138\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 776 loss: 0.24200059473514557\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 777 loss: 0.5052732825279236\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.2857, f1 0.3636\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 778 loss: 0.5001617670059204\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 779 loss: 0.3545023500919342\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 780 loss: 0.39998215436935425\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 781 loss: 0.3397049903869629\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 782 loss: 0.585128664970398\n",
      "class 0: acc 0.7812, precision 0.7308, recall 1.0000, f1 0.8444\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.5455, f1 0.7059\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 783 loss: 0.2526959478855133\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 784 loss: 0.4822612404823303\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 785 loss: 0.2597294747829437\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 786 loss: 0.10328041017055511\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 787 loss: 0.5574243068695068\n",
      "class 0: acc 0.7500, precision 0.7419, recall 1.0000, f1 0.8519\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 788 loss: 0.4157833158969879\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 789 loss: 0.11319226026535034\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 790 loss: 0.4043521285057068\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 791 loss: 0.5072916746139526\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 792 loss: 0.34726694226264954\n",
      "class 0: acc 0.8438, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7778, f1 0.8750\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 793 loss: 0.4332713186740875\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 794 loss: 0.2169937640428543\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 795 loss: 0.4610777497291565\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 796 loss: 0.7507607340812683\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 797 loss: 0.41522374749183655\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 798 loss: 0.36772605776786804\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 799 loss: 0.3167981803417206\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 800 loss: 0.13721463084220886\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 801 loss: 0.2631737291812897\n",
      "class 0: acc 0.9688, precision 0.9600, recall 1.0000, f1 0.9796\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 802 loss: 0.2994595766067505\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 803 loss: 0.60129714012146\n",
      "class 0: acc 0.7500, precision 0.7308, recall 0.9500, f1 0.8261\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 804 loss: 0.11783400177955627\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 805 loss: 0.24259111285209656\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 806 loss: 0.3559149503707886\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 807 loss: 0.15370595455169678\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 808 loss: 0.3667360246181488\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 809 loss: 0.3473717272281647\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 810 loss: 0.4367406368255615\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 811 loss: 0.28149232268333435\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 812 loss: 0.2116641104221344\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 813 loss: 0.2057056874036789\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 814 loss: 0.3790067732334137\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 815 loss: 0.263497918844223\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 816 loss: 0.23622359335422516\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 817 loss: 0.27321264147758484\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 818 loss: 0.7819761633872986\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 819 loss: 0.4655548632144928\n",
      "class 0: acc 0.8438, precision 0.8148, recall 1.0000, f1 0.8980\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "epoch: 10 step: 820 loss: 0.29212814569473267\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 821 loss: 0.4589090645313263\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 822 loss: 0.21203121542930603\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 823 loss: 0.4054481089115143\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 824 loss: 0.46402594447135925\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 825 loss: 0.3473816514015198\n",
      "class 0: acc 0.9062, precision 0.9583, recall 0.9200, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.8571, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 826 loss: 0.2865146994590759\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 827 loss: 0.3360445201396942\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 828 loss: 0.5635954141616821\n",
      "class 0: acc 0.7812, precision 0.8276, recall 0.9231, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.3333, recall 0.2500, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 829 loss: 0.2894543409347534\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 830 loss: 0.6297425627708435\n",
      "class 0: acc 0.7812, precision 0.7857, recall 0.9565, f1 0.8627\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 831 loss: 0.2942807674407959\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 832 loss: 0.2269366979598999\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 833 loss: 0.37685516476631165\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 834 loss: 0.2610441744327545\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 835 loss: 0.2508890926837921\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 836 loss: 0.18780872225761414\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 837 loss: 0.20992758870124817\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 838 loss: 0.1281057894229889\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 839 loss: 0.30095747113227844\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 840 loss: 0.3020952343940735\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 841 loss: 0.2495390921831131\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 842 loss: 0.37730446457862854\n",
      "class 0: acc 0.8438, precision 0.8667, recall 0.9630, f1 0.9123\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 843 loss: 0.41016048192977905\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 844 loss: 0.20462720096111298\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 845 loss: 0.5652218461036682\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 846 loss: 0.48693060874938965\n",
      "class 0: acc 0.7500, precision 0.7742, recall 0.9600, f1 0.8571\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 847 loss: 0.30231425166130066\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 848 loss: 0.4573068916797638\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 849 loss: 0.2985047698020935\n",
      "class 0: acc 0.8438, precision 0.9630, recall 0.8667, f1 0.9123\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 850 loss: 0.10603190958499908\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 851 loss: 0.4237056076526642\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 852 loss: 0.34309378266334534\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 10 step: 853 loss: 0.5296976566314697\n",
      "class 0: acc 0.8750, precision 0.8800, recall 0.9565, f1 0.9167\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 10 step: 854 loss: 0.18609631061553955\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 855 loss: 0.3190731704235077\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 856 loss: 0.4998725354671478\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 857 loss: 0.4483188986778259\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 858 loss: 0.5343243479728699\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.4286, f1 0.5455\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 859 loss: 0.23177488148212433\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 860 loss: 0.3666073679924011\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 861 loss: 0.5617949962615967\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 862 loss: 0.2685868740081787\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 863 loss: 0.26945969462394714\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 864 loss: 0.5334584712982178\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 865 loss: 0.2869192659854889\n",
      "class 0: acc 0.9062, precision 0.9130, recall 0.9545, f1 0.9333\n",
      "class 1: acc 0.9688, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 866 loss: 0.1123591959476471\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 867 loss: 0.33530107140541077\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 868 loss: 0.25532934069633484\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 869 loss: 0.3942335247993469\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 870 loss: 0.28224289417266846\n",
      "class 0: acc 0.8750, precision 0.9600, recall 0.8889, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 871 loss: 0.5745634436607361\n",
      "class 0: acc 0.7812, precision 0.7742, recall 1.0000, f1 0.8727\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.1429, f1 0.2500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 872 loss: 0.3030739426612854\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 873 loss: 0.457421213388443\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 874 loss: 0.35532015562057495\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 875 loss: 0.3533440828323364\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 876 loss: 0.14163954555988312\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 877 loss: 0.1819119155406952\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 878 loss: 0.2161259800195694\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 879 loss: 0.2448091357946396\n",
      "class 0: acc 0.9062, precision 0.9667, recall 0.9355, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 880 loss: 0.3974215090274811\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 881 loss: 0.32810986042022705\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 882 loss: 0.5701181888580322\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.7812, precision 0.7500, recall 0.3333, f1 0.4615\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 883 loss: 0.42160946130752563\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 10 step: 884 loss: 0.37560001015663147\n",
      "class 0: acc 0.8438, precision 0.9630, recall 0.8667, f1 0.9123\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 885 loss: 0.21102890372276306\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 886 loss: 0.2223990261554718\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 887 loss: 0.27309271693229675\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 888 loss: 0.4337288737297058\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 889 loss: 0.33057841658592224\n",
      "class 0: acc 0.8438, precision 0.9259, recall 0.8929, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.4000, recall 0.5000, f1 0.4444\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 890 loss: 0.45356765389442444\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 891 loss: 0.11243735998868942\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 892 loss: 0.34454840421676636\n",
      "class 0: acc 0.8125, precision 0.8571, recall 0.9231, f1 0.8889\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 893 loss: 0.28782957792282104\n",
      "class 0: acc 0.9062, precision 0.9655, recall 0.9333, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 894 loss: 0.5516728162765503\n",
      "class 0: acc 0.8750, precision 0.9000, recall 0.9643, f1 0.9310\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 895 loss: 0.2858166992664337\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 896 loss: 0.2845182418823242\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 897 loss: 0.34031766653060913\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 898 loss: 0.28993695974349976\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 899 loss: 0.28037717938423157\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 900 loss: 0.37417832016944885\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 901 loss: 0.18718241155147552\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 902 loss: 0.19503165781497955\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 903 loss: 0.34281525015830994\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.2500, f1 0.3333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 904 loss: 0.09326303005218506\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 905 loss: 0.2317410707473755\n",
      "class 0: acc 0.9062, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 10 step: 906 loss: 0.2516856789588928\n",
      "class 0: acc 0.9062, precision 0.9667, recall 0.9355, f1 0.9508\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 907 loss: 0.23264172673225403\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 908 loss: 0.21555642783641815\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 909 loss: 0.4366452991962433\n",
      "class 0: acc 0.7812, precision 0.7778, recall 0.9545, f1 0.8571\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 910 loss: 0.41940218210220337\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 911 loss: 0.48271673917770386\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 912 loss: 0.31396958231925964\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 913 loss: 0.30492791533470154\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 0.8333, recall 0.8333, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 914 loss: 0.2784445881843567\n",
      "class 0: acc 0.8438, precision 0.9200, recall 0.8846, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "epoch: 10 step: 915 loss: 0.17426708340644836\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 916 loss: 0.4268716871738434\n",
      "class 0: acc 0.9062, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.8438, precision 0.7500, recall 0.6667, f1 0.7059\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 917 loss: 0.34209105372428894\n",
      "class 0: acc 0.8438, precision 0.8387, recall 1.0000, f1 0.9123\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 918 loss: 0.3230361342430115\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 919 loss: 0.4022030234336853\n",
      "class 0: acc 0.8438, precision 0.9200, recall 0.8846, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.6000, f1 0.5455\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 920 loss: 0.3094850480556488\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 921 loss: 0.11662179231643677\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 922 loss: 0.20903795957565308\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 923 loss: 0.3385738730430603\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 924 loss: 0.19823488593101501\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9375, precision 0.7143, recall 1.0000, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 925 loss: 0.3867911398410797\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 926 loss: 0.10563671588897705\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 927 loss: 0.23334744572639465\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 928 loss: 0.29066002368927\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 929 loss: 0.4003865420818329\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 930 loss: 0.6330305933952332\n",
      "class 0: acc 0.8125, precision 0.8667, recall 0.9286, f1 0.8966\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 931 loss: 0.13431695103645325\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 932 loss: 0.5523698329925537\n",
      "class 0: acc 0.8438, precision 0.8800, recall 0.9167, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.5714, recall 0.8000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 933 loss: 0.4852618873119354\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 934 loss: 0.27430543303489685\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 935 loss: 0.29352471232414246\n",
      "class 0: acc 0.9062, precision 0.8846, recall 1.0000, f1 0.9388\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 936 loss: 0.31542137265205383\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 937 loss: 0.3012027144432068\n",
      "class 0: acc 0.8125, precision 0.8276, recall 0.9600, f1 0.8889\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 938 loss: 0.35323813557624817\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 939 loss: 0.327370285987854\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 940 loss: 0.21963736414909363\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 941 loss: 0.17111600935459137\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 942 loss: 0.22588811814785004\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 943 loss: 0.3288559317588806\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 944 loss: 0.3254186809062958\n",
      "class 0: acc 0.8750, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5556, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 10 step: 945 loss: 0.22397080063819885\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9259, f1 0.9615\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9062, precision 0.2500, recall 1.0000, f1 0.4000\n",
      "epoch: 10 step: 946 loss: 0.388130784034729\n",
      "class 0: acc 0.9062, precision 0.8800, recall 1.0000, f1 0.9362\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "epoch: 10 step: 947 loss: 0.19541746377944946\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.3333, recall 1.0000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 948 loss: 0.44289666414260864\n",
      "class 0: acc 0.8438, precision 0.8571, recall 0.9600, f1 0.9057\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.3333, f1 0.4444\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 949 loss: 0.34360480308532715\n",
      "class 0: acc 0.9375, precision 0.9545, recall 0.9545, f1 0.9545\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "epoch: 10 step: 950 loss: 0.2661484181880951\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 951 loss: 0.28817039728164673\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 952 loss: 0.09035210311412811\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 953 loss: 0.2379351407289505\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "epoch: 10 step: 954 loss: 0.26965567469596863\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 955 loss: 0.14896324276924133\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 956 loss: 0.26973676681518555\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 957 loss: 0.35238298773765564\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 10 step: 958 loss: 0.4007748067378998\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 959 loss: 0.2927675247192383\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 960 loss: 0.36949384212493896\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 961 loss: 0.22671879827976227\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 962 loss: 0.44252705574035645\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 963 loss: 0.38299480080604553\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 964 loss: 0.43318623304367065\n",
      "class 0: acc 0.8438, precision 0.8438, recall 1.0000, f1 0.9153\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 965 loss: 0.4365941882133484\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 966 loss: 0.4517228603363037\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 967 loss: 0.6430975794792175\n",
      "class 0: acc 0.7812, precision 0.8214, recall 0.9200, f1 0.8679\n",
      "class 1: acc 0.7812, precision 0.3333, recall 0.1667, f1 0.2222\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 968 loss: 0.2826353907585144\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9643, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 969 loss: 0.5317175388336182\n",
      "class 0: acc 0.8438, precision 0.8966, recall 0.9286, f1 0.9123\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 970 loss: 0.3158387541770935\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 971 loss: 0.34366700053215027\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 972 loss: 0.18957848846912384\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 973 loss: 0.3990479111671448\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 974 loss: 0.28891265392303467\n",
      "class 0: acc 0.8750, precision 0.9600, recall 0.8889, f1 0.9231\n",
      "class 1: acc 0.9375, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 975 loss: 0.32673126459121704\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 976 loss: 0.5635582804679871\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.8438, precision 0.6000, recall 0.5000, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 977 loss: 0.13467882573604584\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 978 loss: 0.648216962814331\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8125, precision 0.7500, recall 0.3750, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 979 loss: 0.2013072520494461\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 980 loss: 0.2597445249557495\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 981 loss: 0.2807627022266388\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 982 loss: 0.29334548115730286\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 983 loss: 0.2121877670288086\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 984 loss: 0.4041444957256317\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 985 loss: 0.47895511984825134\n",
      "class 0: acc 0.8125, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.7000, f1 0.8235\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 10 step: 986 loss: 0.14414601027965546\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 987 loss: 0.2746749222278595\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "epoch: 10 step: 988 loss: 0.09675291925668716\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 989 loss: 0.5365971326828003\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 990 loss: 0.5997208952903748\n",
      "class 0: acc 0.8438, precision 0.9091, recall 0.8696, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.8125, precision 0.2500, recall 0.2500, f1 0.2500\n",
      "epoch: 10 step: 991 loss: 0.5744835734367371\n",
      "class 0: acc 0.8125, precision 0.8696, recall 0.8696, f1 0.8696\n",
      "class 1: acc 0.7812, precision 0.6000, recall 0.3750, f1 0.4615\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 992 loss: 0.44676893949508667\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 10 step: 993 loss: 0.3580108880996704\n",
      "class 0: acc 0.9062, precision 0.9643, recall 0.9310, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "epoch: 10 step: 994 loss: 0.3042803406715393\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8846, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.6250, recall 1.0000, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 995 loss: 0.4404374659061432\n",
      "class 0: acc 0.8438, precision 0.9200, recall 0.8846, f1 0.9020\n",
      "class 1: acc 0.8125, precision 0.2500, recall 0.2500, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 10 step: 996 loss: 0.39929741621017456\n",
      "class 0: acc 0.9062, precision 0.9200, recall 0.9583, f1 0.9388\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 997 loss: 0.18921050429344177\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 998 loss: 0.25123828649520874\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 999 loss: 0.16775266826152802\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1000 loss: 0.22594155371189117\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 1001 loss: 0.41685739159584045\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 10 step: 1002 loss: 0.2797352969646454\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1003 loss: 0.1455720216035843\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1004 loss: 0.41236191987991333\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1005 loss: 0.4646322429180145\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1006 loss: 0.15733011066913605\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1007 loss: 0.29774877429008484\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1008 loss: 0.3369796872138977\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1009 loss: 0.2914811074733734\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 1010 loss: 0.47553637623786926\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1011 loss: 0.40897896885871887\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "epoch: 10 step: 1012 loss: 0.38661646842956543\n",
      "class 0: acc 0.8125, precision 0.8519, recall 0.9200, f1 0.8846\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "epoch: 10 step: 1013 loss: 0.19863666594028473\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 1014 loss: 0.28163740038871765\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1015 loss: 0.31414794921875\n",
      "class 0: acc 0.8750, precision 0.9130, recall 0.9130, f1 0.9130\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "epoch: 10 step: 1016 loss: 0.26922062039375305\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8929, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.5714, recall 1.0000, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1017 loss: 0.46216267347335815\n",
      "class 0: acc 0.8438, precision 0.9583, recall 0.8519, f1 0.9020\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "epoch: 10 step: 1018 loss: 0.43989497423171997\n",
      "class 0: acc 0.8125, precision 0.7857, recall 1.0000, f1 0.8800\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1019 loss: 0.2596436142921448\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1020 loss: 0.43568503856658936\n",
      "class 0: acc 0.7812, precision 0.8889, recall 0.8571, f1 0.8727\n",
      "class 1: acc 0.8750, precision 0.2500, recall 0.5000, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1021 loss: 0.3665337562561035\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 1022 loss: 0.2712685167789459\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1023 loss: 0.4511699676513672\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 10 step: 1024 loss: 0.5330110192298889\n",
      "class 0: acc 0.8125, precision 0.9091, recall 0.8333, f1 0.8696\n",
      "class 1: acc 0.7812, precision 0.5000, recall 0.2857, f1 0.3636\n",
      "class 2: acc 0.8438, precision 0.1667, recall 1.0000, f1 0.2857\n",
      "epoch: 10 step: 1025 loss: 0.6313329339027405\n",
      "class 0: acc 0.8125, precision 0.8621, recall 0.9259, f1 0.8929\n",
      "class 1: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1026 loss: 0.24755515158176422\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9259, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "epoch: 10 step: 1027 loss: 0.2836930453777313\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 1028 loss: 0.29897236824035645\n",
      "class 0: acc 0.9375, precision 0.9600, recall 0.9600, f1 0.9600\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 1029 loss: 0.3253523111343384\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1030 loss: 0.19150403141975403\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9259, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1031 loss: 0.37098389863967896\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.8750, precision 0.8000, recall 0.5714, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1032 loss: 0.3721136748790741\n",
      "class 0: acc 0.8125, precision 0.8800, recall 0.8800, f1 0.8800\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.8000, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1033 loss: 0.4099651277065277\n",
      "class 0: acc 0.8750, precision 0.9286, recall 0.9286, f1 0.9286\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 1034 loss: 0.2592034935951233\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1035 loss: 0.4350305497646332\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1036 loss: 0.8059347867965698\n",
      "class 0: acc 0.7812, precision 0.7586, recall 1.0000, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.3333, recall 0.2000, f1 0.2500\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1037 loss: 0.39411649107933044\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1038 loss: 0.260364294052124\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1039 loss: 0.3575708270072937\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1040 loss: 0.4523680508136749\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1041 loss: 0.1814981997013092\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1042 loss: 0.18948550522327423\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1043 loss: 0.2343185693025589\n",
      "class 0: acc 0.9062, precision 0.9355, recall 0.9667, f1 0.9508\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1044 loss: 0.27198582887649536\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1045 loss: 0.09564294666051865\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1046 loss: 0.12399619072675705\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1047 loss: 0.7203038930892944\n",
      "class 0: acc 0.7812, precision 0.7667, recall 1.0000, f1 0.8679\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1048 loss: 0.2533792555332184\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1049 loss: 0.15858633816242218\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1050 loss: 0.38366976380348206\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1051 loss: 0.3997940719127655\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1052 loss: 0.24930180609226227\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1053 loss: 0.28763139247894287\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1054 loss: 0.16560761630535126\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 1055 loss: 0.2908603549003601\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 10 step: 1056 loss: 0.2718846797943115\n",
      "class 0: acc 0.8750, precision 0.9333, recall 0.9333, f1 0.9333\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1057 loss: 0.2460293024778366\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1058 loss: 0.2630688548088074\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1059 loss: 0.43957990407943726\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1060 loss: 0.576260507106781\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1061 loss: 0.38696548342704773\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 10 step: 1062 loss: 0.3704274296760559\n",
      "class 0: acc 0.8750, precision 1.0000, recall 0.8519, f1 0.9200\n",
      "class 1: acc 0.9062, precision 0.4000, recall 1.0000, f1 0.5714\n",
      "class 2: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "epoch: 10 step: 1063 loss: 0.34190481901168823\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1064 loss: 0.3250986635684967\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1065 loss: 0.1836404800415039\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 1066 loss: 0.1657106578350067\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9615, f1 0.9804\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 1067 loss: 0.5818074345588684\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.7812, precision 0.6000, recall 0.3750, f1 0.4615\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1068 loss: 0.7070773243904114\n",
      "class 0: acc 0.8750, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 1069 loss: 0.4162727892398834\n",
      "class 0: acc 0.8125, precision 0.8800, recall 0.8800, f1 0.8800\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1070 loss: 0.1971573531627655\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1071 loss: 0.29001155495643616\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1072 loss: 0.44146615266799927\n",
      "class 0: acc 0.7812, precision 0.8571, recall 0.8889, f1 0.8727\n",
      "class 1: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1073 loss: 0.13723644614219666\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9655, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 1074 loss: 0.42798659205436707\n",
      "class 0: acc 0.8125, precision 0.8846, recall 0.8846, f1 0.8846\n",
      "class 1: acc 0.7812, precision 0.2000, recall 0.2500, f1 0.2222\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 1075 loss: 0.4853772819042206\n",
      "class 0: acc 0.8125, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 10 step: 1076 loss: 0.2622305154800415\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9259, f1 0.9615\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 1077 loss: 0.2848576307296753\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1078 loss: 0.3233799338340759\n",
      "class 0: acc 0.9062, precision 0.9583, recall 0.9200, f1 0.9388\n",
      "class 1: acc 0.9062, precision 0.7143, recall 0.8333, f1 0.7692\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1079 loss: 0.6269055604934692\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.1667, f1 0.2500\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 10 step: 1080 loss: 0.8026571273803711\n",
      "class 0: acc 0.7812, precision 0.8333, recall 0.8696, f1 0.8511\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "epoch: 10 step: 1081 loss: 0.3675576448440552\n",
      "class 0: acc 0.8125, precision 0.7778, recall 1.0000, f1 0.8750\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1082 loss: 0.3642038404941559\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1083 loss: 0.2438402622938156\n",
      "class 0: acc 0.9062, precision 0.9032, recall 1.0000, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1084 loss: 0.2879214882850647\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1085 loss: 0.20453934371471405\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1086 loss: 0.45247265696525574\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1087 loss: 0.4587917923927307\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 10 step: 1088 loss: 0.4178692698478699\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1089 loss: 0.28310588002204895\n",
      "class 0: acc 0.9375, precision 1.0000, recall 0.9310, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1090 loss: 0.43813377618789673\n",
      "class 0: acc 0.8438, precision 0.8276, recall 1.0000, f1 0.9057\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.4286, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1091 loss: 0.4439299404621124\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1092 loss: 0.38922470808029175\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1093 loss: 0.2627050578594208\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1094 loss: 0.3939434289932251\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1095 loss: 0.34754815697669983\n",
      "class 0: acc 0.8438, precision 0.8462, recall 0.9565, f1 0.8980\n",
      "class 1: acc 0.8750, precision 0.8333, recall 0.6250, f1 0.7143\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1096 loss: 0.4110979437828064\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1097 loss: 0.642038106918335\n",
      "class 0: acc 0.7812, precision 0.8800, recall 0.8462, f1 0.8627\n",
      "class 1: acc 0.7812, precision 0.2857, recall 0.5000, f1 0.3636\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1098 loss: 0.3834870457649231\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1099 loss: 0.379340261220932\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.8438, precision 0.2500, recall 0.3333, f1 0.2857\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1100 loss: 0.20426703989505768\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 1101 loss: 0.3716788589954376\n",
      "class 0: acc 0.9062, precision 0.8929, recall 1.0000, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1102 loss: 0.46601927280426025\n",
      "class 0: acc 0.8438, precision 0.9565, recall 0.8462, f1 0.8980\n",
      "class 1: acc 0.7812, precision 0.2000, recall 0.2500, f1 0.2222\n",
      "class 2: acc 0.9375, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 1103 loss: 0.5340090990066528\n",
      "class 0: acc 0.8125, precision 0.8462, recall 0.9167, f1 0.8800\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1104 loss: 0.553050696849823\n",
      "class 0: acc 0.8125, precision 0.8148, recall 0.9565, f1 0.8800\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1105 loss: 0.2016502171754837\n",
      "class 0: acc 0.9375, precision 0.9643, recall 0.9643, f1 0.9643\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1106 loss: 0.3097328245639801\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 10 step: 1107 loss: 0.3768494427204132\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 1108 loss: 0.47074228525161743\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1109 loss: 0.4045349955558777\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1110 loss: 0.17351330816745758\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1111 loss: 0.4428515136241913\n",
      "class 0: acc 0.8125, precision 0.8077, recall 0.9545, f1 0.8750\n",
      "class 1: acc 0.8125, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1112 loss: 0.0990789607167244\n",
      "class 0: acc 0.9688, precision 0.9667, recall 1.0000, f1 0.9831\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1113 loss: 0.16608458757400513\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1114 loss: 0.5711253881454468\n",
      "class 0: acc 0.8125, precision 0.8214, recall 0.9583, f1 0.8846\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.4000, f1 0.4444\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1115 loss: 0.12006642669439316\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 1116 loss: 0.5007847547531128\n",
      "class 0: acc 0.8125, precision 0.7931, recall 1.0000, f1 0.8846\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1117 loss: 0.4801105260848999\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1118 loss: 0.45522159337997437\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1119 loss: 0.17861045897006989\n",
      "class 0: acc 0.9375, precision 0.9655, recall 0.9655, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1120 loss: 0.3813697397708893\n",
      "class 0: acc 0.8750, precision 0.9310, recall 0.9310, f1 0.9310\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1121 loss: 0.36057206988334656\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.6667, recall 0.4000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1122 loss: 0.30293551087379456\n",
      "class 0: acc 0.8750, precision 0.9032, recall 0.9655, f1 0.9333\n",
      "class 1: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1123 loss: 0.36357250809669495\n",
      "class 0: acc 0.9062, precision 1.0000, recall 0.8889, f1 0.9412\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.3333, recall 0.6667, f1 0.4444\n",
      "epoch: 10 step: 1124 loss: 0.4858095049858093\n",
      "class 0: acc 0.8438, precision 0.8750, recall 0.9130, f1 0.8936\n",
      "class 1: acc 0.8125, precision 0.6250, recall 0.6250, f1 0.6250\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1125 loss: 0.4723527729511261\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.3333, recall 0.5000, f1 0.4000\n",
      "epoch: 10 step: 1126 loss: 0.3728974461555481\n",
      "class 0: acc 0.8438, precision 0.9615, recall 0.8621, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1127 loss: 0.2970389723777771\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1128 loss: 0.1484173983335495\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1129 loss: 0.45544904470443726\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1130 loss: 0.2831331193447113\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1131 loss: 0.1572030782699585\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1132 loss: 0.13341116905212402\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1133 loss: 0.31752070784568787\n",
      "class 0: acc 0.9375, precision 0.9615, recall 0.9615, f1 0.9615\n",
      "class 1: acc 0.9688, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1134 loss: 0.35113030672073364\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1135 loss: 0.56847083568573\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.6667, f1 0.5714\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 10 step: 1136 loss: 0.6327238082885742\n",
      "class 0: acc 0.8125, precision 0.8333, recall 0.9615, f1 0.8929\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1137 loss: 0.20264023542404175\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9667, f1 0.9831\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1138 loss: 0.379734069108963\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1139 loss: 0.1620047390460968\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1140 loss: 0.3299763798713684\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1141 loss: 0.3718640208244324\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8333, f1 0.9091\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1142 loss: 0.3582066297531128\n",
      "class 0: acc 0.8438, precision 0.8846, recall 0.9200, f1 0.9020\n",
      "class 1: acc 0.8438, precision 0.6667, recall 0.5714, f1 0.6154\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1143 loss: 0.41599440574645996\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1144 loss: 0.5426554679870605\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1145 loss: 0.39690983295440674\n",
      "class 0: acc 0.8438, precision 0.8621, recall 0.9615, f1 0.9091\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1146 loss: 0.36092591285705566\n",
      "class 0: acc 0.9062, precision 0.9062, recall 1.0000, f1 0.9508\n",
      "class 1: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1147 loss: 0.5223395228385925\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1148 loss: 0.15546171367168427\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1149 loss: 0.32480883598327637\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.3333, recall 0.3333, f1 0.3333\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1150 loss: 0.4578758776187897\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1151 loss: 0.24675245583057404\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1152 loss: 0.20395322144031525\n",
      "class 0: acc 0.9375, precision 0.9231, recall 1.0000, f1 0.9600\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1153 loss: 0.27361011505126953\n",
      "class 0: acc 0.9688, precision 0.9677, recall 1.0000, f1 0.9836\n",
      "class 1: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1154 loss: 0.2562328279018402\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1155 loss: 0.1964961737394333\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1156 loss: 0.38294655084609985\n",
      "class 0: acc 0.9375, precision 0.9630, recall 0.9630, f1 0.9630\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1157 loss: 0.2099902629852295\n",
      "class 0: acc 0.8750, precision 0.8966, recall 0.9630, f1 0.9286\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1158 loss: 0.19470830261707306\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1159 loss: 0.4138757586479187\n",
      "class 0: acc 0.7812, precision 0.8148, recall 0.9167, f1 0.8627\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1160 loss: 0.4188949167728424\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1161 loss: 0.22149144113063812\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1162 loss: 0.43543943762779236\n",
      "class 0: acc 0.8750, precision 0.8929, recall 0.9615, f1 0.9259\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1163 loss: 0.5031485557556152\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1164 loss: 0.2932968735694885\n",
      "class 0: acc 0.8750, precision 0.8621, recall 1.0000, f1 0.9259\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1165 loss: 0.3476516902446747\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1166 loss: 0.5541514754295349\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1167 loss: 0.37440726161003113\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1168 loss: 0.2787030339241028\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 1169 loss: 0.17412202060222626\n",
      "class 0: acc 0.9375, precision 0.9259, recall 1.0000, f1 0.9615\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1170 loss: 0.2823963165283203\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1171 loss: 0.11075079441070557\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1172 loss: 0.1855171173810959\n",
      "class 0: acc 0.9062, precision 0.8966, recall 1.0000, f1 0.9455\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1173 loss: 0.3162979483604431\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1174 loss: 0.25208550691604614\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1175 loss: 0.12074825167655945\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1176 loss: 0.5075564384460449\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1177 loss: 0.2939096689224243\n",
      "class 0: acc 0.9062, precision 0.9630, recall 0.9286, f1 0.9455\n",
      "class 1: acc 0.9375, precision 0.6667, recall 0.6667, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.5000, recall 1.0000, f1 0.6667\n",
      "epoch: 10 step: 1178 loss: 0.34722331166267395\n",
      "class 0: acc 0.8750, precision 0.9200, recall 0.9200, f1 0.9200\n",
      "class 1: acc 0.8438, precision 0.4286, recall 0.7500, f1 0.5455\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1179 loss: 0.3447291851043701\n",
      "class 0: acc 0.9375, precision 0.9286, recall 1.0000, f1 0.9630\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1180 loss: 0.377934992313385\n",
      "class 0: acc 0.9062, precision 0.9600, recall 0.9231, f1 0.9412\n",
      "class 1: acc 0.8438, precision 0.4286, recall 0.7500, f1 0.5455\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1181 loss: 0.5413506627082825\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5714, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1182 loss: 0.3494335114955902\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1183 loss: 0.2999753952026367\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9062, precision 0.7500, recall 0.6000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1184 loss: 0.18938477337360382\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 0.6667, recall 1.0000, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1185 loss: 0.3921795189380646\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1186 loss: 0.35832011699676514\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1187 loss: 0.3192434310913086\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1188 loss: 0.4129641354084015\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.6000, recall 1.0000, f1 0.7500\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1189 loss: 0.4363778531551361\n",
      "class 0: acc 0.8125, precision 0.8889, recall 0.8889, f1 0.8889\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1190 loss: 0.12390631437301636\n",
      "class 0: acc 0.9375, precision 0.9355, recall 1.0000, f1 0.9667\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1191 loss: 0.4857989251613617\n",
      "class 0: acc 0.7500, precision 0.7500, recall 0.9545, f1 0.8400\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1192 loss: 0.2187395989894867\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8000, f1 0.8889\n",
      "class 2: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "epoch: 10 step: 1193 loss: 0.6007272005081177\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.8438, precision 0.5000, recall 0.2000, f1 0.2857\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1194 loss: 0.5498395562171936\n",
      "class 0: acc 0.8125, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 1: acc 0.8438, precision 1.0000, recall 0.2857, f1 0.4444\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1195 loss: 0.3296714425086975\n",
      "class 0: acc 0.8750, precision 0.8889, recall 0.9600, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1196 loss: 0.3524239659309387\n",
      "class 0: acc 0.8750, precision 0.9630, recall 0.8966, f1 0.9286\n",
      "class 1: acc 0.8750, precision 0.4000, recall 0.6667, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1197 loss: 0.46812254190444946\n",
      "class 0: acc 0.8750, precision 0.8846, recall 0.9583, f1 0.9200\n",
      "class 1: acc 0.8750, precision 0.7500, recall 0.5000, f1 0.6000\n",
      "class 2: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "epoch: 10 step: 1198 loss: 0.2479710876941681\n",
      "class 0: acc 0.9688, precision 0.9630, recall 1.0000, f1 0.9811\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1199 loss: 0.3172037601470947\n",
      "class 0: acc 0.8750, precision 0.8710, recall 1.0000, f1 0.9310\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1200 loss: 0.38222217559814453\n",
      "class 0: acc 0.8750, precision 0.8519, recall 1.0000, f1 0.9200\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1201 loss: 0.2798055112361908\n",
      "class 0: acc 0.8438, precision 0.8929, recall 0.9259, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1202 loss: 0.2543100416660309\n",
      "class 0: acc 0.8750, precision 0.9231, recall 0.9231, f1 0.9231\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1203 loss: 0.29110828042030334\n",
      "class 0: acc 0.9688, precision 0.9643, recall 1.0000, f1 0.9818\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1204 loss: 0.3349359333515167\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1205 loss: 0.3827331066131592\n",
      "class 0: acc 0.8750, precision 0.8571, recall 1.0000, f1 0.9231\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1206 loss: 0.505479633808136\n",
      "class 0: acc 0.7812, precision 0.7931, recall 0.9583, f1 0.8679\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 0.8750, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1207 loss: 0.3418150544166565\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1208 loss: 0.43854573369026184\n",
      "class 0: acc 0.8438, precision 0.9130, recall 0.8750, f1 0.8936\n",
      "class 1: acc 0.8438, precision 0.7143, recall 0.6250, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1209 loss: 0.5824555158615112\n",
      "class 0: acc 0.8438, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "epoch: 10 step: 1210 loss: 0.2708415985107422\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9062, precision 0.6667, recall 0.5000, f1 0.5714\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1211 loss: 0.2425309717655182\n",
      "class 0: acc 0.9375, precision 0.9667, recall 0.9667, f1 0.9667\n",
      "class 1: acc 0.9375, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1212 loss: 0.3849468529224396\n",
      "class 0: acc 0.9062, precision 0.9286, recall 0.9630, f1 0.9455\n",
      "class 1: acc 0.9688, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1213 loss: 0.35768893361091614\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1214 loss: 0.12490728497505188\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1215 loss: 0.1258479505777359\n",
      "class 0: acc 0.9688, precision 0.9655, recall 1.0000, f1 0.9825\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.7500, f1 0.8571\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1216 loss: 0.1002921387553215\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1217 loss: 0.7893251776695251\n",
      "class 0: acc 0.7812, precision 0.7500, recall 1.0000, f1 0.8571\n",
      "class 1: acc 0.8125, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1218 loss: 0.35208263993263245\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.4000, f1 0.5714\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1219 loss: 0.4706261157989502\n",
      "class 0: acc 0.8438, precision 0.8519, recall 0.9583, f1 0.9020\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1220 loss: 0.3086569309234619\n",
      "class 0: acc 0.8750, precision 0.8750, recall 1.0000, f1 0.9333\n",
      "class 1: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1221 loss: 0.4004463255405426\n",
      "class 0: acc 0.9375, precision 0.9167, recall 1.0000, f1 0.9565\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9062, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "epoch: 10 step: 1222 loss: 0.214695543050766\n",
      "class 0: acc 0.9375, precision 0.9310, recall 1.0000, f1 0.9643\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1223 loss: 0.3525579273700714\n",
      "class 0: acc 0.9062, precision 0.8889, recall 1.0000, f1 0.9412\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.7143, f1 0.8333\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1224 loss: 0.17163753509521484\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9630, f1 0.9811\n",
      "class 1: acc 0.9688, precision 0.8333, recall 1.0000, f1 0.9091\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1225 loss: 0.22202251851558685\n",
      "class 0: acc 0.9062, precision 0.9310, recall 0.9643, f1 0.9474\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1226 loss: 0.2801550328731537\n",
      "class 0: acc 0.9062, precision 0.9167, recall 0.9565, f1 0.9362\n",
      "class 1: acc 0.9375, precision 0.8571, recall 0.8571, f1 0.8571\n",
      "class 2: acc 0.9688, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "epoch: 10 step: 1227 loss: 0.1928965151309967\n",
      "class 0: acc 0.9688, precision 1.0000, recall 0.9565, f1 0.9778\n",
      "class 1: acc 0.9375, precision 0.8000, recall 1.0000, f1 0.8889\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1228 loss: 0.2602221667766571\n",
      "class 0: acc 0.9062, precision 0.9231, recall 0.9600, f1 0.9412\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "epoch: 10 step: 1229 loss: 0.3382498025894165\n",
      "class 0: acc 0.9062, precision 0.9333, recall 0.9655, f1 0.9492\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1230 loss: 0.2146257609128952\n",
      "class 0: acc 0.8750, precision 0.9630, recall 0.8966, f1 0.9286\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1231 loss: 0.24491193890571594\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1232 loss: 0.29558655619621277\n",
      "class 0: acc 0.8750, precision 0.9565, recall 0.8800, f1 0.9167\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.8750, precision 0.2000, recall 1.0000, f1 0.3333\n",
      "epoch: 10 step: 1233 loss: 0.383704274892807\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.5000, recall 0.5000, f1 0.5000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1234 loss: 0.32512998580932617\n",
      "class 0: acc 0.9062, precision 0.9000, recall 1.0000, f1 0.9474\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1235 loss: 0.3707360029220581\n",
      "class 0: acc 0.8750, precision 0.8667, recall 1.0000, f1 0.9286\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.3333, f1 0.5000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1236 loss: 0.4997345507144928\n",
      "class 0: acc 0.8125, precision 0.8065, recall 1.0000, f1 0.8929\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.2000, f1 0.3333\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1237 loss: 0.06681691855192184\n",
      "class 0: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 1: acc 1.0000, precision 1.0000, recall 1.0000, f1 1.0000\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1238 loss: 0.41844964027404785\n",
      "class 0: acc 0.8125, precision 0.7692, recall 1.0000, f1 0.8696\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.6667, f1 0.8000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1239 loss: 0.20809036493301392\n",
      "class 0: acc 0.9375, precision 0.9333, recall 1.0000, f1 0.9655\n",
      "class 1: acc 0.9375, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1240 loss: 0.26445767283439636\n",
      "class 0: acc 0.8750, precision 0.8462, recall 1.0000, f1 0.9167\n",
      "class 1: acc 0.9688, precision 1.0000, recall 0.8571, f1 0.9231\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1241 loss: 0.5800582766532898\n",
      "class 0: acc 0.8438, precision 0.8214, recall 1.0000, f1 0.9020\n",
      "class 1: acc 0.9375, precision 0.7500, recall 0.7500, f1 0.7500\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1242 loss: 0.6740007996559143\n",
      "class 0: acc 0.7188, precision 0.7097, recall 1.0000, f1 0.8302\n",
      "class 1: acc 0.9062, precision 1.0000, recall 0.2500, f1 0.4000\n",
      "class 2: acc 0.8125, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1243 loss: 0.6108475923538208\n",
      "class 0: acc 0.7188, precision 0.7500, recall 0.9130, f1 0.8235\n",
      "class 1: acc 0.8125, precision 0.5000, recall 0.3333, f1 0.4000\n",
      "class 2: acc 0.9062, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1244 loss: 0.36859962344169617\n",
      "class 0: acc 0.8438, precision 0.8889, recall 0.9231, f1 0.9057\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1245 loss: 0.635169506072998\n",
      "class 0: acc 0.7188, precision 0.6786, recall 1.0000, f1 0.8085\n",
      "class 1: acc 0.8750, precision 1.0000, recall 0.5000, f1 0.6667\n",
      "class 2: acc 0.8438, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1246 loss: 0.3763832151889801\n",
      "class 0: acc 0.8750, precision 0.9259, recall 0.9259, f1 0.9259\n",
      "class 1: acc 0.9062, precision 0.6000, recall 0.7500, f1 0.6667\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1247 loss: 0.34057241678237915\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.8750, precision 0.6000, recall 0.6000, f1 0.6000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1248 loss: 0.3069637715816498\n",
      "class 0: acc 0.9375, precision 0.9583, recall 0.9583, f1 0.9583\n",
      "class 1: acc 0.8750, precision 0.7143, recall 0.7143, f1 0.7143\n",
      "class 2: acc 0.9375, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1249 loss: 0.333314448595047\n",
      "class 0: acc 0.9062, precision 0.9259, recall 0.9615, f1 0.9434\n",
      "class 1: acc 0.9062, precision 0.8000, recall 0.6667, f1 0.7273\n",
      "class 2: acc 1.0000, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "epoch: 10 step: 1250 loss: 0.26037517189979553\n",
      "class 0: acc 0.9062, precision 0.9615, recall 0.9259, f1 0.9434\n",
      "class 1: acc 0.9375, precision 0.8000, recall 0.8000, f1 0.8000\n",
      "class 2: acc 0.9688, precision 0.0000, recall 0.0000, f1 0.0000\n",
      "==========================================================================================\n",
      "class 0: acc 0.8853, precision 0.9058, recall 0.9587, f1 0.9315\n",
      "class 1: acc 0.9123, precision 0.6948, recall 0.6458, f1 0.6694\n",
      "class 2: acc 0.9462, precision 0.3162, recall 0.0747, f1 0.1209\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.utils.data\n",
    "\n",
    "# Select the device (GPU if available, otherwise CPU)\n",
    "device = t.device('cuda:0' if t.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Constants related to data processing\n",
    "SENTENCE_LENGTH = 12  # Maximum sentence length (for padding/truncating sentences)\n",
    "WORD_SIZE = 35000     # Vocabulary size\n",
    "EMBED_SIZE = 768      # Word embedding size (BERT embeddings have 768 dimensions)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Preprocess data: sentences, labels, word vectors, and word to index mapping\n",
    "    sentences, label, word_vectors, word2index = process_data(SENTENCE_LENGTH, WORD_SIZE, EMBED_SIZE)\n",
    "    \n",
    "    # Split the data into training and testing sets (80% training, 20% testing)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(sentences, label, test_size=0.2)\n",
    "\n",
    "    # Create DataLoader for training and testing (batch size = 32)\n",
    "    train_data_loader = torch.utils.data.DataLoader(MyData(x_train, y_train), 32, True)\n",
    "    test_data_loader = torch.utils.data.DataLoader(MyData(x_test, y_test), 32, False)\n",
    "\n",
    "    # Initialize the model, optimizer, and loss function\n",
    "    net = SLCABG(EMBED_SIZE, SENTENCE_LENGTH, word_vectors).to(device)  # Initialize model\n",
    "    optimizer = t.optim.Adam(net.parameters(), 0.01)  # Adam optimizer with learning rate of 0.01\n",
    "    criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "\n",
    "    # Training loop (10 epochs)\n",
    "    for epoch in range(10):\n",
    "        for i, (cls, sentences) in enumerate(train_data_loader):\n",
    "            optimizer.zero_grad()  # Zero gradients for the optimizer\n",
    "            sentences = sentences.type(t.LongTensor).to(device)  # Convert sentences to long tensor and send to device\n",
    "            cls = cls.type(t.LongTensor).to(device)  # Convert labels to long tensor and send to device\n",
    "            out = net(sentences)  # Forward pass: get the output of the model\n",
    "            \n",
    "            # Get the predicted class (index with highest probability)\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            predict = predicted.cpu().numpy().tolist()  # Convert predicted class to list\n",
    "            pred = cls.cpu().numpy().tolist()  # Convert actual labels to list\n",
    "            \n",
    "            # Initialize counters for TP, FP, FN, TN for each class (0, 1, 2)\n",
    "            tp = [0, 0, 0]\n",
    "            fp = [0, 0, 0]\n",
    "            fn = [0, 0, 0]\n",
    "            tn = [0, 0, 0]\n",
    "            \n",
    "            # Loop through each prediction and actual label to calculate TP, FP, FN, TN\n",
    "            for f, n in zip(predict, pred):\n",
    "                for k in range(3):\n",
    "                    if f == k and n == k:\n",
    "                        tp[k] += 1\n",
    "                    elif f == k and n != k:\n",
    "                        fp[k] += 1\n",
    "                    elif f != k and n == k:\n",
    "                        fn[k] += 1\n",
    "                    elif f != k and n != k:\n",
    "                        tn[k] += 1\n",
    "\n",
    "            # Calculate precision, recall, F1 score, and accuracy for each class\n",
    "            precision = [tp[k] / (tp[k] + fp[k]) if (tp[k] + fp[k]) > 0 else 0 for k in range(3)]\n",
    "            recall = [tp[k] / (tp[k] + fn[k]) if (tp[k] + fn[k]) > 0 else 0 for k in range(3)]\n",
    "            f1 = [2 * precision[k] * recall[k] / (precision[k] + recall[k]) if (precision[k] + recall[k]) > 0 else 0 for k in range(3)]\n",
    "            acc = [(tp[k] + tn[k]) / (tp[k] + tn[k] + fp[k] + fn[k]) for k in range(3)]\n",
    "            \n",
    "            # Calculate loss and perform backpropagation\n",
    "            loss = criterion(out, cls).to(device)  # Calculate the loss\n",
    "            loss.backward()  # Backpropagation: compute gradients\n",
    "            optimizer.step()  # Update model weights\n",
    "\n",
    "            # Print loss and metrics for each step\n",
    "            if (i + 1) % 1 == 0:\n",
    "                print(f\"epoch: {epoch + 1} step: {i + 1} loss: {loss.item()}\")\n",
    "                for k in range(3):\n",
    "                    print(f'class {k}: acc {acc[k]:.4f}, precision {precision[k]:.4f}, recall {recall[k]:.4f}, f1 {f1[k]:.4f}')\n",
    "\n",
    "    # Set the model to evaluation mode after training\n",
    "    net.eval()\n",
    "    print('==========================================================================================')\n",
    "    \n",
    "    # Test the model performance on the test dataset\n",
    "    with torch.no_grad():  # Disable gradient computation during testing\n",
    "        tp = [0, 0, 0]\n",
    "        fp = [0, 0, 0]\n",
    "        fn = [0, 0, 0]\n",
    "        tn = [0, 0, 0]\n",
    "        \n",
    "        # Loop through the test data loader to calculate metrics\n",
    "        for cls, sentences in test_data_loader:\n",
    "            sentences = sentences.type(t.LongTensor).to(device)  # Send test data to device\n",
    "            cls = cls.type(t.LongTensor).to(device)  # Send actual labels to device\n",
    "            out = net(sentences)  # Get model predictions\n",
    "            _, predicted = torch.max(out.data, 1)  # Get predicted classes\n",
    "            predict = predicted.cpu().numpy().tolist()  # Convert to list\n",
    "            pred = cls.cpu().numpy().tolist()  # Convert to list\n",
    "            \n",
    "            # Calculate TP, FP, FN, TN for each class in the test set\n",
    "            for f, n in zip(predict, pred):\n",
    "                for k in range(3):\n",
    "                    if f == k and n == k:\n",
    "                        tp[k] += 1\n",
    "                    elif f == k and n != k:\n",
    "                        fp[k] += 1\n",
    "                    elif f != k and n == k:\n",
    "                        fn[k] += 1\n",
    "                    elif f != k and n != k:\n",
    "                        tn[k] += 1\n",
    "        \n",
    "        # Calculate precision, recall, F1 score, and accuracy for each class in the test set\n",
    "        precision = [tp[k] / (tp[k] + fp[k]) if (tp[k] + fp[k]) > 0 else 0 for k in range(3)]\n",
    "        recall = [tp[k] / (tp[k] + fn[k]) if (tp[k] + fn[k]) > 0 else 0 for k in range(3)]\n",
    "        f1 = [2 * precision[k] * recall[k] / (precision[k] + recall[k]) if (precision[k] + recall[k]) > 0 else 0 for k in range(3)]\n",
    "        acc = [(tp[k] + tn[k]) / (tp[k] + tn[k] + fp[k] + fn[k]) for k in range(3)]\n",
    "        \n",
    "        # Print evaluation metrics (accuracy, precision, recall, f1 score) for each class\n",
    "        for k in range(3):\n",
    "            print(f'class {k}: acc {acc[k]:.4f}, precision {precision[k]:.4f}, recall {recall[k]:.4f}, f1 {f1[k]:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9446\n"
     ]
    }
   ],
   "source": [
    "# get_sentiment_word function definition\n",
    "def get_sentiment_word():\n",
    "    # Open the file in read mode with UTF-8 encoding\n",
    "    with open('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/sentimen-analysis-based-on-sentiment-lexicon-and-deep-learning/data/sentiment_words.txt', 'r', encoding= 'utf-8') as f:\n",
    "        count = 0  # Initialize the count variable to track the number of words\n",
    "        for line in f:  # Iterate through each line in the file\n",
    "            count += 1  # Increment the count for each line\n",
    "        return count  # Return the total count of sentiment words\n",
    "\n",
    "# Print the result of calling get_sentiment_word function\n",
    "print(get_sentiment_word())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(net.state_dict(), 'D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/model/sentiment_analysis_fix.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get word2index\n",
    "def get_word2index():\n",
    "    word2index = process_data(12, 35000, 768)\n",
    "    return word2index[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define constants for sentence length, word size, and embedding size\n",
    "SENTENCE_LENGTH = 12\n",
    "WORD_SIZE = 35000\n",
    "EMBED_SIZE = 768\n",
    "\n",
    "# Set the device for running the model (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def predict_new_input(new_input):\n",
    "    # Preprocess data (sentence, labels, word vectors, word-to-index mapping)\n",
    "    sentences, label, word_vectors, word2index = process_data(SENTENCE_LENGTH, WORD_SIZE, EMBED_SIZE)\n",
    "    \n",
    "    # Initialize the model with word vectors\n",
    "    net = SLCABG(EMBED_SIZE, SENTENCE_LENGTH, word_vectors).to(device)\n",
    "    \n",
    "    # Load the trained model weights (ensure the path to the model is correct)\n",
    "    net.load_state_dict(torch.load('D:/Semester 4/Kecerdasan Buatan/Sentiment Analysis/model/sentiment_analysis.pth'))\n",
    "    net.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    # Perform prediction using the input sentence\n",
    "    with torch.no_grad():  # Disable gradient calculations for inference\n",
    "        # Preprocess the input text (case folding, cleansing, stop word removal, tokenization)\n",
    "        word2index = get_word2index()  # Get the word-to-index mapping\n",
    "        new_input = case_folding(new_input)  # Convert to lowercase\n",
    "        new_input = cleansing(new_input)  # Remove unnecessary characters\n",
    "        new_input = set_stop_words(new_input)  # Remove stop words\n",
    "        \n",
    "        # Tokenize the cleaned input sentence into words\n",
    "        new_input = new_input.split()\n",
    "        \n",
    "        # Convert each word into its corresponding index from the word2index dictionary\n",
    "        new_input = [word2index[word] for word in new_input]\n",
    "        \n",
    "        # Pad or truncate the input to match the fixed sentence length\n",
    "        if len(new_input) < SENTENCE_LENGTH:\n",
    "            new_input.extend([0 for _ in range(SENTENCE_LENGTH - len(new_input))])  # Pad with zeros\n",
    "        else:\n",
    "            new_input = new_input[:SENTENCE_LENGTH]  # Truncate if necessary\n",
    "        \n",
    "        # Convert the input list to a tensor and move it to the appropriate device (GPU/CPU)\n",
    "        new_input = torch.tensor(new_input).type(torch.LongTensor).to(device)\n",
    "        \n",
    "        # Add an extra batch dimension as the model expects input in batches\n",
    "        new_input = new_input.unsqueeze(0)\n",
    "        \n",
    "        # Pass the input through the model to get predictions\n",
    "        out = net(new_input)\n",
    "        \n",
    "        # Get the predicted class (sentiment)\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        \n",
    "        # Return the sentiment based on the predicted class\n",
    "        if predicted == 0:\n",
    "            return 'positive'\n",
    "        elif predicted == 1:\n",
    "            return 'negative'\n",
    "        else:\n",
    "            return 'neutral'\n",
    "\n",
    "# Example input for prediction\n",
    "new_input = 'very satisfied with this product. It exceeded my expectations and the quality is excellent'\n",
    "\n",
    "# Call the predict function and print the sentiment result\n",
    "print(predict_new_input(new_input))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
